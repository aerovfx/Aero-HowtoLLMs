## **1. T·∫°o b·ªô d·ªØ li·ªáu t·ª´ s√°ch (PDF, EPUB, DOCX)**
### **Ph∆∞∆°ng ph√°p 1: Tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ s√°ch s·ªë h√≥a**
N·∫øu s√°ch ·ªü ƒë·ªãnh d·∫°ng **PDF, EPUB, ho·∫∑c DOCX**, b·∫°n c√≥ th·ªÉ d√πng th∆∞ vi·ªán ƒë·ªÉ tr√≠ch xu·∫•t vƒÉn b·∫£n.

#### **Tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ PDF** (s·ª≠ d·ª•ng `pdfplumber`)
```python
import pdfplumber

def extract_text_from_pdf(pdf_path):
    text = ""
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            text += page.extract_text() + "\n"
    return text

text = extract_text_from_pdf("sample.pdf")
print(text[:500])  # Xem tr∆∞·ªõc 500 k√Ω t·ª± ƒë·∫ßu ti√™n
```

#### **Tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ EPUB** (s·ª≠ d·ª•ng `ebooklib`)
```python
from ebooklib import epub
from bs4 import BeautifulSoup

def extract_text_from_epub(epub_path):
    book = epub.read_epub(epub_path)
    text = ""
    for item in book.items:
        if item.get_type() == 9:  # Type 9 l√† XHTML content
            soup = BeautifulSoup(item.content, 'html.parser')
            text += soup.get_text() + "\n"
    return text

text = extract_text_from_epub("sample.epub")
print(text[:500])
```

### **Ph∆∞∆°ng ph√°p 2: OCR n·∫øu s√°ch ·ªü d·∫°ng ·∫£nh (Scan)**
N·∫øu s√°ch l√† ·∫£nh ho·∫∑c scan d·∫°ng PDF, b·∫°n c√≥ th·ªÉ d√πng **OCR (Nh·∫≠n di·ªán k√Ω t·ª± quang h·ªçc)**.

```python
import pytesseract
from PIL import Image

# ƒê·ªçc ·∫£nh v√† tr√≠ch xu·∫•t vƒÉn b·∫£n
image = Image.open("page1.png")
text = pytesseract.image_to_string(image, lang="eng")
print(text)
```
üöÄ **·ª®ng d·ª•ng:** Chuy·ªÉn s√°ch gi·∫•y th√†nh vƒÉn b·∫£n s·ªë ƒë·ªÉ l√†m dataset!

---

## **2. T·∫°o b·ªô d·ªØ li·ªáu t·ª´ video**
B·∫°n c√≥ th·ªÉ **tr√≠ch xu·∫•t ph·ª• ƒë·ªÅ ho·∫∑c t·∫°o transcript t·ª´ video**.

### **Ph∆∞∆°ng ph√°p 1: Tr√≠ch xu·∫•t ph·ª• ƒë·ªÅ t·ª´ YouTube (n·∫øu c√≥)**
```python
from youtube_transcript_api import YouTubeTranscriptApi

video_id = "dQw4w9WgXcQ"  # Thay b·∫±ng ID video c·ªßa b·∫°n
transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=["en"])

# Gh√©p n·ªôi dung th√†nh vƒÉn b·∫£n
text = "\n".join([t['text'] for t in transcript])
print(text[:500])
```

### **Ph∆∞∆°ng ph√°p 2: T·∫°o transcript t·ª´ video b·∫±ng Whisper**
N·∫øu video kh√¥ng c√≥ ph·ª• ƒë·ªÅ, b·∫°n c√≥ th·ªÉ d√πng m√¥ h√¨nh **Whisper** c·ªßa OpenAI ƒë·ªÉ nh·∫≠n di·ªán gi·ªçng n√≥i.

```python
import whisper

model = whisper.load_model("small")  # Ch·ªçn m√¥ h√¨nh t·ª´ 'tiny' ƒë·∫øn 'large'
result = model.transcribe("video.mp4")
print(result["text"])
```
üöÄ **·ª®ng d·ª•ng:** Chuy·ªÉn n·ªôi dung video th√†nh dataset ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh!

---

## **3. T·∫°o b·ªô d·ªØ li·ªáu t·ª´ √¢m thanh**
N·∫øu b·∫°n c√≥ **file ghi √¢m ho·∫∑c podcast**, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng m√¥ h√¨nh **ASR (Automatic Speech Recognition)** ƒë·ªÉ chuy·ªÉn th√†nh vƒÉn b·∫£n.

### **Ph∆∞∆°ng ph√°p 1: D√πng Whisper**
```python
import whisper

model = whisper.load_model("small")
result = model.transcribe("audio.mp3")
print(result["text"])
```

### **Ph∆∞∆°ng ph√°p 2: D√πng Google Speech-to-Text API**
```python
import speech_recognition as sr

recognizer = sr.Recognizer()
audio_file = "audio.wav"

with sr.AudioFile(audio_file) as source:
    audio = recognizer.record(source)

text = recognizer.recognize_google(audio, language="vi-VN")  # Nh·∫≠n di·ªán ti·∫øng Vi·ªát
print(text)
```
üöÄ **·ª®ng d·ª•ng:** Chuy·ªÉn podcast, b√†i gi·∫£ng th√†nh d·ªØ li·ªáu hu·∫•n luy·ªán!

---

## **4. Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu ƒë·ªÉ t·∫°o dataset**
Sau khi thu th·∫≠p vƒÉn b·∫£n t·ª´ s√°ch, video, ho·∫∑c √¢m thanh, b·∫°n c·∫ßn:
- **Lo·∫°i b·ªè d·∫•u c√¢u, k√Ω t·ª± kh√¥ng c·∫ßn thi·∫øt**
- **Chia nh·ªè th√†nh c√°c c√¢u h·ªèi - c√¢u tr·∫£ l·ªùi**
- **G√°n nh√£n d·ªØ li·ªáu (category, difficulty, source, etc.)**

V√≠ d·ª• t·∫°o dataset:
```python
import json

dataset = [
    {
        "question": "V·∫≠n t·ªëc √°nh s√°ng trong ch√¢n kh√¥ng l√† bao nhi√™u?",
        "answer": "V·∫≠n t·ªëc √°nh s√°ng trong ch√¢n kh√¥ng l√† 299,792,458 m/s.",
        "source": "S√°ch v·∫≠t l√Ω l·ªõp 12",
        "category": "physics",
        "difficulty": "easy"
    }
]

with open("dataset.json", "w", encoding="utf-8") as f:
    json.dump(dataset, f, ensure_ascii=False, indent=4)
```

---

## **5. ƒê∆∞a b·ªô d·ªØ li·ªáu l√™n Hugging Face**
Sau khi c√≥ dataset, b·∫°n c√≥ th·ªÉ t·∫£i l√™n Hugging Face:
```python
from huggingface_hub import HfApi

api = HfApi()
api.upload_file(
    path_or_fileobj="dataset.json",
    path_in_repo="dataset.json",
    repo_id="your-username/physics-dataset",
    repo_type="dataset"
)
```
üöÄ **·ª®ng d·ª•ng:** Chia s·∫ª b·ªô d·ªØ li·ªáu v·ªõi c·ªông ƒë·ªìng AI!

---

### **B·∫°n mu·ªën t√¥i gi√∫p code ph·∫ßn n√†o kh√¥ng?** üöÄ
