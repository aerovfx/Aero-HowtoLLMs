{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\n",
    "- ‚úÖ L·ªánh n√†y gi√∫p c√†i ƒë·∫∑t ho·∫∑c c·∫≠p nh·∫≠t th∆∞ vi·ªán openai v√† datasets trong m√¥i tr∆∞·ªùng l√†m vi·ªác.\n",
    "- ‚úÖ -qU gi√∫p qu√° tr√¨nh c√†i ƒë·∫∑t di·ªÖn ra nhanh g·ªçn m√† kh√¥ng hi·ªÉn th·ªã qu√° nhi·ªÅu th√¥ng tin.\n",
    "- ‚úÖ D√πng ƒë∆∞·ª£c tr√™n Google Colab, Jupyter Notebook ho·∫∑c m√¥i tr∆∞·ªùng terminal (b·ªè !).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# C√†i ƒë·∫∑t th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "! pip install -qU openai datasets  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\n",
    "- ‚úÖ getpass: D√πng ƒë·ªÉ nh·∫≠p th√¥ng tin nh·∫°y c·∫£m nh∆∞ API key m√† kh√¥ng hi·ªÉn th·ªã tr√™n m√†n h√¨nh.\n",
    "- ‚úÖ openai: Th∆∞ vi·ªán ƒë·ªÉ g·ªçi API GPT-3.5, GPT-4 t·ª´ OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass  # Th∆∞ vi·ªán gi√∫p nh·∫≠p m·∫≠t kh·∫©u ho·∫∑c API key m·ªôt c√°ch b·∫£o m·∫≠t\n",
    "from openai import OpenAI  # Th∆∞ vi·ªán OpenAI ƒë·ªÉ g·ªçi API GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # Th∆∞ vi·ªán cung c·∫•p c√°c ch·ª©c nƒÉng t∆∞∆°ng t√°c v·ªõi h·ªá ƒëi·ªÅu h√†nh\n",
    "\n",
    "# Nh·∫Øc ng∆∞·ªùi d√πng nh·∫≠p API key m·ªôt c√°ch b·∫£o m·∫≠t (kh√¥ng hi·ªÉn th·ªã khi nh·∫≠p)\n",
    "os.environ['OPENAI_API_KEY'] = getpass.getpass('L·∫•y API key nh·∫≠p v√†o ƒë√¢y: ')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3\n",
    "- ‚úÖ load_dataset(\"gaodrew/midjourney-prompts-highquality\", split=\"train\")\n",
    "\t‚Ä¢\tT·∫£i dataset t·ª´ Hugging Face (gaodrew/midjourney-prompts-highquality).\n",
    "\t‚Ä¢\tCh·ªâ l·∫•y ph·∫ßn d·ªØ li·ªáu train.\n",
    "\n",
    "- ‚úÖ dataset.select(range(1000))\n",
    "\t‚Ä¢\tCh·ªçn 1000 m·∫´u ƒë·∫ßu ti√™n t·ª´ t·∫≠p d·ªØ li·ªáu.\n",
    "\t‚Ä¢\tGi√∫p gi·∫£m dung l∆∞·ª£ng khi x·ª≠ l√Ω d·ªØ li·ªáu l·ªõn.\n",
    "\n",
    "- L·ª£i √≠ch:\n",
    "\n",
    "‚úîÔ∏è Nhanh h∆°n: Ch·ªâ l·∫•y 1000 m·∫´u thay v√¨ to√†n b·ªô dataset.\n",
    "‚úîÔ∏è D·ªÖ ki·ªÉm so√°t: Gi√∫p ki·ªÉm tra d·ªØ li·ªáu tr∆∞·ªõc khi x·ª≠ l√Ω to√†n b·ªô."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset  # Import h√†m load_dataset t·ª´ th∆∞ vi·ªán datasets (Hugging Face)\n",
    "\n",
    "# T·∫£i t·∫≠p d·ªØ li·ªáu \"midjourney-prompts-highquality\" t·ª´ Hugging Face\n",
    "# Tham s·ªë \"split='train'\" ch·ªâ t·∫£i ph·∫ßn d·ªØ li·ªáu hu·∫•n luy·ªán\n",
    "dataset = load_dataset(\"gaodrew/midjourney-prompts-highquality\", split=\"train\")\n",
    "\n",
    "# Ch·ªçn 1000 m·∫´u ƒë·∫ßu ti√™n t·ª´ t·∫≠p d·ªØ li·ªáu ƒë·ªÉ s·ª≠ d·ª•ng\n",
    "selected_dataset = dataset.select(range(1000))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4\n",
    "- üîπ Ch·ª©c nƒÉng c·ªßa code:\n",
    "-\t‚Ä¢\tTr√≠ch xu·∫•t n·ªôi dung ‚ÄúPrompt‚Äù t·ª´ t·∫≠p d·ªØ li·ªáu selected_dataset.\n",
    "-\t‚Ä¢\tL∆∞u danh s√°ch c√°c prompt v√†o prompt_pairs d∆∞·ªõi d·∫°ng danh s√°ch t·ª´ ƒëi·ªÉn.\n",
    "-\t‚Ä¢\tD√πng bi·ªÉu th·ª©c ch√≠nh quy (re) ƒë·ªÉ t√¨m c√°c ƒëo·∫°n vƒÉn b·∫£n b·∫Øt ƒë·∫ßu b·∫±ng \"Prompt: \" v√† k·∫øt th√∫c b·∫±ng d·∫•u xu·ªëng d√≤ng (\\n)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  # Th∆∞ vi·ªán h·ªó tr·ª£ x·ª≠ l√Ω chu·ªói b·∫±ng bi·ªÉu th·ª©c ch√≠nh quy (regex)\n",
    "\n",
    "# L·∫•y danh s√°ch n·ªôi dung t·ª´ c·ªôt 'content' trong dataset ƒë√£ ch·ªçn\n",
    "enhanced_prompts_raw = selected_dataset['content']\n",
    "\n",
    "# Danh s√°ch ch·ª©a c√°c prompt sau khi tr√≠ch xu·∫•t\n",
    "prompt_pairs = []\n",
    "\n",
    "def extract_prompts(content):\n",
    "    \"\"\"\n",
    "    H√†m tr√≠ch xu·∫•t n·ªôi dung sau t·ª´ \"Prompt: \" trong chu·ªói vƒÉn b·∫£n.\n",
    "    \n",
    "    Args:\n",
    "        content (str): Chu·ªói vƒÉn b·∫£n ƒë·∫ßu v√†o ch·ª©a prompt.\n",
    "    \n",
    "    Returns:\n",
    "        str: N·ªôi dung prompt ƒë∆∞·ª£c tr√≠ch xu·∫•t ho·∫∑c None n·∫øu kh√¥ng t√¨m th·∫•y.\n",
    "    \"\"\"\n",
    "    match = re.search(r\"\\*\\*(.*?)\\*\\*\", text)  # T√¨m ƒëo·∫°n vƒÉn b·∫£n sau \"Prompt: \" ƒë·∫øn k√Ω t·ª± xu·ªëng d√≤ng\n",
    "    \n",
    "    if match:\n",
    "        extracted_prompt = match.group(1)\n",
    "        return extracted_prompt  # L·∫•y n·ªôi dung t√¨m th·∫•y t·ª´ regex\n",
    "    return None  # Tr·∫£ v·ªÅ None n·∫øu kh√¥ng c√≥ prompt n√†o ƒë∆∞·ª£c t√¨m th·∫•y\n",
    "\n",
    "# L·∫∑p qua t·ª´ng ƒëo·∫°n vƒÉn b·∫£n trong t·∫≠p d·ªØ li·ªáu v√† tr√≠ch xu·∫•t prompt\n",
    "for text in enhanced_prompts_raw:\n",
    "    prompt_pairs.append({\n",
    "        \"enhanced_prompts\": extract_prompts(text)  # L∆∞u n·ªôi dung prompt v√†o danh s√°ch\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 5\n",
    "- üîπ Ch·ª©c nƒÉng c·ªßa ch∆∞∆°ng tr√¨nh:\n",
    "-\t‚Ä¢\tG·ªçi OpenAI API ƒë·ªÉ t·∫°o phi√™n b·∫£n ƒë∆°n gi·∫£n c·ªßa c√°c prompt ƒë√£ tr√≠ch xu·∫•t.\n",
    "-\t‚Ä¢\tT·ª± ƒë·ªông retry n·∫øu g·∫∑p l·ªói API (d√πng tenacity).\n",
    "-\t‚Ä¢\tHi·ªÉn th·ªã ti·∫øn tr√¨nh khi x·ª≠ l√Ω nhi·ªÅu prompt (d√πng tqdm).\n",
    "-\t‚Ä¢\tL∆∞u k·∫øt qu·∫£ v√†o file JSON ƒë·ªÉ s·ª≠ d·ª•ng sau n√†y.\n",
    "-\t‚Ä¢\t(T√πy ch·ªçn) T·∫£i file JSON v·ªÅ m√°y n·∫øu ch·∫°y tr√™n Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e6341bf3bc4125ab09a2135b39e917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o simple_prompts.json\n"
     ]
    }
   ],
   "source": [
    "# Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "import json  # X·ª≠ l√Ω d·ªØ li·ªáu JSON\n",
    "import time  # H·ªó tr·ª£ delay gi·ªØa c√°c request\n",
    "from openai import OpenAI  # G·ªçi API OpenAI\n",
    "from tqdm.auto import tqdm  # Hi·ªÉn th·ªã ti·∫øn tr√¨nh ch·∫°y\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential  # H·ªó tr·ª£ retry khi g·∫∑p l·ªói\n",
    "\n",
    "# Kh·ªüi t·∫°o OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# --------------------------------------\n",
    "# üîπ H√ÄM G·ªåI API OPENAI V·ªöI C∆† CH·∫æ RETRY\n",
    "# --------------------------------------\n",
    "@retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=2, min=5, max=60))\n",
    "def get_simple_prompt(enhanced_prompt):\n",
    "    \"\"\"\n",
    "    G·ªçi OpenAI API ƒë·ªÉ ƒë∆°n gi·∫£n h√≥a m·ªôt prompt ƒë√£ tr√≠ch xu·∫•t.\n",
    "\n",
    "    Args:\n",
    "        enhanced_prompt (str): Prompt c·∫ßn ƒë∆°n gi·∫£n h√≥a.\n",
    "\n",
    "    Returns:\n",
    "        str: Phi√™n b·∫£n ƒë∆°n gi·∫£n h√≥a c·ªßa prompt.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",  # S·ª≠ d·ª•ng model gpt-3.5-turbo\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a customer service representative helping a customer with a problem.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"ENHANCE PROMPT: {enhanced_prompt}; SIMPLE BASIC PROMPT: \"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# --------------------------------------\n",
    "# üîπ DANH S√ÅCH PROMPT ƒê·∫¶U V√ÄO\n",
    "# --------------------------------------\n",
    "prompt_pairs = [\n",
    "    {\"extracted_prompts\": \"How can I reset my password?\"},\n",
    "    {\"extracted_prompts\": \"What are your refund policies?\"},\n",
    "    {\"extracted_prompts\": \"How do I update my account details?\"},\n",
    "    {\"extracted_prompts\": \"Where can I find my order history?\"}\n",
    "]\n",
    "\n",
    "# --------------------------------------\n",
    "# üîπ X·ª¨ L√ù V√Ä G·ªåI API\n",
    "# --------------------------------------\n",
    "for prompt in tqdm(prompt_pairs):\n",
    "    try:\n",
    "        # G·ªçi API ƒë·ªÉ l·∫•y phi√™n b·∫£n ƒë∆°n gi·∫£n c·ªßa prompt\n",
    "        prompt['simple_prompt'] = get_simple_prompt(prompt['extracted_prompts'])\n",
    "        time.sleep(2)  # Ch·ªù 2 gi√¢y ƒë·ªÉ tr√°nh qu√° t·∫£i API\n",
    "    except Exception as e:\n",
    "        prompt['simple_prompt'] = f\"Error: {str(e)}\"  # L∆∞u l·ªói n·∫øu g·∫∑p v·∫•n ƒë·ªÅ\n",
    "\n",
    "# --------------------------------------\n",
    "# üîπ L∆ØU D·ªÆ LI·ªÜU V√ÄO FILE JSON\n",
    "# --------------------------------------\n",
    "output_file = \"simple_prompts.json\"\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(prompt_pairs, f, indent=4)  # L∆∞u file v·ªõi format ƒë·∫πp\n",
    "\n",
    "print(f\"‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o {output_file}\")\n",
    "\n",
    "# --------------------------------------\n",
    "# üîπ (T√ôY CH·ªåN) T·∫¢I FILE JSON V·ªÄ M√ÅY TR√äN GOOGLE COLAB\n",
    "# --------------------------------------\n",
    "# N·∫øu ch·∫°y tr√™n Google Colab, c√≥ th·ªÉ t·∫£i file xu·ªëng b·∫±ng ƒëo·∫°n code sau:\n",
    "# from google.colab import files\n",
    "# files.download(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 üìå M√¥ t·∫£ ch·ª©c nƒÉng c·ªßa ch∆∞∆°ng tr√¨nh\n",
    "\n",
    "- Ch∆∞∆°ng tr√¨nh n√†y gi√∫p qu·∫£n l√Ω d·ªØ li·ªáu hu·∫•n luy·ªán b·∫±ng c√°ch:\n",
    "-\t1.\tL∆∞u d·ªØ li·ªáu v√†o file JSON Lines (.jsonl) ‚Üí M·ªói d√≤ng l√† m·ªôt JSON object.\n",
    "-\t2.\tT·∫£i d·ªØ li·ªáu t·ª´ file .jsonl n·∫øu ƒë√£ c√≥ d·ªØ li·ªáu tr∆∞·ªõc ƒë√≥.\n",
    "-\t3.\tTh√™m d·ªØ li·ªáu m·ªõi v√†o file m√† kh√¥ng ghi ƒë√® to√†n b·ªô d·ªØ li·ªáu c≈©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "import json  # X·ª≠ l√Ω d·ªØ li·ªáu JSON\n",
    "from typing import List, Dict  # X√°c ƒë·ªãnh ki·ªÉu d·ªØ li·ªáu ƒë·∫ßu v√†o v√† ƒë·∫ßu ra cho c√°c h√†m\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a ƒë∆∞·ªùng d·∫´n file l∆∞u tr·ªØ d·ªØ li·ªáu\n",
    "FILE_PATH = \"training_data.jsonl\"\n",
    "\n",
    "# ------------------------------\n",
    "# üîπ H√ÄM L∆ØU D·ªÆ LI·ªÜU V√ÄO FILE JSONL\n",
    "# ------------------------------\n",
    "\n",
    "def save_training_data(data: List[Dict], output_file: str = FILE_PATH):\n",
    "    \"\"\"\n",
    "    Ghi d·ªØ li·ªáu v√†o file JSON Lines (.jsonl)\n",
    "    \n",
    "    Args:\n",
    "        data (List[Dict]): Danh s√°ch d·ªØ li·ªáu d·∫°ng dictionary c·∫ßn l∆∞u\n",
    "        output_file (str): ƒê∆∞·ªùng d·∫´n file l∆∞u tr·ªØ\n",
    "    \"\"\"\n",
    "    with open(output_file, 'a') as f:  # M·ªü file ·ªü ch·∫ø ƒë·ªô 'append' (th√™m v√†o cu·ªëi file)\n",
    "        for item in data:\n",
    "            f.write(json.dumps(item) + \"\\n\")  # Ghi t·ª´ng object JSON tr√™n 1 d√≤ng\n",
    "\n",
    "# ------------------------------\n",
    "# üîπ H√ÄM T·∫¢I D·ªÆ LI·ªÜU T·ª™ FILE JSONL\n",
    "# ------------------------------\n",
    "\n",
    "def load_training_data(file_path: str = FILE_PATH) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    ƒê·ªçc d·ªØ li·ªáu t·ª´ file JSONL n·∫øu file t·ªìn t·∫°i\n",
    "\n",
    "    Args:\n",
    "        file_path (str): ƒê∆∞·ªùng d·∫´n file JSONL\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: Danh s√°ch d·ªØ li·ªáu ƒë√£ ƒë·ªçc t·ª´ file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:  # M·ªü file ·ªü ch·∫ø ƒë·ªô ƒë·ªçc ('r')\n",
    "            return [json.loads(line) for line in f]  # ƒê·ªçc t·ª´ng d√≤ng, chuy·ªÉn th√†nh JSON object\n",
    "    except (FileNotFoundError, json.JSONDecodeError):  \n",
    "        return []  # N·∫øu file kh√¥ng t·ªìn t·∫°i ho·∫∑c c√≥ l·ªói ƒë·ªãnh d·∫°ng, tr·∫£ v·ªÅ danh s√°ch r·ªóng\n",
    "\n",
    "# ------------------------------\n",
    "# üîπ H√ÄM TH√äM D·ªÆ LI·ªÜU M·ªöI V√ÄO FILE\n",
    "# ------------------------------\n",
    "\n",
    "def add_training_data(new_data: List[Dict]):\n",
    "    \"\"\"\n",
    "    Th√™m d·ªØ li·ªáu m·ªõi v√†o file JSONL m√† kh√¥ng ghi ƒë√® d·ªØ li·ªáu c≈©\n",
    "\n",
    "    Args:\n",
    "        new_data (List[Dict]): Danh s√°ch d·ªØ li·ªáu m·ªõi c·∫ßn th√™m\n",
    "    \"\"\"\n",
    "    existing_data = load_training_data()  # ƒê·ªçc d·ªØ li·ªáu c≈©\n",
    "    existing_data.extend(new_data)  # Th√™m d·ªØ li·ªáu m·ªõi v√†o danh s√°ch\n",
    "    save_training_data(new_data)  # Ch·ªâ ghi d·ªØ li·ªáu m·ªõi, kh√¥ng ghi l·∫°i to√†n b·ªô file\n",
    "\n",
    "# ------------------------------\n",
    "# üîπ V√ç D·ª§ S·ª¨ D·ª§NG\n",
    "# ------------------------------\n",
    "\n",
    "prompt_pairs = [\n",
    "    {\"question\": \"How to reset my password?\", \"answer\": \"Go to settings and click reset password.\"},\n",
    "    {\"question\": \"What is the refund policy?\", \"answer\": \"You can request a refund within 30 days.\"}\n",
    "]\n",
    "\n",
    "# G·ªçi h√†m ƒë·ªÉ th√™m d·ªØ li·ªáu m·ªõi v√†o file\n",
    "add_training_data(prompt_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are a customer service representative helping a customer with a problem.'},\n",
       " {'role': 'user', 'content': 'Default simple prompt'},\n",
       " {'role': 'assistant', 'content': 'Default enhanced prompt'}]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data = prompt_pairs[0]  # L·∫•y ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n t·ª´ danh s√°ch prompt_pairs\n",
    "\n",
    "# Ki·ªÉm tra xem c√°c key c√≥ t·ªìn t·∫°i kh√¥ng tr∆∞·ªõc khi truy xu·∫•t\n",
    "simple_prompt = example_data.get(\"simple_prompt\", \"Default simple prompt\")  # D√πng `.get()` ƒë·ªÉ tr√°nh l·ªói KeyError\n",
    "enhanced_prompt = example_data.get(\"enhanced_prompt\", \"Default enhanced prompt\")\n",
    "\n",
    "# T·∫°o danh s√°ch tin nh·∫Øn\n",
    "message = [{\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a customer service representative helping a customer with a problem.\"\n",
    "          },{\n",
    "            \"role\": \"user\", \n",
    "            \"content\": simple_prompt  # S·ª≠a ƒë√∫ng key\n",
    "            },{\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": enhanced_prompt  # S·ª≠a ƒë√∫ng key\n",
    "            }]\n",
    "\n",
    "message  # Hi·ªÉn th·ªã k·∫øt qu·∫£"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
