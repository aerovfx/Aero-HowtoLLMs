# Lecture 9: Recap & Current Trends üîÆ

> **T√≥m t·∫Øt t·ª´ kh√≥a h·ªçc Stanford CME 295: Transformers & Large Language Models.**
> B√†i gi·∫£ng cu·ªëi c√πng: T·ªïng k·∫øt l·∫°i to√†n b·ªô h√†nh tr√¨nh v√† c√°i nh√¨n v·ªÅ t∆∞∆°ng lai c·ªßa LLM.

---

## üìö M·ª•c L·ª•c
1. [H√†nh tr√¨nh c·ªßa ch√∫ng ta](#1-h√†nh-tr√¨nh-c·ªßa-ch√∫ng-ta)
2. [C√°c xu h∆∞·ªõng hi·ªán t·∫°i (2025)](#2-c√°c-xu-h∆∞·ªõng-hi·ªán-t·∫°i-2025)
3. [Nh·ªØng th√°ch th·ª©c m·ªü (Open Problems)](#3-nh·ªØng-th√°ch-th·ª©c-m·ªü-open-problems)

---

## 1. H√†nh tr√¨nh c·ªßa ch√∫ng ta
Kh√≥a h·ªçc ƒë√£ ƒëi qua m·ªôt ch·∫∑ng ƒë∆∞·ªùng d√†i t·ª´ nh·ªØng kh√°i ni·ªám c∆° b·∫£n nh·∫•t ƒë·∫øn nh·ªØng k·ªπ thu·∫≠t t·ªëi t√¢n nh·∫•t:
1.  **Ki·∫øn tr√∫c:** Transformer, Attention, Encoder-Decoder.
2.  **Training:** Pre-training (Next token prediction), Scaling Laws, Parallelism.
3.  **Tuning:** SFT, RLHF, PEFT (LoRA).
4.  **Reasoning:** Chain-of-Thought, GRPO (DeepSeek-R1).
5.  **Agent:** RAG, Tool Use, ReAct.
6.  **Evaluation:** LLM-as-a-Judge, Benchmarks.

---

## 2. C√°c xu h∆∞·ªõng hi·ªán t·∫°i (2025)
Th·∫ø gi·ªõi AI ƒëang d·ªãch chuy·ªÉn r·∫•t nhanh:
*   **Reasoning Models (System 2):** S·ª± tr·ªói d·∫≠y c·ªßa c√°c m√¥ h√¨nh "bi·∫øt suy nghƒ©" (nh∆∞ o1, DeepSeek-R1) s·ª≠ d·ª•ng Inference-time compute ƒë·ªÉ gi·∫£i quy·∫øt c√°c b√†i to√°n kh√≥ m√† LLM truy·ªÅn th·ªëng b√≥ tay.
*   **Efficient Inference:** C√°c k·ªπ thu·∫≠t nh∆∞ Quantization (4-bit, 1-bit), Speculative Decoding, KV Cache optimization gi√∫p ch·∫°y LLM tr√™n thi·∫øt b·ªã c√° nh√¢n (Edge AI).
*   **Multimodal (ƒêa ph∆∞∆°ng th·ª©c):** LLM kh√¥ng ch·ªâ ƒë·ªçc text m√† c√≤n nh√¨n (Vision), nghe (Audio), n√≥i (Speech) m·ªôt c√°ch t·ª± nhi√™n (Native Multimodal nh∆∞ GPT-4o, Gemini 1.5).
*   **Agentic Systems:** T·ª´ Chatbot h·ªèi-ƒë√°p chuy·ªÉn sang Agent th·ª±c thi h√†nh ƒë·ªông, t·ª± ch·ªß ho√†n th√†nh c√¥ng vi·ªác ph·ª©c t·∫°p.

---

## 3. Nh·ªØng th√°ch th·ª©c m·ªü (Open Problems)
D√π ph√°t tri·ªÉn m·∫°nh, LLM v·∫´n c√≤n nhi·ªÅu v·∫•n ƒë·ªÅ ch∆∞a gi·∫£i quy·∫øt ƒë∆∞·ª£c:
*   **Reliability (ƒê·ªô tin c·∫≠y):** L√†m sao ƒë·ªÉ lo·∫°i b·ªè ho√†n to√†n Hallucination? L√†m sao ƒë·ªÉ tin t∆∞·ªüng v√†o code do AI vi·∫øt trong c√°c h·ªá th·ªëng quan tr·ªçng?
*   **Data Wall:** D·ªØ li·ªáu ch·∫•t l∆∞·ª£ng cao tr√™n Internet s·∫Øp c·∫°n ki·ªát. *Gi·∫£i ph√°p:* Synthetic Data (D·ªØ li·ªáu t·ªïng h·ª£p), Self-play.
*   **Energy Consumption:** Chi ph√≠ nƒÉng l∆∞·ª£ng cho Training v√† Inference qu√° l·ªõn. C·∫ßn c√°c ki·∫øn tr√∫c xanh h∆°n.
*   **Safety & Alignment:** ƒê·∫£m b·∫£o AI si√™u th√¥ng minh v·∫´n n·∫±m trong t·∫ßm ki·ªÉm so√°t v√† ph·ª•c v·ª• l·ª£i √≠ch con ng∆∞·ªùi.

---
*Bi√™n so·∫°n b·ªüi Pixiboss - D·ª±a tr√™n Stanford CME 295.*
