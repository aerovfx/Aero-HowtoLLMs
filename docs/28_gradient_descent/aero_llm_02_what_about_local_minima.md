
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../index.md) > [28 gradient descent](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../index.md)
- [ğŸ“š Module 01: LLM Course](../../01_llm_course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../02_words_to_tokens_to_numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../04_buildgpt/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../07_fine_tune_pretrained_models/index.md)
- [ğŸ” Module 19: AI Safety](../../19_ai_safety/index.md)
- [ğŸ Module 20: Python for AI](../../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Há»c sÃ¢u: Váº¥n Ä‘á» Cá»±c trá»‹ Äá»‹a phÆ°Æ¡ng (Local Minima)

## TÃ³m táº¯t (Abstract)
BÃ¡o cÃ¡o nÃ y nghiÃªn cá»©u vá» má»™t trong nhá»¯ng thÃ¡ch thá»©c kinh Ä‘iá»ƒn cá»§a thuáº­t toÃ¡n Háº¡ giang (Gradient Descent): hiá»‡n tÆ°á»£ng bá»‹ káº¹t táº¡i cÃ¡c cá»±c trá»‹ Ä‘á»‹a phÆ°Æ¡ng (local minima). chÃºng ta phÃ¢n tÃ­ch sá»± khÃ¡c biá»‡t giá»¯a cá»±c tiá»ƒu toÃ n cá»¥c (global minimum) vÃ  cá»±c tiá»ƒu Ä‘á»‹a phÆ°Æ¡ng, giáº£i mÃ£ lÃ½ do táº¡i sao gradient descent cÃ³ xu hÆ°á»›ng há»™i tá»¥ vá» cÃ¡c thung lÅ©ng gáº§n nháº¥t thay vÃ¬ tÃ¬m kiáº¿m giáº£i phÃ¡p tá»‘i Æ°u nháº¥t. NghiÃªn cá»©u cÅ©ng tháº£o luáº­n vá» nghá»‹ch lÃ½ cá»§a khÃ´ng gian cao chiá»u trong há»c sÃ¢u, nÆ¡i cÃ¡c Ä‘iá»ƒm yÃªn ngá»±a (saddle points) vÃ  sá»‘ lÆ°á»£ng tham sá»‘ khá»•ng lá»“ cÃ³ thá»ƒ vÃ´ tÃ¬nh trá»Ÿ thÃ nh "lá»›p báº£o vá»‡" giÃºp mÃ´ hÃ¬nh trÃ¡nh khá»i cÃ¡c báº«y cá»±c trá»‹ Ä‘á»‹a phÆ°Æ¡ng thÆ°á»ng tháº¥y á»Ÿ khÃ´ng gian tháº¥p chiá»u.

---

## 1. Báº£n cháº¥t cá»§a Cá»±c trá»‹ Äá»‹a phÆ°Æ¡ng

Trong má»™t bá» máº·t lá»—i (loss landscape) phá»©c táº¡p:
- **Global Minimum:** LÃ  Ä‘iá»ƒm mÃ  táº¡i Ä‘Ã³ hÃ m máº¥t mÃ¡t Ä‘áº¡t giÃ¡ trá»‹ nhá» nháº¥t trÃªn toÃ n bá»™ khÃ´ng gian tham sá»‘. ÄÃ¢y lÃ  má»¥c tiÃªu cuá»‘i cÃ¹ng cá»§a quÃ¡ trÃ¬nh huáº¥n luyá»‡n.
- **Local Minima:** LÃ  nhá»¯ng thung lÅ©ng mÃ  táº¡i Ä‘Ã³ giÃ¡ trá»‹ hÃ m lá»—i tháº¥p hÆ¡n cÃ¡c vÃ¹ng lÃ¢n cáº­n nhÆ°ng cao hÆ¡n so vá»›i Global Minimum. 
- **CÆ¡ cháº¿ báº«y:** VÃ¬ Gradient Descent chá»‰ "nhÃ¬n" tháº¥y Ä‘á»™ dá»‘c cá»¥c bá»™, náº¿u mÃ´ hÃ¬nh báº¯t Ä‘áº§u táº¡i má»™t vá»‹ trÃ­ gáº§n má»™t Local Minimum, nÃ³ sáº½ bá»‹ hÃºt vÃ o Ä‘Ã³ vÃ  khÃ´ng thá»ƒ thoÃ¡t ra Ä‘Æ°á»£c do Ä‘áº¡o hÃ m á»Ÿ Ä‘Ã¡y thung lÅ©ng báº±ng 0.

---

## 2. Nghá»‹ch lÃ½ cá»§a KhÃ´ng gian Äa chiá»u

Má»™t khÃ¡m phÃ¡ thÃº vá»‹ trong nghiÃªn cá»©u há»c sÃ¢u hiá»‡n Ä‘áº¡i lÃ : váº¥n Ä‘á» cá»±c trá»‹ Ä‘á»‹a phÆ°Æ¡ng cÃ³ thá»ƒ khÃ´ng nghiÃªm trá»ng nhÆ° chÃºng ta tÆ°á»Ÿng tÆ°á»£ng khi sá»‘ lÆ°á»£ng chiá»u tÄƒng lÃªn.
- **Äiá»u kiá»‡n kháº¯t khe:** Äá»ƒ má»™t Ä‘iá»ƒm trá»Ÿ thÃ nh Local Minimum trong khÃ´ng gian 1.000.000 chiá»u, Ä‘áº¡o hÃ m cá»§a nÃ³ pháº£i báº±ng 0 vÃ  Ä‘á»™ cong pháº£i hÆ°á»›ng lÃªn trÃªn á»Ÿ **táº¥t cáº£** 1.000.000 hÆ°á»›ng Ä‘Ã³. 
- **Saddle Points (Äiá»ƒm yÃªn ngá»±a):** Thá»±c táº¿, háº§u háº¿t cÃ¡c Ä‘iá»ƒm tá»›i háº¡n trong khÃ´ng gian cao chiá»u lÃ  Ä‘iá»ƒm yÃªn ngá»±a â€“ nÆ¡i hÃ m sá»‘ Ä‘áº¡t cá»±c tiá»ƒu theo má»™t sá»‘ hÆ°á»›ng nhÆ°ng láº¡i Ä‘áº¡t cá»±c Ä‘áº¡i theo cÃ¡c hÆ°á»›ng khÃ¡c. Äiá»u nÃ y cho phÃ©p thuáº­t toÃ¡n "lÃ¡ch" qua vÃ  tiáº¿p tá»¥c Ä‘i xuá»‘ng thay vÃ¬ bá»‹ káº¹t láº¡i.
- **Káº¿t luáº­n:** Sá»‘ lÆ°á»£ng tham sá»‘ cÃ ng lá»›n (dimensionality cao), xÃ¡c suáº¥t tá»“n táº¡i má»™t Local Minimum thá»±c thá»¥ cÃ ng giáº£m Ä‘i má»™t cÃ¡ch Ä‘Ã¡ng ká»ƒ.

---

## 3. Táº¡i sao Deep Learning váº«n thÃ nh cÃ´ng?

Máº·c dÃ¹ cÃ³ nguy cÆ¡ bá»‹ káº¹t, Deep Learning váº«n Ä‘áº¡t Ä‘Æ°á»£c nhá»¯ng thÃ nh tá»±u rá»±c rá»¡ nhá» vÃ o cÃ¡c Ä‘áº·c thÃ¹ sau:
1. **Sá»± tá»“n táº¡i cá»§a nhiá»u giáº£i phÃ¡p tá»‘t:** CÃ³ thá»ƒ cÃ³ nhiá»u Local Minima khÃ¡c nhau nhÆ°ng cÃ³ hiá»‡u nÄƒng tÆ°Æ¡ng Ä‘Æ°Æ¡ng vÃ  Ä‘á»§ tá»‘t Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n thá»±c táº¿.
2. **Khá»Ÿi táº¡o ngáº«u nhiÃªn:** Viá»‡c huáº¥n luyá»‡n mÃ´ hÃ¬nh nhiá»u láº§n vá»›i cÃ¡c trá»ng sá»‘ khá»Ÿi táº¡o khÃ¡c nhau giÃºp chÃºng ta cÃ³ cÆ¡ há»™i báº¯t Ä‘áº§u á»Ÿ nhá»¯ng vÃ¹ng thung lÅ©ng sÃ¢u hÆ¡n.
3. **Äá»™ phá»©c táº¡p lÃ  má»™t lá»£i tháº¿:** Viá»‡c tÄƒng kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh (tÄƒng sá»‘ lÆ°á»£ng tham sá»‘) thá»±c cháº¥t giÃºp lÃ m "pháº³ng" bá» máº·t lá»—i vÃ  giáº£m bá»›t cÃ¡c báº«y cá»±c trá»‹ Ä‘á»‹a phÆ°Æ¡ng.

---

## 4. Giáº£i phÃ¡p ká»¹ thuáº­t Ä‘á»‘i phÃ³ vá»›i Local Minima

Náº¿u nghi ngá» mÃ´ hÃ¬nh Ä‘ang bá»‹ káº¹t á»Ÿ má»™t nghiá»‡m kÃ©m cháº¥t lÆ°á»£ng, cÃ¡c nhÃ  nghiÃªn cá»©u thÆ°á»ng Ã¡p dá»¥ng:
- **Multiple Restarts:** Huáº¥n luyá»‡n láº¡i mÃ´ hÃ¬nh nhiá»u láº§n vÃ  chá»n káº¿t quáº£ tá»‘t nháº¥t.
- **Momentum (QuÃ¡n tÃ­nh):** Bá»• sung yáº¿u tá»‘ quÃ¡n tÃ­nh vÃ o bÆ°á»›c cáº­p nháº­t giÃºp mÃ´ hÃ¬nh cÃ³ kháº£ nÄƒng "vÆ°á»£t dá»‘c" Ä‘á»ƒ thoÃ¡t khá»i cÃ¡c thung lÅ©ng nÃ´ng.
- **Lá»±a chá»n kiáº¿n trÃºc:** Sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh cÃ³ Ä‘á»™ rá»™ng vÃ  Ä‘á»™ sÃ¢u lá»›n Ä‘á»ƒ táº­n dá»¥ng Æ°u tháº¿ cá»§a khÃ´ng gian cao chiá»u.

---

## 5. Káº¿t luáº­n
Cá»±c trá»‹ Ä‘á»‹a phÆ°Æ¡ng lÃ  má»™t khÃ¡i niá»‡m toÃ¡n há»c Ä‘Ã¡ng sá»£ nhÆ°ng trong tháº¿ giá»›i cá»§a há»c sÃ¢u hiá»‡n Ä‘áº¡i, nÃ³ dÆ°á»ng nhÆ° khÃ´ng cÃ²n lÃ  "káº» há»§y diá»‡t" mÃ´ hÃ¬nh. Sá»± tÆ°Æ¡ng tÃ¡c giá»¯a giáº£i tÃ­ch cao chiá»u vÃ  cÃ¡c ká»¹ thuáº­t khá»Ÿi táº¡o thÃ´ng minh Ä‘Ã£ biáº¿n nhá»¯ng cáº¡m báº«y nÃ y thÃ nh nhá»¯ng thá»­ thÃ¡ch cÃ³ thá»ƒ vÆ°á»£t qua. Tháº¥u hiá»ƒu báº£n cháº¥t cá»§a Saddle Points vÃ  vai trÃ² cá»§a dimensionality giÃºp cÃ¡c ká»¹ sÆ° AI tá»± tin hÆ¡n trong viá»‡c xÃ¢y dá»±ng nhá»¯ng mÃ´ hÃ¬nh LLM vá»›i hÃ ng tá»· tham sá»‘, nÆ¡i mÃ  sá»± phá»©c táº¡p chÃ­nh lÃ  chÃ¬a khÃ³a Ä‘á»ƒ tÃ¬m ra nhá»¯ng giáº£i phÃ¡p tá»‘i Æ°u.

---

## TÃ i liá»‡u tham kháº£o (Citations)
1. PhÃ¢n tÃ­ch báº«y cá»±c trá»‹ Ä‘á»‹a phÆ°Æ¡ng vÃ  vai trÃ² cá»§a Ä‘iá»ƒm yÃªn ngá»±a dá»±a trÃªn `aero_LL_02_What about local minima.md`. Thuyáº¿t minh vá» dimensionality trong khÃ´ng gian tham sá»‘ tá»· Ä‘Æ¡n vá»‹ vÃ  cÃ¡c chiáº¿n lÆ°á»£c thoÃ¡t khá»i cá»±c trá»‹ Ä‘á»‹a phÆ°Æ¡ng.
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| [Há»c sÃ¢u: Tá»•ng quan vá» Thuáº­t toÃ¡n Háº¡ giang (Gradient Descent)](aero_llm_01_overview_of_gradient_descent.md) | [Xem bÃ i viáº¿t â†’](aero_llm_01_overview_of_gradient_descent.md) |
| ğŸ“Œ **[Há»c sÃ¢u: Váº¥n Ä‘á» Cá»±c trá»‹ Äá»‹a phÆ°Æ¡ng (Local Minima)](aero_llm_02_what_about_local_minima.md)** | [Xem bÃ i viáº¿t â†’](aero_llm_02_what_about_local_minima.md) |
| [Há»c sÃ¢u: Thá»±c thi Háº¡ giang trong KhÃ´ng gian 1 Chiá»u (1D Gradient Descent)](aero_llm_03_gradient_descent_in_1d.md) | [Xem bÃ i viáº¿t â†’](aero_llm_03_gradient_descent_in_1d.md) |
| [Há»c sÃ¢u: Háº¡ giang trong KhÃ´ng gian 2 Chiá»u (2D Gradient Descent)](aero_llm_04_gradient_descent_in_2d.md) | [Xem bÃ i viáº¿t â†’](aero_llm_04_gradient_descent_in_2d.md) |
| [Há»c sÃ¢u: Thá»­ thÃ¡ch Láº­p trÃ¬nh â€“ Tá»‘c Ä‘á»™ há»c Cá»‘ Ä‘á»‹nh vs. Äá»™ng (Fixed vs. Dynamic Learning Rate)](aero_llm_05_codechallenge_fixed_vs_dynamic_learning_rate.md) | [Xem bÃ i viáº¿t â†’](aero_llm_05_codechallenge_fixed_vs_dynamic_learning_rate.md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
