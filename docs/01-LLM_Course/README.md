# ü§ñ Kh√≥a h·ªçc: Transformers & Large Language Models

> **D·ª±a tr√™n gi√°o tr√¨nh Stanford CME 295**
> *Bi√™n so·∫°n b·ªüi Pixiboss*

Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi b·ªô t√†i li·ªáu h∆∞·ªõng d·∫´n chuy√™n s√¢u v·ªÅ LLM. T√†i li·ªáu n√†y ƒëi t·ª´ nh·ªØng kh√°i ni·ªám n·ªÅn t·∫£ng v·ªÅ ki·∫øn tr√∫c Transformer cho ƒë·∫øn c√°c k·ªπ thu·∫≠t hu·∫•n luy·ªán, tinh ch·ªânh v√† x√¢y d·ª±ng ·ª©ng d·ª•ng Agent hi·ªán ƒë·∫°i nh·∫•t.

## üìö M·ª•c L·ª•c

### Ph·∫ßn 1: N·ªÅn T·∫£ng Ki·∫øn Tr√∫c (Foundations)
*   [**B√†i 00: T·ªïng quan v·ªÅ LLM**](aero_LLM_00_Overview.md) - B·ª©c tranh to√†n c·∫£nh v·ªÅ LLM v√† l·ªãch s·ª≠ ph√°t tri·ªÉn.
*   [**B√†i 01: Transformer Architecture**](aero_LLM_01_Transformer.md) - Tr√°i tim c·ªßa m·ªçi m√¥ h√¨nh ng√¥n ng·ªØ hi·ªán ƒë·∫°i. Gi·∫£i m√£ c∆° ch·∫ø Self-Attention.
*   [**B√†i 02: Transformer Tricks & Optimizations**](aero_LLM_02_Transformer_Tricks.md) - C√°c k·ªπ thu·∫≠t t·ªëi ∆∞u h√≥a gi√∫p Transformer ho·∫°t ƒë·ªông ·ªïn ƒë·ªãnh v√† hi·ªáu qu·∫£ h∆°n (Norm, Residual, Positional Encoding).
*   [**B√†i 03: Gi·∫£i m√£ c√°c m√¥ h√¨nh LLM (BERT, GPT, T5)**](aero_LLM_03_Large_Language_Models.md) - Ph√¢n lo·∫°i c√°c ki·∫øn tr√∫c LLM ph·ªï bi·∫øn: Encoder-only, Decoder-only v√† Encoder-Decoder.

### Ph·∫ßn 2: X√¢y D·ª±ng & Tinh Ch·ªânh (Building & Tuning)
*   [**B√†i 04: Training & Pre-training**](aero_LLM_04_Training_Pretraining.md) - Quy tr√¨nh hu·∫•n luy·ªán m√¥ h√¨nh t·ª´ con s·ªë 0. Scaling Laws v√† d·ªØ li·ªáu.
*   [**B√†i 05: Fine-tuning & PEFT**](aero_LLM_05_Tuning_PEFT.md) - Tinh ch·ªânh m√¥ h√¨nh hi·ªáu qu·∫£ v·ªõi chi ph√≠ th·∫•p b·∫±ng LoRA, QLoRA, Prompt Tuning.

> **üí° G√≥c ki·∫øn th·ª©c b·ªï tr·ª£:** ƒê·ªÉ hi·ªÉu s√¢u v·ªÅ **RLHF** (Reinforcement Learning from Human Feedback) trong b√†i 5, b·∫°n n√™n n·∫Øm v·ªØng c√°c kh√°i ni·ªám c∆° b·∫£n v·ªÅ RL:
> *   [**Reinforcement Learning Basics**](Reinforcement_Learning_Basics/README.md) (Bellman Equation, MDP, Policy vs Plan).

### Ph·∫ßn 3: Kh·∫£ NƒÉng N√¢ng Cao (Advanced Capabilities)
*   [**B√†i 06: Reasoning & Prompt Engineering**](aero_LLM_06_Reasoning.md) - K√≠ch ho·∫°t kh·∫£ nƒÉng suy lu·∫≠n c·ªßa m√¥ h√¨nh (Chain-of-Thought, Tree-of-Thought).
*   [**B√†i 07: Agentic LLMs & Tool Use**](aero_LLM_07_Agentic_LLMs.md) - Bi·∫øn LLM th√†nh t√°c nh√¢n t·ª± ch·ªß (Agent) bi·∫øt s·ª≠ d·ª•ng c√¥ng c·ª• v√† RAG.

### Ph·∫ßn 4: ƒê√°nh Gi√° & C√¥ng C·ª• (Evaluation & Tools)
*   [**B√†i 08: Evaluation**](aero_LLM_08_Evaluation.md) - L√†m sao ƒë·ªÉ ƒëo l∆∞·ªùng ƒë·ªô th√¥ng minh c·ªßa AI? (Benchmarks, LLM-as-a-Judge).
*   [**B√†i 09: Recap & Trends**](aero_LLM_09_Trends.md) - T·ªïng k·∫øt v√† nh√¨n v·ªÅ t∆∞∆°ng lai (Multimodal, Efficient AI).
*   [**B√†i 10: Essential Tools for AI Engineers**](aero_LLM_10_Essential_Tools.md) üÜï - Top 12 Repo quan tr·ªçng ƒë·ªÉ t·ªëi ∆∞u, ch·∫°y v√† tinh ch·ªânh LLM (vLLM, llama.cpp, Unsloth...).

---
*T√†i li·ªáu ƒë∆∞·ª£c l∆∞u tr·ªØ t·∫°i `docs/01-01-LLM_Course` c·ªßa repository Aero-HowtoLLMs.*
