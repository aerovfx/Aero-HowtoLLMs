# ðŸ“‚ Module: 01-LLM_Course
[![Status: Active](https://img.shields.io/badge/Status-Active-success.svg)]() [![Content: 100% Vietnamese](https://img.shields.io/badge/Content-Vietnamese-red.svg)]()

[Home](../README.md) > **01-LLM_Course**

---
### ðŸ§­ Quick Navigation

- [ðŸ  Cá»•ng tÃ i liá»‡u](../README.md)
- [ðŸ“š Module 01: LLM Course](../01-LLM_Course/index.md)
- [ðŸ”¢ Module 02: Tokenization](../02-Words-to-tokens-to-numbers/index.md)
- [ðŸ—ï¸ Module 04: Build GPT](../04-buildGPT/index.md)
- [ðŸŽ¯ Module 07: Fine-tuning](../07-Fine-tune-pretrained-models/index.md)
- [ðŸ” Module 19: AI Safety](../19-AI-safety/index.md)
---

> **Dá»±a trÃªn giÃ¡o trÃ¬nh Stanford CME 295**
> *BiÃªn soáº¡n bá»Ÿi Pixiboss*

ChÃ o má»«ng báº¡n Ä‘áº¿n vá»›i bá»™ tÃ i liá»‡u hÆ°á»›ng dáº«n chuyÃªn sÃ¢u vá» LLM. TÃ i liá»‡u nÃ y Ä‘i tá»« nhá»¯ng khÃ¡i niá»‡m ná»n táº£ng vá» kiáº¿n trÃºc Transformer cho Ä‘áº¿n cÃ¡c ká»¹ thuáº­t huáº¥n luyá»‡n, tinh chá»‰nh vÃ  xÃ¢y dá»±ng á»©ng dá»¥ng Agent hiá»‡n Ä‘áº¡i nháº¥t.

## ðŸ“š Má»¥c Lá»¥c

### Pháº§n 1: Ná»n Táº£ng Kiáº¿n TrÃºc (Foundations)
*   [**BÃ i 00: Tá»•ng quan vá» LLM**](aero_LLM_00_Overview.md) - Bá»©c tranh toÃ n cáº£nh vá» LLM vÃ  lá»‹ch sá»­ phÃ¡t triá»ƒn.
*   [**BÃ i 01: Transformer Architecture**](aero_LLM_01_Transformer.md) - TrÃ¡i tim cá»§a má»i mÃ´ hÃ¬nh ngÃ´n ngá»¯ hiá»‡n Ä‘áº¡i. Giáº£i mÃ£ cÆ¡ cháº¿ Self-Attention.
*   [**BÃ i 02: Transformer Tricks & Optimizations**](aero_LLM_02_Transformer_Tricks.md) - CÃ¡c ká»¹ thuáº­t tá»‘i Æ°u hÃ³a giÃºp Transformer hoáº¡t Ä‘á»™ng á»•n Ä‘á»‹nh vÃ  hiá»‡u quáº£ hÆ¡n (Norm, Residual, Positional Encoding).
*   [**BÃ i 03: Giáº£i mÃ£ cÃ¡c mÃ´ hÃ¬nh LLM (BERT, GPT, T5)**](aero_LLM_03_Large_Language_Models.md) - PhÃ¢n loáº¡i cÃ¡c kiáº¿n trÃºc LLM phá»• biáº¿n: Encoder-only, Decoder-only vÃ  Encoder-Decoder.

### Pháº§n 2: XÃ¢y Dá»±ng & Tinh Chá»‰nh (Building & Tuning)
*   [**BÃ i 04: Training & Pre-training**](aero_LLM_04_Training_Pretraining.md) - Quy trÃ¬nh huáº¥n luyá»‡n mÃ´ hÃ¬nh tá»« con sá»‘ 0. Scaling Laws vÃ  dá»¯ liá»‡u.
*   [**BÃ i 05: Fine-tuning & PEFT**](aero_LLM_05_Tuning_PEFT.md) - Tinh chá»‰nh mÃ´ hÃ¬nh hiá»‡u quáº£ vá»›i chi phÃ­ tháº¥p báº±ng LoRA, QLoRA, Prompt Tuning.

> **ðŸ’¡ GÃ³c kiáº¿n thá»©c bá»• trá»£:** Äá»ƒ hiá»ƒu sÃ¢u vá» **RLHF** (Reinforcement Learning from Human Feedback) trong bÃ i 5, báº¡n nÃªn náº¯m vá»¯ng cÃ¡c khÃ¡i niá»‡m cÆ¡ báº£n vá» RL:
> *   [**Reinforcement Learning Basics**](Reinforcement_Learning_Basics/README.md) (Bellman Equation, MDP, Policy vs Plan).

### Pháº§n 3: Kháº£ NÄƒng NÃ¢ng Cao (Advanced Capabilities)
*   [**BÃ i 06: Reasoning & Prompt Engineering**](aero_LLM_06_Reasoning.md) - KÃ­ch hoáº¡t kháº£ nÄƒng suy luáº­n cá»§a mÃ´ hÃ¬nh (Chain-of-Thought, Tree-of-Thought).
*   [**BÃ i 07: Agentic LLMs & Tool Use**](aero_LLM_07_Agentic_LLMs.md) - Biáº¿n LLM thÃ nh tÃ¡c nhÃ¢n tá»± chá»§ (Agent) biáº¿t sá»­ dá»¥ng cÃ´ng cá»¥ vÃ  RAG.

### Pháº§n 4: ÄÃ¡nh GiÃ¡ & CÃ´ng Cá»¥ (Evaluation & Tools)
*   [**BÃ i 08: Evaluation**](aero_LLM_08_Evaluation.md) - LÃ m sao Ä‘á»ƒ Ä‘o lÆ°á»ng Ä‘á»™ thÃ´ng minh cá»§a AI? (Benchmarks, LLM-as-a-Judge).
*   [**BÃ i 09: Recap & Trends**](aero_LLM_09_Trends.md) - Tá»•ng káº¿t vÃ  nhÃ¬n vá» tÆ°Æ¡ng lai (Multimodal, Efficient AI).
*   [**BÃ i 10: Essential Tools for AI Engineers**](aero_LLM_10_Essential_Tools.md) ðŸ†• - Top 12 Repo quan trá»ng Ä‘á»ƒ tá»‘i Æ°u, cháº¡y vÃ  tinh chá»‰nh LLM (vLLM, llama.cpp, Unsloth...).

---
*TÃ i liá»‡u Ä‘Æ°á»£c lÆ°u trá»¯ táº¡i `docs/01-01-LLM_Course` cá»§a repository Aero-HowtoLLMs.*

---
## ðŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ðŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*