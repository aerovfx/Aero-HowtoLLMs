
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../../index.md) > [01 LLM Course](../../index.md) > [LectureStanford](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../../index.md)
- [ğŸ“š Module 01: LLM Course](../../../01-LLM_Course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../../02-Words-to-tokens-to-numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../../04-buildGPT/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../../07-Fine-tune-pretrained-models/index.md)
- [ğŸ” Module 19: AI Safety](../../../19-AI-safety/index.md)
- [ğŸ Module 20: Python for AI](../../../20-Python-Colab-notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# ğŸ› ï¸ Top 12 Repo Quan Trá»ng Cho AI Engineer Tá»‘i Æ¯u LLM

> **Danh sÃ¡ch cÃ¡c cÃ´ng cá»¥ "must-know" giÃºp tá»‘i Æ°u hÃ³a, triá»ƒn khai vÃ  tinh chá»‰nh LLM hiá»‡u quáº£.**
> *BiÃªn soáº¡n bá»Ÿi Pixiboss.*

---

## ğŸš€ 1. Inference & Serving (Triá»ƒn khai & Cháº¡y mÃ´ hÃ¬nh)

### [vLLM](https://github.com/vllm-project/vllm)
*   **Äáº·c Ä‘iá»ƒm:** ThÆ° viá»‡n cháº¡y inference LLM vá»›i tá»‘c Ä‘á»™ cá»±c cao vÃ  thÃ´ng lÆ°á»£ng (throughput) lá»›n.
*   **CÃ´ng nghá»‡:** Sá»­ dá»¥ng **PagedAttention** Ä‘á»ƒ quáº£n lÃ½ bá»™ nhá»› KV cache hiá»‡u quáº£.
*   **á»¨ng dá»¥ng:** PhÃ¹ há»£p nháº¥t Ä‘á»ƒ triá»ƒn khai há»‡ thá»‘ng production quy mÃ´ lá»›n, phá»¥c vá»¥ nhiá»u ngÆ°á»i dÃ¹ng cÃ¹ng lÃºc.

### [llama.cpp](https://github.com/ggerganov/llama.cpp)
*   **Äáº·c Ä‘iá»ƒm:** Cháº¡y LLM offline/local ngay trÃªn mÃ¡y tÃ­nh cÃ¡ nhÃ¢n (MacBook, PC thÆ°á»ng) mÃ  khÃ´ng cáº§n GPU quÃ¡ máº¡nh.
*   **CÃ´ng nghá»‡:** Tá»‘i Æ°u hÃ³a tÃ­nh toÃ¡n trÃªn CPU vÃ  Apple Silicon (Metal), sá»­ dá»¥ng Quantization (GGUF) Ä‘á»ƒ giáº£m nháº¹ mÃ´ hÃ¬nh.
*   **á»¨ng dá»¥ng:** Cháº¡y LLM trÃªn mÃ¡y cáº¥u hÃ¬nh yáº¿u, thiáº¿t bá»‹ cÃ¡ nhÃ¢n.

### [Ollama](https://github.com/ollama/ollama)
*   **Äáº·c Ä‘iá»ƒm:** CÃ¡ch Ä‘Æ¡n giáº£n nháº¥t Ä‘á»ƒ cháº¡y LLM local (nhÆ° Llama 3, Mistral) chá»‰ vá»›i má»™t cÃ¢u lá»‡nh (`ollama run llama3`).
*   **CÃ´ng nghá»‡:** Bao bá»c `llama.cpp` trong má»™t giao diá»‡n thÃ¢n thiá»‡n, dá»… sá»­ dá»¥ng.
*   **á»¨ng dá»¥ng:** Thá»­ nghiá»‡m nhanh mÃ´ hÃ¬nh, dev mÃ´i trÆ°á»ng local.

### [MLC LLM](https://github.com/mlc-ai/mlc-llm)
*   **Äáº·c Ä‘iá»ƒm:** Giáº£i phÃ¡p triá»ƒn khai LLM Ä‘a ná»n táº£ng (Universal Deployment).
*   **á»¨ng dá»¥ng:** Cháº¡y LLM trÃªn Mobile (iOS/Android), Web Browser (WebGPU), vÃ  cÃ¡c thiáº¿t bá»‹ Edge.

---

## ğŸ§  2. Framework & Core Libraries (Ná»n táº£ng cá»‘t lÃµi)

### [Hugging Face Transformers](https://github.com/huggingface/transformers)
*   **Äáº·c Ä‘iá»ƒm:** ThÆ° viá»‡n tiÃªu chuáº©n de-facto cá»§a cá»™ng Ä‘á»“ng AI. Cung cáº¥p hÃ ng ngÃ n mÃ´ hÃ¬nh pre-trained vÃ  pipeline sáºµn sÃ ng sá»­ dá»¥ng.
*   **á»¨ng dá»¥ng:** Táº£i model, fine-tune, vÃ  xÃ¢y dá»±ng cÃ¡c á»©ng dá»¥ng NLP hiá»‡n Ä‘áº¡i.

### [PyTorch](https://github.com/pytorch/pytorch)
*   **Äáº·c Ä‘iá»ƒm:** Framework Deep Learning phá»• biáº¿n nháº¥t tháº¿ giá»›i nghiÃªn cá»©u vÃ  sáº£n pháº©m AI hiá»‡n nay.
*   **á»¨ng dá»¥ng:** LÃ  ná»n mÃ³ng Ä‘á»ƒ xÃ¢y dá»±ng vÃ  huáº¥n luyá»‡n háº§u háº¿t cÃ¡c mÃ´ hÃ¬nh AI hiá»‡n Ä‘áº¡i.

---

## âš¡ 3. Training & Fine-tuning (Huáº¥n luyá»‡n & Tinh chá»‰nh)

### [Unsloth](https://github.com/unslothai/unsloth)
*   **Äáº·c Ä‘iá»ƒm:** ThÆ° viá»‡n Fine-tuning LLM (Llama-3, Mistral...) nhanh hÆ¡n 2x vÃ  tiáº¿t kiá»‡m bá»™ nhá»› VRAM hÆ¡n 60% so vá»›i cÃ¡ch thÃ´ng thÆ°á»ng.
*   **CÃ´ng nghá»‡:** Viáº¿t láº¡i cÃ¡c kernel tÃ­nh toÃ¡n Ä‘áº¡o hÃ m (backpropagation) thá»§ cÃ´ng.
*   **á»¨ng dá»¥ng:** Fine-tune model trÃªn GPU cÃ³ VRAM háº¡n cháº¿ (nhÆ° Colab miá»…n phÃ­).

### [FlashAttention](https://github.com/Dao-AILab/flash-attention)
*   **Äáº·c Ä‘iá»ƒm:** Thuáº­t toÃ¡n tÄƒng tá»‘c cÆ¡ cháº¿ Attention, giÃºp giáº£m bá»™ nhá»› VRAM vÃ  cháº¡y nhanh hÆ¡n.
*   **á»¨ng dá»¥ng:** ÄÆ°á»£c tÃ­ch há»£p sÃ¢u vÃ o PyTorch 2.0 vÃ  cÃ¡c thÆ° viá»‡n khÃ¡c Ä‘á»ƒ huáº¥n luyá»‡n model vá»›i context window cá»±c dÃ i.

---

## ğŸŒ 4. Distributed & System (Há»‡ thá»‘ng phÃ¢n tÃ¡n)

### [exo](https://github.com/exo-explore/exo)
*   **Äáº·c Ä‘iá»ƒm:** Biáº¿n cÃ¡c thiáº¿t bá»‹ rá»i ráº¡c (MacBook, iPhone, iPad...) thÃ nh má»™t "AI Cluster" táº¡i nhÃ .
*   **á»¨ng dá»¥ng:** Chia táº£i (Inference Split) Ä‘á»ƒ cháº¡y mÃ´ hÃ¬nh lá»›n trÃªn nhiá»u thiáº¿t bá»‹ yáº¿u káº¿t há»£p láº¡i.

### [FastChat](https://github.com/lm-sys/FastChat)
*   **Äáº·c Ä‘iá»ƒm:** Ná»n táº£ng má»Ÿ Ä‘á»ƒ huáº¥n luyá»‡n, phá»¥c vá»¥ (serve) vÃ  Ä‘Ã¡nh giÃ¡ Chatbot.
*   **Sáº£n pháº©m ná»•i báº­t:** LÃ  ná»n táº£ng Ä‘á»©ng sau Vicuna vÃ  Chatbot Arena.
*   **á»¨ng dá»¥ng:** XÃ¢y dá»±ng quy trÃ¬nh khÃ©p kÃ­n: Train -> Serve -> Eval.

---

## ğŸ§ª 5. Experimental & Deep Dive (NghiÃªn cá»©u sÃ¢u)

### [llm.c](https://github.com/karpathy/llm.c)
*   **TÃ¡c giáº£:** Andrej Karpathy.
*   **Äáº·c Ä‘iá»ƒm:** Viáº¿t LLM (nhÆ° GPT-2) báº±ng C vÃ  CUDA thuáº§n tÃºy, khÃ´ng dÃ¹ng PyTorch/Python.
*   **á»¨ng dá»¥ng:** TÃ i liá»‡u há»c táº­p tuyá»‡t vá»i Ä‘á»ƒ hiá»ƒu sÃ¢u sáº¯c cÃ¡ch mÃ´ hÃ¬nh hoáº¡t Ä‘á»™ng á»Ÿ táº§ng tháº¥p nháº¥t (bare metal).

### [whisper.cpp](https://github.com/ggerganov/whisper.cpp)
*   **Äáº·c Ä‘iá»ƒm:** PhiÃªn báº£n C++ tá»‘i Æ°u hÃ³a cá»§a mÃ´ hÃ¬nh nháº­n dáº¡ng giá»ng nÃ³i Whisper (OpenAI).
*   **á»¨ng dá»¥ng:** NhÃºng kháº£ nÄƒng Speech-to-Text vÃ o á»©ng dá»¥ng vá»›i tá»‘c Ä‘á»™ cá»±c nhanh, khÃ´ng cáº§n server.

---
*BiÃªn soáº¡n bá»Ÿi Pixiboss.*
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| [CS229: XÃ¢y Dá»±ng MÃ´ HÃ¬nh NgÃ´n Ngá»¯ Lá»›n (LLMs) ğŸ§ ](aero_LLM_00_Overview.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_00_Overview.md) |
| [Lecture 1: Transformer Architecture ğŸ¤–](aero_LLM_01_Transformer.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_01_Transformer.md) |
| [Lecture 2: Transformer Tricks & BERT ğŸ› ï¸](aero_LLM_02_Transformer_Tricks.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_02_Transformer_Tricks.md) |
| [Lecture 3: Large Language Models (LLMs) & Inference ğŸš€](aero_LLM_03_Large_Language_Models.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_03_Large_Language_Models.md) |
| [Lecture 4: LLM Training - Pre-training ğŸ‹ï¸](aero_LLM_04_Training_Pretraining.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_04_Training_Pretraining.md) |
| [Lecture 5: LLM Tuning (SFT & Parameter Efficient) ğŸ›ï¸](aero_LLM_05_Tuning_PEFT.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_05_Tuning_PEFT.md) |
| [Lecture 6: LLM Reasoning ğŸ§ ](aero_LLM_06_Reasoning.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_06_Reasoning.md) |
| [Lecture 7: Agentic LLMs & Tool Use ğŸ› ï¸](aero_LLM_07_Agentic_LLMs.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_07_Agentic_LLMs.md) |
| [Lecture 8: LLM Evaluation âš–ï¸](aero_LLM_08_Evaluation.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_08_Evaluation.md) |
| [Lecture 9: Recap & Current Trends ğŸ”®](aero_LLM_09_Trends.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_09_Trends.md) |
| ğŸ“Œ **[ğŸ› ï¸ Top 12 Repo Quan Trá»ng Cho AI Engineer Tá»‘i Æ¯u LLM](aero_LLM_10_Essential_Tools.md)** | [Xem bÃ i viáº¿t â†’](aero_LLM_10_Essential_Tools.md) |
| [ChÆ°Æ¡ng 1: Tá»•ng Quan Vá» Large Language Models (LLMs) ğŸ§ ](aero_LLM_chapter01_overview_detailed.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_chapter01_overview_detailed.md) |
| [ChÆ°Æ¡ng 2: 5 Trá»¥ Cá»™t Cá»§a Viá»‡c Huáº¥n Luyá»‡n LLMs ğŸ›ï¸](aero_LLM_chapter02_5pillars_part1.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_chapter02_5pillars_part1.md) |
| [ChÆ°Æ¡ng 2: 5 Trá»¥ Cá»™t - Part 2 (Evaluation & Systems)](aero_LLM_chapter02_5pillars_part2.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_chapter02_5pillars_part2.md) |
| [ChÆ°Æ¡ng 3: Pre-training â†’ Post-training Pipeline ğŸ”„](aero_LLM_chapter03_training_pipeline.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_chapter03_training_pipeline.md) |
| [ChÆ°Æ¡ng 4 & 5: Mechanisms & Evaluation ğŸ”§ğŸ“Š](aero_LLM_chapter04_05_mechanisms_eval.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_chapter04_05_mechanisms_eval.md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
