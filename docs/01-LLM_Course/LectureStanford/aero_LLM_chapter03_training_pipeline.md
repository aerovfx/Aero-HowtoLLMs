
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../../index.md) > [01 LLM Course](../../index.md) > [LectureStanford](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../../index.md)
- [ğŸ“š Module 01: LLM Course](../../../01-LLM_Course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../../02-Words-to-tokens-to-numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../../04-buildGPT/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../../07-Fine-tune-pretrained-models/index.md)
- [ğŸ” Module 19: AI Safety](../../../19-AI-safety/index.md)
- [ğŸ Module 20: Python for AI](../../../20-Python-Colab-notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# ChÆ°Æ¡ng 3: Pre-training â†’ Post-training Pipeline ğŸ”„

> **CS229 Stanford** | ChÆ°Æ¡ng 3/5  
> **Tá»« Base Model â†’ ChatGPT**

---

## ğŸ“Š Complete Pipeline

```
13T Tokens Data
      â†“
Pre-training (100 days, $100M)
      â†“
Base Model (knows but doesn't follow)
      â†“
SFT - 50K examples (3 days)
      â†“
Instruction Model
      â†“
RLHF - Reward Model + PPO (1 week)
      â†“
ChatGPT âœ…
```

---

## 1. Pre-training

**Input:** 13 trillion tokens  
**Output:** Base model (GPT-4 base)  
**Time:** 100+ days  
**Cost:** ~$100M

**What it learns:**
- Grammar, syntax
- Facts, knowledge
- Code patterns
- Logic, reasoning

**What it can't do:**
- Follow instructions reliably
- Refuse harmful requests
- Format responses nicely

---

## 2. Supervised Fine-Tuning (SFT)

**Input:** ~50K instruction-response pairs  
**Output:** Instruction-following model  
**Time:** 1-3 days  
**Cost:** ~$10K

**Example data:**
```json
{
  "prompt": "Explain photosynthesis simply",
  "response": "Photosynthesis is how plants make food using sunlight..."
}
```

---

## 3. RLHF (Reinforcement Learning)

**Input:** Human preferences  
**Output:** Aligned assistant (ChatGPT)  
**Time:** ~1 week  
**Cost:** ~$50K

**Process:**
1. Collect comparisons (A vs B)
2. Train reward model
3. Optimize policy with PPO

---

## ğŸ¯ Key Takeaways

- âœ… Pre-training: Learn language (expensive!)
- âœ… SFT: Learn to follow instructions
- âœ… RLHF: Align with human values
- âœ… 3 stages = ChatGPT

---

**Next:** [ChÆ°Æ¡ng 4: Autoregressive & Tokenization â†’](./aero_LLM_chapter04_05_mechanisms_eval.md)
<!-- Aero-Footer-Start -->
---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
