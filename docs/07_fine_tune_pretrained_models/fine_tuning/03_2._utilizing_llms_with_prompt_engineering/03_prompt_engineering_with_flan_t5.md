
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../../index.md) > [07 fine tune pretrained models](../../index.md) > [fine tuning](../index.md) > [03 2. utilizing llms with prompt engineering](index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../../index.md)
- [ğŸ“š Module 01: LLM Course](../../../01_llm_course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../../02_words_to_tokens_to_numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../../04_buildgpt/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../../07_fine_tune_pretrained_models/index.md)
- [ğŸ” Module 19: AI Safety](../../../19_ai_safety/index.md)
- [ğŸ Module 20: Python for AI](../../../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Prompt Engineering Vá»›i FLAN-T5

## Giá»›i Thiá»‡u

HÃ£y nÃ³i vá» cÃ¡ch sá»­ dá»¥ng mÃ´ hÃ¬nh Ä‘a nÄƒng nÃ y cho tÃ³m táº¯t vÄƒn báº£n, dá»‹ch thuáº­t vÃ  tráº£ lá»i cÃ¢u há»i sá»­ dá»¥ng thÆ° viá»‡n Hugging Face Transformers vÃ  TensorFlow.

Hugging Face lÃ  má»™t ná»n táº£ng lÆ°u trá»¯ má»™t bá»™ sÆ°u táº­p lá»›n cÃ¡c mÃ´ hÃ¬nh pre-trained, bao gá»“m FLAN-T5, cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘iá»u chá»‰nh cho nhiá»u tÃ¡c vá»¥ dá»±a trÃªn vÄƒn báº£n.

## CÃ i Äáº·t MÃ´i TrÆ°á»ng

Äáº§u tiÃªn, chÃºng ta cáº§n cÃ i Ä‘áº·t mÃ´i trÆ°á»ng cá»§a mÃ¬nh. Äiá»u nÃ y bao gá»“m cÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n transformers vÃ  TensorFlow, cung cáº¥p cÆ¡ sá»Ÿ háº¡ táº§ng vÃ  mÃ´ hÃ¬nh cáº§n thiáº¿t cho cÃ¡c tÃ¡c vá»¥ cá»§a chÃºng ta.

## Táº£i FLAN-T5

Sau khi cÃ i Ä‘áº·t, chÃºng ta sáº½ táº£i FLAN-T5 sá»­ dá»¥ng thÆ° viá»‡n Transformers. Äá»ƒ lÃ m Ä‘iá»u Ä‘Ã³, chÃºng ta sáº½ sá»­ dá»¥ng:
- **AutoTokenizer:** Xá»­ lÃ½ vÄƒn báº£n thÃ nh Ä‘á»‹nh dáº¡ng mÃ  mÃ´ hÃ¬nh cÃ³ thá»ƒ lÃ m viá»‡c, chuyá»ƒn Ä‘á»•i cÃ¢u thÃ nh chuá»—i tokens hoáº·c biá»ƒu diá»…n sá»‘.
- **TFAutoModelForSeq2SeqLM:** MÃ´ hÃ¬nh sáº½ diá»…n giáº£i cÃ¡c tokens nÃ y vÃ  táº¡o vÄƒn báº£n dá»±a trÃªn chÃºng.

## TÃ³m Táº¯t VÄƒn Báº£n (Text Summarization)

Cho tÃ³m táº¯t vÄƒn báº£n, chÃºng ta sáº½ cho FLAN-T5 má»™t Ä‘oáº¡n vÄƒn báº£n vÃ  yÃªu cáº§u má»™t báº£n tÃ³m táº¯t ngáº¯n gá»n.

**CÃ¡c bÆ°á»›c thá»±c hiá»‡n:**
1. Äáº·t prompt (vÃ­ dá»¥: "Summarize the following article about carrots")

2. Tokenize vá»›i `return_tensors="tf"` Ä‘á»ƒ xuáº¥t TensorFlow tensors

$$
3. Giá»›i háº¡n Ä‘á»™ dÃ i vá»›i `max_length=512`
$$

