
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../../index.md) > [07 fine tune pretrained models](../../index.md) > [fine tuning](../index.md) > [04 3. transfer learning for nlp tasks](index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../../index.md)
- [ğŸ“š Module 01: LLM Course](../../../01_llm_course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../../02_words_to_tokens_to_numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../../04_buildgpt/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../../07_fine_tune_pretrained_models/index.md)
- [ğŸ” Module 19: AI Safety](../../../19_ai_safety/index.md)
- [ğŸ Module 20: Python for AI](../../../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Demo ÄÃ¡nh GiÃ¡ Báº£n Dá»‹ch

## Tá»•ng Quan

Trong bÃ i hÆ°á»›ng dáº«n thá»±c hÃ nh nÃ y, chÃºng ta sáº½ má»Ÿ rá»™ng tá»« bÃ i trÆ°á»›c vá» transfer learning vá»›i FLAN-T5 Ä‘á»ƒ thá»±c hiá»‡n Ä‘Ã¡nh giÃ¡ báº£n dá»‹ch. ChÃºng ta sáº½ sá»­ dá»¥ng hai chá»‰ sá»‘ phá»• biáº¿n: **ROUGE** vÃ  **BLEU** Ä‘á»ƒ Ä‘o lÆ°á»ng cháº¥t lÆ°á»£ng dá»‹ch thuáº­t.

## 1. Giá»›i Thiá»‡u CÃ¡c Chá»‰ Sá»‘ ÄÃ¡nh GiÃ¡

### 1.1 Táº¡i Sao Cáº§n ÄÃ¡nh GiÃ¡?

ÄÃ¡nh giÃ¡ tá»± Ä‘á»™ng lÃ  cáº§n thiáº¿t Ä‘á»ƒ:
- Äo lÆ°á»ng hiá»‡u suáº¥t mÃ´ hÃ¬nh
- So sÃ¡nh cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c nhau
- Tá»‘i Æ°u hÃ³a hyperparameter

### 1.2 CÃ¡c Chá»‰ Sá»‘ Phá»• Biáº¿n

| Chá»‰ sá»‘ | MÃ´ táº£ | á»¨ng dá»¥ng |
|--------|-------|-----------|
| **ROUGE** | Recall-Oriented Understudy for Gisting Evaluation | TÃ³m táº¯t |
| **BLEU** | Bilingual Evaluation Understudy | Dá»‹ch thuáº­t |

## 2. Triá»ƒn Khai Chi Tiáº¿t

### 2.1 CÃ i Äáº·t ThÆ° Viá»‡n

```python
!pip install rouge-score nltk

import nltk
nltk.download('punkt')

### 2.2 Táº£i MÃ´ HÃ¬nh ÄÃ£ Huáº¥n Luyá»‡n

```python
# Giáº£ Ä‘á»‹nh mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n tá»« bÃ i trÆ°á»›c
from transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer

model_name = "google/flan-t5-base"

$$
tokenizer = AutoTokenizer.from_pretrained(model_name)
$$

model = TFAutoModelForSeq2SeqLM.from_pretrained("path/to/model")

### 2.3 HÃ m Dá»‹ch Thuáº­t

```python
def translate(text):

prompt = f"translate English to Spanish: {text}"

$$
inputs = tokenizer(prompt, return_tensors="tf", max_length=128, truncation=True)
$$

outputs = model.generate(**inputs, max_length=128)

$$
return tokenizer.decode(outputs[0], skip_special_tokens=True) ## 3. TÃ­nh ToÃ¡n ROUGE Score ### 3.1 Giá»›i Thiá»‡u vá» ROUGE ROUGE (Recall-Oriented Understudy for Gisting Evaluation) lÃ  má»™t nhÃ³m cÃ¡c chá»‰ sá»‘ Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ tÃ³m táº¯t tá»± Ä‘á»™ng. CÃ¡c biáº¿n thá»ƒ phá»• biáº¿n: - **ROUGE-1**: ÄÆ¡n vá»‹ unigram - **ROUGE-2**: Bigram - **ROUGE-L**: Longest common subsequence ### 3.2 CÃ´ng Thá»©c ToÃ¡n Há»c **ROUGE-N:**
$$

\text{ROUGE-N} = \frac{$\sum$_{s \in \text{Reference}} $\sum$_{\text{n-gram} \in s} \min(\text{Count}_{hypothesis}(n\text{-gram}), \text{Count}_{reference}(n\text{-gram}))}{$\sum$_{s \in \text{Reference}} $\sum$_{\text{n-gram} \in s} \text{Count}_{reference}(n\text{-gram})}

$$
### 3.3 Triá»ƒn Khai ```python from rouge_score import rouge_scorer # Khá»Ÿi táº¡o ROUGE scorer scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True) # TÃ­nh ROUGE cho má»™t cáº·p dá»‹ch def calculate_rouge(reference, hypothesis): scores = scorer.score(reference, hypothesis) return { 'rouge1': scores['rouge1'].precision, 'rouge2': scores['rouge2'].precision, 'rougeL': scores['rougeL'].precision } ## 4. TÃ­nh ToÃ¡n BLEU Score ### 4.1 Giá»›i Thiá»‡u vá» BLEU BLEU (Bilingual Evaluation Understudy) Ä‘o lÆ°á»ng sá»± tÆ°Æ¡ng Ä‘á»“ng giá»¯a báº£n dá»‹ch mÃ¡y vÃ  báº£n dá»‹ch tham chiáº¿u cá»§a con ngÆ°á»i. ### 4.2 CÃ´ng Thá»©c ToÃ¡n Há»c \text{BLEU} = \text{BP} \cdot \exp\left(\sum_{n=1}^{N} w_n \log p_n\right) Trong Ä‘Ã³: - p_n lÃ  precision cho n-gram - w_n lÃ  trá»ng sá»‘ (thÆ°á»ng báº±ng 1/N) - BP lÃ  brevity penalty **Brevity Penalty:** \text{BP} = \begin{cases} 1 & \text{náº¿u } c > r \\ e^{(1-r/c)} & \text{náº¿u } c \leq r \end{cases} ### 4.3 Triá»ƒn Khai ```python from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction # Sá»­ dá»¥ng smoothing Ä‘á»ƒ xá»­ lÃ½ cÃ¢u ngáº¯n smoothing = SmoothingFunction().method1 def calculate_bleu(reference, hypothesis): # Tokenize ref_tokens = reference.split()
$$

hyp_tokens = hypothesis.split()

    
    # TÃ­nh BLEU

score = sentence_bleu([ref_tokens], hyp_tokens, smoothing_function=smoothing)

    return score

## 5. ÄÃ¡nh GiÃ¡ TrÃªn Táº­p Dá»¯ Liá»‡u

### 5.1 Quy TrÃ¬nh

```python
# Láº¥y má»™t batch tá»« test dataset

batch = next(iter(test_dataset))

# Láº¥y reference tá»« labels

references = tokenizer.decode(batch['labels'][0], skip_special_tokens=True)

# Dá»‹ch input

inputs = tokenizer.decode(batch['input_ids'][0], skip_special_tokens=True)

$$
hypothesis = translate(inputs) # TÃ­nh cÃ¡c chá»‰ sá»‘ rouge_scores = calculate_rouge(references, hypothesis)
$$

bleu_score = calculate_bleu(references, hypothesis)

print(f"ROUGE-1: {rouge_scores['rouge1']:.4f}")
print(f"ROUGE-2: {rouge_scores['rouge2']:.4f}")
print(f"ROUGE-L: {rouge_scores['rougeL']:.4f}")
print(f"BLEU: {bleu_score:.4f}")

### 5.2 Káº¿t Quáº£ Máº«u

**VÃ­ dá»¥:**
- **Input:** "I was cleaning"
- **Reference:** "Estaba limpiando"
- **Hypothesis:** "Estaba limpiando"

| Chá»‰ sá»‘ | GiÃ¡ trá»‹ |
|--------|---------|
| ROUGE-1 | 1.0 |
| ROUGE-2 | 1.0 |
| ROUGE-L | 1.0 |
| BLEU | 0.4 |

**Nháº­n xÃ©t:**
- ROUGE = 1.0 cho tháº¥y má»i tá»« trong hypothesis Ä‘á»u cÃ³ trong reference
- BLEU = 0.4 lÃ  giÃ¡ trá»‹ cao, cho tháº¥y dá»‹ch thuáº­t tá»‘t

## 6. PhÃ¢n TÃ­ch Chi Tiáº¿t

### 6.1 So SÃ¡nh Precision vÃ  Recall

\text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}}

$$
\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}
$$

