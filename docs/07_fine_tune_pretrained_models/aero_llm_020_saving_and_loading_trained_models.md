
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../index.md) > [07 fine tune pretrained models](index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../index.md)
- [ğŸ“š Module 01: LLM Course](../01_llm_course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../02_words_to_tokens_to_numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../04_buildgpt/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../07_fine_tune_pretrained_models/index.md)
- [ğŸ” Module 19: AI Safety](../19_ai_safety/index.md)
- [ğŸ Module 20: Python for AI](../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# LÆ°u Trá»¯ vÃ  Táº£i Láº¡i MÃ´ HÃ¬nh Há»c SÃ¢u Trong PyTorch vÃ  Hugging Face: PhÆ°Æ¡ng PhÃ¡p, Cáº¥u TrÃºc vÃ  ÄÃ¡nh GiÃ¡

## TÃ³m táº¯t

BÃ i viáº¿t nÃ y trÃ¬nh bÃ y cÃ¡c phÆ°Æ¡ng phÃ¡p lÆ°u trá»¯ vÃ  táº£i láº¡i mÃ´ hÃ¬nh há»c sÃ¢u trong mÃ´i trÆ°á»ng PyTorch vÃ  há»‡ sinh thÃ¡i Hugging Face. Dá»±a trÃªn tÃ i liá»‡u thá»±c nghiá»‡m , nghiÃªn cá»©u phÃ¢n tÃ­ch cáº¥u trÃºc dá»¯ liá»‡u mÃ´ hÃ¬nh, cÆ¡ cháº¿ tuáº§n tá»± hÃ³a (serialization), quy trÃ¬nh khÃ´i phá»¥c tham sá»‘, vÃ  ká»¹ thuáº­t Ä‘Ã³ng gÃ³i mÃ´ hÃ¬nh. CÃ¡c cÃ´ng thá»©c toÃ¡n há»c Ä‘Æ°á»£c sá»­ dá»¥ng nháº±m mÃ´ hÃ¬nh hÃ³a quÃ¡ trÃ¬nh cáº­p nháº­t vÃ  báº£o toÃ n tham sá»‘. Káº¿t quáº£ cho tháº¥y viá»‡c lÆ°u â€“ táº£i mÃ´ hÃ¬nh Ä‘Ãºng cÃ¡ch Ä‘Ã³ng vai trÃ² then chá»‘t trong tÃ¡i sá»­ dá»¥ng, triá»ƒn khai vÃ  nghiÃªn cá»©u AI.

---

## 1. Giá»›i thiá»‡u

Trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n mÃ´ hÃ¬nh há»c sÃ¢u, viá»‡c khÃ´ng lÆ°u trá»¯ káº¿t quáº£ sáº½ dáº«n Ä‘áº¿n máº¥t toÃ n bá»™ tham sá»‘ khi phiÃªn lÃ m viá»‡c káº¿t thÃºc. Äiá»u nÃ y Ä‘áº·c biá»‡t quan trá»ng trong mÃ´i trÆ°á»ng Ä‘iá»‡n toÃ¡n Ä‘Ã¡m mÃ¢y nhÆ° **Google Colab**.

Theo tÃ i liá»‡u , tÃ¡c giáº£ trÃ¬nh bÃ y cÃ¡ch lÆ°u vÃ  táº£i láº¡i mÃ´ hÃ¬nh ngÃ´n ngá»¯ GPT-2 báº±ng cÃ´ng cá»¥ cá»§a **Hugging Face** vÃ  **PyTorch**.

MÃ´ hÃ¬nh minh há»a chÃ­nh trong nghiÃªn cá»©u lÃ  **GPT-2**, má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ tiá»n huáº¥n luyá»‡n phá»• biáº¿n.

Má»¥c tiÃªu nghiÃªn cá»©u:

* PhÃ¢n tÃ­ch cáº¥u trÃºc dá»¯ liá»‡u mÃ´ hÃ¬nh,
* MÃ´ táº£ cÆ¡ cháº¿ lÆ°u â€“ táº£i tham sá»‘,
* So sÃ¡nh phÆ°Æ¡ng phÃ¡p Hugging Face vÃ  PyTorch,
* ÄÃ¡nh giÃ¡ hiá»‡u quáº£ báº£o toÃ n mÃ´ hÃ¬nh.

---

## 2. CÆ¡ sá»Ÿ lÃ½ thuyáº¿t

### 2.1. Biá»ƒu diá»…n tham sá»‘ mÃ´ hÃ¬nh

Má»™t mÃ´ hÃ¬nh há»c sÃ¢u Ä‘Æ°á»£c Ä‘áº·c trÆ°ng bá»Ÿi táº­p tham sá»‘:

\theta = {W_1, W_2, \dots, W_L, b_1, b_2, \dots, b_L}

Trong Ä‘Ã³:

* $W_l$: ma tráº­n trá»ng sá»‘,
* $b_l$: vector bias,
* $L$: sá»‘ lá»›p.

ToÃ n bá»™ táº­p $\theta$ cáº§n Ä‘Æ°á»£c lÆ°u trá»¯ Ä‘á»ƒ tÃ¡i táº¡o mÃ´ hÃ¬nh.

---

### 2.2. QuÃ¡ trÃ¬nh huáº¥n luyá»‡n

Tham sá»‘ Ä‘Æ°á»£c cáº­p nháº­t theo gradient descent:

\theta_{t+1} = \theta_t-\eta\nabla_\theta\mathcal{L}_t

vá»›i:

* $\eta$: learning rate,

$$
* \mathcal{L}: hÃ m máº¥t mÃ¡t.
$$

Má»¥c tiÃªu cá»§a viá»‡c lÆ°u mÃ´ hÃ¬nh lÃ  báº£o toÃ n $\theta_T$ táº¡i thá»i Ä‘iá»ƒm há»™i tá»¥.

---

### 2.3. State Dictionary

Trong PyTorch, tráº¡ng thÃ¡i mÃ´ hÃ¬nh Ä‘Æ°á»£c biá»ƒu diá»…n bá»Ÿi:

\text{state_dict}={\theta_i}_{i=1}^{P}

vá»›i $$P( lÃ  sá»‘ tensor tham sá»‘.

---

## 3. Cáº¥u trÃºc lÆ°u trá»¯ mÃ´ hÃ¬nh Hugging Face

### 3.1. Äá»‹nh dáº¡ng thÆ° má»¥c

Theo , mÃ´ hÃ¬nh Hugging Face khÃ´ng Ä‘Æ°á»£c lÆ°u dÆ°á»›i dáº¡ng má»™t file duy nháº¥t mÃ  lÃ  má»™t thÆ° má»¥c gá»“m:

* `config.json`,
* `tokenizer.json`,
* `model.safetensors`,
* `version.txt`.

Cáº¥u trÃºc:

)
\mathcal{F}={f_1,f_2,\dots,f_k}

Trong Ä‘Ã³ f_k chá»©a toÃ n bá»™ tham sá»‘. --- ### 3.2. File trá»ng sá»‘ File `model.safetensors` chá»©a ma tráº­n:

W\in\mathbb{R}^{d\times d'}

Dung lÆ°á»£ng xáº¥p xá»‰:

S\approx 4\times P \text{ bytes}

vá»›i P( lÃ  sá»‘ tham sá»‘ dáº¡ng float32. VÃ­ dá»¥ GPT-2 small: )

$$
S\approx 474\text{ MB} . --- ### 3.3. Lá»‡nh lÆ°u mÃ´ hÃ¬nh PhÆ°Æ¡ng thá»©c:
$$

\text{model.save_pretrained(path)}

$$
Thá»±c hiá»‡n Ã¡nh xáº¡: \theta \rightarrow \mathcal{F}_{path} --- ## 4. Chá»‰nh sá»­a vÃ  kiá»ƒm chá»©ng mÃ´ hÃ¬nh ### 4.1. Thao tÃ¡c thay Ä‘á»•i embedding Theo tÃ i liá»‡u, embedding Ä‘Æ°á»£c thay báº±ng vector 1: E_{ij}=1,\ \forall i,j Thay vÃ¬: E_{ij}\sim \mathcal{N}(0,\sigma^2) Äiá»u nÃ y giÃºp kiá»ƒm tra tÃ­nh Ä‘Ãºng Ä‘áº¯n khi táº£i láº¡i mÃ´ hÃ¬nh. --- ### 4.2. So sÃ¡nh tham sá»‘ TrÆ°á»›c vÃ  sau khi chá»‰nh sá»­a: \Delta E = E_{new}-E_{old} Náº¿u:
$$

|\Delta E|_F>0

$$
â‡’ mÃ´ hÃ¬nh Ä‘Ã£ thay Ä‘á»•i. --- ### 4.3. KhÃ´i phá»¥c mÃ´ hÃ¬nh Sá»­ dá»¥ng:
$$

\text{from_pretrained(path)}

$$
TÃ¡i táº¡o: \theta_{load}\approx\theta_{save} --- ## 5. LÆ°u trá»¯ báº±ng PyTorch ### 5.1. LÆ°u state dictionary Vá»›i PyTorch:
$$

\text{torch.save(state_dict, file.pt)}

$$
Biá»ƒu diá»…n:
$$

\theta \rightarrow file.pt

$$
KhÃ¡c vá»›i Hugging Face, phÆ°Æ¡ng phÃ¡p nÃ y chá»‰ táº¡o má»™t file. --- ### 5.2. Táº£i láº¡i mÃ´ hÃ¬nh \theta \leftarrow \text{torch.load(file.pt)} vÃ :
$$

\text{model.load_state_dict}(\theta)

$$
GiÃºp khÃ´i phá»¥c tham sá»‘. --- ### 5.3. TÃ­nh toÃ n váº¹n tham sá»‘ Sai sá»‘ khÃ´i phá»¥c: \varepsilon=|\theta_{load}-\theta_{orig}|_2 LÃ½ tÆ°á»Ÿng: \varepsilon\approx 0 --- ## 6. ÄÃ³ng gÃ³i vÃ  di chuyá»ƒn mÃ´ hÃ¬nh ### 6.1. NÃ©n thÆ° má»¥c Theo , sá»­ dá»¥ng: \text{zip}(\mathcal{F})\rightarrow file.zip Tá»· lá»‡ nÃ©n: r=\frac{S_{zip}}{S_{raw}} ThÃ´ng thÆ°á»ng: r\approx 0.8-0.9 vá»›i mÃ´ hÃ¬nh lá»›n. --- ### 6.2. Giáº£i nÃ©n file.zip \rightarrow \mathcal{F}' Sao cho:
$$

\mathcal{F}'\equiv\mathcal{F}

$$
--- ### 6.3. Di chuyá»ƒn mÃ´i trÆ°á»ng Quy trÃ¬nh: 1. NÃ©n mÃ´ hÃ¬nh, 2. Táº£i vá» mÃ¡y cÃ¡ nhÃ¢n, 3. Upload lÃªn phiÃªn má»›i, 4. Giáº£i nÃ©n, 5. Load mÃ´ hÃ¬nh. Äáº£m báº£o: P(\text{lá»—i})\approx 0 --- ## 7. PhÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡ ### 7.1. So sÃ¡nh Ä‘áº§u ra Cho input x: y_{old}=f(x;\theta_{old})
$$

y_{new}=f(x;\theta_{load})

Sai lá»‡ch:

\delta=|y_{old}-y_{new}|

$$
Náº¿u \delta\approx0 â‡’ khÃ´i phá»¥c thÃ nh cÃ´ng. --- ### 7.2. Kiá»ƒm tra embedding TrÆ°á»ng há»£p kiá»ƒm chá»©ng báº±ng vector 1: E_{ij}=1 \Rightarrow \text{mean}(E)=1 Náº¿u Ä‘Ãºng â‡’ táº£i Ä‘Ãºng mÃ´ hÃ¬nh. --- ### 7.3. ÄÃ¡nh giÃ¡ Ä‘á»™ á»•n Ä‘á»‹nh TÃ­nh phÆ°Æ¡ng sai Ä‘áº§u ra: \sigma^2=\frac{1}{N}\sum(y_i-\bar{y})^2 MÃ´ hÃ¬nh á»•n Ä‘á»‹nh â‡’ \sigma^2 tháº¥p. --- ## 8. Tháº£o luáº­n ### 8.1. So sÃ¡nh hai phÆ°Æ¡ng phÃ¡p | TiÃªu chÃ­      | Hugging Face | PyTorch    | | ------------- | ------------ | ---------- | | Äá»‹nh dáº¡ng     | ThÆ° má»¥c      | File       | | Dá»… triá»ƒn khai | Cao          | Trung bÃ¬nh | | Linh hoáº¡t     | Trung bÃ¬nh   | Cao        | | TÃ­nh phá»• quÃ¡t | Tháº¥p         | Cao        | --- ### 8.2. Æ¯u Ä‘iá»ƒm * Báº£o toÃ n tri thá»©c huáº¥n luyá»‡n, * Há»— trá»£ tÃ¡i sá»­ dá»¥ng, * Thuáº­n tiá»‡n triá»ƒn khai. --- ### 8.3. Háº¡n cháº¿ * Dung lÆ°á»£ng lá»›n, * Phá»¥ thuá»™c phiÃªn báº£n, * KhÃ³ chuáº©n hÃ³a liÃªn thÆ° viá»‡n. --- ## 9. á»¨ng dá»¥ng thá»±c tiá»…n PhÆ°Æ¡ng phÃ¡p lÆ°u â€“ táº£i mÃ´ hÃ¬nh Ä‘Æ°á»£c á»©ng dá»¥ng trong: * Triá»ƒn khai há»‡ thá»‘ng NLP, * Chia sáº» mÃ´ hÃ¬nh nghiÃªn cá»©u, * Fine-tuning nhiá»u giai Ä‘oáº¡n, * Há»c táº­p vÃ  giáº£ng dáº¡y AI. Äáº·c biá»‡t quan trá»ng trong mÃ´i trÆ°á»ng cloud:
$$

T_{session}\lt T_{train}