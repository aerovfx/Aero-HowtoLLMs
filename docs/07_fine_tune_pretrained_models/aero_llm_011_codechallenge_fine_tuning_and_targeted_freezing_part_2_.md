
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../index.md) > [07 fine tune pretrained models](index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../index.md)
- [ğŸ“š Module 01: LLM Course](../01_llm_course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../02_words_to_tokens_to_numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../04_buildgpt/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../07_fine_tune_pretrained_models/index.md)
- [ğŸ” Module 19: AI Safety](../19_ai_safety/index.md)
- [ğŸ Module 20: Python for AI](../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# PhÃ¢n TÃ­ch Hiá»‡u Quáº£ Fine-tuning vÃ  Targeted Freezing (Pháº§n 2): ÄÃ¡nh GiÃ¡ Báº±ng Trá»±c Quan HÃ³a vÃ  Chuáº©n Ma Tráº­n

## TÃ³m táº¯t

BÃ i viáº¿t nÃ y tiáº¿p tá»¥c nghiÃªn cá»©u phÆ°Æ¡ng phÃ¡p fine-tuning káº¿t há»£p vá»›i Ä‘Ã³ng bÄƒng cÃ³ má»¥c tiÃªu (targeted freezing) trong mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n. Dá»±a trÃªn káº¿t quáº£ trá»±c quan hÃ³a báº±ng biá»ƒu Ä‘á»“ loss, phÃ¢n bá»‘ token, thá»i gian tÃ­nh toÃ¡n vÃ  chuáº©n ma tráº­n trá»ng sá»‘, nghiÃªn cá»©u so sÃ¡nh giá»¯a mÃ´ hÃ¬nh huáº¥n luyá»‡n toÃ n pháº§n vÃ  mÃ´ hÃ¬nh Ä‘Ã³ng bÄƒng má»™t pháº§n. Káº¿t quáº£ cho tháº¥y viá»‡c Ä‘Ã³ng bÄƒng cÃ³ má»¥c tiÃªu giÃºp giáº£m chi phÃ­ tÃ­nh toÃ¡n vÃ  tÄƒng tÃ­nh á»•n Ä‘á»‹nh, tuy nhiÃªn khÃ´ng pháº£i lÃºc nÃ o cÅ©ng Ä‘áº£m báº£o hiá»‡u quáº£ sinh vÄƒn báº£n vÆ°á»£t trá»™i.

---

## 1. Giá»›i thiá»‡u

Trong pháº§n trÆ°á»›c, chiáº¿n lÆ°á»£c Ä‘Ã³ng bÄƒng cÃ³ má»¥c tiÃªu Ä‘Ã£ Ä‘Æ°á»£c trÃ¬nh bÃ y nhÆ° má»™t phÆ°Æ¡ng phÃ¡p giáº£m chi phÃ­ fine-tuning. Pháº§n tiáº¿p theo cá»§a nghiÃªn cá»©u táº­p trung vÃ o:

* Trá»±c quan hÃ³a quÃ¡ trÃ¬nh huáº¥n luyá»‡n,
* So sÃ¡nh Ä‘á»™ng lá»±c há»c (training dynamics),
* ÄÃ¡nh giÃ¡ má»©c Ä‘á»™ thay Ä‘á»•i trá»ng sá»‘,
* PhÃ¢n tÃ­ch thá»i gian tÃ­nh toÃ¡n.

Theo tÃ i liá»‡u , cÃ¡c biá»ƒu Ä‘á»“ trá»±c quan Ä‘Ã³ng vai trÃ² quan trá»ng trong viá»‡c hiá»ƒu rÃµ sá»± khÃ¡c biá»‡t giá»¯a hai mÃ´ hÃ¬nh.

---

## 2. CÆ¡ sá»Ÿ lÃ½ thuyáº¿t

### 2.1. HÃ m máº¥t mÃ¡t trong mÃ´ hÃ¬nh sinh

Vá»›i táº­p dá»¯ liá»‡u:

$\mathcal${D}={($x_i$,$y_i$)}_{i=1}^{N}

HÃ m máº¥t mÃ¡t cross-entropy:

$\mathcal${L} = -\frac{1}{N}$\sum$_{i=1}^{N} $\log$ P($y_i$ \mid $x_i$;\theta)

Trong Ä‘Ã³ $\theta$ lÃ  tham sá»‘ mÃ´ hÃ¬nh.

Má»¥c tiÃªu huáº¥n luyá»‡n:

\theta^{\ast}=\arg\min_\theta \mathcal{L}

---

### 2.2. Gradient Descent vá»›i tham sá»‘ Ä‘Ã³ng bÄƒng

Quy táº¯c cáº­p nháº­t:

\theta_{t+1} = \theta_t-\eta\nabla_\theta\mathcal{L}

Vá»›i tham sá»‘ bá»‹ Ä‘Ã³ng bÄƒng:

$\nabla$_{\theta_f}$\mathcal${L}=0

Suy ra:

\theta_f^{(t+1)}=\theta_f^{(t)}

---

### 2.3. Chuáº©n ma tráº­n trá»ng sá»‘

Cho ma tráº­n trá»ng sá»‘ attention:

W_t\in\mathbb{R}^{m\times n}

Hiá»‡u táº¡i bÆ°á»›c $t$:

\Delta W_t=W_t-W_{t-1}

Chuáº©n Frobenius:

$$
|\Delta W_t|_F = \sqrt{\sum_{i=1}^{m}\sum_{j=1}^{n}(\Delta W_{ij})^2}
$$

Chuáº©n nÃ y pháº£n Ã¡nh má»©c Ä‘á»™ thay Ä‘á»•i cá»§a mÃ´ hÃ¬nh theo thá»i gian.

---

## 3. PhÆ°Æ¡ng phÃ¡p nghiÃªn cá»©u

### 3.1. Thiáº¿t láº­p thÃ­ nghiá»‡m

Theo mÃ´ táº£ trong tÃ i liá»‡u , hai mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n song song:

* **Model A**: Huáº¥n luyá»‡n toÃ n pháº§n.
* **Model B**: ÄÃ³ng bÄƒng pháº§n lá»›n trá»ng sá»‘, chá»‰ fine-tuning má»™t sá»‘ lá»›p attention.

Hai mÃ´ hÃ¬nh cÃ³ cÃ¹ng:

\theta_A^{(0)}=\theta_B^{(0)}

vÃ  cÃ¹ng thá»© tá»± dá»¯ liá»‡u.

---

### 3.2. Trá»±c quan hÃ³a loss

Loss táº¡i epoch $k$:

$$
\mathcal{L}_k^{(A)},\quad \mathcal{L}_k^{(B)}
$$

Váº½:

$$
* Biá»ƒu Ä‘á»“ Ä‘Æ°á»ng: \mathcal{L}_k theo k, * Biá»ƒu Ä‘á»“ scatter: (\mathcal{L}_k^{(B},\mathcal{L}_k^{A})).
$$

ÄÆ°á»ng chuáº©n:

y=x

dÃ¹ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ sá»± tÆ°Æ¡ng Ä‘á»“ng.

---

### 3.3. ÄÃ¡nh giÃ¡ phÃ¢n bá»‘ token

Gá»i:

* $S$: táº­p token phá»• biáº¿n,

* G=(g_1,\dots,g_M): chuá»—i sinh.

Tá»· lá»‡:

p=\frac{1}{M}\sum_{i=1}^{M}\mathbf{1}(g_i\in S)

So sÃ¡nh trÆ°á»›c vÃ  sau huáº¥n luyá»‡n:

\Delta p = p_{post}-p_{pre}

---

### 3.4. Äo thá»i gian huáº¥n luyá»‡n

Tá»•ng thá»i gian:

T=\sum_{k=1}^{K}t_k

Tá»· lá»‡ tiáº¿t kiá»‡m:

r=\frac{T_{train}-T_{freeze}}{T_{train}}

---

## 4. Káº¿t quáº£ thá»±c nghiá»‡m

### 4.1. PhÃ¢n tÃ­ch hÃ m máº¥t mÃ¡t

Theo káº¿t quáº£ trong tÃ i liá»‡u :

* MÃ´ hÃ¬nh train cÃ³ Ä‘á»™ dá»‘c loss lá»›n,
* MÃ´ hÃ¬nh freeze giáº£m cháº­m hÆ¡n.

VÃ­ dá»¥:

$$
\mathcal{L}_{freeze}: 3.78 \rightarrow 2.65
$$

Trong khi:

$$
\mathcal{L}_{train}: \text{giáº£m máº¡nh hÆ¡n}
$$

Äiá»u nÃ y cho tháº¥y mÃ´ hÃ¬nh huáº¥n luyá»‡n toÃ n pháº§n há»c nhanh hÆ¡n.

---

### 4.2. Biá»ƒu Ä‘á»“ Scatter Loss

CÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u náº±m dÆ°á»›i Ä‘Æ°á»ng y=x:

$\mathcal${L}^{(B)}>$\mathcal${L}^{(A)}

$$
â‡’ mÃ´ hÃ¬nh freeze thÆ°á»ng cÃ³ loss cao hÆ¡n. Má»™t sá»‘ Ä‘iá»ƒm trÃªn Ä‘Æ°á»ng chÃ©o pháº£n Ã¡nh giai Ä‘oáº¡n Ä‘áº§u huáº¥n luyá»‡n, khi hai mÃ´ hÃ¬nh cÃ²n tÆ°Æ¡ng tá»± nhau . --- ### 4.3. PhÃ¢n bá»‘ token sinh Káº¿t quáº£ cho tháº¥y:
$$

\Delta $p_A$>0,\quad \Delta $p_B$>0

$$
Cáº£ hai mÃ´ hÃ¬nh Ä‘á»u há»c Ä‘Æ°á»£c phong cÃ¡ch dá»¯ liá»‡u. Tuy nhiÃªn, trong má»™t sá»‘ láº§n thá»­:
$$

p_B$>$p_A

$$
Hiá»‡n tÆ°á»£ng nÃ y Ä‘Æ°á»£c giáº£i thÃ­ch bá»Ÿi tÃ­nh ngáº«u nhiÃªn cá»§a sampling . --- ### 4.4. Chuáº©n thay Ä‘á»•i trá»ng sá»‘ Quan sÃ¡t:
$$

|\Delta $W_t$|_F

$$
* Lá»›n á»Ÿ giai Ä‘oáº¡n Ä‘áº§u, * Giáº£m máº¡nh sau vÃ i epoch, * TÄƒng cháº­m vá» sau. MÃ´ hÃ¬nh freeze cÃ³:
$$

|\Delta $W_t$^{(B)}|_F > |\Delta $W_t$^{(A)}|_F

$$
cho tháº¥y cÃ¡c lá»›p cÃ²n trainable pháº£i â€œgÃ¡nhâ€ pháº§n lá»›n quÃ¡ trÃ¬nh há»c . --- ### 4.5. Thá»i gian tÃ­nh toÃ¡n Theo tÃ i liá»‡u: T_{freeze}\approx 89s,\quad T_{train}\approx 120s Tá»· lá»‡ tiáº¿t kiá»‡m: r\approx 25% Máº·c dÃ¹ khÃ´ng quÃ¡ lá»›n, lá»£i Ã­ch sáº½ tÄƒng máº¡nh vá»›i mÃ´ hÃ¬nh lá»›n hÆ¡n. --- ## 5. ThÃ­ nghiá»‡m Ä‘áº£o ngÆ°á»£c chiáº¿n lÆ°á»£c Ä‘Ã³ng bÄƒng Trong bÃ i táº­p 5, chiáº¿n lÆ°á»£c Ä‘Æ°á»£c Ä‘áº£o ngÆ°á»£c: * Huáº¥n luyá»‡n háº§u háº¿t mÃ´ hÃ¬nh, * ÄÃ³ng bÄƒng attention táº§ng cao. Káº¿t quáº£: \mathcal{L}_A \approx \mathcal{L}_B CÃ¡c Ä‘Æ°á»ng loss gáº§n nhÆ° trÃ¹ng nhau . Äiá»u nÃ y cho tháº¥y: * ÄÃ³ng bÄƒng má»™t sá»‘ lá»›p muá»™n Ã­t áº£nh hÆ°á»Ÿng tá»›i hiá»‡u nÄƒng tá»•ng thá»ƒ. --- ## 6. Tháº£o luáº­n ### 6.1. Ã nghÄ©a cá»§a loss trong mÃ´ hÃ¬nh sinh Trong mÃ´ hÃ¬nh phÃ¢n loáº¡i: \min \mathcal{L}\Rightarrow \max \text{accuracy} NhÆ°ng trong mÃ´ hÃ¬nh sinh: \min \mathcal{L} \not\Rightarrow \max \text{quality} Loss tháº¥p khÃ´ng Ä‘áº£m báº£o vÄƒn báº£n máº¡ch láº¡c hay tá»± nhiÃªn. --- ### 6.2. TÃ­nh á»•n Ä‘á»‹nh huáº¥n luyá»‡n MÃ´ hÃ¬nh freeze cÃ³: Var(\mathcal{L}_B)\lt Var(\mathcal{L}_A) â‡’ á»•n Ä‘á»‹nh hÆ¡n á»Ÿ giai Ä‘oáº¡n Ä‘áº§u. --- ### 6.3. Vai trÃ² cá»§a interpretability Theo tÃ i liá»‡u , viá»‡c chá»n lá»›p Ä‘Ã³ng bÄƒng phá»¥ thuá»™c nhiá»u vÃ o nghiÃªn cá»©u interpretability: * PhÃ¢n tÃ­ch vai trÃ² tá»«ng táº§ng, * Hiá»ƒu cáº¥u trÃºc tri thá»©c ná»™i táº¡i, * XÃ¡c Ä‘á»‹nh vÃ¹ng cáº§n fine-tune. --- ## 7. á»¨ng dá»¥ng thá»±c tiá»…n PhÆ°Æ¡ng phÃ¡p trong nghiÃªn cá»©u phÃ¹ há»£p cho: * Fine-tuning dá»¯ liá»‡u doanh nghiá»‡p, * NLP chuyÃªn ngÃ nh, * Há»‡ thá»‘ng tÃ i nguyÃªn tháº¥p, * Huáº¥n luyá»‡n nhanh mÃ´ hÃ¬nh thá»­ nghiá»‡m. Äáº·c biá»‡t hiá»‡u quáº£ khi:
$$

N_{data}\ll P_{model}