
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../index.md) > [07 fine tune pretrained models](index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../index.md)
- [ğŸ“š Module 01: LLM Course](../01_llm_course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../02_words_to_tokens_to_numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../04_buildgpt/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../07_fine_tune_pretrained_models/index.md)
- [ğŸ” Module 19: AI Safety](../19_ai_safety/index.md)
- [ğŸ Module 20: Python for AI](../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Fine-tuning Hiá»‡u Quáº£ Tham Sá»‘ (Parameter-Efficient Fine-Tuning â€“ PEFT) Trong MÃ´ HÃ¬nh NgÃ´n Ngá»¯ Lá»›n

## TÃ³m táº¯t

BÃ i viáº¿t nÃ y trÃ¬nh bÃ y tá»•ng quan vá» phÆ°Æ¡ng phÃ¡p **Parameter-Efficient Fine-Tuning (PEFT)** â€“ má»™t nhÃ³m ká»¹ thuáº­t fine-tuning giÃºp giáº£m sá»‘ lÆ°á»£ng tham sá»‘ cáº§n huáº¥n luyá»‡n trong cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLMs). Dá»±a trÃªn tÃ i liá»‡u bÃ i giáº£ng , nghiÃªn cá»©u phÃ¢n tÃ­ch cÃ¡c phÆ°Æ¡ng phÃ¡p tiÃªu biá»ƒu nhÆ° Adapter, Low-Rank Adaptation, Prefix Tuning vÃ  Bias Tuning. CÃ¡c cÃ´ng thá»©c toÃ¡n há»c Ä‘Æ°á»£c bá»• sung nháº±m lÃ m rÃµ cÆ¡ sá»Ÿ lÃ½ thuyáº¿t. Káº¿t quáº£ cho tháº¥y PEFT lÃ  giáº£i phÃ¡p phÃ¹ há»£p cho mÃ´i trÆ°á»ng háº¡n cháº¿ tÃ i nguyÃªn tÃ­nh toÃ¡n.

---

## 1. Giá»›i thiá»‡u

CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n hiá»‡n Ä‘áº¡i thÆ°á»ng chá»©a hÃ ng chá»¥c Ä‘áº¿n hÃ ng trÄƒm tá»· tham sá»‘. Viá»‡c fine-tuning toÃ n bá»™ mÃ´ hÃ¬nh Ä‘Ã²i há»i:

* TÃ i nguyÃªn GPU lá»›n,
* Thá»i gian huáº¥n luyá»‡n dÃ i,
* Chi phÃ­ triá»ƒn khai cao.

Theo tÃ i liá»‡u , PEFT Ä‘Æ°á»£c Ä‘á» xuáº¥t nháº±m giáº£i quyáº¿t bÃ i toÃ¡n nÃ y báº±ng cÃ¡ch:

> ÄÃ³ng bÄƒng pháº§n lá»›n tham sá»‘ vÃ  chá»‰ huáº¥n luyá»‡n má»™t táº­p con nhá».

Má»¥c tiÃªu cá»§a PEFT lÃ :

* Giáº£m chi phÃ­ huáº¥n luyá»‡n,
* Duy trÃ¬ hiá»‡u quáº£ há»c,
* PhÃ¹ há»£p vá»›i bÃ i toÃ¡n chuyÃªn biá»‡t.

---

## 2. CÆ¡ sá»Ÿ lÃ½ thuyáº¿t

### 2.1. MÃ´ hÃ¬nh ngÃ´n ngá»¯ tá»± há»“i quy

Cho chuá»—i token:

X=(x_1,x_2,\dots,x_n)

XÃ¡c suáº¥t sinh:

P(X)=\prod_{i=1}^{n}P(x_i \mid x_1,\dots,x_{i-1};\theta)

Trong Ä‘Ã³ $\theta$ lÃ  táº­p tham sá»‘ cá»§a mÃ´ hÃ¬nh.

---

### 2.2. Fine-tuning truyá»n thá»‘ng

Vá»›i hÃ m máº¥t mÃ¡t cross-entropy:

$\mathcal${L}(\theta) = -\frac{1}{N}$\sum$_{i=1}^{N} $\log$ P($y_i$ \mid $x_i$;\theta)

Cáº­p nháº­t báº±ng gradient descent:

\theta_{t+1} = \theta_t-\eta\nabla_\theta\mathcal{L}

ToÃ n bá»™ tham sá»‘ Ä‘á»u Ä‘Æ°á»£c cáº­p nháº­t.

---

### 2.3. Fine-tuning hiá»‡u quáº£ tham sá»‘

Trong PEFT, tham sá»‘ Ä‘Æ°á»£c chia:

\theta = (\theta_f, \theta_t)

vá»›i:

* $\theta_f$: tham sá»‘ Ä‘Ã³ng bÄƒng,
* $\theta_t$: tham sá»‘ huáº¥n luyá»‡n.

Äiá»u kiá»‡n:

$\nabla$_{\theta_f}$\mathcal${L}=0

Chá»‰ $\theta_t$ Ä‘Æ°á»£c cáº­p nháº­t.

---

## 3. Tá»•ng quan vá» PEFT

Theo tÃ i liá»‡u , PEFT lÃ  má»™t **há» phÆ°Æ¡ng phÃ¡p**, khÃ´ng pháº£i má»™t ká»¹ thuáº­t Ä‘Æ¡n láº». CÃ¡c phÆ°Æ¡ng phÃ¡p chÃ­nh gá»“m:

1. Adapter
2. Low-Rank Adaptation $LoRA/DoRA$
3. Prefix Tuning
4. Bias Tuning

CÃ¡c phÆ°Æ¡ng phÃ¡p nÃ y thÆ°á»ng Ä‘Æ°á»£c triá»ƒn khai thÃ´ng qua thÆ° viá»‡n cá»§a Hugging Face.

---

## 4. CÃ¡c phÆ°Æ¡ng phÃ¡p PEFT tiÃªu biá»ƒu

### 4.1. Adapter

#### 4.1.1. NguyÃªn lÃ½

Adapter chÃ¨n cÃ¡c mÃ´-Ä‘un nhá» vÃ o giá»¯a cÃ¡c lá»›p Transformer:

h' = h + W_{up}\sigma(W_{down}h)

Trong Ä‘Ã³:

$$
* W_{down}\in\mathbb{R}^{d\times r}, * W_{up}\in\mathbb{R}^{r\times d},
$$

* $r \ll d$.

Cáº¥u trÃºc giá»‘ng autoencoder nÃ©nâ€“giáº£i nÃ©n.

---

#### 4.1.2. Sá»‘ tham sá»‘

Sá»‘ tham sá»‘ adapter:

P_{adapter}=2dr

So vá»›i:

P_{full}=d^2

â‡’ $P_{adapter}\ll P_{full}$

---

### 4.2. Low-Rank Adaptation (LoRA)

#### 4.2.1. PhÃ¢n rÃ£ ma tráº­n

Cho trá»ng sá»‘ gá»‘c:

W\in\mathbb{R}^{m\times n}

LoRA biá»ƒu diá»…n:

W' = W + BA

vá»›i:

B\in\mathbb{R}^{m\times r},\quad A\in\mathbb{R}^{r\times n}

vÃ  $r\ll \min(m,n$).

---

#### 4.2.2. Giáº£m tham sá»‘

Sá»‘ tham sá»‘:

P_{LoRA}=r(m+n)

So vá»›i:

P_{full}=mn

VÃ­ dá»¥:

* m=n=1000,

* r=100:

P_{full}=10^6,\quad P_{LoRA}=2\times10^5

---

### 4.3. Prefix Tuning

#### 4.3.1. CÆ¡ cháº¿

ThÃªm vector tiá»n tá»‘ $$P(:

)
X' = [P; X]

vá»›i:

P\in\mathbb{R}^{k\times d}

Äáº§u vÃ o attention:

Q,K,V = (X'W_Q,X'W_K,X'W_V)

$$
Chá»‰ P( Ä‘Æ°á»£c huáº¥n luyá»‡n. --- #### 4.3.2. Sá»‘ tham sá»‘ ) P_{prefix}=kd Ráº¥t nhá» so vá»›i toÃ n mÃ´ hÃ¬nh. --- ### 4.4. Bias Tuning #### 4.4.1. NguyÃªn lÃ½ Chá»‰ huáº¥n luyá»‡n bias: y = Wx + b Cáº­p nháº­t: b_{t+1}=b_t-\eta\nabla_b\mathcal{L} Giá»¯ nguyÃªn W. --- #### 4.4.2. Äáº·c Ä‘iá»ƒm Bias chá»§ yáº¿u dá»‹ch chuyá»ƒn phÃ¢n phá»‘i: P'(y|x)=P(y-b \mid x) áº¢nh hÆ°á»Ÿng yáº¿u Ä‘áº¿n cáº¥u trÃºc biá»ƒu diá»…n. --- ## 5. PhÃ¢n tÃ­ch hiá»‡u quáº£ PEFT ### 5.1. Chi phÃ­ tÃ­nh toÃ¡n Gá»i: * P_{full}: tham sá»‘ Ä‘áº§y Ä‘á»§, * P_{peft}: tham sá»‘ PEFT. Tá»· lá»‡: r=\frac{P_{peft}}{P_{full}}\ll 1 Thá»i gian huáº¥n luyá»‡n: T_{peft}\approx rT_{full} --- ### 5.2. Kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a Khi sá»‘ tham sá»‘ giáº£m:
$$

P\downarrow \Rightarrow Var(\theta)\downarrow

$$
â‡’ giáº£m overfitting. Tuy nhiÃªn:
$$

Bias(\theta)\uparrow

$$
â‡’ mÃ´ hÃ¬nh kÃ©m linh hoáº¡t. --- ### 5.3. ÄÃ¡nh Ä‘á»•i hiá»‡u nÄƒng Giáº£ sá»­:
$$

Acc_{full},\quad Acc_{peft}

$$
ThÃ´ng thÆ°á»ng: Acc_{peft}\le Acc_{full} nhÆ°ng:
$$

\frac{Acc_{peft}}{Cost_{peft}} > \frac{Acc_{full}}{Cost_{full}}

$$
â‡’ PEFT hiá»‡u quáº£ vá» chi phÃ­. --- ## 6. Tháº£o luáº­n ### 6.1. Æ¯u Ä‘iá»ƒm 1. Giáº£m tÃ i nguyÃªn GPU. 2. Huáº¥n luyá»‡n nhanh. 3. LÆ°u trá»¯ gá»n nháº¹. 4. Dá»… triá»ƒn khai. --- ### 6.2. Háº¡n cháº¿ Theo tÃ i liá»‡u : * Hiá»‡u nÄƒng tháº¥p hÆ¡n fine-tuning Ä‘áº§y Ä‘á»§, * KhÃ³ tá»•ng quÃ¡t hÃ³a Ä‘a nhiá»‡m, * Phá»¥ thuá»™c bÃ i toÃ¡n. --- ### 6.3. Khi nÃ o nÃªn dÃ¹ng PEFT? PEFT phÃ¹ há»£p khi:
$$

N_{data}\ll P_{model}