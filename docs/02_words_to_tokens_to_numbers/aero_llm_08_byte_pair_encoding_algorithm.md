
<!-- Aero-Navigation-Start -->
[üè† Home](../index.md) > [02 words to tokens to numbers](index.md)

---
### üß≠ ƒêi·ªÅu h∆∞·ªõng nhanh

- [üè† C·ªïng t√†i li·ªáu](../index.md)
- [üìö Module 01: LLM Course](../01_llm_course/index.md)
- [üî¢ Module 02: Tokenization](../02_words_to_tokens_to_numbers/index.md)
- [üèóÔ∏è Module 04: Build GPT](../04_buildgpt/index.md)
- [üéØ Module 07: Fine-tuning](../07_fine_tune_pretrained_models/index.md)
- [üîç Module 19: AI Safety](../19_ai_safety/index.md)
- [üêç Module 20: Python for AI](../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
Nh∆∞ v·∫≠y, t·ª´ ‚Äúlowest‚Äù c√≥ th·ªÉ bi·ªÉu di·ªÖn th√†nh:

$$

$$

\text{lowest} = \text{low} + \text{est}

$$

$$

---

## 5. Bi·ªÉu di·ªÖn Embedding v√† K√≠ch th∆∞·ªõc T√≠nh to√°n

Gi·∫£ s·ª≠:

- K√≠ch th∆∞·ªõc t·ª´ v·ª±ng: $V$
- K√≠ch th∆∞·ªõc embedding: $d$

Ma tr·∫≠n embedding:

$$

$$

E \in \mathbb{R}^{V \times d}

$$

$$

S·ªë tham s·ªë c·ªßa embedding:

$$

$$

\text{Params} = V \times d

$$

$$

N·∫øu d√πng word-level tokenization:

$$

$$

V \approx 500,000

$$

$$

N·∫øu d√πng BPE:

$$

$$

V \approx 30,000 - 50,000

$$

$$

Gi·∫£m s·ªë tham s·ªë ƒë√°ng k·ªÉ:

$$

$$

\Delta = (V_{word} - V_{BPE}) \times d

$$

$$

ƒêi·ªÅu n√†y gi√∫p:
- Gi·∫£m b·ªô nh·ªõ
- TƒÉng t·ªëc hu·∫•n luy·ªán
- C·∫£i thi·ªán kh·∫£ nƒÉng t·ªïng qu√°t h√≥a

---

## 6. BPE trong M√¥ h√¨nh Transformer

Trong ki·∫øn tr√∫c Transformer, chu·ªói token ƒë∆∞·ª£c √°nh x·∫° sang embedding:

$$

$$

x_i = E(t_i)

$$

$$

Sau ƒë√≥ ƒë∆∞·ª£c ƒë∆∞a v√†o c∆° ch·∫ø Attention:

$$

$$

\text{Attention}(Q, K, V) = \text{softmax} \left( \frac{QK^T}{\sqrt{d_k}} \right) V

$$

$$

Vi·ªác s·ª≠ d·ª•ng BPE gi√∫p:

- Gi·∫£m chi·ªÅu d√†i chu·ªói so v·ªõi character-level.
- Gi·ªØ th√¥ng tin h√¨nh th√°i t·ªët h∆°n word-level.
- T·ªëi ∆∞u h√≥a hi·ªáu su·∫•t attention.

---

## 7. So s√°nh v·ªõi c√°c ph∆∞∆°ng ph√°p kh√°c

| Ph∆∞∆°ng ph√°p | ƒê∆°n v·ªã | ∆Øu ƒëi·ªÉm | Nh∆∞·ª£c ƒëi·ªÉm |
|------------|--------|----------|------------|
| Word-level | T·ª´ | D·ªÖ hi·ªÉu | OOV cao |
| Character-level | K√Ω t·ª± | Kh√¥ng OOV | Chu·ªói d√†i |
| BPE | Subword | C√¢n b·∫±ng t·ªët | Ph·ª• thu·ªôc s·ªë v√≤ng g·ªôp |

---

## 8. ·ª®ng d·ª•ng trong M√¥ h√¨nh Ng√¥n ng·ªØ L·ªõn

C√°c m√¥ h√¨nh nh∆∞ GPT s·ª≠ d·ª•ng bi·∫øn th·ªÉ c·ªßa BPE ƒë·ªÉ x√¢y d·ª±ng tokenizer. V·ªõi d·ªØ li·ªáu hu·∫•n luy·ªán h√†ng trƒÉm t·ª∑ token, BPE cho ph√©p:

- N√©n bi·ªÉu di·ªÖn t·ª´ v·ª±ng.
- TƒÉng kh·∫£ nƒÉng h·ªçc c·∫•u tr√∫c ng√¥n ng·ªØ.
- X·ª≠ l√Ω t·ªët t·ª´ hi·∫øm v√† t·ª´ m·ªõi.

Gi·∫£ s·ª≠ t·ªïng s·ªë token hu·∫•n luy·ªán:

$$

$$

T = 10^{11}

$$

$$

Th·ªùi gian hu·∫•n luy·ªán ph·ª• thu·ªôc v√†o:

$$
\mathcal{O}(T \cdot L \cdot d^2)
$$

Trong ƒë√≥:
- $L$: chi·ªÅu d√†i chu·ªói
- $d$: k√≠ch th∆∞·ªõc m√¥ h√¨nh

BPE gi√∫p gi·∫£m $L$ so v·ªõi character-level ‚Üí gi·∫£m chi ph√≠ t√≠nh to√°n.

---

## 9. H·∫°n ch·∫ø c·ªßa BPE

- Kh√¥ng x√©t ng·ªØ nghƒ©a khi g·ªôp token.
- C√≥ th·ªÉ t·∫°o token kh√¥ng tr·ª±c quan.
- Ph·ª• thu·ªôc m·∫°nh v√†o d·ªØ li·ªáu hu·∫•n luy·ªán ban ƒë·∫ßu.

---

## 10. K·∫øt lu·∫≠n

Byte Pair Encoding l√† m·ªôt ph∆∞∆°ng ph√°p ph√¢n t√°ch t·ª´ hi·ªáu qu·∫£, ƒë√≥ng vai tr√≤ n·ªÅn t·∫£ng trong c√°c m√¥ h√¨nh ng√¥n ng·ªØ hi·ªán ƒë·∫°i. Nh·ªù kh·∫£ nƒÉng c√¢n b·∫±ng gi·ªØa k√≠ch th∆∞·ªõc t·ª´ v·ª±ng v√† chi·ªÅu d√†i chu·ªói, BPE gi√∫p t·ªëi ∆∞u h√≥a c·∫£ b·ªô nh·ªõ v√† hi·ªáu su·∫•t t√≠nh to√°n.

Trong b·ªëi c·∫£nh c√°c m√¥ h√¨nh ng√†y c√†ng l·ªõn (h√†ng trƒÉm t·ª∑ tham s·ªë), vi·ªác t·ªëi ∆∞u tokenizer nh∆∞ BPE kh√¥ng ch·ªâ l√† b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω, m√† c√≤n ·∫£nh h∆∞·ªüng tr·ª±c ti·∫øp ƒë·∫øn hi·ªáu qu·∫£ hu·∫•n luy·ªán v√† suy lu·∫≠n.

---

## T√†i li·ªáu tham kh·∫£o

1. Gage, P. (1994). *A New Algorithm for Data Compression.*
2. Sennrich, R., Haddow, B., & Birch, A. (2016). *Neural Machine Translation of Rare Words with Subword Units.*
3. Vaswani, A. et al. (2017). *Attention Is All You Need.*
4. Radford, A. et al. (2019). *Language Models are Unsupervised Multitask Learners.*

---
<!-- Aero-Footer-Start -->

## üìÑ T√†i li·ªáu c√πng chuy√™n m·ª•c
| B√†i h·ªçc | Li√™n k·∫øt |
| :--- | :--- |
| [T·∫°i sao vƒÉn b·∫£n c·∫ßn ƒë∆∞·ª£c ƒë√°nh s·ªë?](aero_llm_01_why_text_needs_to_be_numbered.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_01_why_text_needs_to_be_numbered.md) |
| [Ph√¢n t√≠ch v√† chuy·ªÉn ƒë·ªïi vƒÉn b·∫£n th√†nh chu·ªói token ƒë∆∞·ª£c ƒë√°nh s·ªë: C∆° s·ªü to√°n h·ªçc v√† ·ª©ng d·ª•ng trong m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn](aero_llm_02_parsing_text_to_numbered_tokens.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_02_parsing_text_to_numbered_tokens.md) |
| [T·∫°o v√† tr·ª±c quan h√≥a Token trong m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn: C∆° s·ªü to√°n h·ªçc v√† ph√¢n t√≠ch bi·ªÉu di·ªÖn](aero_llm_03_codechallenge_create_and_visualize_tokens_part_1_.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_03_codechallenge_create_and_visualize_tokens_part_1_.md) |
| [T·∫°o v√† tr·ª±c quan h√≥a Token (Ph·∫ßn 2): Ph√¢n t√≠ch h√¨nh h·ªçc kh√¥ng gian embedding v√† Attention Map trong m√¥ h√¨nh Transformer](aero_llm_04_codechallenge_create_and_visualize_tokens_part_2_.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_04_codechallenge_create_and_visualize_tokens_part_2_.md) |
| [Chu·∫©n b·ªã vƒÉn b·∫£n cho Tokenization trong m√¥ h√¨nh Transformer: C∆° s·ªü l√Ω thuy·∫øt v√† ph√¢n t√≠ch to√°n h·ªçc](aero_llm_05_preparing_text_for_tokenization.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_05_preparing_text_for_tokenization.md) |
| [Ph√¢n t√≠ch quy tr√¨nh Tokenization qua v√≠ d·ª• *The Time Machine*: C∆° s·ªü thu·∫≠t to√°n v√† m√¥ h√¨nh h√≥a to√°n h·ªçc](aero_llm_06_codechallenge_tokenizing_the_time_machine.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_06_codechallenge_tokenizing_the_time_machine.md) |
| [So s√°nh Tokenization m·ª©c k√Ω t·ª±, t·ª´ v√† subword: Ph√¢n t√≠ch l√Ω thuy·∫øt v√† m√¥ h√¨nh to√°n h·ªçc](aero_llm_07_tokenizing_characters_vs_subwords_vs_words.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_07_tokenizing_characters_vs_subwords_vs_words.md) |
| üìå **[aero llm 08 byte pair encoding algorithm](aero_llm_08_byte_pair_encoding_algorithm.md)** | [Xem b√†i vi·∫øt ‚Üí](aero_llm_08_byte_pair_encoding_algorithm.md) |
| [Thu·∫≠t to√°n Byte Pair Encoding (BPE) v√† B√†i to√°n T·ªëi ∆∞u K√≠ch th∆∞·ªõc T·ª´ v·ª±ng trong M√¥ h√¨nh Ng√¥n ng·ªØ](aero_llm_09_codechallenge_byte_pair_encoding_to_a_desired_vocab_size.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_09_codechallenge_byte_pair_encoding_to_a_desired_vocab_size.md) |
| [aero llm 10 exploring chatgpt4 s tokenizer](aero_llm_10_exploring_chatgpt4_s_tokenizer.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_10_exploring_chatgpt4_s_tokenizer.md) |
| [aero llm 11 codechallenge token count by subword length part 1](aero_llm_11_codechallenge_token_count_by_subword_length_part_1_.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_11_codechallenge_token_count_by_subword_length_part_1_.md) |
| [aero llm 12 codechallenge token count by subword length part 2](aero_llm_12_codechallenge_token_count_by_subword_length_part_2_.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_12_codechallenge_token_count_by_subword_length_part_2_.md) |
| [aero llm 13 how many rs in strawberry](aero_llm_13_how_many_rs_in_strawberry.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_13_how_many_rs_in_strawberry.md) |
| [aero llm 14 codechallenge create your algorithmic rapper name](aero_llm_14_codechallenge_create_your_algorithmic_rapper_name_.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_14_codechallenge_create_your_algorithmic_rapper_name_.md) |
| [aero llm 15 tokenization in bert](aero_llm_15_tokenization_in_bert.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_15_tokenization_in_bert.md) |
| [aero llm 16 codechallenge character counts in bert tokens](aero_llm_16_codechallenge_character_counts_in_bert_tokens.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_16_codechallenge_character_counts_in_bert_tokens.md) |
| [aero llm 17 translating between tokenizers](aero_llm_17_translating_between_tokenizers.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_17_translating_between_tokenizers.md) |
| [aero llm 18 codechallenge more on token translation](aero_llm_18_codechallenge_more_on_token_translation.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_18_codechallenge_more_on_token_translation.md) |
| [aero llm 19 codechallenge tokenization compression ratios](aero_llm_19_codechallenge_tokenization_compression_ratios.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_19_codechallenge_tokenization_compression_ratios.md) |
| [aero llm 20 tokenization in different languages](aero_llm_20_tokenization_in_different_languages.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_20_tokenization_in_different_languages.md) |
| [aero llm 21 codechallenge zipf s law in characters and tokens](aero_llm_21_codechallenge_zipf_s_law_in_characters_and_tokens.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_21_codechallenge_zipf_s_law_in_characters_and_tokens.md) |
| [aero llm 22 word variations in claude tokenizer](aero_llm_22_word_variations_in_claude_tokenizer.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_22_word_variations_in_claude_tokenizer.md) |

---
## ü§ù Li√™n h·ªá & ƒê√≥ng g√≥p
D·ª± √°n ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi **Pixibox**. M·ªçi ƒë√≥ng g√≥p v·ªÅ n·ªôi dung v√† m√£ ngu·ªìn ƒë·ªÅu ƒë∆∞·ª£c ch√†o ƒë√≥n.

> *"Ki·∫øn th·ª©c l√† ƒë·ªÉ chia s·∫ª. H√£y c√πng nhau x√¢y d·ª±ng c·ªông ƒë·ªìng AI v·ªØng m·∫°nh!"* üöÄ

*C·∫≠p nh·∫≠t t·ª± ƒë·ªông b·ªüi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
