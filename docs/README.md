# üìÇ Aero-HowtoLLMs Documentation

Kho l∆∞u tr·ªØ t√†i li·ªáu h∆∞·ªõng d·∫´n chuy√™n s√¢u v·ªÅ **Large Language Models (LLM)** v√† c√°c c√¥ng ngh·ªá AI li√™n quan.

## üéì Kh√≥a H·ªçc Ch√≠nh

### [Transformers & Large Language Models (LLM)](LLM_Course/README.md) ü§ñ
> **Ngu·ªìn:** Stanford CME 295 & T√†i li·ªáu b·ªï tr·ª£ Reinforcement Learning.

Kh√≥a h·ªçc to√†n di·ªán t·ª´ A-Z gi√∫p b·∫°n l√†m ch·ªß c√¥ng ngh·ªá LLM:

*   **N·ªÅn t·∫£ng:** Transformer, BERT, GPT, T5.
*   **Hu·∫•n luy·ªán:** Pre-training, Fine-tuning (PEFT/LoRA), RLHF.
*   **·ª®ng d·ª•ng:** Prompt Engineering, RAG, AI Agents.
*   **B·ªï tr·ª£:** Ki·∫øn th·ª©c n·ªÅn t·∫£ng v·ªÅ Reinforcement Learning (MDP, Bellman).

üëâ **[B·∫ÆT ƒê·∫¶U H·ªåC NGAY](LLM_Course/README.md)**

---
*Bi√™n so·∫°n b·ªüi Pixiboss.*
