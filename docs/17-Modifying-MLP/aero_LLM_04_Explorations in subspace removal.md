
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../index.md) > [17 Modifying MLP](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../index.md)
- [ğŸ“š Module 01: LLM Course](../../01-LLM_Course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../02-Words-to-tokens-to-numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../04-buildGPT/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../07-Fine-tune-pretrained-models/index.md)
- [ğŸ” Module 19: AI Safety](../../19-AI-safety/index.md)
- [ğŸ Module 20: Python for AI](../../20-Python-Colab-notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# KhÃ¡m phÃ¡ viá»‡c Loáº¡i bá» KhÃ´ng gian con trong MLP (Explorations in Subspace Removal)

## TÃ³m táº¯t (Abstract)
BÃ¡o cÃ¡o nÃ y trÃ¬nh bÃ y má»™t ká»¹ thuáº­t can thiá»‡p tÃ¢n tiáº¿n dá»±a trÃªn Ä‘áº¡i sá»‘ tuyáº¿n tÃ­nh Ä‘á»ƒ nghiÃªn cá»©u khá»‘i MLP: Loáº¡i bá» khÃ´ng gian con (Subspace Removal). Thay vÃ¬ triá»‡t tiÃªu cÃ¡c neurons riÃªng láº», phÆ°Æ¡ng phÃ¡p nÃ y sá»­ dá»¥ng PhÃ¢n tÃ¡ch giÃ¡ trá»‹ suy biáº¿n (SVD) Ä‘á»ƒ xÃ¡c Ä‘á»‹nh cÃ¡c thÃ nh pháº§n chiáº¿m phÆ°Æ¡ng sai lá»›n nháº¥t (principal components) vÃ  chiáº¿u chÃºng ra khá»i dá»¯ liá»‡u hoáº¡t hÃ³a. Thá»±c nghiá»‡m trÃªn GPT-2 Excel (6400 neurons MLP) cho tháº¥y viá»‡c loáº¡i bá» chá»‰ má»™t chiá»u (1D subspace) mang phÆ°Æ¡ng sai lá»›n nháº¥t cÃ³ thá»ƒ phÃ¡ há»§y cÃ¡c cáº¥u trÃºc hiá»‡p biáº¿n (covariance patterns) phÃ¢n tÃ¡n trÃªn hÃ ng ngÃ n neurons, dáº«n Ä‘áº¿n hiá»‡u á»©ng gá»£n sÃ³ng (ripple effects) tÃ­ch tá»¥ qua cÃ¡c táº§ng vÃ  lÃ m suy yáº¿u kháº£ nÄƒng táº­n dá»¥ng tri thá»©c tháº¿ giá»›i cá»§a mÃ´ hÃ¬nh.

---

## 1. Má»Ÿ Äáº§u (Introduction)
CÃ¡c phÆ°Æ¡ng phÃ¡p can thiá»‡p trÆ°á»›c Ä‘Ã¢y táº­p trung vÃ o tÃ­nh thÆ°a (sparsity) cá»§a tá»«ng neuron. Tuy nhiÃªn, thÃ´ng tin trong LLM thÆ°á»ng Ä‘Æ°á»£c mÃ£ hÃ³a phÃ¢n tÃ¡n (distributed representation). BÃ¡o cÃ¡o nÃ y Ä‘á» xuáº¥t viá»‡c bÃ¡c bá» khÃ´ng gian con â€“ má»™t ká»¹ thuáº­t ngÆ°á»£c láº¡i vá»›i nÃ©n dá»¯ liá»‡u PCA â€“ Ä‘á»ƒ kiá»ƒm chá»©ng vai trÃ² cá»§a cÃ¡c thÃ nh pháº§n tiá»m áº©n Ä‘á»‘i vá»›i hÃ nh vi cá»§a mÃ´ hÃ¬nh.

---

## 2. PhÆ°Æ¡ng PhÃ¡p Thá»±c Nghiá»‡m (Methodology)

### 2.1. Pháº«u thuáº­t SVD trÃªn Hoáº¡t hÃ³a MLP
- **Dá»¯ liá»‡u:** Ma tráº­n hoáº¡t hÃ³a $A$ kÃ­ch thÆ°á»›c `[tokens, neurons]`.
- **PhÃ¢n tÃ¡ch:** $A = U \Sigma V^T$.
- **Can thiá»‡p:** GÃ¡n giÃ¡ trá»‹ 0 cho giÃ¡ trá»‹ suy biáº¿n lá»›n nháº¥t ($\sigma_1 = 0$) trong ma tráº­n $\Sigma$.
- **TÃ¡i thiáº¿t:** TÃ­nh toÃ¡n ma tráº­n Ä‘Ã£ can thiá»‡p $A_{proj} = U \Sigma_{modified} V^T$.
- **BÃ¹ trá»« giÃ¡ trá»‹ trung bÃ¬nh:** Má»™t bÆ°á»›c quan trá»ng lÃ  cá»™ng láº¡i vector trung bÃ¬nh ($\mu$) cá»§a dá»¯ liá»‡u gá»‘c vÃ o $A_{proj}$ Ä‘á»ƒ Ä‘áº£m báº£o phÃ¢n phá»‘i khÃ´ng bá»‹ dá»‹ch chuyá»ƒn quÃ¡ má»©c khi Ä‘i qua hÃ m GELU.

### 2.2. Triá»ƒn khai Hook vÃ  Äo lÆ°á»ng
Sá»­ dá»¥ng mÃ´ hÃ¬nh GPT-2 Excel vá»›i 48 táº§ng. Hook Ä‘Æ°á»£c Ä‘áº·t táº¡i táº§ng `c_fc` Ä‘á»ƒ can thiá»‡p vÃ o khÃ´ng gian MLP trÆ°á»›c khi pháº£n há»“i láº¡i residual stream. Biáº¿n quan sÃ¡t lÃ  chuáº©n (norm) cá»§a sá»± sai lá»‡ch vector hidden states vÃ  logit cá»§a token dá»± Ä‘oÃ¡n tiáº¿p theo.

---

## 3. Káº¿t Quáº£ VÃ  PhÃ¢n TÃ­ch (Results & Analysis)

### 3.1. Sá»± phÃ¡ há»§y cáº¥u trÃºc Hiá»‡p biáº¿n (Covariance Destruction)
- **Quan sÃ¡t:** Máº·c dÃ¹ cÃ¡c giÃ¡ trá»‹ neuron cÃ¡ nhÃ¢n chá»‰ thay Ä‘á»•i ráº¥t Ã­t sau khi loáº¡i bá» principal component, ma tráº­n hiá»‡p biáº¿n bá»‹ biáº¿n Ä‘á»•i sÃ¢u sáº¯c. 
- **Káº¿t luáº­n:** ThÃ nh pháº§n chÃ­nh Ä‘áº§u tiÃªn khÃ´ng chá»‰ lÃ  "nhiá»…u" mÃ  mang giá»¯ cÃ¡c mÃ´ thá»©c tÆ°Æ¡ng quan phá»©c táº¡p giá»¯a hÃ ng ngÃ n neurons. Loáº¡i bá» nÃ³ tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i viá»‡c xÃ³a bá» "ngá»¯ cáº£nh chung" mÃ  cÃ¡c neurons Ä‘ang cÃ¹ng chia sáº».

### 3.2. Hiá»‡u á»©ng Gá»£n sÃ³ng vÃ  TÃ­ch tá»¥ (Compounding Effects)
- **CÆ¡ cháº¿:** ThÃ­ nghiá»‡m can thiá»‡p táº¡i má»™t táº§ng duy nháº¥t (vÃ­ dá»¥ táº§ng 24) cho tháº¥y sai lá»‡ch trong hidden states tÄƒng dáº§n theo Ä‘á»™ sÃ¢u cá»§a mÃ´ hÃ¬nh.
- **Giáº£i thÃ­ch:** Má»—i block transformer thá»±c hiá»‡n má»™t Ä‘iá»u chá»‰nh nhá». Náº¿u Ä‘áº§u vÃ o cá»§a block $N+1$ Ä‘Ã£ bá»‹ sai lá»‡ch tá»« block $N$, cÃ¡c Ä‘iá»u chá»‰nh tiáº¿p theo sáº½ lÃ m sai lá»‡ch Ä‘Ã³ tráº§m trá»ng hÆ¡n. ÄÃ¢y lÃ  hiá»‡n tÆ°á»£ng "embedding drift".

### 3.3. TÃ¡c Ä‘á»™ng lÃªn Dá»± Ä‘oÃ¡n Token
- **PhÃ¢n tÃ­ch T-test:** Cháº¡y thá»‘ng kÃª trÃªn toÃ n bá»™ cÃ¢u cho tháº¥y viá»‡c loáº¡i bá» thÃ nh pháº§n chÃ­nh lÃ m giáº£m logit cá»§a token Ä‘Ãºng á»Ÿ háº§u háº¿t cÃ¡c táº§ng.
- **Má»‘i tÆ°Æ¡ng quan giá»¯a PhÆ°Æ¡ng sai vÃ  TÃ¡c Ä‘á»™ng:** CÃ³ má»™t má»‘i tÆ°Æ¡ng quan yáº¿u giá»¯a tá»· lá»‡ phÆ°Æ¡ng sai mÃ  thÃ nh pháº§n chÃ­nh chiáº¿m giá»¯ vÃ  má»©c Ä‘á»™ sá»¥t giáº£m hiá»‡u nÄƒng. Tuy nhiÃªn, cÃ¡c táº§ng Ä‘áº§u tiÃªn cá»§a mÃ´ hÃ¬nh Ä‘Ã³ng vai trÃ² quyáº¿t Ä‘á»‹nh, nÆ¡i principal component chiáº¿m tá»· trá»ng ráº¥t lá»›n (Ä‘áº¿n 37% phÆ°Æ¡ng sai).

---

## 4. Tháº£o Luáº­n: Giá»›i háº¡n cá»§a Giáº£ Ä‘á»‹nh PCA
NghiÃªn cá»©u chá»‰ ra ráº±ng máº·c dÃ¹ PCA lÃ  cÃ´ng cá»¥ máº¡nh máº½, giáº£ Ä‘á»‹nh "phÆ°Æ¡ng sai lá»›n nháº¥t tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i thÃ´ng tin quan trá»ng nháº¥t" khÃ´ng pháº£i lÃºc nÃ o cÅ©ng Ä‘Ãºng trong diá»…n giáº£i há»c cÆ¡ há»c. CÃ¡c chiá»u cÃ³ phÆ°Æ¡ng sai nhá» hÆ¡n Ä‘Ã´i khi láº¡i mang thÃ´ng tin ngá»¯ nghÄ©a cá»¥ thá»ƒ hÆ¡n. Tuy nhiÃªn, quy trÃ¬nh ká»¹ thuáº­t Ä‘Æ°á»£c giá»›i thiá»‡u á»Ÿ Ä‘Ã¢y cÃ³ thá»ƒ Ã¡p dá»¥ng cho báº¥t ká»³ phÆ°Æ¡ng thá»©c phÃ¢n tÃ¡ch tuyáº¿n tÃ­nh nÃ o (nhÆ° ICA hoáº·c Sparse Autoencoders).

---

## 5. Káº¿t Luáº­n
BÃ¡o cÃ¡o kháº³ng Ä‘á»‹nh táº§m quan trá»ng cá»§a viá»‡c nhÃ¬n nháº­n MLP nhÆ° má»™t khÃ´ng gian vector thay vÃ¬ chá»‰ lÃ  táº­p há»£p cÃ¡c Ä‘Æ¡n vá»‹ Ä‘á»™c láº­p. Viá»‡c bÃ¡c bá» khÃ´ng gian con má»Ÿ ra má»™t hÆ°á»›ng Ä‘i má»›i Ä‘á»ƒ "táº¯t" cÃ¡c khÃ¡i niá»‡m hoáº·c mÃ´ thá»©c tÆ° duy cá»¥ thá»ƒ trong LLM mÃ  khÃ´ng cáº§n tÃ¡c Ä‘á»™ng thÃ´ báº¡o lÃªn cáº¥u trÃºc váº­t lÃ½ cá»§a máº¡ng.

---

## TÃ i liá»‡u tham kháº£o (Citations)
1. Thá»±c nghiá»‡m Subspace Removal trÃªn GPT-2 Excel dá»±a trÃªn `aero_LLM_04_Explorations in subspace removal.md`. PhÃ¢n tÃ­ch SVD vÃ  hiá»‡u á»©ng tÃ­ch tá»¥ sai lá»‡ch embeddings.
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| [Thay tháº¿ Trung vá»‹ Ná»‘i tiáº¿p cÃ¡c Neurons trong Lá»›p MLP (Successive Median-Replacement of MLP Neurons)](aero_LLM_01_Successive median-replacement of MLP neurons.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_01_Successive median-replacement of MLP neurons.md) |
| [Cáº¯t bá» Tiá»‡m cáº­n cÃ¡c Neurons MLP trÃªn cÆ¡ sá»Ÿ Thá»‘ng kÃª (Statistics-based Lesioning of MLP Neurons)](aero_LLM_02_Statistics-based lesioning MLP neurons.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_02_Statistics-based lesioning MLP neurons.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Há»“ sÆ¡ PhÃ¢n táº§ng cá»§a cÃ¡c T-lesions trong MLP (Laminar Profile of MLP T-lesions)](aero_LLM_03_CodeChallenge Laminar profile of MLP t-lesions.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_03_CodeChallenge Laminar profile of MLP t-lesions.md) |
| ğŸ“Œ **[KhÃ¡m phÃ¡ viá»‡c Loáº¡i bá» KhÃ´ng gian con trong MLP (Explorations in Subspace Removal)](aero_LLM_04_Explorations in subspace removal.md)** | [Xem bÃ i viáº¿t â†’](aero_LLM_04_Explorations in subspace removal.md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
