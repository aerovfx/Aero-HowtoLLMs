
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../index.md) > [09 quantitative evaluations](index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../index.md)
- [ğŸ“š Module 01: LLM Course](../01_llm_course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../02_words_to_tokens_to_numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../04_buildgpt/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../07_fine_tune_pretrained_models/index.md)
- [ğŸ” Module 19: AI Safety](../19_ai_safety/index.md)
- [ğŸ Module 20: Python for AI](../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
ÄÃ¡nh giÃ¡ HellaSwag trÃªn hai mÃ´ hÃ¬nh ngÃ´n ngá»¯: PhÃ¢n tÃ­ch Ä‘á»‹nh lÆ°á»£ng vÃ  so sÃ¡nh xÃ¡c suáº¥t sinh chuá»—i

Tiáº¿p cáº­n log-likelihood, chuáº©n hoÃ¡ Ä‘á»™ dÃ i vÃ  Ã½ nghÄ©a thá»‘ng kÃª

â¸»

TÃ³m táº¯t

BÃ i viáº¿t nÃ y trÃ¬nh bÃ y phÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡ bá»™ dá»¯ liá»‡u HellaSwag trÃªn hai mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLMs), dá»±a trÃªn ná»™i dung tÃ i liá»‡u Ä‘Ã­nh kÃ¨m. ChÃºng tÃ´i phÃ¢n tÃ­ch cÆ¡ cháº¿ tÃ­nh Ä‘iá»ƒm báº±ng log-likelihood, chuáº©n hoÃ¡ theo Ä‘á»™ dÃ i chuá»—i, vÃ  phÆ°Æ¡ng phÃ¡p tÃ­nh accuracy. BÃ i viáº¿t má»Ÿ rá»™ng vá»›i cÃ¡c ná»n táº£ng lÃ½ thuyáº¿t tá»« nghiÃªn cá»©u cá»§a Rowan Zellers et al. (2019), kiáº¿n trÃºc Transformer cá»§a Ashish Vaswani et al. (2017), vÃ  cÃ¡c phÃ¢n tÃ­ch scaling tá»« OpenAI.

â¸»

1. Giá»›i thiá»‡u

HellaSwag lÃ  bá»™ benchmark Ä‘o lÆ°á»ng kháº£ nÄƒng:
	â€¢	Suy luáº­n thÆ°á»ng thá»©c (commonsense reasoning)
	â€¢	Hiá»ƒu chuá»—i hÃ nh Ä‘á»™ng váº­t lÃ½
	â€¢	PhÃ¢n biá»‡t continuation há»£p lÃ½ vÃ  phi lÃ½

Trong bÃ i toÃ¡n nÃ y, má»—i cÃ¢u há»i gá»“m:
	â€¢	Ngá»¯ cáº£nh c
	â€¢	4 lá»±a chá»n hoÃ n thÃ nh \{a_1, a_2, a_3, a_4\}

Má»¥c tiÃªu: chá»n Ä‘Ã¡p Ã¡n cÃ³ xÃ¡c suáº¥t cao nháº¥t theo mÃ´ hÃ¬nh.

â¸»

2. MÃ´ hÃ¬nh xÃ¡c suáº¥t cho bÃ i toÃ¡n multiple choice

Vá»›i mÃ´ hÃ¬nh tá»± há»“i quy (autoregressive), xÃ¡c suáº¥t cá»§a má»™t Ä‘Ã¡p Ã¡n Ä‘Æ°á»£c tÃ­nh:

P$a_i \mid c$ = \prod_{t=1}^{T_i} P$w_t \mid c, w_{\lt t}$

Trong thá»±c nghiá»‡m, ta dÃ¹ng log Ä‘á»ƒ trÃ¡nh underflow:

\log P$a_i \mid c$ = \sum_{t=1}^{T_i} \log P$w_t \mid c, w_{\lt t}$

â¸»

3. Váº¥n Ä‘á» thiÃªn lá»‡ch Ä‘á»™ dÃ i (Length Bias)

Náº¿u dÃ¹ng tá»•ng log-likelihood trá»±c tiáº¿p:
	â€¢	Chuá»—i dÃ i â†’ log nhá» hÆ¡n (Ã¢m hÆ¡n)
	â€¢	Chuá»—i ngáº¯n â†’ Ä‘Æ°á»£c Æ°u tiÃªn

Do Ä‘Ã³ cáº§n chuáº©n hoÃ¡:

Score$a_i$ = \frac{1}{T_i} \sum_{t=1}^{T_i} \log P$w_t \mid c, w_{\lt t}$

ÄÃ¢y lÃ  ave18_rage log-probability.

â¸»

4. Quy táº¯c chá»n Ä‘Ã¡p Ã¡n

\hat{a} = \arg\max_{a_i} Score$a_i$

Accuracy Ä‘Æ°á»£c tÃ­nh:

Accuracy = \frac{1}{N} \sum_{j=1}^{N} \mathbf{1}$\hat{a}^{(j$} = a_{\text{true}}^{$j$})

Baseline ngáº«u nhiÃªn:

P_{\text{random}} = 25\%

â¸»

5. So sÃ¡nh hai mÃ´ hÃ¬nh

Giáº£ sá»­ hai mÃ´ hÃ¬nh:
	â€¢	M_1
	â€¢	M_2

Accuracy tÆ°Æ¡ng á»©ng:

\hat{p}_1, \hat{p}_2

Sai sá»‘ chuáº©n:

SE = \sqrt{\frac{\hat{p}$1-\hat{p}$}{N}}

Kiá»ƒm Ä‘á»‹nh sá»± khÃ¡c biá»‡t:

z = \frac{\hat{p}_1 - \hat{p}_2}{\sqrt{SE_1^2 + SE_2^2}}

Náº¿u:

|z| > 1.96

â†’ khÃ¡c biá»‡t cÃ³ Ã½ nghÄ©a thá»‘ng kÃª (95%).

â¸»

6. LiÃªn há»‡ vá»›i Self-Attention

Transformer sá»­ dá»¥ng cÆ¡ cháº¿:

Attention(Q,K,V) = \text{softmax}\left$\frac{QK^T}{\sqrt{d_k}}\right$V

CÆ¡ cháº¿ nÃ y giÃºp mÃ´ hÃ¬nh:
	â€¢	Theo dÃµi quan há»‡ dÃ i háº¡n
	â€¢	LiÃªn káº¿t hÃ nh Ä‘á»™ng trÆ°á»›câ€“sau
	â€¢	PhÃ¡t hiá»‡n logic váº­t lÃ½ ngáº§m Ä‘á»‹nh

â¸»

7. So sÃ¡nh vá»›i Perplexity

Perplexity Ä‘o kháº£ nÄƒng dá»± Ä‘oÃ¡n token káº¿ tiáº¿p:

PP = \exp\left$- \frac{1}{N} \sum \log P(w_i$\right)

Trong khi HellaSwag Ä‘o:
	â€¢	So sÃ¡nh chuá»—i hoÃ n chá»‰nh
	â€¢	Kháº£ nÄƒng reasoning cáº¥p cao

Má»™t mÃ´ hÃ¬nh cÃ³ perplexity tháº¥p chÆ°a cháº¯c cÃ³ accuracy cao trÃªn HellaSwag.

â¸»

8. PhÃ¢n tÃ­ch scaling

Theo luáº­t scaling cá»§a OpenAI:

Loss$N$ = A N^{-\alpha} + B

Khi tÄƒng sá»‘ tham sá»‘ N:
	â€¢	Log-likelihood tÄƒng
	â€¢	Accuracy trÃªn HellaSwag tÄƒng theo hÃ m lÅ©y thá»«a

â¸»

9. Háº¡n cháº¿ cá»§a phÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡

9.1 Shortcut Learning

MÃ´ hÃ¬nh cÃ³ thá»ƒ:
	â€¢	Há»c phong cÃ¡ch cÃ¢u há»£p lÃ½
	â€¢	KhÃ´ng thá»±c sá»± hiá»ƒu váº­t lÃ½

â¸»

9.2 Dataset Saturation

Náº¿u fine-tune trá»±c tiáº¿p trÃªn HellaSwag:

D_{train} \cap D_{test} \neq \varnothing

â†’ KhÃ´ng cÃ²n pháº£n Ã¡nh nÄƒng lá»±c tá»•ng quÃ¡t.

â¸»

9.3 Calibration

MÃ´ hÃ¬nh cÃ³ thá»ƒ:
	â€¢	Chá»n Ä‘Ãºng
	â€¢	NhÆ°ng xÃ¡c suáº¥t khÃ´ng cao

Äo calibration:

ECE = \sum_{m=1}^{M} \frac{|B_m|}{n} |acc$B_m$ - conf$B_m$|

â¸»

10. Ã nghÄ©a thá»±c tiá»…n

ÄÃ¡nh giÃ¡ HellaSwag giÃºp:
	â€¢	So sÃ¡nh mÃ´ hÃ¬nh trÆ°á»›c khi fine-tune
	â€¢	ÄÃ¡nh giÃ¡ kháº£ nÄƒng reasoning
	â€¢	Kiá»ƒm tra hiá»‡u quáº£ scaling

Trong pipeline triá»ƒn khai thá»±c táº¿, cáº§n káº¿t há»£p:
	â€¢	Accuracy
	â€¢	Log-likelihood
	â€¢	Calibration
	â€¢	Robustness test

â¸»

11. Káº¿t luáº­n

ÄÃ¡nh giÃ¡ HellaSwag trÃªn hai mÃ´ hÃ¬nh yÃªu cáº§u:
	â€¢	TÃ­nh log-likelihood chÃ­nh xÃ¡c
	â€¢	Chuáº©n hoÃ¡ Ä‘á»™ dÃ i
	â€¢	So sÃ¡nh thá»‘ng kÃª

Benchmark nÃ y khÃ´ng chá»‰ Ä‘o fluency mÃ  Ä‘o kháº£ nÄƒng suy luáº­n hÃ nh Ä‘á»™ng, do Ä‘Ã³ quan trá»ng trong Ä‘Ã¡nh giÃ¡ LLM hiá»‡n Ä‘áº¡i.

â¸»

TÃ i liá»‡u tham kháº£o
	1.	Zellers, R. et al. (2019). HellaSwag: Can a Machine Really Finish Your Sentence?
	2.	Vaswani, A. et al. (2017). Attention is All You Need.
	3.	Brown et al. (2020). Language Models are Few-Shot Learners.
	4.	Kaplan et al. (2020). Scaling Laws for Neural Language Models.
	5.	Jurafsky & Martin. Speech and Language Processing.
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| [ÄÃ¡nh GiÃ¡ Há»™p Äen (Black-box Evaluations) trong MÃ´ HÃ¬nh NgÃ´n Ngá»¯ Lá»›n](aero_llm_016_black_box_evals.md) | [Xem bÃ i viáº¿t â†’](aero_llm_016_black_box_evals.md) |
| [Red Teaming: Äá»™i Äá» vÃ  Thá»­ Nghiá»‡m Äá»‘i KhÃ¡ng trong AI Safety](aero_llm_017_red_teaming.md) | [Xem bÃ i viáº¿t â†’](aero_llm_017_red_teaming.md) |
| [Äá»™ ChÃ­nh XÃ¡c, TÃ­nh Máº¡ch Láº¡c vÃ  Sá»± PhÃ¹ Há»£p trong ÄÃ¡nh GiÃ¡ MÃ´ HÃ¬nh NgÃ´n Ngá»¯](aero_llm_018_accuracy_coherence_and_relevance.md) | [Xem bÃ i viáº¿t â†’](aero_llm_018_accuracy_coherence_and_relevance.md) |
| [PhÃ¢n Phá»‘i Cá»§a CÃ¡c KÃ­ch Hoáº¡t Tráº¡ng ThÃ¡i áº¨n Trong MÃ´ HÃ¬nh NgÃ´n Ngá»¯](aero_llm_019_distributions_of_hidden_state_activations.md) | [Xem bÃ i viáº¿t â†’](aero_llm_019_distributions_of_hidden_state_activations.md) |
| [Há»©a Háº¹n vÃ  ThÃ¡ch Thá»©c cá»§a ÄÃ¡nh GiÃ¡ Äá»‹nh LÆ°á»£ng trong MÃ´ HÃ¬nh Há»c MÃ¡y](aero_llm_01_promises_and_challenges_of_quantitative_evaluations.md) | [Xem bÃ i viáº¿t â†’](aero_llm_01_promises_and_challenges_of_quantitative_evaluations.md) |
| [Báº£n Äá»“ Nhiá»‡t Cá»§a Token Cho CÃ¢n Nháº¯c Äá»‹nh TÃ­nh (Text Heatmaps)](aero_llm_020_heatmaps_of_tokens_for_qualitative_inspection.md) | [Xem bÃ i viáº¿t â†’](aero_llm_020_heatmaps_of_tokens_for_qualitative_inspection.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh: Trá»±c Quan HÃ³a Dá»± ÄoÃ¡n ÄÆ¡n Token](aero_llm_021_codechallenge_visualize_single_token_predictions.md) | [Xem bÃ i viáº¿t â†’](aero_llm_021_codechallenge_visualize_single_token_predictions.md) |
| [CÃ¡c Váº¥n Äá» Sá»‘ Há»c trong Logits vÃ  Softmax: PhÃ¢n TÃ­ch ToÃ¡n Há»c vÃ  Giáº£i PhÃ¡p á»”n Äá»‹nh](aero_llm_02_numerical_issues_in_logits_and_softmax.md) | [Xem bÃ i viáº¿t â†’](aero_llm_02_numerical_issues_in_logits_and_softmax.md) |
| [Perplexity trong MÃ´ HÃ¬nh NgÃ´n Ngá»¯: CÆ¡ Sá»Ÿ ToÃ¡n Há»c, Diá»…n Giáº£i vÃ  Giá»›i Háº¡n](aero_llm_03_perplexity.md) | [Xem bÃ i viáº¿t â†’](aero_llm_03_perplexity.md) |
| [aero llm 04 codechallenge perplexing perplexities](aero_llm_04_codechallenge_perplexing_perplexities.md) | [Xem bÃ i viáº¿t â†’](aero_llm_04_codechallenge_perplexing_perplexities.md) |
| [aero llm 05 masked word prediction accuracy](aero_llm_05_masked_word_prediction_accuracy.md) | [Xem bÃ i viáº¿t â†’](aero_llm_05_masked_word_prediction_accuracy.md) |
| [aero llm 06 hellaswag](aero_llm_06_hellaswag.md) | [Xem bÃ i viáº¿t â†’](aero_llm_06_hellaswag.md) |
| [aero llm 07 import large models using bitsandbytes](aero_llm_07_import_large_models_using_bitsandbytes.md) | [Xem bÃ i viáº¿t â†’](aero_llm_07_import_large_models_using_bitsandbytes.md) |
| ğŸ“Œ **[aero llm 08 codechallenge hellaswag evals in two models part 1](aero_llm_08_codechallenge_hellaswag_evals_in_two_models_part_1_.md)** | [Xem bÃ i viáº¿t â†’](aero_llm_08_codechallenge_hellaswag_evals_in_two_models_part_1_.md) |
| [aero llm 09 codechallenge hellaswag evals in two models part 2](aero_llm_09_codechallenge_hellaswag_evals_in_two_models_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_09_codechallenge_hellaswag_evals_in_two_models_part_2_.md) |
| [aero llm 10 kl kullback leibler divergence](aero_llm_10_kl_kullback_leibler_divergence.md) | [Xem bÃ i viáº¿t â†’](aero_llm_10_kl_kullback_leibler_divergence.md) |
| [aero llm 11 mauve](aero_llm_11_mauve.md) | [Xem bÃ i viáº¿t â†’](aero_llm_11_mauve.md) |
| [aero llm 12 codechallenge large and small mauve explorations](aero_llm_12_codechallenge_large_and_small_mauve_explorations.md) | [Xem bÃ i viáº¿t â†’](aero_llm_12_codechallenge_large_and_small_mauve_explorations.md) |
| [aero llm 13 superglue and other amalgamations](aero_llm_13_superglue_and_other_amalgamations.md) | [Xem bÃ i viáº¿t â†’](aero_llm_13_superglue_and_other_amalgamations.md) |
| [aero llm 14 assessing bias and fairness](aero_llm_14_assessing_bias_and_fairness.md) | [Xem bÃ i viáº¿t â†’](aero_llm_14_assessing_bias_and_fairness.md) |
| [aero llm 15 non technical benchmarks](aero_llm_15_non_technical_benchmarks.md) | [Xem bÃ i viáº¿t â†’](aero_llm_15_non_technical_benchmarks.md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
