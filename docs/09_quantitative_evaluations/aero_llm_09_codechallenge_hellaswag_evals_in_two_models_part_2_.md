
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../index.md) > [09 quantitative evaluations](index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../index.md)
- [ğŸ“š Module 01: LLM Course](../01_llm_course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../02_words_to_tokens_to_numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../04_buildgpt/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../07_fine_tune_pretrained_models/index.md)
- [ğŸ” Module 19: AI Safety](../19_ai_safety/index.md)
- [ğŸ Module 20: Python for AI](../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
So sÃ¡nh thá»±c nghiá»‡m HellaSwag trÃªn hai mÃ´ hÃ¬nh ngÃ´n ngá»¯ (Pháº§n 2):

PhÃ¢n tÃ­ch log-likelihood, chuáº©n hoÃ¡ Ä‘á»™ dÃ i vÃ  kiá»ƒm Ä‘á»‹nh thá»‘ng kÃª

â¸»

TÃ³m táº¯t

BÃ i viáº¿t nÃ y tiáº¿p tá»¥c phÃ¢n tÃ­ch bÃ i toÃ¡n Ä‘Ã¡nh giÃ¡ HellaSwag trÃªn hai mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLMs), dá»±a trÃªn ná»™i dung tÃ i liá»‡u Ä‘Ã­nh kÃ¨m (pháº§n 2). Trá»ng tÃ¢m lÃ :
	â€¢	Triá»ƒn khai tÃ­nh log-likelihood cÃ³ Ä‘iá»u kiá»‡n
	â€¢	So sÃ¡nh hai mÃ´ hÃ¬nh thÃ´ng qua accuracy
	â€¢	PhÃ¢n tÃ­ch Ä‘á»™ lá»‡ch do chuáº©n hoÃ¡ Ä‘á»™ dÃ i
	â€¢	Kiá»ƒm Ä‘á»‹nh Ã½ nghÄ©a thá»‘ng kÃª

Ná»n táº£ng lÃ½ thuyáº¿t dá»±a trÃªn nghiÃªn cá»©u cá»§a Rowan Zellers et al. (2019), kiáº¿n trÃºc Transformer cá»§a Ashish Vaswani et al. (2017) vÃ  cÃ¡c phÃ¢n tÃ­ch scaling cá»§a OpenAI.

â¸»

1. BÃ i toÃ¡n Ä‘Ã¡nh giÃ¡ thá»±c nghiá»‡m

Vá»›i má»—i máº«u dá»¯ liá»‡u:
	â€¢	Ngá»¯ cáº£nh c
	â€¢	4 lá»±a chá»n \{$a_1$, $a_2$, $a_3$, $a_4$\}
	â€¢	ÄÃ¡p Ã¡n Ä‘Ãºng a_{\text{true}}

Má»¥c tiÃªu: so sÃ¡nh hai mÃ´ hÃ¬nh $M_1$ vÃ  $M_2$.

â¸»

2. TÃ­nh log-likelihood chi tiáº¿t

Vá»›i mÃ´ hÃ¬nh tá»± há»“i quy:

$P($a_i$ \mid c)$ = $\prod$_{t=1}^{$T_i$} $P($w_t$ \mid c, w_{\lt t})$

Äá»ƒ trÃ¡nh trÃ n sá»‘:

$$
\log P(a_i \mid c) = \sum_{t=1}^{T_i} \log P(w_t \mid c, w_{\lt t})
$$

Trong thá»±c táº¿, ta tÃ­nh:

$$

$$

Scorea_i = \frac{1}{T_i^\alpha} \sum_{t=1}^{T_i} \log P(w_t \mid c, w_{\lt t})

$$

$$

Trong Ä‘Ã³:

$$
â€¢	\alpha = 1 â†’ chuáº©n hoÃ¡ trung bÃ¬nh
$$

	â€¢	0 < \alpha < 1 â†’ giáº£m thiÃªn lá»‡ch Ä‘á»™ dÃ i

â¸»

3. CÆ¡ cháº¿ forward pass trong Transformer

Transformer tÃ­nh xÃ¡c suáº¥t thÃ´ng qua:

$$

$$

h_t = \text{Transformer}c, w_{\lt t}

$$

$$

Sau Ä‘Ã³:

$P($w_t$)$ = \text{softmax}$Wh_t$

Trong Ä‘Ã³:

$$

$$

\text{softmax}z_i = \frac{e^{z_i}}{\sum_j e^{z_j}}

$$

$$

Self-attention:

$$

$$

Attention(Q,K,V) = \text{softmax}\left\frac{QK^T}{\sqrt{d_k}}\rightV

$$

$$

â¸»

4. So sÃ¡nh Accuracy giá»¯a hai mÃ´ hÃ¬nh

Giáº£ sá»­:
	â€¢	MÃ´ hÃ¬nh $M_1$: accuracy \hat{p}_1
	â€¢	MÃ´ hÃ¬nh $M_2$: accuracy \hat{p}_2
	â€¢	Sá»‘ máº«u: N

Sai sá»‘ chuáº©n:

$$

$$

SE_i = \sqrt{\frac{\hat{p}_i 1-\hat{p}_i}{N}}

$$

$$

Kiá»ƒm Ä‘á»‹nh z:

$$

$$

z = \frac{\hat{p}_1 - \hat{p}_2}{\sqrt{SE_1^2 + SE_2^2}}

$$

$$

Náº¿u:

|z| > 1.96

â†’ KhÃ¡c biá»‡t cÃ³ Ã½ nghÄ©a á»Ÿ má»©c 95%.

â¸»

5. PhÃ¢n tÃ­ch sai lá»‡ch do Ä‘á»™ dÃ i

Náº¿u khÃ´ng chuáº©n hoÃ¡:
	â€¢	Chuá»—i dÃ i cÃ³ tá»•ng log nhá» hÆ¡n
	â€¢	MÃ´ hÃ¬nh Æ°u tiÃªn Ä‘Ã¡p Ã¡n ngáº¯n

Giáº£ sá»­ hai Ä‘Ã¡p Ã¡n:

$$

$$

â€¢	T_1 = 5

$$

$$

$$
â€¢	T_2 = 20
$$

$$
Náº¿u xÃ¡c suáº¥t token trung bÃ¬nh nhÆ° nhau:
$$

$\sum$_{t=1}^{5} $\log$ p = -10

$$

$$

$\sum$_{t=1}^{20} $\log$ p = -40

$$
KhÃ´ng chuáº©n hoÃ¡ â†’ chá»n chuá»—i ngáº¯n Chuáº©n hoÃ¡:
$$

\frac{-10}{5} = -2

$$

$$

\frac{-40}{20} = -2

$$
â†’ cÃ´ng báº±ng. â¸» 6. So sÃ¡nh vá»›i Perplexity Perplexity:
$$

$$
PP = \exp\left- \frac{1}{N} \sum \log P(w_i\right)
$$

$$
HellaSwag Ä‘o kháº£ nÄƒng phÃ¢n biá»‡t nhiá»u chuá»—i hoÃ n chá»‰nh. MÃ´ hÃ¬nh cÃ³ perplexity tá»‘t nhÆ°ng thiáº¿u reasoning váº«n cÃ³ thá»ƒ: Accuracy_{\text{HellaSwag}} tháº¥p â¸» 7. PhÃ¢n tÃ­ch scaling Theo luáº­t scaling:
$$

LossN = A N^{-\alpha} + B

$$
Accuracy thÆ°á»ng tÄƒng theo:
$$

$$
AccuracyN \approx C - D N^{-\beta}
$$

$$
Khi N tÄƒng â†’ performance tiá»‡m cáº­n tráº§n. â¸» 8. PhÃ¢n tÃ­ch lá»—i CÃ¡c lá»—i phá»• biáº¿n: 1.	Chá»n continuation â€œnghe tá»± nhiÃªnâ€ nhÆ°ng sai logic váº­t lÃ½. 2.	Nháº§m láº«n do bias dá»¯ liá»‡u huáº¥n luyá»‡n. 3.	Sai do thiáº¿u hiá»ƒu biáº¿t hÃ nh Ä‘á»™ng hiáº¿m gáº·p. â¸» 9. Calibration vÃ  Ä‘á»™ tin cáº­y Expected Calibration Error (ECE):
$$

$$
ECE = \sum_{m=1}^{M} \frac{|B_m|}{n} |accB_m - confB_m|
$$

$$
MÃ´ hÃ¬nh tá»‘t khÃ´ng chá»‰ cáº§n accuracy cao mÃ  cÃ²n:
$$

$$
acc \approx conf
$$
