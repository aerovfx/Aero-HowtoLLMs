
<!-- Aero-Navigation-Start -->
[üè† Home](../index.md) > [09 quantitative evaluations](index.md)

---
### üß≠ ƒêi·ªÅu h∆∞·ªõng nhanh

- [üè† C·ªïng t√†i li·ªáu](../index.md)
- [üìö Module 01: LLM Course](../01_llm_course/index.md)
- [üî¢ Module 02: Tokenization](../02_words_to_tokens_to_numbers/index.md)
- [üèóÔ∏è Module 04: Build GPT](../04_buildgpt/index.md)
- [üéØ Module 07: Fine-tuning](../07_fine_tune_pretrained_models/index.md)
- [üîç Module 19: AI Safety](../19_ai_safety/index.md)
- [üêç Module 20: Python for AI](../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
Ph√¢n k·ª≥ Kullback‚ÄìLeibler (KL Divergence) trong m√¥ h√¨nh ng√¥n ng·ªØ v√† h·ªçc s√¢u

Ph√¢n t√≠ch l√Ω thuy·∫øt, c√¥ng th·ª©c to√°n h·ªçc v√† ·ª©ng d·ª•ng trong t·ªëi ∆∞u h√≥a ph√¢n ph·ªëi x√°c su·∫•t

‚∏ª

T√≥m t·∫Øt

B√†i vi·∫øt n√†y tr√¨nh b√†y c∆° s·ªü l√Ω thuy·∫øt v√† ·ª©ng d·ª•ng c·ªßa ph√¢n k·ª≥ Kullback‚ÄìLeibler (KL Divergence) trong h·ªçc m√°y v√† m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn (LLMs). D·ª±a tr√™n n·ªôi dung t√†i li·ªáu ƒë√≠nh k√®m, ch√∫ng t√¥i m·ªü r·ªông ph√¢n t√≠ch v·ªõi c√°c n·ªÅn t·∫£ng t·ª´ l√Ω thuy·∫øt th√¥ng tin c·ªßa Claude Shannon, c√¥ng tr√¨nh g·ªëc c·ªßa Solomon Kullback v√† Richard Leibler, c√πng c√°c ·ª©ng d·ª•ng hi·ªán ƒë·∫°i trong hu·∫•n luy·ªán Transformer c·ªßa Ashish Vaswani et al. v√† nghi√™n c·ª©u RLHF t·∫°i OpenAI.

‚∏ª

1. Gi·ªõi thi·ªáu

Trong h·ªçc m√°y, ta th∆∞·ªùng c·∫ßn ƒëo kho·∫£ng c√°ch gi·ªØa hai ph√¢n ph·ªëi x√°c su·∫•t:
	‚Ä¢	Ph√¢n ph·ªëi th·ª±c P$x$
	‚Ä¢	Ph√¢n ph·ªëi m√¥ h√¨nh Q$x$

Ph√¢n k·ª≥ KL ƒëo m·ª©c ‚Äúm·∫•t m√°t th√¥ng tin‚Äù khi d√πng Q ƒë·ªÉ x·∫•p x·ªâ P.

‚∏ª

2. ƒê·ªãnh nghƒ©a to√°n h·ªçc

2.1 Tr∆∞·ªùng h·ª£p r·ªùi r·∫°c

D_{KL}$P \\mid  Q$ = \sum_{x} P$x$ \log \frac{P$x$}{Q$x$}

ƒêi·ªÅu ki·ªán:

Q$x$ > 0 \quad \text{n·∫øu } P$x$ > 0

‚∏ª

2.2 Tr∆∞·ªùng h·ª£p li√™n t·ª•c

D_{KL}$P \\mid  Q$ = \int P$x$ \log \frac{P$x$}{Q$x$} dx

‚∏ª

3. C√°c t√≠nh ch·∫•t quan tr·ªçng

3.1 Kh√¥ng √¢m (Non-negativity)

D_{KL}$P \\mid  Q$ \ge 0

v√†

D_{KL}$P \\mid  Q$ = 0 \iff P = Q

Ch·ª©ng minh d·ª±a tr√™n b·∫•t ƒë·∫≥ng th·ª©c Jensen.

‚∏ª

3.2 Kh√¥ng ƒë·ªëi x·ª©ng

D_{KL}$P \\mid  Q$ \neq D_{KL}$Q \\mid  P$

Do ƒë√≥ KL kh√¥ng ph·∫£i l√† metric.

‚∏ª

4. Li√™n h·ªá v·ªõi Cross-Entropy

Cross-entropy:

H(P, Q) = - \sum_x P$x$ \log Q$x$

Entropy:

H$P$ = - \sum_x P$x$ \log P$x$

Ta c√≥:

D_{KL}$P \\mid  Q$ = H(P, Q) - H$P$

Trong hu·∫•n luy·ªán m√¥ h√¨nh, v√¨ H$P$ kh√¥ng ph·ª• thu·ªôc v√†o tham s·ªë m√¥ h√¨nh, n√™n t·ªëi thi·ªÉu h√≥a cross-entropy t∆∞∆°ng ƒë∆∞∆°ng t·ªëi thi·ªÉu h√≥a KL divergence.

‚∏ª

5. KL Divergence trong m√¥ h√¨nh ng√¥n ng·ªØ

V·ªõi m√¥ h√¨nh d·ª± ƒëo√°n token:
	‚Ä¢	Ph√¢n ph·ªëi th·∫≠t: P_{data}
	‚Ä¢	Ph√¢n ph·ªëi m√¥ h√¨nh: P_\theta

H√†m m·∫•t m√°t:

\mathcal{L}$\theta$ = D_{KL}$P_{data} \\mid  P_\theta$

T·ªëi ∆∞u:

\theta^* = \arg\min_\theta D_{KL}$P_{data} \\mid  P_\theta$

‚∏ª

6. Li√™n h·ªá v·ªõi Perplexity

Perplexity:

PP = \exp\left$H(P_{data}, P_\theta$\right)

V√¨:

H$P_{data}, P_\theta$ = H$P_{data}$ + D_{KL}$P_{data} \\mid  P_\theta$

‚Üí Gi·∫£m KL ‚Üí gi·∫£m perplexity.

‚∏ª

7. KL Divergence trong RLHF

Trong Reinforcement Learning from Human Feedback (RLHF), ta t·ªëi ∆∞u:

\max_\theta \mathbb{E}_{x \sim P_\theta}[R$x$] - \beta D_{KL}$P_\theta \\mid  P_{ref}$

Trong ƒë√≥:
	‚Ä¢	R$x$: reward model
	‚Ä¢	P_{ref}: m√¥ h√¨nh tham chi·∫øu
	‚Ä¢	\beta: h·ªá s·ªë ƒëi·ªÅu ch·ªânh

Th√†nh ph·∫ßn KL gi√∫p:
	‚Ä¢	NgƒÉn m√¥ h√¨nh l·ªách qu√° xa m√¥ h√¨nh g·ªëc
	‚Ä¢	Tr√°nh over-optimization

‚∏ª

8. KL Divergence gi·ªØa hai ph√¢n ph·ªëi chu·∫©n

Gi·∫£ s·ª≠:

P = \mathcal{N}$\mu_1, \sigma_1^2$
Q = \mathcal{N}$\mu_2, \sigma_2^2$

Ta c√≥:

D_{KL}$P \\mid  Q$ =
\log \frac{\sigma_2}{\sigma_1}
+ \frac{\sigma_1^2 + $\mu_1 - \mu_2$^2}{2\sigma_2^2}
- \frac{1}{2}

C√¥ng th·ª©c n√†y th∆∞·ªùng d√πng trong Variational Autoencoder (VAE).

‚∏ª

9. KL Divergence v√† Self-Attention

Trong Transformer:

P_\theta$w_t$ = \text{softmax}$Wh_t$

Hu·∫•n luy·ªán t·ªëi thi·ªÉu h√≥a:

D_{KL}$P_{data} \\mid  P_\theta$

C∆° ch·∫ø self-attention:

Attention(Q,K,V) =
\text{softmax}\left$\frac{QK^T}{\sqrt{d_k}}\right$V

Gi√∫p m√¥ h√¨nh x√¢y d·ª±ng ph√¢n ph·ªëi x√°c su·∫•t ch√≠nh x√°c h∆°n.

‚∏ª

10. Tr·ª±c gi√°c th√¥ng tin h·ªçc

Theo l√Ω thuy·∫øt th√¥ng tin c·ªßa Claude Shannon:
	‚Ä¢	Entropy ƒëo ƒë·ªô b·∫•t ƒë·ªãnh
	‚Ä¢	KL ƒëo m·ª©c th√¥ng tin m·∫•t ƒëi khi x·∫•p x·ªâ ph√¢n ph·ªëi

N·∫øu:

D_{KL}$P \\mid  Q$ = 2

‚Üí Trung b√¨nh ta m·∫•t 2 nat th√¥ng tin m·ªói m·∫´u.

‚∏ª

11. ·ª®ng d·ª•ng th·ª±c t·∫ø

11.1 Distillation

Gi·ªØa teacher T v√† student S:

\mathcal{L} = D_{KL}$P_T \\mid  P_S$

‚∏ª

11.2 Regularization

Th√™m ƒëi·ªÅu kho·∫£n KL ƒë·ªÉ:
	‚Ä¢	Gi·∫£m overfitting
	‚Ä¢	Ki·ªÉm so√°t divergence

‚∏ª

11.3 Variational Inference

T·ªëi ∆∞u:

D_{KL}(q(z) \| p(z|x))

‚∏ª

12. H·∫°n ch·∫ø c·ªßa KL Divergence
	1.	Kh√¥ng ƒë·ªëi x·ª©ng
	2.	Nh·∫°y khi Q$x$ \to 0
	3.	Kh√¥ng ph·∫£i metric

Trong m·ªôt s·ªë tr∆∞·ªùng h·ª£p, Jensen-Shannon divergence ƒë∆∞·ª£c d√πng thay th·∫ø.

‚∏ª

13. K·∫øt lu·∫≠n

Ph√¢n k·ª≥ KL l√† n·ªÅn t·∫£ng c·ªßa:
	‚Ä¢	Hu·∫•n luy·ªán m√¥ h√¨nh ng√¥n ng·ªØ
	‚Ä¢	Cross-entropy loss
	‚Ä¢	Perplexity
	‚Ä¢	RLHF
	‚Ä¢	Distillation

N√≥ k·∫øt n·ªëi tr·ª±c ti·∫øp gi·ªØa l√Ω thuy·∫øt th√¥ng tin v√† h·ªçc s√¢u hi·ªán ƒë·∫°i.

‚∏ª

T√†i li·ªáu tham kh·∫£o
	1.	Kullback, S., Leibler, R. (1951). On Information and Sufficiency.
	2.	Shannon, C. (1948). A Mathematical Theory of Communication.
	3.	Vaswani, A. et al. (2017). Attention is All You Need.
	4.	Goodfellow, I. et al. (2016). Deep Learning.
	5.	Ouyang et al. (2022). Training language models to follow instructions with human feedback.
<!-- Aero-Footer-Start -->

## üìÑ T√†i li·ªáu c√πng chuy√™n m·ª•c
| B√†i h·ªçc | Li√™n k·∫øt |
| :--- | :--- |
| [ƒê√°nh Gi√° H·ªôp ƒêen (Black-box Evaluations) trong M√¥ H√¨nh Ng√¥n Ng·ªØ L·ªõn](aero_llm_016_black_box_evals.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_016_black_box_evals.md) |
| [Red Teaming: ƒê·ªôi ƒê·ªè v√† Th·ª≠ Nghi·ªám ƒê·ªëi Kh√°ng trong AI Safety](aero_llm_017_red_teaming.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_017_red_teaming.md) |
| [ƒê·ªô Ch√≠nh X√°c, T√≠nh M·∫°ch L·∫°c v√† S·ª± Ph√π H·ª£p trong ƒê√°nh Gi√° M√¥ H√¨nh Ng√¥n Ng·ªØ](aero_llm_018_accuracy_coherence_and_relevance.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_018_accuracy_coherence_and_relevance.md) |
| [Ph√¢n Ph·ªëi C·ªßa C√°c K√≠ch Ho·∫°t Tr·∫°ng Th√°i ·∫®n Trong M√¥ H√¨nh Ng√¥n Ng·ªØ](aero_llm_019_distributions_of_hidden_state_activations.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_019_distributions_of_hidden_state_activations.md) |
| [H·ª©a H·∫πn v√† Th√°ch Th·ª©c c·ªßa ƒê√°nh Gi√° ƒê·ªãnh L∆∞·ª£ng trong M√¥ H√¨nh H·ªçc M√°y](aero_llm_01_promises_and_challenges_of_quantitative_evaluations.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_01_promises_and_challenges_of_quantitative_evaluations.md) |
| [B·∫£n ƒê·ªì Nhi·ªát C·ªßa Token Cho C√¢n Nh·∫Øc ƒê·ªãnh T√≠nh (Text Heatmaps)](aero_llm_020_heatmaps_of_tokens_for_qualitative_inspection.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_020_heatmaps_of_tokens_for_qualitative_inspection.md) |
| [Th·ª≠ Th√°ch L·∫≠p Tr√¨nh: Tr·ª±c Quan H√≥a D·ª± ƒêo√°n ƒê∆°n Token](aero_llm_021_codechallenge_visualize_single_token_predictions.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_021_codechallenge_visualize_single_token_predictions.md) |
| [C√°c V·∫•n ƒê·ªÅ S·ªë H·ªçc trong Logits v√† Softmax: Ph√¢n T√≠ch To√°n H·ªçc v√† Gi·∫£i Ph√°p ·ªîn ƒê·ªãnh](aero_llm_02_numerical_issues_in_logits_and_softmax.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_02_numerical_issues_in_logits_and_softmax.md) |
| [Perplexity trong M√¥ H√¨nh Ng√¥n Ng·ªØ: C∆° S·ªü To√°n H·ªçc, Di·ªÖn Gi·∫£i v√† Gi·ªõi H·∫°n](aero_llm_03_perplexity.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_03_perplexity.md) |
| [aero llm 04 codechallenge perplexing perplexities](aero_llm_04_codechallenge_perplexing_perplexities.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_04_codechallenge_perplexing_perplexities.md) |
| [aero llm 05 masked word prediction accuracy](aero_llm_05_masked_word_prediction_accuracy.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_05_masked_word_prediction_accuracy.md) |
| [aero llm 06 hellaswag](aero_llm_06_hellaswag.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_06_hellaswag.md) |
| [aero llm 07 import large models using bitsandbytes](aero_llm_07_import_large_models_using_bitsandbytes.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_07_import_large_models_using_bitsandbytes.md) |
| [aero llm 08 codechallenge hellaswag evals in two models part 1](aero_llm_08_codechallenge_hellaswag_evals_in_two_models_part_1_.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_08_codechallenge_hellaswag_evals_in_two_models_part_1_.md) |
| [aero llm 09 codechallenge hellaswag evals in two models part 2](aero_llm_09_codechallenge_hellaswag_evals_in_two_models_part_2_.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_09_codechallenge_hellaswag_evals_in_two_models_part_2_.md) |
| üìå **[aero llm 10 kl kullback leibler divergence](aero_llm_10_kl_kullback_leibler_divergence.md)** | [Xem b√†i vi·∫øt ‚Üí](aero_llm_10_kl_kullback_leibler_divergence.md) |
| [aero llm 11 mauve](aero_llm_11_mauve.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_11_mauve.md) |
| [aero llm 12 codechallenge large and small mauve explorations](aero_llm_12_codechallenge_large_and_small_mauve_explorations.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_12_codechallenge_large_and_small_mauve_explorations.md) |
| [aero llm 13 superglue and other amalgamations](aero_llm_13_superglue_and_other_amalgamations.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_13_superglue_and_other_amalgamations.md) |
| [aero llm 14 assessing bias and fairness](aero_llm_14_assessing_bias_and_fairness.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_14_assessing_bias_and_fairness.md) |
| [aero llm 15 non technical benchmarks](aero_llm_15_non_technical_benchmarks.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_15_non_technical_benchmarks.md) |

---
## ü§ù Li√™n h·ªá & ƒê√≥ng g√≥p
D·ª± √°n ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi **Pixibox**. M·ªçi ƒë√≥ng g√≥p v·ªÅ n·ªôi dung v√† m√£ ngu·ªìn ƒë·ªÅu ƒë∆∞·ª£c ch√†o ƒë√≥n.

> *"Ki·∫øn th·ª©c l√† ƒë·ªÉ chia s·∫ª. H√£y c√πng nhau x√¢y d·ª±ng c·ªông ƒë·ªìng AI v·ªØng m·∫°nh!"* üöÄ

*C·∫≠p nh·∫≠t t·ª± ƒë·ªông b·ªüi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
