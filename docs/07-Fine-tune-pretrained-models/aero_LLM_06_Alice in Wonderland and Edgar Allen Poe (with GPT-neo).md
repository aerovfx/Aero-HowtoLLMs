
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../index.md) > [07 Fine tune pretrained models](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../index.md)
- [ğŸ“š Module 01: LLM Course](../../01-LLM_Course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../02-Words-to-tokens-to-numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../04-buildGPT/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../07-Fine-tune-pretrained-models/index.md)
- [ğŸ” Module 19: AI Safety](../../19-AI-safety/index.md)
- [ğŸ Module 20: Python for AI](../../20-Python-Colab-notebooks/index.md)
---
<!-- Aero-Navigation-End -->
DÆ°á»›i Ä‘Ã¢y lÃ  **bÃ i viáº¿t khoa há»c báº±ng tiáº¿ng Viá»‡t**, Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn tÃ i liá»‡u báº¡n cung cáº¥p , cÃ³ bá»• sung **nguá»“n tham kháº£o**, **cÃ´ng thá»©c toÃ¡n há»c minh há»a**, vÃ  trÃ¬nh bÃ y theo Ä‘á»‹nh dáº¡ng **Markdown**.

---

# Tinh Chá»‰nh MÃ´ HÃ¬nh GPT-Neo Äá»ƒ MÃ´ Phá»ng Phong CÃ¡ch VÄƒn Há»c Alice in Wonderland vÃ  Edgar Allan Poe

---

## TÃ³m táº¯t

Tinh chá»‰nh mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (Large Language Models â€“ LLMs) theo phong cÃ¡ch vÄƒn há»c cá»¥ thá»ƒ lÃ  má»™t hÆ°á»›ng nghiÃªn cá»©u quan trá»ng trong lÄ©nh vá»±c trÃ­ tuá»‡ nhÃ¢n táº¡o sÃ¡ng táº¡o. BÃ i bÃ¡o nÃ y trÃ¬nh bÃ y phÆ°Æ¡ng phÃ¡p fine-tuning mÃ´ hÃ¬nh GPT-Neo nháº±m mÃ´ phá»ng phong cÃ¡ch viáº¿t cá»§a *Alice in Wonderland* vÃ  *Edgar Allan Poe*. NghiÃªn cá»©u táº­p trung vÃ o phÃ¢n tÃ­ch kiáº¿n trÃºc mÃ´ hÃ¬nh, quÃ¡ trÃ¬nh tiá»n xá»­ lÃ½ dá»¯ liá»‡u, phÆ°Æ¡ng phÃ¡p huáº¥n luyá»‡n, Ä‘Ã¡nh giÃ¡ Ä‘á»‹nh lÆ°á»£ng vÃ  Ä‘á»‹nh tÃ­nh. Káº¿t quáº£ cho tháº¥y ráº±ng mÃ´ hÃ¬nh sau tinh chá»‰nh cÃ³ kháº£ nÄƒng tÃ¡i hiá»‡n rÃµ nÃ©t phong cÃ¡ch vÄƒn há»c Ä‘áº·c trÆ°ng cá»§a tá»«ng tÃ¡c giáº£. 

---

## Tá»« khÃ³a

GPT-Neo, Fine-tuning, Language Modeling, Style Transfer, Transformer, Sinh vÄƒn báº£n

---

## 1. Giá»›i thiá»‡u

Trong nhá»¯ng nÄƒm gáº§n Ä‘Ã¢y, cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ dá»±a trÃªn Transformer Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c nhiá»u thÃ nh tá»±u ná»•i báº­t trong lÄ©nh vá»±c xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn. Má»™t trong nhá»¯ng á»©ng dá»¥ng quan trá»ng lÃ  sinh vÄƒn báº£n theo phong cÃ¡ch cá»¥ thá»ƒ.

Má»¥c tiÃªu cá»§a nghiÃªn cá»©u nÃ y lÃ  huáº¥n luyá»‡n hai mÃ´ hÃ¬nh GPT-Neo giá»‘ng nhau vá» kiáº¿n trÃºc nhÆ°ng Ä‘Æ°á»£c tinh chá»‰nh trÃªn hai táº­p dá»¯ liá»‡u khÃ¡c nhau:

* VÄƒn báº£n *Alice in Wonderland*
* Tuyá»ƒn táº­p tÃ¡c pháº©m cá»§a Edgar Allan Poe

Qua Ä‘Ã³, Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng há»c phong cÃ¡ch vÄƒn há»c cá»§a mÃ´ hÃ¬nh. 

---

## 2. CÆ¡ sá»Ÿ lÃ½ thuyáº¿t

### 2.1 MÃ´ hÃ¬nh ngÃ´n ngá»¯ tá»± há»“i quy

GPT-Neo thuá»™c nhÃ³m mÃ´ hÃ¬nh ngÃ´n ngá»¯ tá»± há»“i quy (Autoregressive Language Model), vá»›i xÃ¡c suáº¥t sinh chuá»—i:

[
P(x_1,x_2,...,x_T)=\prod_{t=1}^{T}P(x_t|x_1,...,x_{t-1})
]

Trong Ä‘Ã³:

* (x_t): token táº¡i thá»i Ä‘iá»ƒm (t)
* (T): Ä‘á»™ dÃ i chuá»—i

MÃ´ hÃ¬nh dá»± Ä‘oÃ¡n token tiáº¿p theo dá»±a trÃªn toÃ n bá»™ ngá»¯ cáº£nh trÆ°á»›c Ä‘Ã³.

---

### 2.2 Kiáº¿n trÃºc Transformer

Má»—i block Transformer gá»“m:

* Multi-head Self-Attention
* Feed-forward Network (MLP)
* Layer Normalization

CÃ´ng thá»©c Attention:

[
\text{Attention}(Q,K,V)=\text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
]

Trong Ä‘Ã³:

* (Q,K,V): ma tráº­n truy váº¥n, khÃ³a, giÃ¡ trá»‹
* (d_k): chiá»u vector khÃ³a

---

### 2.3 HÃ m Softmax vÃ  Log-likelihood

Äáº§u ra cá»§a mÃ´ hÃ¬nh lÃ  vector logit (\mathbf{z}):

[
\mathbf{z}=(z_1,z_2,...,z_V)
]

XÃ¡c suáº¥t token thá»© (i):

[
P(i)=\frac{e^{z_i}}{\sum_{j=1}^{V}e^{z_j}}
]

Log-likelihood:

[
\log P(i)=z_i-\log\sum_{j}e^{z_j}
]

---

## 3. PhÆ°Æ¡ng phÃ¡p nghiÃªn cá»©u

### 3.1 MÃ´ hÃ¬nh GPT-Neo

MÃ´ hÃ¬nh sá»­ dá»¥ng trong nghiÃªn cá»©u lÃ  GPT-Neo 125M vá»›i:

* Sá»‘ tham sá»‘: ~125 triá»‡u
* Embedding dimension: 768
* Vocabulary size: 50,257
* Sá»‘ block Transformer: 12

MÃ´ hÃ¬nh cÃ³ kÃ­ch thÆ°á»›c tÆ°Æ¡ng Ä‘Æ°Æ¡ng GPT-2 Small. 

---

### 3.2 Táº­p dá»¯ liá»‡u

Hai táº­p dá»¯ liá»‡u chÃ­nh:

| Táº­p dá»¯ liá»‡u         | Sá»‘ token |
| ------------------- | -------- |
| Alice in Wonderland | ~50,000  |
| Edgar Allan Poe     | ~200,000 |

Táº­p Poe cÃ³ Ä‘á»™ Ä‘a dáº¡ng cao hÆ¡n do gá»“m nhiá»u truyá»‡n vÃ  thÆ¡ khÃ¡c nhau. 

---

### 3.3 Tokenization

Dá»¯ liá»‡u Ä‘Æ°á»£c mÃ£ hÃ³a báº±ng tokenizer GPT-2:

[
x = (x_1,x_2,...,x_T), \quad x_i \in {1,...,V}
]

Trong Ä‘Ã³ (V = 50257) lÃ  kÃ­ch thÆ°á»›c tá»« vá»±ng.

Tokenizer cá»§a GPT-Neo trÃ¹ng vá»›i GPT-2 tokenizer. 

---

### 3.4 HÃ m máº¥t mÃ¡t

MÃ´ hÃ¬nh sá»­ dá»¥ng Negative Log-Likelihood Loss:

[
\mathcal{L}=-\frac{1}{T}\sum_{t=1}^{T}\log P(x_t|x_{<t})
]

HÃ m nÃ y Ä‘o Ä‘á»™ phÃ¹ há»£p giá»¯a phÃ¢n phá»‘i dá»± Ä‘oÃ¡n vÃ  dá»¯ liá»‡u thá»±c táº¿.

---

### 3.5 Quy trÃ¬nh huáº¥n luyá»‡n

Má»—i vÃ²ng huáº¥n luyá»‡n gá»“m:

1. Láº¥y batch token ngáº«u nhiÃªn
2. Forward pass
3. TÃ­nh loss
4. Backpropagation
5. Cáº­p nháº­t trá»ng sá»‘

Cáº­p nháº­t tham sá»‘:

[
\theta_{k+1}=\theta_k-\eta\nabla_\theta\mathcal{L}
]

Trong Ä‘Ã³:

* (\eta): learning rate
* (\theta): tham sá»‘ mÃ´ hÃ¬nh



---

### 3.6 Tá»‘i Æ°u hÃ³a

Sá»­ dá»¥ng Adam Optimizer:

[
m_t=\beta_1 m_{t-1}+(1-\beta_1)g_t
]

[
v_t=\beta_2 v_{t-1}+(1-\beta_2)g_t^2
]

[
\theta_t=\theta_{t-1}-\eta\frac{m_t}{\sqrt{v_t}+\epsilon}
]

Trong Ä‘Ã³ (g_t) lÃ  gradient táº¡i bÆ°á»›c (t).

---

## 4. Thá»±c nghiá»‡m

### 4.1 Thiáº¿t láº­p

| Tham sá»‘         | GiÃ¡ trá»‹ |
| --------------- | ------- |
| Batch size      | 16      |
| Sequence length | 256     |
| Sá»‘ vÃ²ng láº·p     | 500     |
| Optimizer       | Adam    |
| GPU             | CÃ³      |



---

### 4.2 PhÃ¢n tÃ­ch hÃ m máº¥t mÃ¡t

Káº¿t quáº£:

* Alice: Loss â†’ 0.19
* Poe: Loss â†’ 1.46

Biá»ƒu Ä‘á»“ loss cho tháº¥y tá»‘c Ä‘á»™ há»™i tá»¥ cá»§a Alice nhanh hÆ¡n.

NguyÃªn nhÃ¢n:

* Dá»¯ liá»‡u Alice Ä‘á»“ng nháº¥t hÆ¡n
* VÄƒn phong gáº§n tiáº¿ng Anh hiá»‡n Ä‘áº¡i hÆ¡n

---

### 4.3 ÄÃ¡nh giÃ¡ Ä‘á»‹nh lÆ°á»£ng

Perplexity Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡:

[
PPL = e^{\mathcal{L}}
]

Perplexity tháº¥p cho tháº¥y mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n tá»‘t hÆ¡n.

MÃ´ hÃ¬nh Alice cÃ³ perplexity tháº¥p hÆ¡n mÃ´ hÃ¬nh Poe.

---

### 4.4 ÄÃ¡nh giÃ¡ Ä‘á»‹nh tÃ­nh

Vá»›i cÃ¹ng prompt:

> â€œWhat did the Red Queen say to Alice?â€

* MÃ´ hÃ¬nh Alice sinh há»™i thoáº¡i, Ä‘á»‘i thoáº¡i
* MÃ´ hÃ¬nh Poe sinh vÄƒn báº£n u Ã¡m, siÃªu thá»±c

Äiá»u nÃ y cho tháº¥y mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c phong cÃ¡ch riÃªng biá»‡t. 

---

## 5. Tháº£o luáº­n

### 5.1 Æ¯u Ä‘iá»ƒm

* Há»c Ä‘Æ°á»£c phong cÃ¡ch tÃ¡c giáº£
* Dá»… triá»ƒn khai
* KhÃ´ng cáº§n huáº¥n luyá»‡n tá»« Ä‘áº§u
* Linh hoáº¡t vá»›i nhiá»u táº­p dá»¯ liá»‡u

---

### 5.2 Háº¡n cháº¿

* Dá»… overfitting
* Phá»¥ thuá»™c cháº¥t lÆ°á»£ng dá»¯ liá»‡u
* KhÃ³ Ä‘Ã¡nh giÃ¡ tá»± Ä‘á»™ng
* Tá»‘n tÃ i nguyÃªn tÃ­nh toÃ¡n

Loss tháº¥p khÃ´ng Ä‘á»“ng nghÄ©a vá»›i cháº¥t lÆ°á»£ng sinh vÄƒn báº£n tá»‘t.

---

## 6. Káº¿t luáº­n

NghiÃªn cá»©u Ä‘Ã£ chá»©ng minh ráº±ng mÃ´ hÃ¬nh GPT-Neo cÃ³ thá»ƒ Ä‘Æ°á»£c tinh chá»‰nh thÃ nh cÃ´ng Ä‘á»ƒ mÃ´ phá»ng phong cÃ¡ch vÄƒn há»c khÃ¡c nhau. Viá»‡c sá»­ dá»¥ng cÃ¹ng kiáº¿n trÃºc nhÆ°ng huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u khÃ¡c nhau dáº«n Ä‘áº¿n sá»± khÃ¡c biá»‡t rÃµ rá»‡t trong Ä‘áº§u ra.

HÆ°á»›ng phÃ¡t triá»ƒn tiáº¿p theo:

* Káº¿t há»£p nhiá»u phong cÃ¡ch
* Prompt tuning
* RLHF
* Style regularization
* ÄÃ¡nh giÃ¡ tá»± Ä‘á»™ng nÃ¢ng cao

---

## TÃ i liá»‡u tham kháº£o

1. *Alice in Wonderland and Edgar Allen Poe (with GPT-Neo)*. â€œ6 - Alice in Wonderland and Edgar Allen Poe (with GPT-neo).txtâ€. 
2. Vaswani et al. (2017). *Attention Is All You Need*.
3. Radford et al. (2019). *Language Models are Unsupervised Multitask Learners*.
4. Goodfellow et al. (2016). *Deep Learning*.

---
<!-- Aero-Footer-Start -->
---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
