
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../index.md) > [07 Fine tune pretrained models](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../index.md)
- [ğŸ“š Module 01: LLM Course](../../01-LLM_Course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../02-Words-to-tokens-to-numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../04-buildGPT/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../07-Fine-tune-pretrained-models/index.md)
- [ğŸ” Module 19: AI Safety](../../19-AI-safety/index.md)
- [ğŸ Module 20: Python for AI](../../20-Python-Colab-notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Tinh Chá»‰nh MÃ´ HÃ¬nh GPT-2 Báº±ng HÃ m Máº¥t MÃ¡t KL Divergence Äá»ƒ Tá»‘i Æ¯u HÃ³a Viá»‡c Sinh Token Chá»©a KÃ½ Tá»± â€œXâ€

---

## TÃ³m táº¯t

Tinh chá»‰nh mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (Large Language Models â€“ LLMs) lÃ  má»™t hÆ°á»›ng tiáº¿p cáº­n quan trá»ng nháº±m Ä‘iá»u chá»‰nh hÃ nh vi sinh vÄƒn báº£n theo má»¥c tiÃªu cá»¥ thá»ƒ. BÃ i bÃ¡o nÃ y trÃ¬nh bÃ y phÆ°Æ¡ng phÃ¡p tinh chá»‰nh mÃ´ hÃ¬nh GPT-2 Medium thÃ´ng qua viá»‡c xÃ¢y dá»±ng hÃ m máº¥t mÃ¡t tÃ¹y chá»‰nh dá»±a trÃªn Ä‘á»™ Ä‘o KL Divergence nháº±m gia tÄƒng xÃ¡c suáº¥t sinh cÃ¡c token chá»©a kÃ½ tá»± â€œXâ€. NghiÃªn cá»©u táº­p trung vÃ o viá»‡c phÃ¢n tÃ­ch kiáº¿n trÃºc mÃ´ hÃ¬nh, Ä‘áº·c trÆ°ng Ä‘áº§u ra, chuyá»ƒn Ä‘á»•i logit sang phÃ¢n phá»‘i xÃ¡c suáº¥t, thiáº¿t káº¿ hÃ m máº¥t mÃ¡t vÃ  Ä‘Ã¡nh giÃ¡ tÃ¡c Ä‘á»™ng cá»§a siÃªu tham sá»‘ há»c. Káº¿t quáº£ cho tháº¥y viá»‡c lá»±a chá»n tá»‘c Ä‘á»™ há»c cÃ³ áº£nh hÆ°á»Ÿng quyáº¿t Ä‘á»‹nh Ä‘áº¿n hiá»‡n tÆ°á»£ng quÃ¡ khá»›p vÃ  cháº¥t lÆ°á»£ng sinh vÄƒn báº£n. 

---

## Tá»« khÃ³a

GPT-2, Fine-tuning, KL Divergence, Language Modeling, Custom Loss Function, Token Optimization

---

## 1. Giá»›i thiá»‡u

CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ dá»±a trÃªn Transformer Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c nhiá»u thÃ nh tá»±u trong lÄ©nh vá»±c xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn. Trong Ä‘Ã³, GPT-2 lÃ  má»™t mÃ´ hÃ¬nh sinh vÄƒn báº£n tá»± há»“i quy ná»•i báº­t.

BÃªn cáº¡nh viá»‡c huáº¥n luyá»‡n chuáº©n trÃªn dá»¯ liá»‡u lá»›n, tinh chá»‰nh mÃ´ hÃ¬nh vá»›i má»¥c tiÃªu Ä‘áº·c biá»‡t lÃ  má»™t hÆ°á»›ng nghiÃªn cá»©u quan trá»ng. BÃ i toÃ¡n trong nghiÃªn cá»©u nÃ y nháº±m huáº¥n luyá»‡n GPT-2 sinh ra nhiá»u token chá»©a kÃ½ tá»± â€œXâ€ thÃ´ng qua má»™t hÃ m máº¥t mÃ¡t Ä‘Æ°á»£c thiáº¿t káº¿ riÃªng. 

---

## 2. CÆ¡ sá»Ÿ lÃ½ thuyáº¿t

### 2.1 MÃ´ hÃ¬nh GPT-2

GPT-2 lÃ  mÃ´ hÃ¬nh Transformer má»™t chiá»u vá»›i kiáº¿n trÃºc tá»± há»“i quy. XÃ¡c suáº¥t sinh chuá»—i tá»« (x_1, x_2, ..., x_T) Ä‘Æ°á»£c mÃ´ hÃ¬nh hÃ³a bá»Ÿi:

[
P(x_1, ..., x_T)=\prod_{t=1}^{T} P(x_t|x_1,...,x_{t-1})
]

Má»—i bÆ°á»›c sinh token phá»¥ thuá»™c vÃ o toÃ n bá»™ ngá»¯ cáº£nh trÆ°á»›c Ä‘Ã³.

---

### 2.2 Biá»ƒu diá»…n Logit vÃ  Softmax

Äáº§u ra cá»§a mÃ´ hÃ¬nh táº¡i thá»i Ä‘iá»ƒm (t) lÃ  vector logit:

[
\mathbf{z}_t = (z_1, z_2, ..., z_V)
]

vá»›i (V) lÃ  kÃ­ch thÆ°á»›c tá»« vá»±ng.

XÃ¡c suáº¥t Ä‘Æ°á»£c tÃ­nh báº±ng hÃ m Softmax:

[
P(i|t)=\frac{e^{z_i}}{\sum_{j=1}^{V} e^{z_j}}
]

Log-probability:

[
\log P(i|t)= z_i - \log\left(\sum_{j=1}^{V} e^{z_j}\right)
]

---

### 2.3 Äá»™ Ä‘o KL Divergence

KL Divergence Ä‘o khoáº£ng cÃ¡ch giá»¯a hai phÃ¢n phá»‘i xÃ¡c suáº¥t (P) vÃ  (Q):

[
D_{KL}(P||Q)=\sum_{i} P(i)\log\frac{P(i)}{Q(i)}
]

Trong nghiÃªn cá»©u nÃ y:

* (P): phÃ¢n phá»‘i má»¥c tiÃªu (Æ°u tiÃªn token chá»©a â€œXâ€)
* (Q): phÃ¢n phá»‘i dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh

---

## 3. PhÆ°Æ¡ng phÃ¡p nghiÃªn cá»©u

### 3.1 Kiáº¿n trÃºc mÃ´ hÃ¬nh

MÃ´ hÃ¬nh Ä‘Æ°á»£c sá»­ dá»¥ng lÃ  GPT-2 Medium vá»›i:

* Sá»‘ block Transformer: 24
* Embedding dimension: 1024
* Vocabulary size: 50,257

Cáº¥u trÃºc má»—i block gá»“m:

* Multi-head Attention
* MLP (4Ã— expansion)
* Layer Normalization



---

### 3.2 PhÃ¢n tÃ­ch Ä‘áº§u ra mÃ´ hÃ¬nh

Äáº§u ra cá»§a mÃ´ hÃ¬nh cÃ³ dáº¡ng tensor:

[
O \in \mathbb{R}^{B \times T \times V}
]

Trong Ä‘Ã³:

* (B): Batch size
* (T): Sequence length
* (V): Vocabulary size

VÃ­ dá»¥:

[
O \in \mathbb{R}^{4 \times 64 \times 50257}
]

---

### 3.3 Kiá»ƒm tra phÃ¢n phá»‘i Ä‘áº§u ra

Tá»•ng xÃ¡c suáº¥t:

[
\sum_{i=1}^{V} P_i \neq 1
]

Suy ra Ä‘áº§u ra ban Ä‘áº§u lÃ  logit thÃ´.

Sau khi Ã¡p dá»¥ng:

[
\text{LogSoftmax}(z_i)=\log\frac{e^{z_i}}{\sum_j e^{z_j}}
]

Má»›i thu Ä‘Æ°á»£c phÃ¢n phá»‘i há»£p lá»‡.



---

### 3.4 Biáº¿n Ä‘á»•i dá»¯ liá»‡u

Tensor 3 chiá»u Ä‘Æ°á»£c reshape thÃ nh:

[
\mathbb{R}^{(B \times T) \times V}
]

Cá»¥ thá»ƒ:

[
4 \times 64 \times 50257 \rightarrow 256 \times 50257
]

Nháº±m phÃ¹ há»£p vá»›i hÃ m máº¥t mÃ¡t KL.

---

### 3.5 HÃ m máº¥t mÃ¡t tÃ¹y chá»‰nh

HÃ m máº¥t mÃ¡t Ä‘Æ°á»£c thiáº¿t káº¿ nhÆ° sau:

[
\mathcal{L} = D_{KL}(P_{target}||Q_{model})
]

Trong Ä‘Ã³:

[
P_{target}(i)=
\begin{cases}
\alpha & \text{náº¿u token chá»©a "X"} \
\beta & \text{ngÆ°á»£c láº¡i}
\end{cases}
]

vá»›i (\alpha > \beta).

Má»¥c tiÃªu lÃ  tÄƒng xÃ¡c suáº¥t token chá»©a â€œXâ€.



---

### 3.6 Quy trÃ¬nh huáº¥n luyá»‡n

Má»—i vÃ²ng huáº¥n luyá»‡n gá»“m:

1. Sinh token ngáº«u nhiÃªn
2. Forward pass
3. LogSoftmax
4. TÃ­nh KL loss
5. Backpropagation
6. Cáº­p nháº­t tham sá»‘

CÃ´ng thá»©c cáº­p nháº­t:

[
\theta_{t+1}=\theta_t - \eta\nabla_\theta \mathcal{L}
]

vá»›i (\eta) lÃ  learning rate.

---

## 4. Thá»±c nghiá»‡m

### 4.1 Thiáº¿t láº­p

| Tham sá»‘         | GiÃ¡ trá»‹           |
| --------------- | ----------------- |
| Batch size      | 4                 |
| Sequence length | 64                |
| Epochs          | 300               |
| Optimizer       | Adam              |
| Learning rate   | (10^{-6},10^{-4}) |



---

### 4.2 áº¢nh hÆ°á»Ÿng cá»§a Learning Rate

#### TrÆ°á»ng há»£p (\eta = 10^{-6})

* Loss giáº£m: 6 â†’ 2
* Ãt token chá»©a â€œXâ€
* VÄƒn báº£n cÃ²n tá»± nhiÃªn

#### TrÆ°á»ng há»£p (\eta = 10^{-4})

* Loss â†’ 0.001
* 100% token chá»©a â€œXâ€
* VÄƒn báº£n vÃ´ nghÄ©a

Hiá»‡n tÆ°á»£ng overfitting rÃµ rá»‡t.

---

### 4.3 ÄÃ¡nh giÃ¡ káº¿t quáº£

Chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡:

[
R = \frac{Sá»‘\ token\ chá»©a\ X}{Tá»•ng\ token}
]

Khi (\eta=10^{-4}):

[
R \approx 1
]

Cho tháº¥y mÃ´ hÃ¬nh bá»‹ chi phá»‘i hoÃ n toÃ n bá»Ÿi má»¥c tiÃªu phá»¥.



---

## 5. Tháº£o luáº­n

### 5.1 Æ¯u Ä‘iá»ƒm

* Linh hoáº¡t Ä‘iá»u chá»‰nh hÃ nh vi mÃ´ hÃ¬nh
* KhÃ´ng cáº§n huáº¥n luyá»‡n láº¡i tá»« Ä‘áº§u
* Dá»… má»Ÿ rá»™ng sang má»¥c tiÃªu khÃ¡c

---

### 5.2 Háº¡n cháº¿

* Dá»… quÃ¡ khá»›p
* Máº¥t tÃ­nh tá»± nhiÃªn
* Nháº¡y cáº£m vá»›i siÃªu tham sá»‘
* KhÃ³ cÃ¢n báº±ng nhiá»u má»¥c tiÃªu

Fine-tuning Ä‘Ã²i há»i nhiá»u thá»­ nghiá»‡m thá»±c táº¿. 

---

## 6. Káº¿t luáº­n

NghiÃªn cá»©u Ä‘Ã£ trÃ¬nh bÃ y phÆ°Æ¡ng phÃ¡p tinh chá»‰nh GPT-2 báº±ng hÃ m máº¥t mÃ¡t KL nháº±m tá»‘i Æ°u hÃ³a viá»‡c sinh token chá»©a â€œXâ€. Káº¿t quáº£ cho tháº¥y learning rate lÃ  yáº¿u tá»‘ quyáº¿t Ä‘á»‹nh Ä‘áº¿n hiá»‡u quáº£ vÃ  Ä‘á»™ á»•n Ä‘á»‹nh cá»§a mÃ´ hÃ¬nh.

HÆ°á»›ng phÃ¡t triá»ƒn tÆ°Æ¡ng lai:

* Multi-objective fine-tuning
* Reinforcement Learning from Human Feedback
* Regularization nÃ¢ng cao
* Human-in-the-loop training

---

## TÃ i liá»‡u tham kháº£o

1. Code Challenge: *Maximize the X Factor*, â€œ5 - CodeChallenge Maximize the X factor.txtâ€. 
2. Vaswani et al. (2017). *Attention Is All You Need*.
3. Radford et al. (2019). *Language Models are Unsupervised Multitask Learners*.
4. Goodfellow et al. (2016). *Deep Learning*.

---
<!-- Aero-Footer-Start -->
---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
