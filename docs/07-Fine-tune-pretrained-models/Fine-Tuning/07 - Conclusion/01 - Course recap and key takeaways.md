# Tóm Tắt Khóa Học Và Điểm Chính

## Giới Thiệu

Chúng ta đã đi qua các kỹ thuật và phương pháp cần thiết để fine-tuning các mô hình ngôn ngữ lớn. Hãy dành một khoảng thời gian để tóm tắt các khái niệm và kỹ năng quan trọng mà chúng ta đã covered.

## Hành Trình Của Chúng Ta

### Bắt Đầu: Hiểu Tầm Quan Trọng Của Fine-tuning

Chúng ta bắt đầu bằng việc hiểu tầm quan trọng của fine-tuning và cách nó nâng cao hiệu suất của các mô hình pre-trained cho các tác vụ cụ thể.

### Khám Phá Kiến Trúc

Từ đó, chúng ta khám phá các kiến trúc khác nhau, bao gồm encoder-decoder, encoder-only, và decoder-only, hiểu các điểm mạnh và trường hợp sử dụng độc đáo của chúng.

### Ứng Dụng Thực Tế

Thông qua các ví dụ thực tế, chúng ta đã đi sâu vào các ứng dụng thực tế của LLMs trong nhiều ngành, như y tế, tài chính, và dịch vụ khách hàng. Những ví dụ này nhấn mạnh fine-tuning có thể được tận dụng để tạo ra các giải pháp mạnh mẽ và hiệu quả được tùy chỉnh cho nhu cầu cụ thể.

### Khía Cạnh Kỹ Thuật

Sau đó, chúng ta tập trung vào các khía cạnh kỹ thuật nơi chúng ta fine-tuned các mô hình sử dụng LoRA adapters. Kỹ thuật đổi mới này cho phép parameter-efficient fine-tuning, làm cho việc thích nghi các mô hình lớn khả thi ngay cả với tài nguyên tính toán hạn chế.

### Thực Hành Hands-on

Trong suốt khóa học, bạn đã tham gia vào các bài tập hands-on từ:
- Fine-tuning BERT models cho phân tích cảm xúc với LoRA
- Simple transfer learning cho Q&A và tóm tắt
- Áp dụng LoRA adapters trong T5-small
- Tóm tắt hiệu quả

Những bài tập này cung cấp cho bạn kinh nghiệm thực tế và hiểu biết sâu hơn về quá trình fine-tuning.

## Điểm Chính Từ Khóa Học

### 1. Hiểu Fine-tuning
Nắm bắt ý nghĩa quan trọng và các kỹ thuật của fine-tuning LLMs.

### 2. Học Kiến Trúc Mô Hình  
Làm quen với các kiến trúc mô hình khác nhau và trường hợp sử dụng của chúng.

### 3. Học Ứng Dụng Thực Tế
Bạn đã học các ứng dụng thực tế về cách fine-tuning có thể được triển khai để giải quyết các vấn đề cụ thể.

### 4. LoRA Adapters
Bạn đã học cách sử dụng LoRA cho parameter-efficient fine-tuning.

### 5. Thực Hành Hands-on
Có được kinh nghiệm thực tế thông qua các bài tập về phân tích cảm xúc, Q&A, và tóm tắt.

## Kết Luận

Khóa học này đã trang bị cho bạn các kỹ năng và kiến thức cần thiết để fine-tune các mô hình ngôn ngữ lớn một cách hiệu quả. Với những gì bạn đã học, bạn có thể áp dụng các kỹ thuật này vào các dự án thực tế và tiếp tục khám phá thế giới đầy tiềm năng của LLMs.

## Tài liệu tham khảo

1. **Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., & Polosukhin, I. (2017).** *Attention Is All You Need.* Advances in Neural Information Processing Systems, 30, 5998-6008. https://arxiv.org/abs/1706.03762

2. **Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018).** *BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.* arXiv preprint arXiv:1810.04805. https://arxiv.org/abs/1810.04805

3. **Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., & Liu, P. J. (2019).** *Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.* arXiv preprint arXiv:1910.10683. https://arxiv.org/abs/1910.10683

4. **Hu, E. J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., & Chen, W. (2021).** *LoRA: Low-Rank Adaptation of Large Language Models.* arXiv preprint arXiv:2106.09685. https://arxiv.org/abs/2106.09685

5. **Chung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., ... & Wei, J. (2022).** *Scaling Instruction-Finetuned Language Models.* arXiv preprint arXiv:2210.11416. https://arxiv.org/abs/2210.11416

6. **Longpre, S., Hou, L., Vu, T., Webson, A., Chung, H. W., Tay, Y., Zhou, D., Le, Q. V., Zoph, B., Wei, J., & Roberts, A. (2023).** *The Flan Collection: Designing Data and Methods for Effective Instruction Tuning.* arXiv preprint arXiv:2301.13688. https://arxiv.org/abs/2301.13688

7. **Han, Z., Gao, C., Liu, J., Zhang, J., & Zhang, S. Q. (2024).** *Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey.* arXiv preprint arXiv:2403.14608. https://arxiv.org/abs/2403.14608

8. **Weidinger, L., Mellor, J., Rauh, M., Griffin, C., Uesato, J., Huang, P. S., Cheng, M., Glaese, M., Balle, B., Kasirzadeh, A., Kenton, Z., Brown, S., Hawkins, W., Stepleton, T., Biles, C., Birhane, A., Haas, J., Rimell, L., Hendricks, L. A., ... & Gabriel, I. (2021).** *Ethical and Social Risks of Harm from Language Models.* DeepMind. https://storage.googleapis.com/deepmind-media/research/language-research/Ethical%20and%20social%20risks.pdf

9. **Bengio, Y., Mindermann, S., Privitera, D., Besiroglu, T., Bommasani, R., Casper, S., Choi, Y., Goldfarb, D., Heidari, H., Khalatbari, L., Longpre, S., Mavroudis, V., Mazeika, M., Ng, K. Y., Okolo, C. T., Raji, D., Skeadas, T., Tramèr, F., Adekanmbi, B., ... & Zhou, D. (2024).** *International Scientific Report on the Safety of Advanced AI (Interim Report).* arXiv preprint arXiv:2412.05282. https://arxiv.org/abs/2412.05282

10. **Amodei, D., Ananthanarayanan, S., Bapna, R., Chen, Z., Du, E., Goodfellow, I., ... & Sutskever, I. (2016).** *Concrete Problems in AI Safety.* arXiv preprint arXiv:1606.06565. https://arxiv.org/abs/1606.06565

11. **Dettmers, T., Pagnoni, A., Holtzman, A., & Zettlemoyer, L. (2024).** *QLoRA: Efficient Finetuning of Quantized LLMs.* arXiv preprint arXiv:2305.14314. https://arxiv.org/abs/2305.14314

12. **Zhang, Y., Yang, X., Cai, Y., & Giannakis, G. B. (2025).** *ScaLoRA: Optimally Scaled Low-Rank Adaptation for Efficient High-Rank Fine-Tuning.* arXiv preprint arXiv:2510.23818. https://arxiv.org/abs/2510.23818

13. **Wang, R., Dvijotham, K. D., & Manchester, I. R. (2025).** *Norm-Bounded Low-Rank Adaptation.* arXiv preprint arXiv:2501.19050. https://arxiv.org/abs/2501.19050

14. **Liu, H., Tam, D., Muqeeth, M., Mohta, J., Huang, T. A., Bernhard, M., ... & Houlsby, N. (2022).** *LoRA+: Efficient Low Rank Adaptation of Large Models.* arXiv preprint arXiv:2402.12354. https://arxiv.org/abs/2402.12354

15. **Wang, L., Lyu, C., Ji, T., Chen, M., Yu, Z., Shi, A., ... & Yu, P. S. (2023).** *A Survey on Parameter-Efficient Fine-Tuning for Foundation Models.* arXiv preprint arXiv:2504.21099. https://arxiv.org/abs/2504.21099

16. **Laakso, A., Kemell, K. K., & Nurminen, J. K. (2024).** *Ethical Issues in Large Language Models: A Systematic Literature Review.* CEUR Workshop Proceedings, 3901. https://ceur-ws.org/Vol-3901/paper_4.pdf

17. **Bosma, M., & Wei, J. (2021).** *Introducing FLAN: More Generalizable Language Models with Instruction Fine-Tuning.* Google AI Blog. https://research.google/blog/introducing-flan-more-generalizable-language-models-with-instruction-fine-tuning/

18. **Roberts, A., & Raffel, C. (2020).** *Exploring Transfer Learning with T5: the Text-To-Text Transfer Transformer.* Google AI Blog. https://research.google/blog/exploring-transfer-learning-with-t5-the-text-to-text-transfer-transformer/

19. **Lester, B., Al-Rfou, R., & Wang, L. (2021).** *The Power of Scale for Parameter-Efficient Prompt Tuning.* Proceedings of EMNLP 2021. https://arxiv.org/abs/2104.08691

20. **Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., ... & Amodei, D. (2020).** *Language Models are Few-Shot Learners.* Advances in Neural Information Processing Systems, 33, 1877-1901. https://arxiv.org/abs/2005.14165
