
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../../../index.md) > [07 Fine tune pretrained models](../../../index.md) > [Fine Tuning](../../index.md) > [06   5. Project Creating a Full NLP Solution](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../../../index.md)
- [ğŸ“š Module 01: LLM Course](../../../../01-LLM_Course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../../../02-Words-to-tokens-to-numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../../../04-buildGPT/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../../../07-Fine-tune-pretrained-models/index.md)
- [ğŸ” Module 19: AI Safety](../../../../19-AI-safety/index.md)
- [ğŸ Module 20: Python for AI](../../../../20-Python-Colab-notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Demo TÃ­ch Há»£p Má»i Thá»© vÃ o Giáº£i PhÃ¡p

## Tá»•ng Quan

Trong bÃ i hÆ°á»›ng dáº«n thá»±c hÃ nh cuá»‘i cÃ¹ng nÃ y, chÃºng ta sáº½ xem xÃ©t cÃ¡ch táº¡o má»™t chatbot hoÃ n chá»‰nh sá»­ dá»¥ng ba mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c fine-tune: phÃ¢n tÃ­ch cáº£m xÃºc, tÃ³m táº¯t vÃ  tráº£ lá»i cÃ¢u há»i. Chatbot sáº½ Ä‘Æ°á»£c triá»ƒn khai sá»­ dá»¥ng Flask.

## 1. Giá»›i Thiá»‡u Kiáº¿n TrÃºc

### 1.1 CÃ¡c ThÃ nh Pháº§n

Má»™t chatbot hoÃ n chá»‰nh bao gá»“m:

| ThÃ nh pháº§n | Chá»©c nÄƒng | MÃ´ hÃ¬nh |
|------------|-----------|---------|
| Sentiment Analysis | PhÃ¢n tÃ­ch cáº£m xÃºc ngÆ°á»i dÃ¹ng | SST-2 fine-tuned |
| Summarization | TÃ³m táº¯t cuá»™c trÃ² chuyá»‡n | CNN DailyMail fine-tuned |
| Question Answering | Tráº£ lá»i cÃ¢u há»i | SQuAD fine-tuned |
| Text Generation | Táº¡o pháº£n há»“i | GPT-2 |

### 1.2 Luá»“ng Hoáº¡t Äá»™ng

```
User Input â†’ Sentiment Analysis â†’ Response Generation
                  â†“
            Summarization â†’ Conversation History
                  â†“
            Question Answering â†’ (if question detected)
```

## 2. Triá»ƒn Khai Chi Tiáº¿t

### 2.1 CÃ i Äáº·t Flask

```python
!pip install flask requests

from flask import Flask, request, jsonify
import requests
```

### 2.2 Táº£i CÃ¡c MÃ´ HÃ¬nh

```python
from transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer

# Táº£i mÃ´ hÃ¬nh phÃ¢n tÃ­ch cáº£m xÃºc
sentiment_model = TFAutoModelForSeq2SeqLM.from_pretrained("path/to/sentiment_model")
sentiment_tokenizer = AutoTokenizer.from_pretrained("path/to/sentiment_tokenizer")

# Táº£i mÃ´ hÃ¬nh tÃ³m táº¯t
summarization_model = TFAutoModelForSeq2SeqLM.from_pretrained("google/flan-t5-large")
summarization_tokenizer = AutoTokenizer.from_pretrained("google/flan-t5-large")

# Táº£i mÃ´ hÃ¬nh QA
qa_model = TFAutoModelForSeq2SeqLM.from_pretrained("path/to/qa_model")
qa_tokenizer = AutoTokenizer.from_pretrained("path/to/qa_tokenizer")

# Táº£i mÃ´ hÃ¬nh text generation (GPT-2)
from transformers import TFGPT2LMHeadModel
generation_model = TFGPT2LMHeadModel.from_pretrained("gpt2")
generation_tokenizer = AutoTokenizer.from_pretrained("gpt2")
```

### 2.3 Äá»‹nh NghÄ©a CÃ¡c HÃ m Chá»©c NÄƒng

#### 2.3.1 TÃ³m Táº¯t Cuá»™c TrÃ² Chuyá»‡n

```python
def summarize_conversation(conversation_history):
    """TÃ³m táº¯t toÃ n bá»™ cuá»™c trÃ² chuyá»‡n"""
    prompt = "summarize: " + " ".join(conversation_history)
    
    inputs = summarization_tokenizer(prompt, return_tensors="tf", max_length=512)
    outputs = summarization_model.generate(**inputs, max_length=150)
    
    return summarization_tokenizer.decode(outputs[0], skip_special_tokens=True)
```

#### 2.3.2 Tráº£ Lá»i CÃ¢u Há»i

```python
def answer_question(context, question):
    """Tráº£ lá»i cÃ¢u há»i dá»±a trÃªn context"""
    prompt = f"{context} Question: {question} Answer:"
    
    inputs = qa_tokenizer(prompt, return_tensors="tf", max_length=384)
    outputs = qa_model.generate(**inputs, max_length=128)
    
    return qa_tokenizer.decode(outputs[0], skip_special_tokens=True)
```

#### 2.3.3 Táº¡o Pháº£n Há»“i

```python
def generate_response(user_message, sentiment):
    """Táº¡o pháº£n há»“i dá»±a trÃªn cáº£m xÃºc"""
    if sentiment == "negative":
        prompt = f"The user is angry. Their message: {user_message}"
    else:
        prompt = user_message
    
    inputs = generation_tokenizer(prompt, return_tensors="tf")
    outputs = generation_model.generate(**inputs, max_length=100)
    
    return generation_tokenizer.decode(outputs[0], skip_special_tokens=True)
```

#### 2.3.4 PhÃ¢n TÃ­ch Cáº£m XÃºc

```python
def analyze_sentiment(message):
    """PhÃ¢n tÃ­ch cáº£m xÃºc cá»§a tin nháº¯n"""
    prompt = f"sst2 sentence: {message}"
    
    inputs = sentiment_tokenizer(prompt, return_tensors="tf")
    outputs = sentiment_model.generate(**inputs)
    
    result = sentiment_tokenizer.decode(outputs[0], skip_special_tokens=True)
    
    return "negative" if "negative" in result.lower() else "positive"
```

### 2.4 Táº¡o Flask App

```python
app = Flask(__name__)

# LÆ°u trá»¯ lá»‹ch sá»­ cuá»™c trÃ² chuyá»‡n
conversation_history = []
conversation_summary = []

@app.route('/reset', methods=['POST'])
def reset():
    """Reset cuá»™c trÃ² chuyá»‡n"""
    global conversation_history, conversation_summary
    
    # TÃ³m táº¯t cuá»™c trÃ² chuyá»‡n trÆ°á»›c khi reset
    if conversation_history:
        summary = summarize_conversation(conversation_history)
        conversation_summary.append(summary)
    
    conversation_history = []
    return jsonify({"summary": summary})

@app.route('/greet', methods=['GET'])
def greet():
    """ChÃ o há»i"""
    return jsonify({"message": "Hello! How can I help you today?"})

@app.route('/chat', methods=['POST'])
def chat():
    """Xá»­ lÃ½ tin nháº¯n chat"""
    global conversation_history
    
    # Láº¥y tin nháº¯n tá»« request
    user_message = request.json.get('message')
    
    # ThÃªm vÃ o lá»‹ch sá»­
    conversation_history.append(user_message)
    
    # PhÃ¢n tÃ­ch cáº£m xÃºc
    sentiment = analyze_sentiment(user_message)
    
    # Kiá»ƒm tra loáº¡i tin nháº¯n
    if "summarize" in user_message.lower():
        response = summarize_conversation(conversation_history)
    
    elif "?" in user_message:
        # Sá»­ dá»¥ng QA model
        context = " ".join(conversation_history[-5:])
        response = answer_question(context, user_message)
    
    else:
        # Sá»­ dá»¥ng text generation
        response = generate_response(user_message, sentiment)
    
    # LÆ°u pháº£n há»“i vÃ o lá»‹ch sá»­
    conversation_history.append(response)
    
    return jsonify({
        "response": response,
        "sentiment": sentiment
    })

if __name__ == '__main__':
    app.run(port=5000)
```

## 3. Kiá»ƒm Tra Chatbot

### 3.1 Cháº¡y Chatbot

```python
# Khá»Ÿi Ä‘á»™ng Flask app trong background
import subprocess
subprocess.Popen(["python", "chatbot.py"], stdout=open("nohup.out", "w"))
```

### 3.2 CÃ¡c Lá»‡nh Test

```python
import requests

BASE_URL = "http://localhost:5000"

# Test greeting
response = requests.get(f"{BASE_URL}/greet")
print(response.json())

# Test chat - cÃ¢u há»i
response = requests.post(f"{BASE_URL}/chat", json={
    "message": "What is the capital of France?"
})
print(response.json())

# Test chat - tÃ³m táº¯t
response = requests.post(f"{BASE_URL}/chat", json={
    "message": "Summarize this conversation"
})
print(response.json())

# Test chat - tin nháº¯n thÆ°á»ng
response = requests.post(f"{BASE_URL}/chat", json={
    "message": "I want to build an app"
})
print(response.json())

# Test reset
response = requests.post(f"{BASE_URL}/reset")
print(response.json())
```

### 3.3 Káº¿t Quáº£ Máº«u

| Loáº¡i test | Input | Output |
|-----------|-------|--------|
| Greeting | - | "Hello! How can I help you today?" |
| Question | "What is the capital of France?" | "Paris" |
| Summarization | "Summarize..." | "The Bastille was a fortress..." |
| Text gen | "I want to build an app" | "What do you want?" |
| Reset | - | Summary of conversation |

## 4. PhÃ¢n TÃ­ch Kiáº¿n TrÃºc

### 4.1 SÆ¡ Äá»“ Luá»“ng Dá»¯ Liá»‡u

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User      â”‚â”€â”€â”€â”€>â”‚  Sentiment        â”‚
â”‚  Input     â”‚     â”‚  Analysis         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                   â”‚                   â”‚
         â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Summarize   â”‚     â”‚  Question        â”‚  â”‚   Text      â”‚
â”‚ (if asked)  â”‚     â”‚  Answer          â”‚  â”‚  Generation â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  (if "?")        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Æ¯u vÃ  NhÆ°á»£c Äiá»ƒm

| Æ¯u Ä‘iá»ƒm | NhÆ°á»£c Ä‘iá»ƒm |
|----------|-------------|
| Module, dá»… má»Ÿ rá»™ng | Cáº§n nhiá»u model |
| Linh hoáº¡t | Latency cao |
| Dá»… debug | TÃ i nguyÃªn lá»›n |

## 5. Káº¿t Luáº­n

Trong bÃ i hÆ°á»›ng dáº«n nÃ y, chÃºng ta Ä‘Ã£:

1. **TÃ­ch há»£p** ba mÃ´ hÃ¬nh fine-tuned vÃ o má»™t chatbot
2. **Triá»ƒn khai** sá»­ dá»¥ng Flask
3. **Xá»­ lÃ½** cÃ¡c loáº¡i tin nháº¯n khÃ¡c nhau
4. **Quáº£n lÃ½** lá»‹ch sá»­ cuá»™c trÃ² chuyá»‡n

Chatbot cÃ³ thá»ƒ Ä‘Æ°á»£c cáº£i thiá»‡n báº±ng:
- Sá»­ dá»¥ng mÃ´ hÃ¬nh lá»›n hÆ¡n
- ThÃªm memory cho long-term context
- Fine-tune cho domain cá»¥ thá»ƒ

## TÃ i Liá»‡u Tham Kháº£o

1. Adiwardana, D., et al. (2020). "Towards a Human-like Open-Domain Chatbot." *Google Research*.

2. Roller, S., et al. (2020). "Recipes for building an open-domain chatbot." *EACL 2021*.

3. Huang, M., et al. (2020). "Sextant: A Conversational AI System for Crisis Support." *ACL 2020*.
<!-- Aero-Footer-Start -->
---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
