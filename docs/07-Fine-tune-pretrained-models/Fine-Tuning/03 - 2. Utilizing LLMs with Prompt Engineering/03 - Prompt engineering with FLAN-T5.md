
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../../../index.md) > [07 Fine tune pretrained models](../../../index.md) > [Fine Tuning](../../index.md) > [03   2. Utilizing LLMs with Prompt Engineering](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../../../index.md)
- [ğŸ“š Module 01: LLM Course](../../../../01-LLM_Course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../../../02-Words-to-tokens-to-numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../../../04-buildGPT/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../../../07-Fine-tune-pretrained-models/index.md)
- [ğŸ” Module 19: AI Safety](../../../../19-AI-safety/index.md)
- [ğŸ Module 20: Python for AI](../../../../20-Python-Colab-notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Prompt Engineering Vá»›i FLAN-T5

## Giá»›i Thiá»‡u

HÃ£y nÃ³i vá» cÃ¡ch sá»­ dá»¥ng mÃ´ hÃ¬nh Ä‘a nÄƒng nÃ y cho tÃ³m táº¯t vÄƒn báº£n, dá»‹ch thuáº­t vÃ  tráº£ lá»i cÃ¢u há»i sá»­ dá»¥ng thÆ° viá»‡n Hugging Face Transformers vÃ  TensorFlow.

Hugging Face lÃ  má»™t ná»n táº£ng lÆ°u trá»¯ má»™t bá»™ sÆ°u táº­p lá»›n cÃ¡c mÃ´ hÃ¬nh pre-trained, bao gá»“m FLAN-T5, cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘iá»u chá»‰nh cho nhiá»u tÃ¡c vá»¥ dá»±a trÃªn vÄƒn báº£n.

## CÃ i Äáº·t MÃ´i TrÆ°á»ng

Äáº§u tiÃªn, chÃºng ta cáº§n cÃ i Ä‘áº·t mÃ´i trÆ°á»ng cá»§a mÃ¬nh. Äiá»u nÃ y bao gá»“m cÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n transformers vÃ  TensorFlow, cung cáº¥p cÆ¡ sá»Ÿ háº¡ táº§ng vÃ  mÃ´ hÃ¬nh cáº§n thiáº¿t cho cÃ¡c tÃ¡c vá»¥ cá»§a chÃºng ta.

## Táº£i FLAN-T5

Sau khi cÃ i Ä‘áº·t, chÃºng ta sáº½ táº£i FLAN-T5 sá»­ dá»¥ng thÆ° viá»‡n Transformers. Äá»ƒ lÃ m Ä‘iá»u Ä‘Ã³, chÃºng ta sáº½ sá»­ dá»¥ng:
- **AutoTokenizer:** Xá»­ lÃ½ vÄƒn báº£n thÃ nh Ä‘á»‹nh dáº¡ng mÃ  mÃ´ hÃ¬nh cÃ³ thá»ƒ lÃ m viá»‡c, chuyá»ƒn Ä‘á»•i cÃ¢u thÃ nh chuá»—i tokens hoáº·c biá»ƒu diá»…n sá»‘.
- **TFAutoModelForSeq2SeqLM:** MÃ´ hÃ¬nh sáº½ diá»…n giáº£i cÃ¡c tokens nÃ y vÃ  táº¡o vÄƒn báº£n dá»±a trÃªn chÃºng.

## TÃ³m Táº¯t VÄƒn Báº£n (Text Summarization)

Cho tÃ³m táº¯t vÄƒn báº£n, chÃºng ta sáº½ cho FLAN-T5 má»™t Ä‘oáº¡n vÄƒn báº£n vÃ  yÃªu cáº§u má»™t báº£n tÃ³m táº¯t ngáº¯n gá»n.

**CÃ¡c bÆ°á»›c thá»±c hiá»‡n:**
1. Äáº·t prompt (vÃ­ dá»¥: "Summarize the following article about carrots")
2. Tokenize vá»›i `return_tensors="tf"` Ä‘á»ƒ xuáº¥t TensorFlow tensors
3. Giá»›i háº¡n Ä‘á»™ dÃ i vá»›i `max_length=512`
4. Sá»­ dá»¥ng `model.generate()` Ä‘á»ƒ táº¡o Ä‘áº§u ra
5. Decode káº¿t quáº£ vá»›i tokenizer

**Tham sá»‘ quan trá»ng:**
- `num_beams`: Kiá»ƒm soÃ¡t beam search
- `early_stopping`: Dá»«ng táº¡o khi cÃ³ cÃ¢u tráº£ lá»i hÃ i lÃ²ng
- `max_length`: Giá»›i háº¡n sá»‘ tokens

## Dá»‹ch Thuáº­t (Translation)

Cho dá»‹ch thuáº­t tá»« tiáº¿ng Anh sang tiáº¿ng PhÃ¡p:
- Prompt: "translate English to French: [vÄƒn báº£n cáº§n dá»‹ch]"
- Tiáº¿p tá»¥c vá»›i cÃ¡c bÆ°á»›c tokenize, generate, vÃ  decode

## Tráº£ Lá»i CÃ¢u Há»i (Question Answering)

Cho tráº£ lá»i cÃ¢u há»i:
- Cung cáº¥p ngá»¯ cáº£nh: "The Great Wall of China is over 13,000 miles long."
- Äáº·t cÃ¢u há»i: "question: How long is the Great Wall of China?"

**Tham sá»‘ quan trá»ng:**
- `num_beams`: Kiá»ƒm soÃ¡t beam search algorithm
- `early_stopping`: Quan trá»ng trong Q&A, dá»«ng táº¡o khi cÃ³ cÃ¢u tráº£ lá»i hÃ i lÃ²ng

## Káº¿t Luáº­n

ChÃºng ta Ä‘Ã£ tháº¥y cÃ¡ch Ã¡p dá»¥ng FLAN-T5 cho ba tÃ¡c vá»¥ khÃ¡c nhau, chá»©ng minh tÃ­nh linh hoáº¡t vÃ  sá»©c máº¡nh cá»§a mÃ´ hÃ¬nh. Báº±ng cÃ¡ch hiá»ƒu cÃ¡ch táº¡o prompts hiá»‡u quáº£ vÃ  cáº¥u hÃ¬nh cÃ¡c tham sá»‘ mÃ´ hÃ¬nh, báº¡n cÃ³ thá»ƒ nÃ¢ng cao kháº£ nÄƒng cá»§a cÃ¡c á»©ng dá»¥ng cá»§a mÃ¬nh, lÃ m cho chÃºng thÃ´ng minh vÃ  pháº£n há»“i nhanh hÆ¡n.

## TÃ i Liá»‡u Tham Kháº£o

1. Liu, P., et al. (2023). "Prefix Tuning vs. Prompt Tuning: A Comparative Study." *arXiv:2303.13402*.

2. Reynolds, L., & McDonell, K. (2021). "Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm." *arXiv:2102.07350*.

3. Stiennon, N., et al. (2020). "Learning to Summarize with Human Feedback." *Advances in Neural Information Processing Systems*, 33, 3008-3021.
<!-- Aero-Footer-Start -->
---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
