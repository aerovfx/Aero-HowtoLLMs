
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../index.md) > [07 Fine tune pretrained models](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../index.md)
- [ğŸ“š Module 01: LLM Course](../../01-LLM_Course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../02-Words-to-tokens-to-numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../04-buildGPT/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../07-Fine-tune-pretrained-models/index.md)
- [ğŸ” Module 19: AI Safety](../../19-AI-safety/index.md)
- [ğŸ Module 20: Python for AI](../../20-Python-Colab-notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Fine-tuning MÃ´ hÃ¬nh GPT-2 trÃªn TÃ¡c pháº©m *Gulliverâ€™s Travels*: PhÃ¢n tÃ­ch Thá»±c nghiá»‡m vÃ  ÄÃ¡nh giÃ¡ Hiá»‡u quáº£

## TÃ³m táº¯t (Abstract)

BÃ i viáº¿t nÃ y trÃ¬nh bÃ y quy trÃ¬nh fine-tuning mÃ´ hÃ¬nh ngÃ´n ngá»¯ GPT-2 Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n sáºµn trÃªn vÄƒn báº£n *Gulliverâ€™s Travels*. ThÃ´ng qua viá»‡c phÃ¢n tÃ­ch táº§n suáº¥t token, Ä‘Ã¡nh giÃ¡ loss huáº¥n luyá»‡n vÃ  cháº¥t lÆ°á»£ng vÄƒn báº£n sinh ra, nghiÃªn cá»©u cho tháº¥y quÃ¡ trÃ¬nh fine-tuning giÃºp mÃ´ hÃ¬nh thÃ­ch nghi tá»‘t hÆ¡n vá»›i phong cÃ¡ch vÄƒn báº£n má»¥c tiÃªu. Tuy nhiÃªn, viá»‡c giáº£m loss quÃ¡ má»©c cÅ©ng tiá»m áº©n nguy cÆ¡ overfitting, áº£nh hÆ°á»Ÿng Ä‘áº¿n kháº£ nÄƒng sÃ¡ng táº¡o cá»§a mÃ´ hÃ¬nh.

---

## 1. Giá»›i thiá»‡u (Introduction)

Fine-tuning lÃ  má»™t ká»¹ thuáº­t phá»• biáº¿n trong há»c sÃ¢u nháº±m Ä‘iá»u chá»‰nh mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n sáºµn cho má»™t nhiá»‡m vá»¥ hoáº·c táº­p dá»¯ liá»‡u cá»¥ thá»ƒ. Trong lÄ©nh vá»±c xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn, GPT-2 lÃ  má»™t mÃ´ hÃ¬nh ná»n táº£ng máº¡nh máº½, cÃ³ thá»ƒ Ä‘Æ°á»£c tinh chá»‰nh Ä‘á»ƒ thÃ­ch nghi vá»›i phong cÃ¡ch vÄƒn báº£n chuyÃªn biá»‡t.

Theo tÃ i liá»‡u, má»¥c tiÃªu chÃ­nh cá»§a quÃ¡ trÃ¬nh nÃ y lÃ  huáº¥n luyá»‡n GPT-2 trÃªn tÃ¡c pháº©m *Gulliverâ€™s Travels* nháº±m táº¡o ra vÄƒn báº£n mang phong cÃ¡ch tÆ°Æ¡ng tá»±, thay vÃ¬ huáº¥n luyá»‡n tá»« Ä‘áº§u. CÃ¡ch tiáº¿p cáº­n nÃ y táº­n dá»¥ng tri thá»©c ngÃ´n ngá»¯ Ä‘Ã£ há»c trÆ°á»›c Ä‘Ã³ cá»§a mÃ´ hÃ¬nh .

---

## 2. PhÆ°Æ¡ng phÃ¡p (Methodology)

### 2.1. MÃ´ hÃ¬nh vÃ  MÃ´i trÆ°á»ng Huáº¥n luyá»‡n

NghiÃªn cá»©u sá»­ dá»¥ng mÃ´ hÃ¬nh GPT-2 ná»n táº£ng Ä‘Æ°á»£c cung cáº¥p bá»Ÿi thÆ° viá»‡n Hugging Face, káº¿t há»£p vá»›i PyTorch Ä‘á»ƒ huáº¥n luyá»‡n. MÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘Æ°a lÃªn GPU nháº±m tÄƒng tá»‘c Ä‘á»™ xá»­ lÃ½ trong quÃ¡ trÃ¬nh fine-tuning .

CÃ¡c siÃªu tham sá»‘ chÃ­nh bao gá»“m:

* Batch size: 16
* Äá»™ dÃ i chuá»—i: 256 token
* Learning rate: nhá» hÆ¡n so vá»›i huáº¥n luyá»‡n tá»« Ä‘áº§u
* Tá»‘i Æ°u hÃ³a: Adam optimizer

Viá»‡c sá»­ dá»¥ng learning rate nhá» giÃºp trÃ¡nh lÃ m máº¥t cÃ¡c tri thá»©c ngÃ´n ngá»¯ Ä‘Ã£ Ä‘Æ°á»£c há»c tá»« trÆ°á»›c .

---

### 2.2. Tiá»n xá»­ lÃ½ Dá»¯ liá»‡u vÃ  Tokenization

Ban Ä‘áº§u, dá»¯ liá»‡u Ä‘Æ°á»£c mÃ£ hÃ³a báº±ng phÆ°Æ¡ng thá»©c `tokenizer.encode`, sau Ä‘Ã³ chuyá»ƒn thÃ nh tensor PyTorch. Tuy nhiÃªn, cÃ¡ch tiáº¿p cáº­n Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a báº±ng viá»‡c sá»­ dá»¥ng trá»±c tiáº¿p:

```python
tokenizer(text, return_tensors="pt")
```

PhÆ°Æ¡ng phÃ¡p nÃ y tráº£ vá» tensor trá»±c tiáº¿p, thuáº­n tiá»‡n cho huáº¥n luyá»‡n, nhÆ°ng táº¡o ra tensor hai chiá»u (1 Ã— N). Do Ä‘Ã³, cáº§n truy cáº­p hÃ ng Ä‘áº§u tiÃªn Ä‘á»ƒ chuyá»ƒn vá» dáº¡ng má»™t chiá»u .

---

### 2.3. PhÃ¢n tÃ­ch Táº§n suáº¥t Token

Äá»ƒ Ä‘Ã¡nh giÃ¡ má»©c Ä‘á»™ â€œhá»c phong cÃ¡châ€ cá»§a mÃ´ hÃ¬nh, nghiÃªn cá»©u xÃ¡c Ä‘á»‹nh 100 token xuáº¥t hiá»‡n nhiá»u nháº¥t trong *Gulliverâ€™s Travels*. CÃ¡c token phá»• biáº¿n bao gá»“m dáº¥u pháº©y, xuá»‘ng dÃ²ng, â€œtheâ€, â€œandâ€,â€¦ .

Sau Ä‘Ã³, mÃ´ hÃ¬nh Ä‘Æ°á»£c yÃªu cáº§u sinh vÄƒn báº£n vÃ  tÃ­nh tá»· lá»‡ token trong Ä‘áº§u ra thuá»™c nhÃ³m 100 token phá»• biáº¿n nÃ y.

---

### 2.4. Chiáº¿n lÆ°á»£c Sinh VÄƒn báº£n

Viá»‡c sinh vÄƒn báº£n sá»­ dá»¥ng hÃ m `generate` vá»›i cÃ¡c tham sá»‘ quan trá»ng:

* `do_sample=True`: Ä‘áº£m báº£o tÃ­nh ngáº«u nhiÃªn
* `bad_words_ids`: loáº¡i bá» token káº¿t thÃºc (EOS)
* `min_length = max_length`: Ä‘áº£m báº£o Ä‘á»™ dÃ i cá»‘ Ä‘á»‹nh

Loáº¡i bá» token EOS giÃºp mÃ´ hÃ¬nh khÃ´ng dá»«ng sá»›m khi sinh vÄƒn báº£n, tá»« Ä‘Ã³ thu Ä‘Æ°á»£c Ä‘á»§ sá»‘ lÆ°á»£ng token cáº§n thiáº¿t cho phÃ¢n tÃ­ch .

NgoÃ i ra, thay vÃ¬ sinh má»™t chuá»—i dÃ i 1000 token, mÃ´ hÃ¬nh sinh 10 chuá»—i 100 token nháº±m duy trÃ¬ tÃ­nh máº¡ch láº¡c .

---

### 2.5. Huáº¥n luyá»‡n vÃ  TÃ­nh Loss

MÃ´ hÃ¬nh Hugging Face tÃ­ch há»£p sáºµn hÃ m loss. Khi truyá»n tham sá»‘ `labels` trÃ¹ng vá»›i `input_ids`, mÃ´ hÃ¬nh tá»± Ä‘á»™ng:

* Dá»‹ch chuá»—i Ä‘áº§u vÃ o sang pháº£i 1 bÆ°á»›c
* Ãp dá»¥ng negative log-likelihood loss

Äiá»u nÃ y giÃºp Ä‘Æ¡n giáº£n hÃ³a quÃ¡ trÃ¬nh huáº¥n luyá»‡n, khÃ´ng cáº§n Ä‘á»‹nh nghÄ©a loss thá»§ cÃ´ng .

---

## 3. Káº¿t quáº£ Thá»±c nghiá»‡m (Experimental Results)

### 3.1. Tá»· lá»‡ Token Äáº·c trÆ°ng

TrÆ°á»›c khi fine-tuning, khoáº£ng 40% token sinh ra thuá»™c nhÃ³m token phá»• biáº¿n trong *Gulliverâ€™s Travels* .

Sau khi fine-tuning, con sá»‘ nÃ y tÄƒng lÃªn khoáº£ng 60% .

Äiá»u nÃ y cho tháº¥y mÃ´ hÃ¬nh Ä‘Ã£ thÃ­ch nghi tá»‘t hÆ¡n vá»›i phong cÃ¡ch vÄƒn báº£n má»¥c tiÃªu.

---

### 3.2. PhÃ¢n tÃ­ch VÄƒn báº£n Sinh ra

Sau fine-tuning, vÄƒn báº£n sinh ra cÃ³ Ä‘áº·c Ä‘iá»ƒm:

* Cáº¥u trÃºc dÃ²ng ngáº¯n
* CÃ¡ch trÃ¬nh bÃ y tÆ°Æ¡ng tá»± báº£n gá»‘c
* NgÃ´n ngá»¯ mang phong cÃ¡ch cá»• Ä‘iá»ƒn

VÃ­ dá»¥ Ä‘Æ°á»£c cung cáº¥p cho tháº¥y ná»™i dung sinh ra ráº¥t giá»‘ng vÄƒn báº£n gá»‘c vá» máº·t ngá»¯ Ä‘iá»‡u vÃ  bá»‘ cá»¥c .

---

### 3.3. HÃ nh vi Loss

Loss huáº¥n luyá»‡n giáº£m nhanh vÃ  tiáº¿n gáº§n vá» 0 trong quÃ¡ trÃ¬nh fine-tuning .

Máº·c dÃ¹ Ä‘Ã¢y lÃ  dáº¥u hiá»‡u há»™i tá»¥ tá»‘t, nhÆ°ng cÅ©ng pháº£n Ã¡nh nguy cÆ¡ mÃ´ hÃ¬nh ghi nhá»› quÃ¡ má»©c dá»¯ liá»‡u huáº¥n luyá»‡n.

---

## 4. Tháº£o luáº­n (Discussion)

### 4.1. Nguy cÆ¡ Overfitting

Loss tiáº¿n vá» 0 cho tháº¥y mÃ´ hÃ¬nh cÃ³ thá»ƒ Ä‘Ã£ há»c thuá»™c vÄƒn báº£n huáº¥n luyá»‡n, dáº«n Ä‘áº¿n:

* Giáº£m kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a
* Háº¡n cháº¿ tÃ­nh sÃ¡ng táº¡o
* Nguy cÆ¡ sao chÃ©p ná»™i dung gá»‘c

TÃ¡c giáº£ nháº¥n máº¡nh ráº±ng má»¥c tiÃªu cá»§a mÃ´ hÃ¬nh sinh vÄƒn báº£n khÃ´ng pháº£i lÃ  ghi nhá»› hoÃ n toÃ n dá»¯ liá»‡u, mÃ  lÃ  táº¡o ra ná»™i dung má»›i, há»£p lÃ½ vÃ  há»¯u Ã­ch .

---

### 4.2. ÄÃ¡nh giÃ¡ Hiá»‡u quáº£ Fine-tuning

Viá»‡c sá»­ dá»¥ng tá»· lá»‡ token phá»• biáº¿n lÃ  má»™t chá»‰ sá»‘ Ä‘Æ¡n giáº£n nhÆ°ng há»¯u Ã­ch. Tuy nhiÃªn, chá»‰ sá»‘ nÃ y chá»§ yáº¿u pháº£n Ã¡nh Ä‘áº·c Ä‘iá»ƒm bá» máº·t cá»§a ngÃ´n ngá»¯, chÆ°a Ä‘Ã¡nh giÃ¡ Ä‘áº§y Ä‘á»§:

* TÃ­nh máº¡ch láº¡c
* TÃ­nh sÃ¡ng táº¡o
* TÃ­nh ngá»¯ nghÄ©a

Do Ä‘Ã³, cáº§n káº¿t há»£p thÃªm cÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡ Ä‘á»‹nh tÃ­nh vÃ  Ä‘á»‹nh lÆ°á»£ng khÃ¡c.

---

## 5. Káº¿t luáº­n (Conclusion)

NghiÃªn cá»©u cho tháº¥y fine-tuning GPT-2 trÃªn *Gulliverâ€™s Travels* giÃºp mÃ´ hÃ¬nh:

* Gia tÄƒng má»©c Ä‘á»™ phÃ¹ há»£p phong cÃ¡ch
* Sinh vÄƒn báº£n gáº§n vá»›i dá»¯ liá»‡u má»¥c tiÃªu
* Giáº£m Ä‘Ã¡ng ká»ƒ loss huáº¥n luyá»‡n

Tuy nhiÃªn, viá»‡c giáº£m loss quÃ¡ máº¡nh cÃ³ thá»ƒ dáº«n Ä‘áº¿n overfitting. Do Ä‘Ã³, trong cÃ¡c á»©ng dá»¥ng thá»±c táº¿, cáº§n cÃ¢n nháº¯c giá»¯a má»©c Ä‘á»™ thÃ­ch nghi vÃ  kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a.

CÃ¡c thÃ¡ch thá»©c chÃ­nh trong fine-tuning khÃ´ng náº±m á»Ÿ Ä‘á»™ phá»©c táº¡p cá»§a mÃ£ nguá»“n, mÃ  á»Ÿ viá»‡c:

* Lá»±a chá»n dá»¯ liá»‡u phÃ¹ há»£p
* Äiá»u chá»‰nh siÃªu tham sá»‘
* Thiáº¿t káº¿ tiÃªu chÃ­ Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£ .

---

## TÃ i liá»‡u Tham kháº£o (References)

Táº¥t cáº£ cÃ¡c trÃ­ch dáº«n trong bÃ i viáº¿t Ä‘Æ°á»£c láº¥y tá»« tÃ i liá»‡u:

* *2 - Fine-tune a pretrained GPT2.txt*
  (Nguá»“n ná»™i bá»™ do ngÆ°á»i dÃ¹ng cung cáº¥p)

---
<!-- Aero-Footer-Start -->
---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
