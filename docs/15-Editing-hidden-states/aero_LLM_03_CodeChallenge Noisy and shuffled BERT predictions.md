
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../index.md) > [15 Editing hidden states](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../index.md)
- [ğŸ“š Module 01: LLM Course](../../01-LLM_Course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../02-Words-to-tokens-to-numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../04-buildGPT/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../07-Fine-tune-pretrained-models/index.md)
- [ğŸ” Module 19: AI Safety](../../19-AI-safety/index.md)
- [ğŸ Module 20: Python for AI](../../20-Python-Colab-notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Thá»­ thÃ¡ch Láº­p trÃ¬nh: Dá»± Ä‘oÃ¡n BERT vá»›i Nhiá»…u vÃ  HoÃ¡n vá»‹ (Noisy and Shuffled BERT Predictions)

## TÃ³m táº¯t (Abstract)
BÃ¡o cÃ¡o nÃ y kháº£o sÃ¡t tÃ¡c Ä‘á»™ng cá»§a hai loáº¡i can thiá»‡p nhÃ¢n quáº£ lÃªn mÃ´ hÃ¬nh BERT Large: HoÃ¡n vá»‹ ngáº«u nhiÃªn cÃ¡c chiá»u Embeddings (Shuffling) vÃ  BÆ¡m nhiá»…u Gaussian (Noise Injection). ThÃ´ng qua viá»‡c sá»­ dá»¥ng Prompt ná»•i tiáº¿ng tá»« phim "PhÃ¹ thá»§y xá»© Oz", nghiÃªn cá»©u Ä‘á»‹nh lÆ°á»£ng má»©c Ä‘á»™ sá»¥p Ä‘á»• cá»§a kháº£ nÄƒng dá»± Ä‘oÃ¡n tá»« bá»‹ che khuáº¥t (Masked token). Thá»±c nghiá»‡m cho tháº¥y viá»‡c hoÃ¡n vá»‹ chiá»u khÃ´ng gian dáº«n Ä‘áº¿n sá»± sá»¥p Ä‘á»• hoÃ n toÃ n vá» ngá»¯ nghÄ©a (háº§u háº¿t tráº£ vá» dáº¥u cÃ¢u vÃ´ nghÄ©a), trong khi viá»‡c bÆ¡m nhiá»…u cÃ³ kiá»ƒm soÃ¡t (Scale $\sigma=2$) váº«n báº£o toÃ n Ä‘Æ°á»£c kháº£ nÄƒng sinh tá»« nhÆ°ng lÃ m suy giáº£m Ä‘á»™ chÃ­nh xÃ¡c vÃ  tÄƒng dáº§n sai sá»‘ khi can thiá»‡p á»Ÿ cÃ¡c táº§ng sÃ¢u hÆ¡n.

---

## 1. Má»Ÿ Äáº§u (Introduction)
Can thiá»‡p nhÃ¢n quáº£ lÃªn Hidden States khÃ´ng chá»‰ giá»›i háº¡n á»Ÿ viá»‡c thay Ä‘á»•i quy mÃ´ (Scaling) mÃ  cÃ²n cÃ³ thá»ƒ tÃ¡c Ä‘á»™ng lÃªn "Cáº¥u trÃºc" (Structure) vÃ  "Äá»™ trung thá»±c" (Fidelity) cá»§a thÃ´ng tin. BÃ¡o cÃ¡o nÃ y so sÃ¡nh hai phÆ°Æ¡ng phÃ¡p phÃ¡ há»§y dá»¯ liá»‡u khÃ¡c nhau Ä‘á»ƒ tÃ¬m hiá»ƒu xem mÃ´ hÃ¬nh nháº¡y cáº£m hÆ¡n vá»›i vá»‹ trÃ­ tá»a Ä‘á»™ cá»§a vector hay vá»›i Ä‘á»™ lá»›n cá»§a tÃ­n hiá»‡u nhiá»…u.

---

## 2. PhÆ°Æ¡ng PhÃ¡p NghiÃªn Cá»©u (Methodology)

### 2.1. HoÃ¡n vá»‹ Embeddings (Exercise 1 - 3)
- **Ká»¹ thuáº­t:** Sá»­ dá»¥ng `torch.randperm()` Ä‘á»ƒ trÃ¡o Ä‘á»•i thá»© tá»± cá»§a cÃ¡c chiá»u thuá»™c embeddings dimension cá»§a má»™t token duy nháº¥t (Masked token). Äáº·c Ä‘iá»ƒm cá»§a phÆ°Æ¡ng phÃ¡p nÃ y lÃ  báº£o toÃ n giÃ¡ trá»‹ cÆ°á»ng Ä‘á»™ nhÆ°ng phÃ¡ há»§y hoÃ n toÃ n Ã½ nghÄ©a tá»a Ä‘á»™ áº©n.
- **Dá»¯ liá»‡u:** "Pay no attention to that man [MASK] the curtain". Target: "behind".

### 2.2. BÆ¡m Nhiá»…u Gaussian Äá»™ng (Exercise 4)
- **Ká»¹ thuáº­t:** Thay vÃ¬ hoÃ¡n vá»‹, ta cá»™ng thÃªm nhiá»…u $\epsilon \sim \mathcal{N}(0, \sigma^2)$ vÃ o vector nguyÃªn báº£n.
- **Tinh chá»‰nh:** GiÃ¡ trá»‹ $\sigma$ Ä‘Æ°á»£c tÃ­nh toÃ¡n Ä‘á»™ng dá»±a trÃªn Ä‘á»™ lá»‡ch chuáº©n thá»±c táº¿ cá»§a chÃ­nh cÃ¡c vector táº¡i táº§ng Ä‘Ã³: `noise = torch.randn_like(hidden) * hidden.std() * scale_index`. Äiá»u nÃ y Ä‘áº£m báº£o nhiá»…u luÃ´n cÃ³ tá»· lá»‡ tÆ°Æ¡ng xá»©ng vá»›i cÆ°á»ng Ä‘á»™ tÃ­n hiá»‡u ná»™i táº¡i cá»§a mÃ´ hÃ¬nh.

---

## 3. Káº¿t Quáº£ VÃ  Tháº£o Luáº­n (Results & Analysis)

### 3.1. Tháº£m há»a HoÃ¡n vá»‹ (Catastrophic Shuffling)
Káº¿t quáº£ dá»± Ä‘oÃ¡n cá»§a BERT sau khi bá»‹ hoÃ¡n vá»‹ chiá»u táº¡i báº¥t ká»³ táº§ng nÃ o Ä‘á»u trá»Ÿ thÃ nh cÃ¡c chuá»—i vÃ´ nghÄ©a nhÆ° dÃ¢Ìu pháº©y, dáº¥u cháº¥m hoáº·c kÃ½ tá»± láº¡. 
- **Nháº­n Ä‘á»‹nh:** Äiá»u nÃ y chá»©ng minh ráº±ng "Ã nghÄ©a" (Meaning) trong LLM Ä‘Æ°á»£c mÃ£ hÃ³a cá»±c ká»³ cháº·t cháº½ vÃ o cÃ¡c trá»¥c tá»a Ä‘á»™ cá»¥ thá»ƒ trong khÃ´ng gian embeddings. Viá»‡c xÃ¡o trá»™n chÃºng tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i viá»‡c phÃ¡ há»§y tá»« Ä‘iá»ƒn mÃ£ hÃ³a cá»§a mÃ´ hÃ¬nh.

### 3.2. Sá»± Suy Giáº£m CÃ³ Quy Luáº­t Cá»§a Nhiá»…u
- **Äá»™ chÃ­nh xÃ¡c:** KhÃ¡c vá»›i hoÃ¡n vá»‹, bÆ¡m nhiá»…u váº«n cho phÃ©p mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n ra "tá»«" (Words), dÃ¹ Ä‘Ã´i khi sai má»¥c tiÃªu (vd: "in", "to" thay cho "behind").
- **TÃ¡c Ä‘á»™ng theo táº§ng:** Sai sá»‘ (Loss) vÃ  sá»± sá»¥t giáº£m Log Softmax cá»§a tá»« Ä‘Ãºng tÄƒng dáº§n theo Ä‘á»™ sÃ¢u cá»§a táº§ng bá»‹ can thiá»‡p. Viá»‡c bÆ¡m nhiá»…u á»Ÿ lá»›p cuá»‘i cÃ¹ng (Layer 23) gÃ¢y ra tÃ¡c Ä‘á»™ng náº·ng ná» nháº¥t, do mÃ´ hÃ¬nh khÃ´ng cÃ²n cÃ¡c táº§ng háº¡ nguá»“n Ä‘á»ƒ "lá»c" bá»›t nhiá»…u hoáº·c tÃ¡i cáº¥u trÃºc láº¡i thÃ´ng tin.

### 3.3. So sÃ¡nh PhÃ¢n phá»‘i: Nhiá»…u vs. TÃ­n Hiá»‡u (Exercise 5)
PhÃ¢n tÃ­ch Histogram cho tháº¥y má»™t thá»±c táº¿ quan trá»ng: PhÃ¢n phá»‘i hoáº¡t hÃ³a thá»±c cá»§a BERT táº¡i cÃ¡c Transformer Blocks (Hidden States) cá»±c ká»³ háº¹p vÃ  cÃ³ Ä‘á»‰nh nhá»n hÆ¡n nhiá»u so vá»›i phÃ¢n phá»‘i Gaussian chuáº©n.
- **Nghá»‹ch lÃ½ Gaussian:** Viá»‡c sá»­ dá»¥ng nhiá»…u Gaussian Ä‘á»ƒ kiá»ƒm thá»­ mÃ´ hÃ¬nh thá»±c cháº¥t lÃ  Ä‘Æ°a vÃ o má»™t loáº¡i nhiá»…u cÃ³ Ä‘uÃ´i (tails) rá»™ng hÆ¡n nhiá»u so vá»›i phÃ¢n phá»‘i tá»± nhiÃªn cá»§a mÃ´ hÃ¬nh. Äiá»u nÃ y Ä‘áº·t ra cÃ¢u há»i vá» tÃ­nh há»£p lá»‡ cá»§a viá»‡c dÃ¹ng phÃ¢n phá»‘i chuáº©n Ä‘á»ƒ mÃ´ phá»ng "nhiá»…u sinh há»c/váº­t lÃ½" trong cÃ¡c thÃ­ nghiá»‡m Interpretability.

---

## 4. Káº¿t Luáº­n
HoÃ¡n vá»‹ chiá»u khÃ´ng gian lÃ  can thiá»‡p mang tÃ­nh há»§y diá»‡t, trong khi bÆ¡m nhiá»…u mang tÃ­nh thá»‘ng kÃª. ThÃ­ nghiá»‡m kháº³ng Ä‘á»‹nh ráº±ng LLM nháº¡y cáº£m nháº¥t vá»›i cÃ¡c can thiá»‡p á»Ÿ nhá»¯ng giai Ä‘oáº¡n tÃ­nh toÃ¡n cuá»‘i cÃ¹ng. Viá»‡c hiá»ƒu rÃµ sá»± khÃ¡c biá»‡t giá»¯a hÃ¬nh dáº¡ng phÃ¢n phá»‘i (Distribution shape) cá»§a nhiá»…u vÃ  tÃ­n hiá»‡u thá»±c lÃ  yáº¿u tá»‘ then chá»‘t Ä‘á»ƒ thiáº¿t káº¿ cÃ¡c ká»‹ch báº£n can thiá»‡p nhÃ¢n quáº£ chÃ­nh xÃ¡c hÆ¡n trong tÆ°Æ¡ng lai.

---

## TÃ i liá»‡u tham kháº£o (Citations)
1. Thá»­ thÃ¡ch Noisy vs Shuffled BERT dá»±a trÃªn tÃ i liá»‡u `aero_LLM_03_CodeChallenge Noisy and shuffled BERT predictions.md`. So sÃ¡nh trá»±c quan hÃ³a giá»¯a Histogram Gaussian vÃ  Hidden State thá»±c táº¿.
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| [TÃ¡c Ä‘á»™ng Háº¡ nguá»“n cá»§a viá»‡c Thay Ä‘á»•i Quy mÃ´ Lá»›p sá»›m (Downstream Impact of Early Layer Scaling)](aero_LLM_01_Downstream impact of early layer scaling.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_01_Downstream impact of early layer scaling.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Thay Ä‘á»•i Quy mÃ´ Hidden State vÃ  Tá»•n tháº¥t Token](aero_LLM_02_CodeChallenge Hidden-state scaling and token loss.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_02_CodeChallenge Hidden-state scaling and token loss.md) |
| ğŸ“Œ **[Thá»­ thÃ¡ch Láº­p trÃ¬nh: Dá»± Ä‘oÃ¡n BERT vá»›i Nhiá»…u vÃ  HoÃ¡n vá»‹ (Noisy and Shuffled BERT Predictions)](aero_LLM_03_CodeChallenge Noisy and shuffled BERT predictions.md)** | [Xem bÃ i viáº¿t â†’](aero_LLM_03_CodeChallenge Noisy and shuffled BERT predictions.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Äo lÆ°á»ng vÃ  Hiá»‡u chá»‰nh Äá»‹nh kiáº¿n Giá»›i trong BERT](aero_LLM_04_CodeChallenge Measure and correct BERT's bias.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_04_CodeChallenge Measure and correct BERT's bias.md) |
| [VÃ¡ Hoáº¡t hÃ³a vÃ  TÃ¡c vá»¥ Nháº­n diá»‡n TÃ¢n ngá»¯ GiÃ¡n tiáº¿p (Activation Patching and Indirect Object Identification)](aero_LLM_05_Activation patching with indirect object identification.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_05_Activation patching with indirect object identification.md) |
| [Bá» qua má»™t Táº§ng Transformer (Skip a Layer)](aero_LLM_06_Skip a layer.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_06_Skip a layer.md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
