
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../index.md) > [01 llm course](../index.md) > [lecturestanford](index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../index.md)
- [ğŸ“š Module 01: LLM Course](../../01_llm_course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../02_words_to_tokens_to_numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../04_buildgpt/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../07_fine_tune_pretrained_models/index.md)
- [ğŸ” Module 19: AI Safety](../../19_ai_safety/index.md)
- [ğŸ Module 20: Python for AI](../../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# ChÆ°Æ¡ng 1: Tá»•ng Quan Vá» Large Language Models (LLMs) ğŸ§ 

> **KhÃ³a há»c:** CS229 - Machine Learning (Stanford)  
> **ChÆ°Æ¡ng:** 1/5 - Foundation & Overview  
> **Má»¥c tiÃªu:** Hiá»ƒu khÃ¡i niá»‡m cÆ¡ báº£n vá» LLMs vÃ  vá»‹ trÃ­ cá»§a chÃºng trong AI

---

## ğŸ“š Ná»™i Dung ChÆ°Æ¡ng

1. [Äá»‹nh NghÄ©a LLM](#Ä‘á»‹nh-nghÄ©a-llm)
2. [Kiáº¿n TrÃºc Transformer](#kiáº¿n-trÃºc-transformer)
3. [CÃ¡c MÃ´ HÃ¬nh TiÃªu Biá»ƒu](#cÃ¡c-mÃ´-hÃ¬nh-tiÃªu-biá»ƒu)
4. [GPT-4: Case Study](#gpt-4-case-study)
5. [Táº¡i Sao LLMs Quan Trá»ng](#táº¡i-sao-llms-quan-trá»ng)

---

## 1. Äá»‹nh NghÄ©a LLM

### **LLM lÃ  gÃ¬?**

**Large Language Model** (MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n) lÃ  cÃ¡c mÃ´ hÃ¬nh phÃ¢n phá»‘i xÃ¡c suáº¥t trÃªn cÃ¡c chuá»—i tá»« (sequences of tokens).

**Äá»‹nh nghÄ©a toÃ¡n há»c:**

P(xâ‚, xâ‚‚, ..., xâ‚™) = P(xâ‚) Ã— P(xâ‚‚|xâ‚) Ã— P(xâ‚ƒ|xâ‚,xâ‚‚) Ã— ... Ã— P(xâ‚™|xâ‚,...,xâ‚™â‚‹â‚)

NÃ³i cÃ¡ch khÃ¡c:
- **Input:** Chuá»—i vÄƒn báº£n (text sequence)
- **Output:** XÃ¡c suáº¥t cá»§a tá»« tiáº¿p theo (next token probability)
- **Má»¥c tiÃªu:** MÃ´ hÃ¬nh hÃ³a ngÃ´n ngá»¯ tá»± nhiÃªn theo cÃ¡ch mÃ¡y tÃ­nh cÃ³ thá»ƒ "hiá»ƒu"

### **"Large" cÃ³ nghÄ©a lÃ  gÃ¬?**

| Tháº¿ há»‡ | Sá»‘ tham sá»‘ | VÃ­ dá»¥ |
|--------|------------|-------|
| **Small** | < 1B | GPT-2 (1.5B) |
| **Medium** | 1B - 10B | Llama 2 (7B) |
| **Large** | 10B - 100B | GPT-3 (175B) |
| **Extra Large** | > 100B | GPT-4 (1.76T) |

> ğŸ’¡ **LÆ°u Ã½:** "Large" khÃ´ng chá»‰ vá» sá»‘ lÆ°á»£ng tham sá»‘ mÃ  cÃ²n vá»:
> - Dá»¯ liá»‡u training (trillions of tokens)
> - Kháº£ nÄƒng emergent (xuáº¥t hiá»‡n tá»± nhiÃªn)
> - Context window (Ä‘á»™ dÃ i vÄƒn báº£n xá»­ lÃ½ Ä‘Æ°á»£c)

---

## 2. Kiáº¿n TrÃºc Transformer

### **Táº¡i sao Transformer?**

TrÆ°á»›c Transformer (2017), cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ sá»­ dá»¥ng:
- **RNN** (Recurrent Neural Networks): Cháº­m, khÃ³ train
- **LSTM** (Long Short-Term Memory): Tá»‘t hÆ¡n nhÆ°ng váº«n tuáº§n tá»±
- **CNN**: KhÃ´ng phÃ¹ há»£p vá»›i sequences dÃ i

**Transformer** giáº£i quyáº¿t váº¥n Ä‘á» báº±ng **Self-Attention**:
Attention(Q, K, V) = softmax(QKáµ€/âˆšd) Ã— V

### **Cáº¥u TrÃºc Transformer Block**

Input Embedding
    â†“
[Position Embedding] â”€â”
    â†“                 â”‚
Layer Norm            â”‚
    â†“                 â”‚
Multi-Head Attention  â”‚
    â†“                 â”‚
Add & Norm â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ (Residual Connection)
    â†“
Layer Norm â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“                 â”‚
Feed-Forward (MLP)    â”‚
    â†“                 â”‚
Add & Norm â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ (Residual Connection)
    â†“

$$
Repeat N times
$$

â†“
Output Layer

### **ThÃ nh pháº§n chÃ­nh:**

1. **Embeddings:**
   - Token Embedding: Chuyá»ƒn tá»« â†’ vector
   - Position Embedding: ThÃªm thÃ´ng tin vá»‹ trÃ­

2. **Self-Attention:**
   - Q (Query): "TÃ´i Ä‘ang tÃ¬m gÃ¬?"
   - K (Key): "TÃ´i cung cáº¥p thÃ´ng tin gÃ¬?"
   - V (Value): "GiÃ¡ trá»‹ thá»±c táº¿ tÃ´i mang"

3. **Feed-Forward (MLP):**
   - ThÆ°á»ng expand 4Ã— (C â†’ 4C â†’ C)
   - Activation: GELU (GPT), ReLU (BERT)

4. **Layer Normalization:**
   - á»”n Ä‘á»‹nh training
   - Normalize theo tá»«ng column

5. **Residual Connections:**
   - GiÃºp gradient flow
   - Cho phÃ©p train mÃ´ hÃ¬nh sÃ¢u

---

## 3. CÃ¡c MÃ´ HÃ¬nh TiÃªu Biá»ƒu

### **A. GPT Series (OpenAI)**

| Model | Year | Params | Context | Key Features |
|-------|------|--------|---------|--------------|
| GPT-1 | 2018 | 117M | 512 | Proof of concept |
| GPT-2 | 2019 | 1.5B | 1024 | Zero-shot learning |
| GPT-3 | 2020 | 175B | 2048 | Few-shot learning |
| GPT-3.5 | 2022 | ~175B | 4096 | ChatGPT base |
| **GPT-4** | 2023 | **1.76T** | **32K-128K** | **MoE, Multimodal** |

**Äáº·c Ä‘iá»ƒm:**
- **Architecture:** Decoder-only Transformer
- **Training:** Autoregressive (predict next token)
- **Strength:** Text generation, reasoning

### **B. Claude (Anthropic)**

| Model | Year | Context | Key Features |
|-------|------|---------|--------------|
| Claude 1 | 2022 | 9K | RLHF focused |
| Claude 2 | 2023 | 100K | Long context |
| **Claude 3** | 2024 | **200K** | **Opus/Sonnet/Haiku** |

**Äáº·c Ä‘iá»ƒm:**
- **Focus:** Safety, helpfulness, harmlessness (HHH)
- **Strength:** Long documents, technical writing

### **C. Gemini (Google)**

| Model | Year | Params | Key Features |
|-------|------|--------|--------------|
| Gemini Pro | 2023 | ~175B | Production |
| **Gemini Ultra** | 2024 | **~1.5T** | **SOTA multimodal** |

**Äáº·c Ä‘iá»ƒm:**
- **Multimodal:** Text, image, video, audio
- **Integration:** Google ecosystem

### **D. Llama (Meta)**

| Model | Year | Open Source | Key Features |
|-------|------|-------------|--------------|
| Llama | 2023 | âœ… | Research only |
| **Llama 2** | 2023 | âœ… | **Commercial use** |
| **Llama 3** | 2024 | âœ… | **400B, multilingual** |

**Äáº·c Ä‘iá»ƒm:**
- **Open weights:** Available for download
- **Community:** Huge ecosystem (Alpaca, Vicuna, etc.)

---

## 4. GPT-4: Case Study

### **Kiáº¿n TrÃºc GPT-4**

**ğŸ”¥ Mixture of Experts (MoE):**

Input
  â†“
Embedding
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Transformer Block   â”‚
â”‚   â†“                 â”‚
â”‚ Self-Attention      â”‚
â”‚   â†“                 â”‚
â”‚ [Router] â”€â”€â†’ Top-K  â”‚  â† Chá»n 2/8 experts
â”‚   â†“                 â”‚
â”‚ â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”   â”‚
â”‚ â”‚E0 â”‚E1 â”‚E2 â”‚E3 â”‚   â”‚  â† Expert grid 2Ã—4
â”‚ â”‚E4 â”‚E5 â”‚E6 â”‚E7 â”‚   â”‚
â”‚ â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜   â”‚
â”‚   â†“                 â”‚
â”‚ Aggregation         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“

$$
Repeat 120 layers
$$

â†“
Output

**ThÃ´ng sá»‘ ká»¹ thuáº­t:**

| Metric | Value |
|--------|-------|
| **Total Parameters** | ~1.76 Trillion |
| **Active Parameters** | ~220B per forward pass |
| **Experts per layer** | 8 (MoE) |
| **Active experts** | 2 (Top-K) |
| **Layers** | ~120 |
| **Embedding dimension** | ~18,432 |
| **Attention heads** | ~128 |
| **Context window** | 32K (standard), 128K (extended) |
| **Training tokens** | ~13 Trillion |

### **So sÃ¡nh GPT-3 vs GPT-4:**

| Feature | GPT-3 | GPT-4 |
|---------|-------|-------|
| Architecture | Dense | **MoE (Sparse)** |
| Total params | 175B | **1.76T** |
| Active params | 175B | **~220B** |
| Multimodal | âŒ | **âœ… (Vision)** |
| Context | 2K-4K | **32K-128K** |
| Training cost | ~$4M | **~$100M** |

### **Æ¯u Ä‘iá»ƒm MoE:**

1. **Hiá»‡u quáº£ hÆ¡n:**
   - Only 2/8 experts active â†’ Save compute
   - 1.76T total, ~220B active â†’ 8Ã— cheaper than dense

2. **ChuyÃªn mÃ´n hÃ³a:**
   - Expert 0: Math, logic
   - Expert 1: Creative writing
   - Expert 2: Code generation
   - ...

3. **Scalability:**
   - Dá»… má»Ÿ rá»™ng (add more experts)
   - Parallel training

---

## 5. Táº¡i Sao LLMs Quan Trá»ng?

### **A. Emergent Abilities (Kháº£ nÄƒng Xuáº¥t Hiá»‡n)**

Khi model Ä‘á»§ lá»›n (>100B params), xuáº¥t hiá»‡n cÃ¡c kháº£ nÄƒng má»›i:

1. **Few-shot Learning:** Há»c tá»« vÃ i vÃ­ dá»¥
2. **Chain-of-Thought:** Suy luáº­n tá»«ng bÆ°á»›c
3. **Reasoning:** Giáº£i toÃ¡n, logic
4. **Code Generation:** Viáº¿t code cháº¥t lÆ°á»£ng cao

### **B. á»¨ng Dá»¥ng Thá»±c Táº¿**

| Domain | Use Cases |
|--------|-----------|
| **Programming** | GitHub Copilot, Code review |
| **Writing** | Content generation, editing |
| **Education** | Tutoring, explanations |
| **Research** | Literature review, summarization |
| **Business** | Customer service, automation |
| **Creative** | Storytelling, brainstorming |

### **C. TÃ¡c Äá»™ng Kinh Táº¿**

- **Productivity:** McKinsey: +$4.4T/year by 2030
- **Jobs:** 300M jobs affected (transformed, not replaced)
- **Industry:** Every sector integrating AI

### **D. Research Direction**

**Hot topics:**

1. **Efficiency:**
   - Quantization (INT8, INT4)
   - Pruning
   - Distillation

2. **Multimodality:**
   - Text + Vision + Audio
   - Unified embeddings

3. **Reasoning:**
   - Chain-of-Thought
   - Tree-of-Thought
   - Self-consistency

4. **Safety:**
   - Alignment
   - RLHF
   - Constitutional AI

---

## ğŸ“Š Visualization Link

**Xem trá»±c quan GPT-4 Architecture:**

```bash
cd llm_viz
npm run dev
# Open: http://localhost:3002/llm
# Select: GPT-4 model

**CÃ¡c pháº§n cÃ³ thá»ƒ explore:**
- âœ… Token & Position Embeddings
- âœ… Layer Normalization
- âœ… Self-Attention Mechanism
- âœ… MoE Expert Grid (2Ã—4)
- âœ… Router & Top-K Selection
- âœ… MLP (Feed-Forward)
- âœ… Residual Connections
- âœ… Output Layer & Logits

**NgÃ´n ngá»¯:** ğŸ‡»ğŸ‡³ Vietnamese (100% localized)

---

## ğŸ¯ Key Takeaways

1. âœ… **LLM = Probability model** over token sequences
2. âœ… **Transformer architecture** is the foundation
3. âœ… **GPT-4 uses MoE** for efficiency at scale
4. âœ… **Emergent abilities** appear at 100B+ params
5. âœ… **Multimodality** is the future direction

---

## ğŸ“š Äá»c ThÃªm

**Papers:**
- [Attention Is All You Need (2017)](https://arxiv.org/abs/1706.03762) - Original Transformer
- [GPT-3 (2020)](https://arxiv.org/abs/2005.14165) - Language Models are Few-Shot Learners
- [GPT-4 Technical Report (2023)](https://arxiv.org/abs/2303.08774)

**Courses:**
- Stanford CS229: Machine Learning
- Stanford CS224N: NLP with Deep Learning
- Fast.ai: Practical Deep Learning

**Interactive:**
- Our visualization tool $llm_viz$
- Transformer Explainer (Poloclub)
- LLM Visualization (bbycroft)

---

**Next:** [ChÆ°Æ¡ng 2: 5 Trá»¥ Cá»™t Cá»§a Viá»‡c Huáº¥n Luyá»‡n â†’](./aero_LLM_chapter02_5pillars_part1.md)

---

*BiÃªn soáº¡n bá»Ÿi Pixibot - Based on Stanford CS229*  
*Last updated: 2026-02-15*
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| [CS229: XÃ¢y Dá»±ng MÃ´ HÃ¬nh NgÃ´n Ngá»¯ Lá»›n (LLMs) ğŸ§ ](aero_llm_00_overview.md) | [Xem bÃ i viáº¿t â†’](aero_llm_00_overview.md) |
| [Lecture 1: Transformer Architecture ğŸ¤–](aero_llm_01_transformer.md) | [Xem bÃ i viáº¿t â†’](aero_llm_01_transformer.md) |
| [Lecture 2: Transformer Tricks & BERT ğŸ› ï¸](aero_llm_02_transformer_tricks.md) | [Xem bÃ i viáº¿t â†’](aero_llm_02_transformer_tricks.md) |
| [Lecture 3: Large Language Models (LLMs) & Inference ğŸš€](aero_llm_03_large_language_models.md) | [Xem bÃ i viáº¿t â†’](aero_llm_03_large_language_models.md) |
| [Lecture 4: LLM Training - Pre-training ğŸ‹ï¸](aero_llm_04_training_pretraining.md) | [Xem bÃ i viáº¿t â†’](aero_llm_04_training_pretraining.md) |
| [Lecture 5: LLM Tuning (SFT & Parameter Efficient) ğŸ›ï¸](aero_llm_05_tuning_peft.md) | [Xem bÃ i viáº¿t â†’](aero_llm_05_tuning_peft.md) |
| [Lecture 6: LLM Reasoning ğŸ§ ](aero_llm_06_reasoning.md) | [Xem bÃ i viáº¿t â†’](aero_llm_06_reasoning.md) |
| [Lecture 7: Agentic LLMs & Tool Use ğŸ› ï¸](aero_llm_07_agentic_llms.md) | [Xem bÃ i viáº¿t â†’](aero_llm_07_agentic_llms.md) |
| [Lecture 8: LLM Evaluation âš–ï¸](aero_llm_08_evaluation.md) | [Xem bÃ i viáº¿t â†’](aero_llm_08_evaluation.md) |
| [Lecture 9: Recap & Current Trends ğŸ”®](aero_llm_09_trends.md) | [Xem bÃ i viáº¿t â†’](aero_llm_09_trends.md) |
| [ğŸ› ï¸ Top 12 Repo Quan Trá»ng Cho AI Engineer Tá»‘i Æ¯u LLM](aero_llm_10_essential_tools.md) | [Xem bÃ i viáº¿t â†’](aero_llm_10_essential_tools.md) |
| ğŸ“Œ **[ChÆ°Æ¡ng 1: Tá»•ng Quan Vá» Large Language Models (LLMs) ğŸ§ ](aero_llm_chapter01_overview_detailed.md)** | [Xem bÃ i viáº¿t â†’](aero_llm_chapter01_overview_detailed.md) |
| [ChÆ°Æ¡ng 2: 5 Trá»¥ Cá»™t Cá»§a Viá»‡c Huáº¥n Luyá»‡n LLMs ğŸ›ï¸](aero_llm_chapter02_5pillars_part1.md) | [Xem bÃ i viáº¿t â†’](aero_llm_chapter02_5pillars_part1.md) |
| [ChÆ°Æ¡ng 2: 5 Trá»¥ Cá»™t - Part 2 (Evaluation & Systems)](aero_llm_chapter02_5pillars_part2.md) | [Xem bÃ i viáº¿t â†’](aero_llm_chapter02_5pillars_part2.md) |
| [ChÆ°Æ¡ng 3: Pre-training â†’ Post-training Pipeline ğŸ”„](aero_llm_chapter03_training_pipeline.md) | [Xem bÃ i viáº¿t â†’](aero_llm_chapter03_training_pipeline.md) |
| [ChÆ°Æ¡ng 4 & 5: Mechanisms & Evaluation ğŸ”§ğŸ“Š](aero_llm_chapter04_05_mechanisms_eval.md) | [Xem bÃ i viáº¿t â†’](aero_llm_chapter04_05_mechanisms_eval.md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
