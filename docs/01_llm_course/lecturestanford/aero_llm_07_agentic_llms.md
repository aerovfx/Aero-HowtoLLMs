
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../../index.md) > [01 llm course](../../index.md) > [lecturestanford](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../../index.md)
- [ğŸ“š Module 01: LLM Course](../../../01_llm_course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../../02_words_to_tokens_to_numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../../04_buildgpt/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../../07_fine_tune_pretrained_models/index.md)
- [ğŸ” Module 19: AI Safety](../../../19_ai_safety/index.md)
- [ğŸ Module 20: Python for AI](../../../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Lecture 7: Agentic LLMs & Tool Use ğŸ› ï¸

> **TÃ³m táº¯t tá»« khÃ³a há»c Stanford CME 295: Transformers & Large Language Models.**
> BÃ i giáº£ng nÃ y giá»›i thiá»‡u cÃ¡ch má»Ÿ rá»™ng kháº£ nÄƒng cá»§a LLM thÃ´ng qua viá»‡c sá»­ dá»¥ng cÃ´ng cá»¥ (Tool Use), káº¿t ná»‘i vá»›i dá»¯ liá»‡u ngoÃ i (RAG) vÃ  xÃ¢y dá»±ng cÃ¡c tÃ¡c nhÃ¢n tá»± chá»§ (Agents).

---

## ğŸ“š Má»¥c Lá»¥c
1. [Giá»›i háº¡n cá»§a LLM & Giáº£i phÃ¡p](#1-giá»›i-háº¡n-cá»§a-llm--giáº£i-phÃ¡p)
2. [RAG (Retrieval-Augmented Generation)](#2-18_rag-retrieval-augmented-generation)
3. [Tool Calling (Function Calling)](#3-tool-calling-function-calling)
4. [Agents (TÃ¡c nhÃ¢n AI)](#4-agents-tÃ¡c-nhÃ¢n-ai)
5. [ReAct Framework](#5-react-framework)
6. [Multi-Agent Systems & MCP](#6-multi-agent-systems--mcp)

---

## 1. Giá»›i háº¡n cá»§a LLM & Giáº£i phÃ¡p
Máº·c dÃ¹ LLM ráº¥t máº¡nh, chÃºng váº«n cÃ³ 3 Ä‘iá»ƒm yáº¿u lá»›n:
1.  **Kiáº¿n thá»©c tÄ©nh (Static Knowledge):** KhÃ´ng biáº¿t thÃ´ng tin má»›i sau ngÃ y cáº¯t dá»¯ liá»‡u (knowledge cutoff).
2.  **áº¢o giÃ¡c (Hallucination):** Tá»± bá»‹a Ä‘áº·t thÃ´ng tin khi khÃ´ng biáº¿t cÃ¢u tráº£ lá»i.
3.  **KhÃ´ng hÃ nh Ä‘á»™ng (No Action):** Chá»‰ táº¡o ra vÄƒn báº£n, khÃ´ng thá»ƒ tÆ°Æ¡ng tÃ¡c vá»›i tháº¿ giá»›i thá»±c (gá»­i mail, Ä‘áº·t hÃ ng).

-> **Giáº£i phÃ¡p:** Káº¿t ná»‘i LLM vá»›i cÃ´ng cá»¥ vÃ  dá»¯ liá»‡u bÃªn ngoÃ i.

---

## 2. RAG (Retrieval-Augmented Generation)
Ká»¹ thuáº­t giÃºp LLM truy cáº­p dá»¯ liá»‡u má»›i mÃ  khÃ´ng cáº§n train láº¡i.

**Quy trÃ¬nh 3 bÆ°á»›c:**
1.  **Retrieve (Truy xuáº¥t):** TÃ¬m kiáº¿m cÃ¡c tÃ i liá»‡u liÃªn quan tá»« Knowledge Base (dá»±a trÃªn Vector Search/Semantic Search).
2.  **Augment (Bá»• sung):** ÄÆ°a thÃ´ng tin tÃ¬m Ä‘Æ°á»£c vÃ o Prompt (Context).
3.  **Generate (Sinh vÄƒn báº£n):** LLM tráº£ lá»i cÃ¢u há»i dá»±a trÃªn thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p.

**Ká»¹ thuáº­t nÃ¢ng cao:**
*   **Chunking:** Chia nhá» vÄƒn báº£n thÃ nh cÃ¡c Ä‘oáº¡n (chunks) vá»«a váº·n (khoáº£ng 500 tokens).
*   **Hybrid Search:** Káº¿t há»£p Vector Search (Semantic) vÃ  Keyword Search (BM25) Ä‘á»ƒ tÄƒng Ä‘á»™ chÃ­nh xÃ¡c.
*   **Re-ranking:** DÃ¹ng mÃ´ hÃ¬nh Cross-Encoder Ä‘á»ƒ sáº¯p xáº¿p láº¡i káº¿t quáº£ tÃ¬m kiáº¿m cho chÃ­nh xÃ¡c hÆ¡n trÆ°á»›c khi Ä‘Æ°a vÃ o LLM.

---

## 3. Tool Calling (Function Calling)
Cho phÃ©p LLM sá»­ dá»¥ng cÃ¡c cÃ´ng cá»¥ bÃªn ngoÃ i (Calculator, Weather API, Database...).

**CÆ¡ cháº¿:**
1.  **Äá»‹nh nghÄ©a:** NgÆ°á»i láº­p trÃ¬nh cung cáº¥p mÃ´ táº£ cÃ´ng cá»¥ (TÃªn, Tham sá»‘, CÃ´ng dá»¥ng) cho LLM.
2.  **Quyáº¿t Ä‘á»‹nh:** LLM quyáº¿t Ä‘á»‹nh xem cÃ³ cáº§n dÃ¹ng cÃ´ng cá»¥ khÃ´ng. Náº¿u cáº§n, nÃ³ sinh ra má»™t cáº¥u trÃºc JSON chá»©a tÃªn hÃ m vÃ  tham sá»‘.
3.  **Thá»±c thi:** Há»‡ thá»‘ng thá»±c thi hÃ m Ä‘Ã³ vÃ  tráº£ káº¿t quáº£ vá» cho LLM.
4.  **Tráº£ lá»i:** LLM dÃ¹ng káº¿t quáº£ Ä‘Ã³ Ä‘á»ƒ tráº£ lá»i ngÆ°á»i dÃ¹ng.

---

## 4. Agents (TÃ¡c nhÃ¢n AI)
Agent lÃ  má»™t há»‡ thá»‘ng dÃ¹ng LLM lÃ m "bá»™ nÃ£o" Ä‘á»ƒ tá»± chá»§ giáº£i quyáº¿t váº¥n Ä‘á» qua nhiá»u bÆ°á»›c.
*   **KhÃ¡c biá»‡t vá»›i Tool Calling:** Tool Calling chá»‰ lÃ  má»™t bÆ°á»›c Ä‘Æ¡n láº». Agent cÃ³ kháº£ nÄƒng láº­p káº¿ hoáº¡ch (Plan), ghi nhá»› (Memory) vÃ  tá»± sá»­a lá»—i (Self-correction).

---

## 5. ReAct Framework
PhÆ°Æ¡ng phÃ¡p phá»• biáº¿n Ä‘á»ƒ xÃ¢y dá»±ng Agent: **Re**ason + **Act**.

**VÃ²ng láº·p ReAct:**
1.  **Thought (Suy nghÄ©):** PhÃ¢n tÃ­ch váº¥n Ä‘á», láº­p káº¿ hoáº¡ch. ("NgÆ°á»i dÃ¹ng tháº¥y láº¡nh -> Cáº§n kiá»ƒm tra nhiá»‡t Ä‘á»™ phÃ²ng").
2.  **Action (HÃ nh Ä‘á»™ng):** Gá»i cÃ´ng cá»¥. (`get_temperature()`).
3.  **Observation (Quan sÃ¡t):** Nháº­n káº¿t quáº£ tá»« cÃ´ng cá»¥. ("Nhiá»‡t Ä‘á»™ lÃ  18 Ä‘á»™ C").
4.  **Thought (Suy nghÄ© tiáº¿p):** ("18 Ä‘á»™ lÃ  láº¡nh -> Cáº§n báº­t Ä‘iá»u hÃ²a").
5.  ... Láº·p láº¡i cho Ä‘áº¿n khi xong viá»‡c.

---

## 6. Multi-Agent Systems & MCP
*   **Multi-Agent:** Thay vÃ¬ má»™t Agent lÃ m táº¥t cáº£, ta dÃ¹ng nhiá»u Agent chuyÃªn biá»‡t (Coder, Writer, Reviewer) phá»‘i há»£p vá»›i nhau.
*   **MCP (Model Context Protocol):** TiÃªu chuáº©n má»›i (tá»« Anthropic) giÃºp chuáº©n hÃ³a cÃ¡ch káº¿t ná»‘i LLM vá»›i cÃ¡c nguá»“n dá»¯ liá»‡u vÃ  cÃ´ng cá»¥, giÃºp trÃ¡nh viá»‡c pháº£i viáº¿t láº¡i code káº¿t ná»‘i cho tá»«ng mÃ´ hÃ¬nh/á»©ng dá»¥ng khÃ¡c nhau.

---
*BiÃªn soáº¡n bá»Ÿi Pixiboss - Dá»±a trÃªn Stanford CME 295.*
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| [CS229: XÃ¢y Dá»±ng MÃ´ HÃ¬nh NgÃ´n Ngá»¯ Lá»›n (LLMs) ğŸ§ ](aero_llm_00_overview.md) | [Xem bÃ i viáº¿t â†’](aero_llm_00_overview.md) |
| [Lecture 1: Transformer Architecture ğŸ¤–](aero_llm_01_transformer.md) | [Xem bÃ i viáº¿t â†’](aero_llm_01_transformer.md) |
| [Lecture 2: Transformer Tricks & BERT ğŸ› ï¸](aero_llm_02_transformer_tricks.md) | [Xem bÃ i viáº¿t â†’](aero_llm_02_transformer_tricks.md) |
| [Lecture 3: Large Language Models (LLMs) & Inference ğŸš€](aero_llm_03_large_language_models.md) | [Xem bÃ i viáº¿t â†’](aero_llm_03_large_language_models.md) |
| [Lecture 4: LLM Training - Pre-training ğŸ‹ï¸](aero_llm_04_training_pretraining.md) | [Xem bÃ i viáº¿t â†’](aero_llm_04_training_pretraining.md) |
| [Lecture 5: LLM Tuning (SFT & Parameter Efficient) ğŸ›ï¸](aero_llm_05_tuning_peft.md) | [Xem bÃ i viáº¿t â†’](aero_llm_05_tuning_peft.md) |
| [Lecture 6: LLM Reasoning ğŸ§ ](aero_llm_06_reasoning.md) | [Xem bÃ i viáº¿t â†’](aero_llm_06_reasoning.md) |
| ğŸ“Œ **[Lecture 7: Agentic LLMs & Tool Use ğŸ› ï¸](aero_llm_07_agentic_llms.md)** | [Xem bÃ i viáº¿t â†’](aero_llm_07_agentic_llms.md) |
| [Lecture 8: LLM Evaluation âš–ï¸](aero_llm_08_evaluation.md) | [Xem bÃ i viáº¿t â†’](aero_llm_08_evaluation.md) |
| [Lecture 9: Recap & Current Trends ğŸ”®](aero_llm_09_trends.md) | [Xem bÃ i viáº¿t â†’](aero_llm_09_trends.md) |
| [ğŸ› ï¸ Top 12 Repo Quan Trá»ng Cho AI Engineer Tá»‘i Æ¯u LLM](aero_llm_10_essential_tools.md) | [Xem bÃ i viáº¿t â†’](aero_llm_10_essential_tools.md) |
| [ChÆ°Æ¡ng 1: Tá»•ng Quan Vá» Large Language Models (LLMs) ğŸ§ ](aero_llm_chapter01_overview_detailed.md) | [Xem bÃ i viáº¿t â†’](aero_llm_chapter01_overview_detailed.md) |
| [ChÆ°Æ¡ng 2: 5 Trá»¥ Cá»™t Cá»§a Viá»‡c Huáº¥n Luyá»‡n LLMs ğŸ›ï¸](aero_llm_chapter02_5pillars_part1.md) | [Xem bÃ i viáº¿t â†’](aero_llm_chapter02_5pillars_part1.md) |
| [ChÆ°Æ¡ng 2: 5 Trá»¥ Cá»™t - Part 2 (Evaluation & Systems)](aero_llm_chapter02_5pillars_part2.md) | [Xem bÃ i viáº¿t â†’](aero_llm_chapter02_5pillars_part2.md) |
| [ChÆ°Æ¡ng 3: Pre-training â†’ Post-training Pipeline ğŸ”„](aero_llm_chapter03_training_pipeline.md) | [Xem bÃ i viáº¿t â†’](aero_llm_chapter03_training_pipeline.md) |
| [ChÆ°Æ¡ng 4 & 5: Mechanisms & Evaluation ğŸ”§ğŸ“Š](aero_llm_chapter04_05_mechanisms_eval.md) | [Xem bÃ i viáº¿t â†’](aero_llm_chapter04_05_mechanisms_eval.md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
