
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../index.md) > [11 investigating token embeddings](index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../index.md)
- [ğŸ“š Module 01: LLM Course](../01_llm_course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../02_words_to_tokens_to_numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../04_buildgpt/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../07_fine_tune_pretrained_models/index.md)
- [ğŸ” Module 19: AI Safety](../19_ai_safety/index.md)
- [ğŸ Module 20: Python for AI](../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# PhÃ¢n Cá»¥m Ngá»¯ NghÄ©a Qua PhÃ©p Chiáº¿u t-SNE & Máº­t Äá»™ DBSCAN (Python)

## TÃ³m táº¯t

Máº¡ng thÃ´ng tin mÃ£ vÃ©c-tÆ¡ trong cÃ¡c mÃ´ hÃ¬nh tá»± há»“i quy máº¡nh máº½ nhÆ° GPT-2 thÆ°á»ng bá»‹ Ä‘Ã³ng gÃ³i á»Ÿ lá»›p mÃ ng 768 chiá»u. Äá»ƒ máº¯t thÆ°á»ng linh trÆ°á»Ÿng cÃ³ thá»ƒ tÃ¬m ra nhá»¯ng vi quáº§n thá»ƒ Ä‘á»“ng dáº¡ng káº¿t ná»‘i tá»« kho vá»±ng, hai thuáº­t toÃ¡n siÃªu nÄƒng lá»±c Ä‘Æ°á»£c káº¿t dÃ­nh láº¡i: **t-SNE** (T-Distributed Stochastic Neighbor Embedding) Ä‘Ã³ng vai trÃ² thá»£ Ã©p pháº³ng ma tráº­n xuá»‘ng 2 Chiá»u KhÃ´ng Gian, vÃ  thuáº­t toÃ¡n **DBSCAN** (Density-Based Spatial Clustering of Applications with Noise) Ä‘Ã³ng vai trÃ² káº» dÃ² tÃ¬m biÃªn giá»›i gáº¡ lá»c cÃ¡c tá»• há»£p cÃ³ Ä‘á»™ káº¿t dÃ­nh máº­t Ä‘á»™ lÃµi cao.
NghiÃªn cá»©u dÆ°á»›i Ä‘Ã¢y sáº½ lá»™t tráº§n tá»«ng ngÃ³c ngÃ¡ch cá»§a quÃ¡ trÃ¬nh tá»• chá»©c cáº¥u trÃºc cá»§a Gram-Matrix.

---

## 1. Gram-Matrix: Bá»©c Tranh Tá»•ng Thá»ƒ Ná»™i Táº¡i Tiá»n Máº­t Äá»™

Äá»ƒ trÃ¡nh quÃ¡ táº£i thá»‹ giÃ¡c, ta cáº¯t gá»n má»™t Ma tráº­n con 100 Tokens Ä‘áº§u tiÃªn $\mathbf{E}_{\text{sub}} \in \mathbb{R}^{100 \times 768}$ tá»« GPT-2. 
Láº­p tá»©c táº¡o ngay Gram-Matrix $\mathbf{G} = \mathbf{E}_{\text{sub}} \cdot \mathbf{E}_{\text{sub}}^T \in \mathbb{R}^{100 \times 100}$. HÃ¬nh áº£nh chÃ©o Ä‘á»‘i xá»©ng phÆ¡i bÃ y má»™t tráº­t tá»± sÃ¢u sáº¯c khÃ´ng thá»ƒ tháº¥y khi nhÃ¬n ngang Matrix:
CÃ¡c Ã´ cháº¥m vuÃ´ng Ä‘áº­m Ä‘áº·c xuáº¥t hiá»‡n liÃªn káº¿t chÃ©o cho cÃ¡c nhÃ³m TÃ­n hiá»‡u Ä‘áº·c thÃ¹: (Chá»¯ sá»‘ Arab, Dáº¥u cÃ¢u Punctuation, Há»‡ thá»‘ng Cáº¥u trÃºc chá»¯ cÃ¡i Alphabetical Capital - Lowercase). Gram-Matrix dá»n Ä‘Æ°á»ng trÆ°á»›c ranh giá»›i há»‡ Ã½ niá»‡m.

---

## 2. Sá»± NÃ©n MÃ ng VÃ  CÆ¡ Cháº¿ Hoáº¡t Äá»™ng Cá»§a Thuáº­t ToÃ¡n t-SNE

Vá»›i $\text{perplexity} = 5$ (Ä‘áº¡i diá»‡n cho ngÆ°á»¡ng Ä‘á»™ linh hoáº¡t tÃ¬m lÃ¢n cáº­n - smoothing parameter), t-SNE nÃ©n nháº¹p há»‡ thá»‘ng tá»a Ä‘á»™ Vector báº±ng Ä‘á»‹nh lÃ½ xÃ¡c suáº¥t khoáº£ng cÃ¡ch Ä‘iá»ƒm tá»« $768D$ co vá» $\mathbf{Y} \in \mathbb{R}^{100 \times 2}$.

**Lá»— há»•ng cá»§a PhÃ©p XÃ¡c Suáº¥t t-SNE:**
Do báº£n tÃ­nh thiáº¿t káº¿ hÃ m phÃ¢n phá»‘i lÃ¢n cáº­n Gauss ngáº«u nhiÃªn (Probabilistic initializations) cá»§a hÃ m loss Kulllback-Leibler, biá»ƒu Ä‘á»“ 2D cho ra nhá»¯ng máº£ng Ä‘áº£o cá»¥m token cá»±c ká»³ khÃ¡c nhau qua má»—i láº§n tÃ¡i cháº¡y Model (Stochastic solving). VÃ­ dá»¥: NhÃ³m Chá»¯ cÃ¡i in hoa $X, Y, Z$ váº«n káº¿t dÃ­nh nhau nhÆ°ng cÃ³ thá»ƒ xuáº¥t hiá»‡n lÃºc á»Ÿ tá»a Ä‘á»™ GÃ³c ÄÃ´ng Báº¯c, lÃºc thÃ¬ á»Ÿ GÃ³c TÃ¢y Nam. Dáº«u váº­y, khoáº£ng cÃ¡ch giá»¯a cÃ¡c quáº§n thá»ƒ báº£n ngÃ£ (Global clusters structures) luÃ´n báº£o lÆ°u Ä‘áº·c trÆ°ng cÃ´ Ä‘áº·c phi tuyáº¿n.
t-SNE chá»‰ háº¡ táº§ng chiá»u cao táº¡o Ä‘Ã¡m mÃ¢y ráº£i ráº¯c chá»© khÃ´ng phÃ¢n cá»¥m, Ä‘Ã¢y lÃ  lÃºc DBScan tung chiÃªu.

---

## 3. KhÃ³a Quáº§n Thá»ƒ Nhá» ÄÆ°á»ng BiÃªn Máº­t Äá»™ DBScan

Cáº¥u hÃ¬nh DBSCAN: 
- `Epsilon = 6.0` (Äá»™ dÃ i Ä‘Æ°á»ng kÃ­nh vÃ²ng lÃ¢n cáº­n giá»›i háº¡n)
- `Min_samples = 3` (Sá»‘ Ä‘iá»ƒm tá»‘i thiá»ƒu Ä‘á»ƒ Ä‘áº¡t má»‘c lÃµi Core-Point Ä‘á»ƒ gá»i lÃ  má»™t cá»¥m).

ÄÆ°a ma tráº­n 2D cá»§a t-SNE vÃ o cháº£o lá»­a DBScan, thuáº­t toÃ¡n sáº½ Ä‘i sÄƒn cÃ¡c chuá»—i liá»n ká» báº±ng lÆ°á»›i quÃ©t bÃ¡n kÃ­nh. 
Há»‡ thá»‘ng sáº½ dÃ¡n cÃ¡c sá»‘ nguyÃªn ngáº«u hÃ¬nh (Integer labels) cho cÃ¡c tá»¥ Ä‘iá»ƒm: *Group 0, Group 1...*
Äáº·c biá»‡t, há»‡ thá»‘ng sinh ra Ä‘iá»ƒm $\text{Label} = -1$ . ÄÃ¢y lÃ  cÃ¡c Outlier Noises (TrÃ´i dáº¡c cÃ´ Ä‘á»™c). VÃ­ dá»¥: Náº¿u chá»‰ cÃ³ 2 chá»¯ cÃ¡i `[y, Y]` náº±m gáº§n nhau, nhÆ°ng vÃ¬ `Min_samples = 3`, vÃ²ng trÃ²n Epsilon khÃ´ng Ä‘á»§ dÃ¢n sá»‘ nÃªn thuáº­t toÃ¡n háº¥t bá» chÃºng vá» láº¡i nhÃ³m phÃ¢n ly.

Sá»± lá»£i háº¡i cá»§a DBScan Ä‘Ã¡nh gá»¥c thuáº­t toÃ¡n *K-Means clustering* truyá»n thá»‘ng vÃ¬ nÃ³ khÃ´ng Ä‘Ã²i há»i ká»¹ sÆ° pháº£i "ÄoÃ¡n MÃ² Sá»‘ Há»c" cÃ³ sáºµn Ä‘á»‹nh kiáº¿n quy mÃ´ bao nhiÃªu cá»¥m $k$. DBscan tá»± do giÃ£n ná»Ÿ nhÆ° mÃ ng bá»t sinh há»c há»… tháº¥y máº­t Ä‘á»™ dáº§y sáº½ láº­p tá»©c khoanh trÃ²n láº¡i tá»• chá»©c cho ta.

---

## 4. Hiá»‡n TÆ°á»£ng CÄƒng TrÃ n Thuáº­t ToÃ¡n (Parameters Breakdown)

ToÃ n bá»™ há»‡ thá»‘ng t-SNE káº¿t dÃ­nh DBscan lÃ  má»™t sá»± káº¿t há»£p mong manh.
Khi vÃ´ tÃ¬nh hoáº·c cá»‘ Ã½ Ä‘iá»u chá»‰nh `Epsilon = 16.0`: DBscan phÃ¡ vá»¡ Ä‘Æ°á»ng cÆ°Æ¡ng Ä‘á»‹nh vá»‹, phÃ³ng bÃ¡n kÃ­nh quÃ©t cá»±c ká»³ thÃ´ thiá»ƒn dáº«n Ä‘áº¿n hiá»‡n tÆ°á»£ng gá»™p dÃ­nh toÃ n bá»™ $100$ Ä‘iá»ƒm chÃ³p vÃ o má»™t Bá»“n trÅ©ng khá»•ng lá»“ khÃ´ng cÃ²n kháº£ nÄƒng phÃ¢n rÃ£. 
Hoáº·c vá»›i biáº¿n thiÃªn nhá» hÆ¡n khi Epsilon giáº­t xuá»‘ng, vÃ´ sá»‘ cá»¥m siÃªu nhá» bá»‹ báº» vá»¥n phÃ¢n liá»‡t thÃ nh cÃ¡c phÃ¢n khu sai lá»‡ch ngá»¯ nghÄ©a (VÃ­ dá»¥: `galaxy` bá»‹ gá»™p lá»™n xá»™n vÃ o vá»›i cÃ¡c cá»¥m Token cÃº phÃ¡p `syntax`, `regex`, `codex`). 

Äiá»u nÃ y giÃ³ng lÃªn má»™t há»“i chuÃ´ng khoa há»c: MÃ´ phá»ng khÃ´ng gian giáº£m chiá»u kÃ­ch (Visualization of Reduced Dimension) cho Machine Learning khÃ´ng pháº£i cá»© nhÃ¬n tháº¥y cá»¥m tá»¥ thÃ¬ chÃºng mang chung má»™t luá»“ng ná»™i hÃ m. Viá»‡c cÃ¡c tá»• há»£p gá»™p dÃ­nh láº¡i vá»›i nhau hay láº£ng trÃ¡nh nhau hoÃ n toÃ n cÃ³ thá»ƒ lÃ  tÃ¡c pháº©m tá»« sá»± Ä‘iá»u phá»‘i thá»§ cÃ´ng tham sá»‘ ngoáº¡i lai Parameters bá»Ÿi chÃ­nh con ngÆ°á»i Ã¡p Ä‘áº·t, táº¡o ra Ä‘iá»ƒm má» vá» thiÃªn kiáº¿n giáº£i thÃ­ch phÃ¢n liá»‡t há»c thuáº­t. 

---

## TÃ i liá»‡u tham kháº£o

1. **Laurens van der Maaten & Geoffrey Hinton (2008).** *Visualizing Data using t-SNE.* Journal of Machine Learning Research.
2. **Ester, M., et al. (1996).** *A density-based algorithm for discovering clusters in large spatial databases with noise (DBSCAN).* KDD.
3. TÃ i liá»‡u mÃ´ phá»ng ká»¹ thuáº­t thá»±c hÃ nh phÃ¢n tÃ­ch *T-SNE projection and DBSCAN clustering.*
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| [aero llm 01 codechallenge cosine similarity advanced part 1](aero_llm_01_codechallenge_cosine_similarity_advanced_part_1_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_01_codechallenge_cosine_similarity_advanced_part_1_.md) |
| [aero llm 02 codechallenge cosine similarity advanced part 2](aero_llm_02_codechallenge_cosine_similarity_advanced_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_02_codechallenge_cosine_similarity_advanced_part_2_.md) |
| [Theo DÃµi DÃ²ng Cháº£y Cosine Similarity TrÃªn Trá»¥c VÄƒn Báº£n ChuyÃªn Tuáº§n Tá»± (Word Sequences)](aero_llm_03_codechallenge_cosine_similarity_in_word_sequences.md) | [Xem bÃ i viáº¿t â†’](aero_llm_03_codechallenge_cosine_similarity_in_word_sequences.md) |
| [Nghá»‡ Thuáº­t Váº½ Báº£n Äá»“ Nhiá»‡t Ma Tráº­n NhÃºng Báº±ng CÆ°á»ng Äá»™ Tá»« (Coloring Cosine Similarity)](aero_llm_04_codechallenge_coloring_cosine_similarity.md) | [Xem bÃ i viáº¿t â†’](aero_llm_04_codechallenge_coloring_cosine_similarity.md) |
| [áº¢o áº¢nh Cá»§a TrÃ­ Tuá»‡ ToÃ¡n Há»c Trong NgÃ´n Ngá»¯: Sá»©c Máº¡nh Cá»§a Random Embeddings](aero_llm_05_codechallenge_can_random_embeddings_be_interpreted.md) | [Xem bÃ i viáº¿t â†’](aero_llm_05_codechallenge_can_random_embeddings_be_interpreted.md) |
| [PhÆ°Æ¡ng PhÃ¡p T-SNE VÃ  Thuáº­t ToÃ¡n PhÃ¢n Cá»¥m DBSCAN: Chiáº¿u KhÃ´ng Gian Äa Chiá»u Cho LLMs](aero_llm_06_t_sne_projection_and_dbscan_clustering_theory_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_06_t_sne_projection_and_dbscan_clustering_theory_.md) |
| ğŸ“Œ **[PhÃ¢n Cá»¥m Ngá»¯ NghÄ©a Qua PhÃ©p Chiáº¿u t-SNE & Máº­t Äá»™ DBSCAN (Python)](aero_llm_07_t_sne_projection_and_dbscan_clustering_python_.md)** | [Xem bÃ i viáº¿t â†’](aero_llm_07_t_sne_projection_and_dbscan_clustering_python_.md) |
| [ThÃ¡ch Thá»©c Code: TÃ¬m Lá»— Há»•ng PhÃ¢n Cá»¥m Báº±ng Bá»™ Lá»c Báº£ng Chá»¯ CÃ¡i Chá»¯ X](aero_llm_08_codechallenge_cluster_the_x_terms.md) | [Xem bÃ i viáº¿t â†’](aero_llm_08_codechallenge_cluster_the_x_terms.md) |
| [PhÃ¢n RÃ£ Token, NhÃºng VÃ  PhÃ¢n Cá»¥m Biá»ƒu TÆ°á»£ng Emojis Báº±ng Äá»“ Thá»‹ Máº­t Äá»™](aero_llm_09_codechallenge_tokenize_embed_and_cluster_happy_emojis.md) | [Xem bÃ i viáº¿t â†’](aero_llm_09_codechallenge_tokenize_embed_and_cluster_happy_emojis.md) |
| [PhÃ¢n TÃ­ch RSA (Representational Similarity Analysis) Giá»¯a CÃ¡c MÃ´ HÃ¬nh NgÃ´n Ngá»¯](aero_llm_10_rsa_representational_similarity_analysis_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_10_rsa_representational_similarity_analysis_.md) |
| [PhÃ¢n TÃ­ch Äá»™ Lá»‡ch RSA (Part 1): So SÃ¡nh Sá»± Báº¥t Äá»“ng Giá»¯a KhÃ´ng Gian GloVe 50D vÃ  300D](aero_llm_11_codechallenge_compare_embeddings_with_rsa_part_1_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_11_codechallenge_compare_embeddings_with_rsa_part_1_.md) |
| [PhÃ¢n TÃ­ch Äá»™ Lá»‡ch RSA (Part 2): Äá»‘i Chiáº¿u TÆ°Æ¡ng Quan Pearson Cho Khoáº£ng CÃ¡ch Cosine](aero_llm_12_codechallenge_compare_embeddings_with_rsa_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_12_codechallenge_compare_embeddings_with_rsa_part_2_.md) |
| [So SÃ¡nh KhÃ´ng Gian NhÃºng: Word2Vec VÃ  GPT-2 Qua PhÃ¢n TÃ­ch RSA](aero_llm_13_codechallenge_word2vec_vs_gpt2.md) | [Xem bÃ i viáº¿t â†’](aero_llm_13_codechallenge_word2vec_vs_gpt2.md) |
| [Bá»‘ Cá»¥c Äá»“ Thá»‹ Máº¡ng (Network Graph) ThÃ´ng Qua Ma Tráº­n Cosine Similarity](aero_llm_14_codechallenge_graph_representation_of_cosine_similarities.md) | [Xem bÃ i viáº¿t â†’](aero_llm_14_codechallenge_graph_representation_of_cosine_similarities.md) |
| [Sá»‘ Há»c Tuyáº¿n TÃ­nh vÃ  RÃºt TrÃ­ch TÆ°Æ¡ng Äá»“ng Giá»¯a CÃ¡c Tá»« NhÃºng (Word Embeddings Analogies)](aero_llm_15_embeddings_arithmetic_and_analogies.md) | [Xem bÃ i viáº¿t â†’](aero_llm_15_embeddings_arithmetic_and_analogies.md) |
| [Vá»¡ Má»™ng Vá» Sá»‘ Há»c Vector TÆ°Æ¡ng ÄÆ°Æ¡ng (Soft-Coded Analogies) TrÃªn Word2Vec](aero_llm_16_codechallenge_soft_coded_analogies_in_word2vec.md) | [Xem bÃ i viáº¿t â†’](aero_llm_16_codechallenge_soft_coded_analogies_in_word2vec.md) |
| [Thiáº¿t Láº­p VÃ  Diá»…n Giáº£i Trá»¥c Ngá»¯ NghÄ©a Tuyáº¿n TÃ­nh (Linear Semantic Axes)](aero_llm_17_creating_and_interpreting_linear_semantic_axes.md) | [Xem bÃ i viáº¿t â†’](aero_llm_17_creating_and_interpreting_linear_semantic_axes.md) |
| [Khai ThÃ¡c Thuáº­t ToÃ¡n k-NN Cho TÃ¬m Kiáº¿m Tá»« Äá»“ng NghÄ©a TrÃªn BERT](aero_llm_18_knn_for_synonym_searching_in_bert.md) | [Xem bÃ i viáº¿t â†’](aero_llm_18_knn_for_synonym_searching_in_bert.md) |
| [Cáº¡nh Tranh TÃ¬m Tá»« Äá»“ng NghÄ©a BERT vs GPT: CÆ¡ Cháº¿ Tokenization Äa KÃ½ Tá»±](aero_llm_19_codechallenge_bert_v_gpt_knn_kompetition.md) | [Xem bÃ i viáº¿t â†’](aero_llm_19_codechallenge_bert_v_gpt_knn_kompetition.md) |
| [Sá»± Dá»‹ch Chuyá»ƒn VÃ  Äá»“ng Tá»“n Biá»ƒu Diá»…n Giá»¯a CÃ¡c KhÃ´ng Gian NhÃºng](aero_llm_20_research_on_translating_embeddings_spaces.md) | [Xem bÃ i viáº¿t â†’](aero_llm_20_research_on_translating_embeddings_spaces.md) |
| [PhÃ¢n TÃ­ch ChÃ¹m Quang Phá»• Suy Biáº¿n (Singular Value Spectrum) Cá»§a KhÃ´ng Gian NhÃºng](aero_llm_21_singular_value_spectrum_of_embeddings_submatrices.md) | [Xem bÃ i viáº¿t â†’](aero_llm_21_singular_value_spectrum_of_embeddings_submatrices.md) |
| [Ãnh Xáº¡ SVD CÃ¡c Dáº£i Äiá»ƒm NhÃºng CÃ³ Quan Há»‡ ChÃ©o](aero_llm_22_codechallenge_svd_projections_of_related_embeddings.md) | [Xem bÃ i viáº¿t â†’](aero_llm_22_codechallenge_svd_projections_of_related_embeddings.md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
