
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../index.md) > [11 investigating token embeddings](index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../index.md)
- [ğŸ“š Module 01: LLM Course](../01_llm_course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../02_words_to_tokens_to_numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../04_buildgpt/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../07_fine_tune_pretrained_models/index.md)
- [ğŸ” Module 19: AI Safety](../19_ai_safety/index.md)
- [ğŸ Module 20: Python for AI](../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Cáº¡nh Tranh TÃ¬m Tá»« Äá»“ng NghÄ©a BERT vs GPT: CÆ¡ Cháº¿ Tokenization Äa KÃ½ Tá»±

## TÃ³m táº¯t

BÃ i bÃ¡o cÃ¡o thá»±c nghiá»‡m so sÃ¡nh phÆ°Æ¡ng phÃ¡p trÃ­ch lá»c cÃ¡c máº£ng "hÃ ng xÃ³m" gáº§n nháº¥t dá»±a trÃªn ká»¹ luáº­t k-Nearest Neighbors (k-NN) báº±ng thuáº­t chuáº©n khoáº£ng cÃ¡ch Euclidean giá»¯a hai siÃªu kiáº¿n trÃºc mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLMs): Há»‡ tá»± mÃ£ hÃ³a sinh Ä‘Ã´i BERT vÃ  Há»‡ tá»± há»“i quy má»™t chiá»u GPT-2. Äiá»ƒm Ä‘áº·c sáº¯c táº­p trung giáº£i quyáº¿t bÃ i toÃ¡n sá»¥p Ä‘á»• cá»§a má»™t token Ä‘a pháº§n tá»­ trÆ°á»›c dáº¥u cÃ¡ch khÃ´ng gian (Space tokens), cáº¥u trÃºc mÃ  GPT-2 chia ráº½ cÃ¡c chuá»—i Ä‘á»“ng nháº¥t. Hiá»‡n tÆ°á»£ng trung bÃ¬nh hÃ³a Ä‘a vÃ©c-tÆ¡ (vector mean-pooling) Ä‘á»ƒ Ã©p há»£p má»™t Vector sáº½ cho ra cÃ¡c tá»« vá»±c xa rá»i vá»›i Ä‘á»“ng cáº¥u sinh há»c logic.

---

## 1. Báº£n Äá»“ Máº­t Äá»™ VÃ  Khoáº£ng CÃ¡ch Xa TÆ°Æ¡ng Äá»‘i

Thá»±c nghiá»‡m báº¯t Ä‘áº§u vá»›i má»™t tá»« háº¡t giá»‘ng (Seed Token) khÃ´ng cÃ³ chuá»—i khÃ´ng gian xen vÃ o, vÃ­ dá»¥: cá»¥m `"ring"`.
Thuáº­t toÃ¡n láº¥y vetor mÃ£ cá»§a `ring` cÃ n quÃ©t Ä‘o khoáº£ng cÃ¡ch Euclidean Distance ($\| \vec{a} - \vec{b} \|$) so vá»›i háº±ng sá»‘ $50.000$ (táº­p Vocab) cÃ¡c vÃ©ctÆ¡ mÃ£ trong cáº£ BERT vÃ  GPT-2. CÃ¡c há»‡ quáº£ trá»±c quan:
- **Biá»ƒu Äá»“ Lá»‡ch Histograms:** ÄÆ°á»ng hÃ¬nh chuÃ´ng (Gaussian curves) cá»§a GPT-2 vÃ  BERT cÃ³ phÃ¢n bá»‘ bÃ¬nh thÆ°á»ng mÆ°á»£t mÃ  vÃ  táº­p trung xa dáº§n vá» khu vá»±c trung bÃ¬nh. Cáº£ hai Ä‘á»u chá»«a láº¡i má»™t dáº£i siÃªu háº¹p (Long-tail) tá»« khoáº£ng cÃ¡ch cá»±c tiá»ƒu cho vÃ i Token siÃªu liÃªn Ä‘á»›i, trong khi lÆ°á»£ng lá»›n hÃ ng chá»¥c ngÃ n tá»« á»Ÿ phÆ°Æ¡ng trá»i xa tháº©m.
- Tuy nhiÃªn, quáº§n thá»ƒ khÃ´ng trung chuáº©n (Non-normalized points) cá»§a BERT Ä‘Æ°á»£c giá»¯ co láº¡i dáº§y Ä‘áº·c, trong khi GPT-2 táº¡o Ä‘á»™ dÃ£n máº­t Ä‘á»™ vector cao hÆ¡n hÃ ng chuá»—i chá»‰ má»¥c.

Khi Normalized Matrix ($\|\vec{v}\| = 1$), lá»±c kÃ©o cá»§a Ä‘á»™ dÃ i vector bá»‹ triá»‡t biáº¿n, biáº¿n Ä‘á»“ thá»‹ Histogram Euclidean cá»§a hai gÃ£ khá»•ng lá»“ nÃ y Ä‘Ã¨ lÃªn nhau trÃ¹ng khá»›p thÃ nh má»™t biá»ƒu Ä‘á»“ há»£p vÄ© duy nháº¥t, hÃ© lá»™ sá»©c máº¡nh thá»±c sá»± cá»§a hÆ°á»›ng gÃ³c Vector (Direction Angles).

---

## 2. Há»‡ MÃ£ HÃ³a Lá»‡ch (The Space Sensitivity)

Viá»‡c khai thÃ¡c Synonym qua k-NN trÃªn BERT dá»… dÃ ng cung cáº¥p chuá»—i Top 15 khÃ¡ cháº·t cháº½: `rings`, `ringing`, `fifth`, `sixth`.. (cÃ¡c tá»« ngá»¯ Ä‘á»“ng lÃµa ngá»¯ phÃ¡p). 
Khi ta tháº£ háº¡t giá»‘ng má»›i lÃ  `" ring"` (khoáº£ng tráº¯ng náº±m trÆ°á»›c kÃ­ tá»±), BERT Tokenizer láº­p tá»©c nÃ©m chuá»—i khoáº£ng tráº¯ng Ä‘i vÃ¬ cÆ¡ cháº¿ PhÃ¢n lá»›p Má»©c Ä‘á»™ ChÃº Ã½ (Classification token) cá»§a BERT khÃ´ng quan tÃ¢m yáº¿u tá»‘ hÃ¬nh thá»©c ngá»¯ phÃ¡p hiá»ƒn thá»‹. 

**GPT-2 lÃ  má»™t vÅ© trá»¥ khÃ¡c biá»‡t:**
Bá»™ mÃ£ hÃ³a Byte-Pair Encoding BPE cá»§a GPT-2 xem khoáº£ng tráº¯ng cÅ©ng lÃ  xÆ°Æ¡ng sá»‘ng cáº¥u thÃ nh tá»« vá»±ng ná»™i hÃ m.
- Vá»›i háº¡t giá»‘ng `"ring"`, GPT-2 tÃ¬m ra nhá»¯ng token ngáº«u nhiÃªn dá»±a vÃ o cáº¥u trÃºc Ä‘á»“ há»a hÃ¬nh há»c Orthographically (vÃ­ dá»¥: `ringa`, `ringred`, `drying`, `ping`) thay vÃ¬ báº¥t kÃ¬ Ã½ nghÄ©a ngá»¯ nghÄ©a nÃ o.
- Chá»‰ khi Ã¡p dá»¥ng Normalization vÃ  chÃ¨n dáº¥u khoáº£ng trá»‘ng Ä‘áº§u háº¡t `" ring"`, GPT-2 má»›i kháº£i huyá»n ra cÃ¡c máº£ng tá»« khÃ³a Synonym Ä‘Ã¡ng sá»£ nhÆ°: `amulet` (bÃ¹a ngáº£i chuá»—i), `circle` (vÃ²ng xoay), `necklace` (chuá»—i háº¡t), `bracelet` (vÃ²ng tay Ä‘eo). Tá»©c lÃ  GPT chá»‰ hoáº¡t Ä‘á»™ng nÃ£o bá»™ káº¿t tá»§a Synonym khi tá»« vá»±ng bá»‹ ngáº¯t Ä‘á»©t vá»›i tiáº¿p vá»‹ ngá»¯ dÆ° thá»«a.

---

## 3. Khá»§ng Hoáº£ng PhÃ¢n RÃ£ Tokenize VÃ  Biá»‡n PhÃ¡p Mean Pooling
Thá»­ thÃ¡ch bÃ¹ng ná»• khi sá»­ dá»¥ng tÃ¬m kiáº¿m Ä‘á»“ng nghÄ©a cho háº¡t giá»‘ng `"beauty"`. 
- Báº­t Tokenize cá»§a BERT: Nháº­n rá»… `"beauty"` lÃ m 1 Single Token $\to$ Euclidean Scan mÆ°á»£t mÃ .
- Báº­t Tokenize cá»§a GPT-2: Chá»¯ `"beauty"` bá»‹ cÆ°a xáº» nÃ¡t bung thÃ nh **2 Tokens Ä‘á»™c láº­p**.

KhÃ´ng thá»ƒ dÃ¹ng thÆ°á»›c dÃ¢y k-NN cho 2 ngá»n vÃ©c-tÆ¡ Ä‘á»™c láº­p, kiáº¿n trÃºc sÆ° chá»‰ Ä‘Æ°á»£c phÃ©p chá»n 1 trong 2 giáº£i phÃ¡p:
1. TÃ­nh khoáº£ng cÃ¡ch 50.000 Ä‘iá»ƒm tá»« vÃ©c-tÆ¡ $\vec{v}_1$, lÃ m tÆ°Æ¡ng tá»± cho $\vec{v}_2$. Sau Ä‘Ã³ cá»™ng Average 50.000 cáº·p khoáº£ng cÃ¡ch (Khoáº£ng cÃ¡ch kÃ©o trung bÃ¬nh).
2. Ã‰p trung bÃ¬nh 2 VÃ©c-tÆ¡ báº±ng hÃ m nhÃºng Vector (Mean Pooling) $\vec{E}_{\text{seed}} = \frac{\vec{v}_1 + \vec{v}_2}{2}$. Sau Ä‘Ã³ dÃ¹ng má»™t Vector duy nháº¥t nÃ y phÃ³ng chá»•i quÃ©t máº¡ng lÆ°á»›i KhÃ´ng gian (Option 2).

Náº¿u dÃ¹ng Mean-Pooling phÆ°Æ¡ng thá»©c 2, khÃ´ng gian phÃ¢n hÃ³a tráº£ bá» má»™t há»‡ tÆ°Æ¡ng Ä‘á»‡ tá»« Ä‘á»“ng nghÄ©a áº¥n tÆ°á»£ng Ä‘á»‰nh Ä‘iá»ƒm: Dáº£i GPT-2 báº¯n ra `beautiful, gorgeous, pretty, wonderful, lovely`.
Viá»‡c sÃ¡p nháº­p mÃ£ Ä‘á»™c láº­p khÃ´ng giáº¿t cháº¿t ná»™i hÃ m, nÃ³ táº¡o ra TÃ¬nh tráº¡ng Chuyá»ƒn giao Äa hÆ°á»›ng (Multi-direction Translation), má»™t tÃ­nh cháº¥t sá»‘ng cÃ²n Ä‘á»ƒ káº¿t tinh cÃ¡c kiáº¿n thá»©c phá»©c táº¡p cá»§a Human Language vÃ o AI.

---

## TÃ i liá»‡u tham kháº£o

1. **Bojanowski, P., et al. (2017).** *Enriching Word Vectors with Subword Information.* TACL (CÃ¹ng kiáº¿n trÃºc token hoÃ¡ subword áº£nh hÆ°á»Ÿng k-NN).
2. **Sennrich, H., et al. (2016).** *Neural Machine Translation of Rare Words with Subword Units.* ACL.
3. TÃ i liá»‡u thá»±c hÃ nh láº­p trÃ¬nh *BERT v GPT kNN kompetition.*
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| [aero llm 01 codechallenge cosine similarity advanced part 1](aero_llm_01_codechallenge_cosine_similarity_advanced_part_1_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_01_codechallenge_cosine_similarity_advanced_part_1_.md) |
| [aero llm 02 codechallenge cosine similarity advanced part 2](aero_llm_02_codechallenge_cosine_similarity_advanced_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_02_codechallenge_cosine_similarity_advanced_part_2_.md) |
| [Theo DÃµi DÃ²ng Cháº£y Cosine Similarity TrÃªn Trá»¥c VÄƒn Báº£n ChuyÃªn Tuáº§n Tá»± (Word Sequences)](aero_llm_03_codechallenge_cosine_similarity_in_word_sequences.md) | [Xem bÃ i viáº¿t â†’](aero_llm_03_codechallenge_cosine_similarity_in_word_sequences.md) |
| [Nghá»‡ Thuáº­t Váº½ Báº£n Äá»“ Nhiá»‡t Ma Tráº­n NhÃºng Báº±ng CÆ°á»ng Äá»™ Tá»« (Coloring Cosine Similarity)](aero_llm_04_codechallenge_coloring_cosine_similarity.md) | [Xem bÃ i viáº¿t â†’](aero_llm_04_codechallenge_coloring_cosine_similarity.md) |
| [áº¢o áº¢nh Cá»§a TrÃ­ Tuá»‡ ToÃ¡n Há»c Trong NgÃ´n Ngá»¯: Sá»©c Máº¡nh Cá»§a Random Embeddings](aero_llm_05_codechallenge_can_random_embeddings_be_interpreted.md) | [Xem bÃ i viáº¿t â†’](aero_llm_05_codechallenge_can_random_embeddings_be_interpreted.md) |
| [PhÆ°Æ¡ng PhÃ¡p T-SNE VÃ  Thuáº­t ToÃ¡n PhÃ¢n Cá»¥m DBSCAN: Chiáº¿u KhÃ´ng Gian Äa Chiá»u Cho LLMs](aero_llm_06_t_sne_projection_and_dbscan_clustering_theory_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_06_t_sne_projection_and_dbscan_clustering_theory_.md) |
| [PhÃ¢n Cá»¥m Ngá»¯ NghÄ©a Qua PhÃ©p Chiáº¿u t-SNE & Máº­t Äá»™ DBSCAN (Python)](aero_llm_07_t_sne_projection_and_dbscan_clustering_python_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_07_t_sne_projection_and_dbscan_clustering_python_.md) |
| [ThÃ¡ch Thá»©c Code: TÃ¬m Lá»— Há»•ng PhÃ¢n Cá»¥m Báº±ng Bá»™ Lá»c Báº£ng Chá»¯ CÃ¡i Chá»¯ X](aero_llm_08_codechallenge_cluster_the_x_terms.md) | [Xem bÃ i viáº¿t â†’](aero_llm_08_codechallenge_cluster_the_x_terms.md) |
| [PhÃ¢n RÃ£ Token, NhÃºng VÃ  PhÃ¢n Cá»¥m Biá»ƒu TÆ°á»£ng Emojis Báº±ng Äá»“ Thá»‹ Máº­t Äá»™](aero_llm_09_codechallenge_tokenize_embed_and_cluster_happy_emojis.md) | [Xem bÃ i viáº¿t â†’](aero_llm_09_codechallenge_tokenize_embed_and_cluster_happy_emojis.md) |
| [PhÃ¢n TÃ­ch RSA (Representational Similarity Analysis) Giá»¯a CÃ¡c MÃ´ HÃ¬nh NgÃ´n Ngá»¯](aero_llm_10_rsa_representational_similarity_analysis_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_10_rsa_representational_similarity_analysis_.md) |
| [PhÃ¢n TÃ­ch Äá»™ Lá»‡ch RSA (Part 1): So SÃ¡nh Sá»± Báº¥t Äá»“ng Giá»¯a KhÃ´ng Gian GloVe 50D vÃ  300D](aero_llm_11_codechallenge_compare_embeddings_with_rsa_part_1_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_11_codechallenge_compare_embeddings_with_rsa_part_1_.md) |
| [PhÃ¢n TÃ­ch Äá»™ Lá»‡ch RSA (Part 2): Äá»‘i Chiáº¿u TÆ°Æ¡ng Quan Pearson Cho Khoáº£ng CÃ¡ch Cosine](aero_llm_12_codechallenge_compare_embeddings_with_rsa_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_12_codechallenge_compare_embeddings_with_rsa_part_2_.md) |
| [So SÃ¡nh KhÃ´ng Gian NhÃºng: Word2Vec VÃ  GPT-2 Qua PhÃ¢n TÃ­ch RSA](aero_llm_13_codechallenge_word2vec_vs_gpt2.md) | [Xem bÃ i viáº¿t â†’](aero_llm_13_codechallenge_word2vec_vs_gpt2.md) |
| [Bá»‘ Cá»¥c Äá»“ Thá»‹ Máº¡ng (Network Graph) ThÃ´ng Qua Ma Tráº­n Cosine Similarity](aero_llm_14_codechallenge_graph_representation_of_cosine_similarities.md) | [Xem bÃ i viáº¿t â†’](aero_llm_14_codechallenge_graph_representation_of_cosine_similarities.md) |
| [Sá»‘ Há»c Tuyáº¿n TÃ­nh vÃ  RÃºt TrÃ­ch TÆ°Æ¡ng Äá»“ng Giá»¯a CÃ¡c Tá»« NhÃºng (Word Embeddings Analogies)](aero_llm_15_embeddings_arithmetic_and_analogies.md) | [Xem bÃ i viáº¿t â†’](aero_llm_15_embeddings_arithmetic_and_analogies.md) |
| [Vá»¡ Má»™ng Vá» Sá»‘ Há»c Vector TÆ°Æ¡ng ÄÆ°Æ¡ng (Soft-Coded Analogies) TrÃªn Word2Vec](aero_llm_16_codechallenge_soft_coded_analogies_in_word2vec.md) | [Xem bÃ i viáº¿t â†’](aero_llm_16_codechallenge_soft_coded_analogies_in_word2vec.md) |
| [Thiáº¿t Láº­p VÃ  Diá»…n Giáº£i Trá»¥c Ngá»¯ NghÄ©a Tuyáº¿n TÃ­nh (Linear Semantic Axes)](aero_llm_17_creating_and_interpreting_linear_semantic_axes.md) | [Xem bÃ i viáº¿t â†’](aero_llm_17_creating_and_interpreting_linear_semantic_axes.md) |
| [Khai ThÃ¡c Thuáº­t ToÃ¡n k-NN Cho TÃ¬m Kiáº¿m Tá»« Äá»“ng NghÄ©a TrÃªn BERT](aero_llm_18_knn_for_synonym_searching_in_bert.md) | [Xem bÃ i viáº¿t â†’](aero_llm_18_knn_for_synonym_searching_in_bert.md) |
| ğŸ“Œ **[Cáº¡nh Tranh TÃ¬m Tá»« Äá»“ng NghÄ©a BERT vs GPT: CÆ¡ Cháº¿ Tokenization Äa KÃ½ Tá»±](aero_llm_19_codechallenge_bert_v_gpt_knn_kompetition.md)** | [Xem bÃ i viáº¿t â†’](aero_llm_19_codechallenge_bert_v_gpt_knn_kompetition.md) |
| [Sá»± Dá»‹ch Chuyá»ƒn VÃ  Äá»“ng Tá»“n Biá»ƒu Diá»…n Giá»¯a CÃ¡c KhÃ´ng Gian NhÃºng](aero_llm_20_research_on_translating_embeddings_spaces.md) | [Xem bÃ i viáº¿t â†’](aero_llm_20_research_on_translating_embeddings_spaces.md) |
| [PhÃ¢n TÃ­ch ChÃ¹m Quang Phá»• Suy Biáº¿n (Singular Value Spectrum) Cá»§a KhÃ´ng Gian NhÃºng](aero_llm_21_singular_value_spectrum_of_embeddings_submatrices.md) | [Xem bÃ i viáº¿t â†’](aero_llm_21_singular_value_spectrum_of_embeddings_submatrices.md) |
| [Ãnh Xáº¡ SVD CÃ¡c Dáº£i Äiá»ƒm NhÃºng CÃ³ Quan Há»‡ ChÃ©o](aero_llm_22_codechallenge_svd_projections_of_related_embeddings.md) | [Xem bÃ i viáº¿t â†’](aero_llm_22_codechallenge_svd_projections_of_related_embeddings.md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
