
<!-- Aero-Navigation-Start -->
[üè† Home](../index.md) > [11 investigating token embeddings](index.md)

---
### üß≠ ƒêi·ªÅu h∆∞·ªõng nhanh

- [üè† C·ªïng t√†i li·ªáu](../index.md)
- [üìö Module 01: LLM Course](../01_llm_course/index.md)
- [üî¢ Module 02: Tokenization](../02_words_to_tokens_to_numbers/index.md)
- [üèóÔ∏è Module 04: Build GPT](../04_buildgpt/index.md)
- [üéØ Module 07: Fine-tuning](../07_fine_tune_pretrained_models/index.md)
- [üîç Module 19: AI Safety](../19_ai_safety/index.md)
- [üêç Module 20: Python for AI](../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
Cosine Similarity n√¢ng cao (Ph·∫ßn 2):

Ph√¢n t√≠ch h√¨nh h·ªçc x√°c su·∫•t, anisotropy v√† t·ªëi ∆∞u ho√° trong kh√¥ng gian embedding chi·ªÅu cao

‚∏ª

T√≥m t·∫Øt

Ti·∫øp n·ªëi ph·∫ßn tr∆∞·ªõc v·ªÅ Cosine Similarity, b√†i vi·∫øt n√†y m·ªü r·ªông ph√¢n t√≠ch sang c√°c v·∫•n ƒë·ªÅ n√¢ng cao bao g·ªìm: hi·ªán t∆∞·ª£ng anisotropy trong embedding space, ph√¢n ph·ªëi g√≥c trong kh√¥ng gian chi·ªÅu cao, ·∫£nh h∆∞·ªüng c·ªßa chu·∫©n h√≥a (normalization), whitening transformation, v√† vai tr√≤ c·ªßa cosine similarity trong contrastive learning v√† retrieval hi·ªán ƒë·∫°i. C√°c c√¥ng th·ª©c to√°n h·ªçc ƒë∆∞·ª£c tr√¨nh b√†y nh·∫±m l√†m r√µ b·∫£n ch·∫•t h√¨nh h·ªçc ‚Äì x√°c su·∫•t c·ªßa c√°c embedding ƒë∆∞·ª£c hu·∫•n luy·ªán b·ªüi m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn (LLMs).

‚∏ª

1. Gi·ªõi thi·ªáu

Embedding kh√¥ng c√≤n l√† vector ng·∫´u nhi√™n ƒë∆°n gi·∫£n; ch√∫ng ƒë∆∞·ª£c hu·∫•n luy·ªán th√¥ng qua t·ªëi ∆∞u h√≥a gradient, d·∫´n ƒë·∫øn c·∫•u tr√∫c h√¨nh h·ªçc ƒë·∫∑c bi·ªát. C√°c t·ªï ch·ª©c nh∆∞:
	‚Ä¢	OpenAI
	‚Ä¢	Google Research
	‚Ä¢	Meta AI

ƒë√£ ·ª©ng d·ª•ng cosine similarity l√†m l√µi cho:
	‚Ä¢	Semantic search
	‚Ä¢	Retrieval-Augmented Generation (RAG)
	‚Ä¢	Vector database indexing

Tuy nhi√™n, embedding th·ª±c t·∫ø kh√¥ng ph√¢n b·ªë ƒë·ªÅu trong kh√¥ng gian \mathbb{R}^d.

‚∏ª

2. Ph√¢n ph·ªëi g√≥c trong kh√¥ng gian chi·ªÅu cao

Gi·∫£ s·ª≠:

\mathbf{x}, \mathbf{y} \sim \mathcal{N}(0, I_d)

Sau chu·∫©n h√≥a:

\tilde{\mathbf{x}} = \frac{\mathbf{x}}{\|\mathbf{x}\|}

Ph√¢n ph·ªëi c·ªßa:

\cos \theta = \tilde{\mathbf{x}} \cdot \tilde{\mathbf{y}}

Khi d \to \infty:

\cos \theta \xrightarrow{p} 0

V√† ph∆∞∆°ng sai:

Var$\cos \theta$ \approx \frac{1}{d}

ƒêi·ªÅu n√†y gi·∫£i th√≠ch v√¨ sao trong embedding dimension l·ªõn (512‚Äì4096), c√°c vector ng·∫´u nhi√™n g·∫ßn nh∆∞ tr·ª±c giao.

‚∏ª

3. Hi·ªán t∆∞·ª£ng Anisotropy

3.1 ƒê·ªãnh nghƒ©a

Anisotropy x·∫£y ra khi embedding t·∫≠p trung quanh m·ªôt h∆∞·ªõng ∆∞u th·∫ø.

Gi·∫£ s·ª≠ trung b√¨nh embedding:

\mu = \mathbb{E}[\mathbf{x}]

N·∫øu:

\|\mu\| \gg 0

‚Üí embedding l·ªách h∆∞·ªõng.

‚∏ª

3.2 H·ªá qu·∫£

Cosine similarity gi·ªØa hai vector b·∫•t k·ª≥:

\cos$\mathbf{x}, \mathbf{y}$

b·ªã chi ph·ªëi b·ªüi th√†nh ph·∫ßn chung theo h∆∞·ªõng \mu.

‚∏ª

4. Centering v√† Whitening

4.1 Centering

Lo·∫°i b·ªè trung b√¨nh:

\mathbf{x}' = \mathbf{x} - \mu

‚∏ª

4.2 Whitening Transformation

Cho ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai:

\Sigma = \mathbb{E}[$\mathbf{x}-\mu$$\mathbf{x}-\mu$^T]

Whitening:

\mathbf{x}_{white} = \Sigma^{-1/2}$\mathbf{x}-\mu$

Khi ƒë√≥:

Cov$\mathbf{x}_{white}$ = I

ƒêi·ªÅu n√†y gi√∫p ph√¢n ph·ªëi ƒë·ªìng ƒë·ªÅu h∆°n trong kh√¥ng gian.

‚∏ª

5. Cosine Similarity v√† Contrastive Learning

Trong contrastive loss:

\mathcal{L}_i =
- \log
\frac{\exp$\cos(\mathbf{z}_i,\mathbf{z}_j$/\tau)}
{\sum_k \exp$\cos(\mathbf{z}_i,\mathbf{z}_k$/\tau)}

Trong ƒë√≥:
	‚Ä¢	\tau: temperature
	‚Ä¢	\mathbf{z}: embedding ƒë√£ chu·∫©n h√≥a

Khi \tau \to 0:

\exp$\cos/\tau$

khu·∫øch ƒë·∫°i s·ª± kh√°c bi·ªát g√≥c nh·ªè.

‚∏ª

6. Cosine Similarity v√† Maximum Likelihood

Gi·∫£ s·ª≠ embedding query q v√† document d:

P(d|q) =
\frac{\exp$\alpha \cos(q,d$)}
{\sum_j \exp$\alpha \cos(q,d_j$)}

ƒê√¢y ch√≠nh l√† softmax over cosine scores.

H√†m log-likelihood:

\mathcal{L} =
\sum_i \log P$d_i|q_i$

‚∏ª

7. Ph√¢n t√≠ch Gradient trong Kh√¥ng gian Chu·∫©n h√≥a

Cho:

S = \frac{\mathbf{x} \cdot \mathbf{y}}{\|\mathbf{x}\|\|\mathbf{y}\|}

Gradient theo \mathbf{x}:

\frac{\partial S}{\partial \mathbf{x}} =
\frac{\mathbf{y}}{\|\mathbf{x}\|\|\mathbf{y}\|}
-
\frac{$\mathbf{x}\cdot\mathbf{y}$\mathbf{x}}
{\|\mathbf{x}\|^3\|\mathbf{y}\|}

Gradient n√†y g·ªìm hai th√†nh ph·∫ßn:
	1.	H∆∞·ªõng v·ªÅ ph√≠a \mathbf{y}
	2.	Th√†nh ph·∫ßn ƒëi·ªÅu ch·ªânh ƒë·ªô l·ªõn

ƒêi·ªÅu n√†y l√†m embedding t·ª± ƒë·ªông chu·∫©n h√≥a h∆∞·ªõng thay v√¨ ƒë·ªô l·ªõn.

‚∏ª

8. Li√™n h·ªá v·ªõi Information Geometry

Theo Pattern Recognition and Machine Learning:

Kho·∫£ng c√°ch Bregman v·ªõi entropy:

D_\phi(p,q) =
\phi$p$ - \phi$q$ - \nabla\phi$q$^T(p-q)

Cosine similarity kh√¥ng ph·∫£i metric Bregman nh∆∞ng c√≥ th·ªÉ xem nh∆∞ metric g√≥c tr√™n hypersphere:

S^{d-1} =
\{\mathbf{x} \in \mathbb{R}^d : \|\mathbf{x}\| = 1\}

‚∏ª

9. ·ª®ng d·ª•ng trong Vector Database

C√°c h·ªá th·ªëng nh∆∞:
	‚Ä¢	FAISS (Meta AI)
	‚Ä¢	ScaNN (Google Research)

s·ª≠ d·ª•ng cosine similarity ho·∫∑c inner product.

N·∫øu vector chu·∫©n h√≥a:

\mathbf{x} \cdot \mathbf{y}
=
\cos$\mathbf{x},\mathbf{y}$

‚Üí t·ªëi ∆∞u t√≠nh to√°n b·∫±ng Approximate Nearest Neighbor.

‚∏ª

10. So s√°nh v·ªõi c√°c metric kh√°c

Metric	C√¥ng th·ª©c	Nh·∫°y ƒë·ªô l·ªõn	Ph√π h·ª£p NLP
Euclidean	\|\mathbf{x}-\mathbf{y}\|	C√≥	Trung b√¨nh
Dot Product	x \cdot y	C√≥	Cao
Cosine	\frac{x\cdot y}{\|x\|\|y\|}	Kh√¥ng	R·∫•t cao


‚∏ª

11. Th·∫£o lu·∫≠n

∆Øu ƒëi·ªÉm
	‚Ä¢	B·∫•t bi·∫øn theo scale
	‚Ä¢	Ph√π h·ª£p cho embedding chu·∫©n h√≥a
	‚Ä¢	T·ªëi ∆∞u cho retrieval

H·∫°n ch·∫ø
	‚Ä¢	Kh√¥ng x·ª≠ l√Ω t·ªët anisotropy
	‚Ä¢	Kh√¥ng ƒëo quan h·ªá phi tuy·∫øn
	‚Ä¢	D·ªÖ b·ªã cluster collapse n·∫øu kh√¥ng regularize

‚∏ª

12. K·∫øt lu·∫≠n

Cosine similarity trong embedding hi·ªán ƒë·∫°i kh√¥ng ch·ªâ l√† ph√©p ƒëo h√¨nh h·ªçc ƒë∆°n gi·∫£n m√† l√†:
	‚Ä¢	Metric tr√™n hypersphere
	‚Ä¢	Th√†nh ph·∫ßn c·ªët l√µi c·ªßa contrastive learning
	‚Ä¢	C∆° s·ªü cho retrieval v√† vector database

Hi·ªÉu r√µ ph√¢n ph·ªëi g√≥c, anisotropy v√† whitening gi√∫p c·∫£i thi·ªán ƒë√°ng k·ªÉ ch·∫•t l∆∞·ª£ng embedding trong LLM.

‚∏ª

T√†i li·ªáu tham kh·∫£o
	1.	Bishop (2006). Pattern Recognition and Machine Learning.
	2.	Cover & Thomas (2006). Elements of Information Theory.
	3.	Mikolov et al. (2013). Word2Vec.
	4.	Chen et al. (2020). SimCLR.
	5.	Reimers & Gurevych (2019). Sentence-BERT.
<!-- Aero-Footer-Start -->

## üìÑ T√†i li·ªáu c√πng chuy√™n m·ª•c
| B√†i h·ªçc | Li√™n k·∫øt |
| :--- | :--- |
| [aero llm 01 codechallenge cosine similarity advanced part 1](aero_llm_01_codechallenge_cosine_similarity_advanced_part_1_.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_01_codechallenge_cosine_similarity_advanced_part_1_.md) |
| üìå **[aero llm 02 codechallenge cosine similarity advanced part 2](aero_llm_02_codechallenge_cosine_similarity_advanced_part_2_.md)** | [Xem b√†i vi·∫øt ‚Üí](aero_llm_02_codechallenge_cosine_similarity_advanced_part_2_.md) |
| [Theo D√µi D√≤ng Ch·∫£y Cosine Similarity Tr√™n Tr·ª•c VƒÉn B·∫£n Chuy√™n Tu·∫ßn T·ª± (Word Sequences)](aero_llm_03_codechallenge_cosine_similarity_in_word_sequences.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_03_codechallenge_cosine_similarity_in_word_sequences.md) |
| [Ngh·ªá Thu·∫≠t V·∫Ω B·∫£n ƒê·ªì Nhi·ªát Ma Tr·∫≠n Nh√∫ng B·∫±ng C∆∞·ªùng ƒê·ªô T·ª´ (Coloring Cosine Similarity)](aero_llm_04_codechallenge_coloring_cosine_similarity.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_04_codechallenge_coloring_cosine_similarity.md) |
| [·∫¢o ·∫¢nh C·ªßa Tr√≠ Tu·ªá To√°n H·ªçc Trong Ng√¥n Ng·ªØ: S·ª©c M·∫°nh C·ªßa Random Embeddings](aero_llm_05_codechallenge_can_random_embeddings_be_interpreted.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_05_codechallenge_can_random_embeddings_be_interpreted.md) |
| [Ph∆∞∆°ng Ph√°p T-SNE V√† Thu·∫≠t To√°n Ph√¢n C·ª•m DBSCAN: Chi·∫øu Kh√¥ng Gian ƒêa Chi·ªÅu Cho LLMs](aero_llm_06_t_sne_projection_and_dbscan_clustering_theory_.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_06_t_sne_projection_and_dbscan_clustering_theory_.md) |
| [Ph√¢n C·ª•m Ng·ªØ Nghƒ©a Qua Ph√©p Chi·∫øu t-SNE & M·∫≠t ƒê·ªô DBSCAN (Python)](aero_llm_07_t_sne_projection_and_dbscan_clustering_python_.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_07_t_sne_projection_and_dbscan_clustering_python_.md) |
| [Th√°ch Th·ª©c Code: T√¨m L·ªó H·ªïng Ph√¢n C·ª•m B·∫±ng B·ªô L·ªçc B·∫£ng Ch·ªØ C√°i Ch·ªØ X](aero_llm_08_codechallenge_cluster_the_x_terms.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_08_codechallenge_cluster_the_x_terms.md) |
| [Ph√¢n R√£ Token, Nh√∫ng V√† Ph√¢n C·ª•m Bi·ªÉu T∆∞·ª£ng Emojis B·∫±ng ƒê·ªì Th·ªã M·∫≠t ƒê·ªô](aero_llm_09_codechallenge_tokenize_embed_and_cluster_happy_emojis.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_09_codechallenge_tokenize_embed_and_cluster_happy_emojis.md) |
| [Ph√¢n T√≠ch RSA (Representational Similarity Analysis) Gi·ªØa C√°c M√¥ H√¨nh Ng√¥n Ng·ªØ](aero_llm_10_rsa_representational_similarity_analysis_.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_10_rsa_representational_similarity_analysis_.md) |
| [Ph√¢n T√≠ch ƒê·ªô L·ªách RSA (Part 1): So S√°nh S·ª± B·∫•t ƒê·ªìng Gi·ªØa Kh√¥ng Gian GloVe 50D v√† 300D](aero_llm_11_codechallenge_compare_embeddings_with_rsa_part_1_.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_11_codechallenge_compare_embeddings_with_rsa_part_1_.md) |
| [Ph√¢n T√≠ch ƒê·ªô L·ªách RSA (Part 2): ƒê·ªëi Chi·∫øu T∆∞∆°ng Quan Pearson Cho Kho·∫£ng C√°ch Cosine](aero_llm_12_codechallenge_compare_embeddings_with_rsa_part_2_.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_12_codechallenge_compare_embeddings_with_rsa_part_2_.md) |
| [So S√°nh Kh√¥ng Gian Nh√∫ng: Word2Vec V√† GPT-2 Qua Ph√¢n T√≠ch RSA](aero_llm_13_codechallenge_word2vec_vs_gpt2.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_13_codechallenge_word2vec_vs_gpt2.md) |
| [B·ªë C·ª•c ƒê·ªì Th·ªã M·∫°ng (Network Graph) Th√¥ng Qua Ma Tr·∫≠n Cosine Similarity](aero_llm_14_codechallenge_graph_representation_of_cosine_similarities.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_14_codechallenge_graph_representation_of_cosine_similarities.md) |
| [S·ªë H·ªçc Tuy·∫øn T√≠nh v√† R√∫t Tr√≠ch T∆∞∆°ng ƒê·ªìng Gi·ªØa C√°c T·ª´ Nh√∫ng (Word Embeddings Analogies)](aero_llm_15_embeddings_arithmetic_and_analogies.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_15_embeddings_arithmetic_and_analogies.md) |
| [V·ª° M·ªông V·ªÅ S·ªë H·ªçc Vector T∆∞∆°ng ƒê∆∞∆°ng (Soft-Coded Analogies) Tr√™n Word2Vec](aero_llm_16_codechallenge_soft_coded_analogies_in_word2vec.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_16_codechallenge_soft_coded_analogies_in_word2vec.md) |
| [Thi·∫øt L·∫≠p V√† Di·ªÖn Gi·∫£i Tr·ª•c Ng·ªØ Nghƒ©a Tuy·∫øn T√≠nh (Linear Semantic Axes)](aero_llm_17_creating_and_interpreting_linear_semantic_axes.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_17_creating_and_interpreting_linear_semantic_axes.md) |
| [Khai Th√°c Thu·∫≠t To√°n k-NN Cho T√¨m Ki·∫øm T·ª´ ƒê·ªìng Nghƒ©a Tr√™n BERT](aero_llm_18_knn_for_synonym_searching_in_bert.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_18_knn_for_synonym_searching_in_bert.md) |
| [C·∫°nh Tranh T√¨m T·ª´ ƒê·ªìng Nghƒ©a BERT vs GPT: C∆° Ch·∫ø Tokenization ƒêa K√Ω T·ª±](aero_llm_19_codechallenge_bert_v_gpt_knn_kompetition.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_19_codechallenge_bert_v_gpt_knn_kompetition.md) |
| [S·ª± D·ªãch Chuy·ªÉn V√† ƒê·ªìng T·ªìn Bi·ªÉu Di·ªÖn Gi·ªØa C√°c Kh√¥ng Gian Nh√∫ng](aero_llm_20_research_on_translating_embeddings_spaces.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_20_research_on_translating_embeddings_spaces.md) |
| [Ph√¢n T√≠ch Ch√πm Quang Ph·ªï Suy Bi·∫øn (Singular Value Spectrum) C·ªßa Kh√¥ng Gian Nh√∫ng](aero_llm_21_singular_value_spectrum_of_embeddings_submatrices.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_21_singular_value_spectrum_of_embeddings_submatrices.md) |
| [√Ånh X·∫° SVD C√°c D·∫£i ƒêi·ªÉm Nh√∫ng C√≥ Quan H·ªá Ch√©o](aero_llm_22_codechallenge_svd_projections_of_related_embeddings.md) | [Xem b√†i vi·∫øt ‚Üí](aero_llm_22_codechallenge_svd_projections_of_related_embeddings.md) |

---
## ü§ù Li√™n h·ªá & ƒê√≥ng g√≥p
D·ª± √°n ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi **Pixibox**. M·ªçi ƒë√≥ng g√≥p v·ªÅ n·ªôi dung v√† m√£ ngu·ªìn ƒë·ªÅu ƒë∆∞·ª£c ch√†o ƒë√≥n.

> *"Ki·∫øn th·ª©c l√† ƒë·ªÉ chia s·∫ª. H√£y c√πng nhau x√¢y d·ª±ng c·ªông ƒë·ªìng AI v·ªØng m·∫°nh!"* üöÄ

*C·∫≠p nh·∫≠t t·ª± ƒë·ªông b·ªüi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
