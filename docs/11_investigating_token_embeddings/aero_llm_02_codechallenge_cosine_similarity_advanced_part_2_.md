
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../index.md) > [11 investigating token embeddings](index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../index.md)
- [ğŸ“š Module 01: LLM Course](../01_llm_course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../02_words_to_tokens_to_numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../04_buildgpt/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../07_fine_tune_pretrained_models/index.md)
- [ğŸ” Module 19: AI Safety](../19_ai_safety/index.md)
- [ğŸ Module 20: Python for AI](../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
Cosine Similarity nÃ¢ng cao (Pháº§n 2):

PhÃ¢n tÃ­ch hÃ¬nh há»c xÃ¡c suáº¥t, anisotropy vÃ  tá»‘i Æ°u hoÃ¡ trong khÃ´ng gian embedding chiá»u cao

â¸»

TÃ³m táº¯t

Tiáº¿p ná»‘i pháº§n trÆ°á»›c vá» Cosine Similarity, bÃ i viáº¿t nÃ y má»Ÿ rá»™ng phÃ¢n tÃ­ch sang cÃ¡c váº¥n Ä‘á» nÃ¢ng cao bao gá»“m: hiá»‡n tÆ°á»£ng anisotropy trong embedding space, phÃ¢n phá»‘i gÃ³c trong khÃ´ng gian chiá»u cao, áº£nh hÆ°á»Ÿng cá»§a chuáº©n hÃ³a (normalization), whitening transformation, vÃ  vai trÃ² cá»§a cosine similarity trong contrastive learning vÃ  retrieval hiá»‡n Ä‘áº¡i. CÃ¡c cÃ´ng thá»©c toÃ¡n há»c Ä‘Æ°á»£c trÃ¬nh bÃ y nháº±m lÃ m rÃµ báº£n cháº¥t hÃ¬nh há»c â€“ xÃ¡c suáº¥t cá»§a cÃ¡c embedding Ä‘Æ°á»£c huáº¥n luyá»‡n bá»Ÿi mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLMs).

â¸»

1. Giá»›i thiá»‡u

Embedding khÃ´ng cÃ²n lÃ  vector ngáº«u nhiÃªn Ä‘Æ¡n giáº£n; chÃºng Ä‘Æ°á»£c huáº¥n luyá»‡n thÃ´ng qua tá»‘i Æ°u hÃ³a gradient, dáº«n Ä‘áº¿n cáº¥u trÃºc hÃ¬nh há»c Ä‘áº·c biá»‡t. CÃ¡c tá»• chá»©c nhÆ°:
	â€¢	OpenAI
	â€¢	Google Research
	â€¢	Meta AI

Ä‘Ã£ á»©ng dá»¥ng cosine similarity lÃ m lÃµi cho:
	â€¢	Semantic search
	â€¢	Retrieval-Augmented Generation (RAG)
	â€¢	Vector database indexing

Tuy nhiÃªn, embedding thá»±c táº¿ khÃ´ng phÃ¢n bá»‘ Ä‘á»u trong khÃ´ng gian $\mathbb${R}^d.

â¸»

2. PhÃ¢n phá»‘i gÃ³c trong khÃ´ng gian chiá»u cao

Giáº£ sá»­:

\mathbf{x}, \mathbf{y} \sim $\mathcal${N}(0, I_d)

Sau chuáº©n hÃ³a:

\tilde{\mathbf{x}} = \frac{\mathbf{x}}{\|\mathbf{x}\|}

PhÃ¢n phá»‘i cá»§a:

\cos \theta = \tilde{\mathbf{x}} \cdot \tilde{\mathbf{y}}

Khi d \to $\infty$:

\cos \theta \xrightarrow{p} 0

VÃ  phÆ°Æ¡ng sai:

$$
Var$\cos \theta$ $\approx$ \frac{1}{d}
$$

Äiá»u nÃ y giáº£i thÃ­ch vÃ¬ sao trong embedding dimension lá»›n (512â€“4096), cÃ¡c vector ngáº«u nhiÃªn gáº§n nhÆ° trá»±c giao.

â¸»

3. Hiá»‡n tÆ°á»£ng Anisotropy

3.1 Äá»‹nh nghÄ©a

Anisotropy xáº£y ra khi embedding táº­p trung quanh má»™t hÆ°á»›ng Æ°u tháº¿.

Giáº£ sá»­ trung bÃ¬nh embedding:

$$
\mu = $\mathbb${E}[\mathbf{x}]
$$

Náº¿u:

\|\mu\| \gg 0

â†’ embedding lá»‡ch hÆ°á»›ng.

â¸»

3.2 Há»‡ quáº£

Cosine similarity giá»¯a hai vector báº¥t ká»³:

\cos$\mathbf{x}, \mathbf{y}$

bá»‹ chi phá»‘i bá»Ÿi thÃ nh pháº§n chung theo hÆ°á»›ng \mu.

â¸»

4. Centering vÃ  Whitening

4.1 Centering

Loáº¡i bá» trung bÃ¬nh:

\mathbf{x}' = \mathbf{x} - \mu

â¸»

4.2 Whitening Transformation

Cho ma tráº­n hiá»‡p phÆ°Æ¡ng sai:

$$
\Sigma = $\mathbb${E}[$\mathbf{x}-\mu
$$

