
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../index.md) > [11 investigating token embeddings](index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../index.md)
- [ğŸ“š Module 01: LLM Course](../01_llm_course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../02_words_to_tokens_to_numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../04_buildgpt/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../07_fine_tune_pretrained_models/index.md)
- [ğŸ” Module 19: AI Safety](../19_ai_safety/index.md)
- [ğŸ Module 20: Python for AI](../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Theo DÃµi DÃ²ng Cháº£y Cosine Similarity TrÃªn Trá»¥c VÄƒn Báº£n ChuyÃªn Tuáº§n Tá»± (Word Sequences)

## TÃ³m táº¯t

TrÃªn thá»±c táº¿, ngÃ´n ngá»¯ giao tiáº¿p khÃ´ng Ä‘Æ¡n thuáº§n lÃ  nhá»¯ng cá»¥m tá»« Ä‘Æ¡n Ä‘á»™c vÄƒng láº£ng vÃ£ng trong khÃ´ng gian Embeddings. NgÃ´n tá»« thá»±c thá»¥ chá»‰ cÃ³ giÃ¡ trá»‹ khi bá»‹ trÃ³i buá»™c vÃ o má»™t "Trá»‹ sá»‘ KhÃ´ng thá»i gian" - ÄÃ³ lÃ  TrÃ¬nh Tá»± Chá»¯ Viáº¿t (Sequences). BÃ¡o cÃ¡o thá»±c hÃ nh nÃ y Ä‘Ã o cáº¯t khÃ´ng gian Vector tÄ©nh cá»§a mÃ´ hÃ¬nh BERT, Ã¡p dá»¥ng liÃªn hoÃ n ká»¹ thuáº­t Vector hÃ³a Ä‘á»™ tÆ°Æ¡ng quan Cosine tá»«ng bÆ°á»›c Ä‘á»‡m (Sequential Pairs) thÃ´ng qua hÃ m lÃ¢n cáº­n Ä‘á»ƒ giáº£i mÃ£ cÃ¡ch bá»™ mÃ¡y há»c tá»± Ä‘á»™ng bÃ³p mÃ©o Ã½ nghÄ©a theo luá»“ng di chuyá»ƒn tá»« vá»±ng.

---

## 1. CÆ¡ Cháº¿ Káº¿t Tinh Vector Cosine Ná»‘i Tiáº¿p Bá» Máº·t (Sequential Pairs)
MÃ´ táº£ cho cÃ¢u lá»‡nh: 
> *My phone is in the kitchen near the cold ice cream.*

Thuáº­t toÃ¡n khÃ´ng cháº¡y Ä‘iá»ƒm quy náº¡p tÆ°Æ¡ng tá»± cho toÃ n cÃ¢u, mÃ  nÃ³ cáº¯t nhá» tá»«ng cháº·ng $t_i$:
$C(t_i, t_{i-1}) = \cos(\vec{v}_i, \vec{v}_{i-1}) = \frac{\vec{v}_i \cdot \vec{v}_{i-1}}{\\mid \vec{v}_i\\mid \\mid\vec{v}_{i-1}\\mid}$

Khi Ä‘áº·t lÃªn thanh Ä‘á»“ thá»‹ Bar plot:
- Lá»±c hÃºt giá»¯a `cold` vÃ  `ice` Ä‘áº©y Cosine vá»t lÃªn ngÆ°á»¡ng $\sim 0.6$ (Má»‘i quan há»‡ nhiá»‡t Ä‘áº¡i Ä‘a cáº¥u trÃºc).
- Lá»±c hÃºt giá»¯a `ice` vÃ  `cream` duy trÃ¬ $\sim 0.5$ (Cáº¥u trÃºc danh tá»« ghÃ©p truyá»n thá»‘ng).
- NhÆ°ng lá»±c hÃºt giá»¯a `phone` vÃ  `is` sá»¥p Ä‘á»• xuá»‘ng má»©c $\sim 0.15$. Máº¡ng lÃ½ láº½ cá»§a BERT Ä‘Ã£ há»c tá»« hÃ ng triá»‡u trang sÃ¡ch ráº±ng `is` lÃ  Ä‘á»™ng tá»« to be liÃªn káº¿t ngáº«u nhiÃªn vá»›i váº¡n váº­t. `Phone` cháº£ cÃ³ thuá»™c tÃ­nh gÃ¬ sinh ra lá»±c háº¥p dáº«n vá»›i `is`.

Do Ä‘Ã³, Ä‘á»“ thá»‹ Sequential Cosine nÃ y chÃ­nh lÃ  Biá»ƒu Äá»“ Äiá»‡n NÃ£o Äá»“ (EEG) cho tháº¥y má»©c Ä‘á»™ gáº¯n káº¿t logic liá»n ká» (Logical transition density) cá»§a tá»«ng chuá»—i tÆ° duy.

---

## 2. Äo Kháº£o PhÃ¢n NhÃ¡nh NghÄ©a Báº±ng ÄÆ°á»ng Tiá»‡m Cáº­n Biáº¿n Äá»•i (Diverging Sequences)

LÃ½ do vÃ¬ sao Cosine Cá»¥c bá»™ quan trá»ng Ä‘Æ°á»£c chá»©ng minh qua hai cÃ¢u Garden-Path:
A: *The conductor waved his hands as the train departed.*
B: *The conductor waved his hands as the orchestra began.*

Táº¡i thá»i Ä‘iá»ƒm bá»™ Tokenizer Ä‘i tá»« Ä‘áº§u Ä‘áº¿n chá»¯ `The conductor waved his hands as...`: TrÃ­ tuá»‡ cá»§a BERT láº«n nÃ£o sinh há»c chÃºng ta chÆ°a phÃ¢n tÃ­ch Ä‘Æ°á»£c tá»« "Conductor" nÃ y lÃ  "NgÆ°á»i soÃ¡t vÃ© tÃ u tá»§y" hay "Nháº¡c trÆ°á»Ÿng giao hÆ°á»Ÿng" (TÃ­nh máº­p má» Ã½ niá»‡m Ä‘a nghÄ©a Polysense). 

ToÃ n bá»™ biá»ƒu Ä‘á»“ Ä‘á»“ thá»‹ Cosine cá»§a hai cÃ¢u vÄƒn Ä‘Ã¨ lÃªn nhau trÃ¹ng khá»›p Ä‘áº¿n $\mathbf{100\%}$. Chá»‰ Ä‘áº¿n khi Ä‘Ã¢m sáº§m vÃ o 2 Tokens biáº¿n hÃ³a cuá»‘i cÃ¹ng (`train departed` vÃ  `orchestra began`), biá»ƒu Ä‘á»“ má»›i ráº½ nhÃ¡nh Ä‘á»“ thá»‹ (Forking transition):
- Táº¡i Ä‘iá»ƒm ráº½ $\to$ `train` vá»›i Ä‘á»™ dá»‘c Cosine cao hÆ¡n, kÃ©o ngÆ°á»£c tÃ¢m nhÃºng cá»§a máº¡ng ná»™i hÃ m lÃªn má»™t miá»n váº­n chuyá»ƒn giao thÃ´ng.
- Táº¡i Ä‘iá»ƒm ráº½ $\to$ `orchestra`, má»™t hÃ m phÃ¢n bá»• Vector khÃ¡c Ä‘Æ°á»£c báº» gÃ£y kÃ­ch hoáº¡t. 
ÄÃ³ chÃ­nh lÃ  lÃºc sá»± tÃ¡i Ä‘á»‹nh nghÄ©a Ä‘Æ°á»£c kiáº¿n táº¡o.

---

## 3. Báº£n Cháº¥t Cá»§a TÃ­nh Máº­p Má» Giáº£i Pháº«u

Äiá»u tiáº¿t lá»™ chua xÃ³t nháº¥t tá»« thá»±c nghiá»‡m trÃªn: CÃ¡c ma tráº­n tÄ©nh Embedded Matrix thuáº§n tÃºy (nhÆ° BERT raw vector) **hoÃ n toÃ n cÃ¢m Ä‘iáº¿c trong viá»‡c hiá»ƒu vÄƒn cáº£nh ngÆ°á»£c**.
- DÃ¹ chá»¯ `conductor` sau nÃ y Ä‘Ã£ Ä‘Æ°á»£c lÃ m ráº¡ng tá» lÃ  *Nháº¡c trÆ°á»Ÿng*. Tháº¿ nhÆ°ng, tá»a Ä‘á»™ Ä‘iá»ƒm $\vec{v}_{\text{conductor}}$ khi rÃºt tháº³ng tá»« Vocabulary Embeddings $E$, rá»“i Ä‘Æ°á»£c Ä‘á»‘i chiáº¿u vá»›i $\vec{v}_{\text{waved}}$ lÃ  hoÃ n toÃ n tÄ©nh táº¡i. Thá»‘ng kÃª khoáº£ng cÃ¡ch sáº½ bá»‹ cá»©ng ngáº¯c (Frozen logic).

Tuy nhiÃªn máº¡ng ngÃ´n ngá»¯ há»c sÃ¢u BERT láº¡i khÃ´ng cháº¿t bá»Ÿi nguyÃªn lÃ½ Ä‘Ã³ vÃ¬ Embedded matrix nÃ y má»›i chá»‰ lÃ  "Táº§ng Trá»‡t". Khi cÃ¡c giÃ¡ trá»‹ nÃ y má»›m dáº§n qua nhiá»u Trá»¥ Cá»™t Attention Layers, má»™t cÆ¡ cháº¿ truy ngÆ°á»£c thá»i gian ngáº§m Ä‘á»‹nh (Backward context flow) sáº½ Ã©p cáº­p nháº­t láº¡i Ä‘á»‹nh dáº¡ng vÃ©c-tÆ¡ cá»§a tá»« `conductor` báº±ng cÆ¡ cháº¿ Self-attention cÃ³ trá»ng sá»‘ (Weighted dot matrix). PhÃ¢n tÃ­ch chuá»—i tuáº§n tá»± chÃ­nh lÃ  tiá»n Ä‘á» cÄƒn báº£n nháº¥t Ä‘á»ƒ ta má»Ÿ Ä‘Æ°á»ng lÃªn phÃ¢n tÃ­ch Context Vectors sau nÃ y.

---

## TÃ i liá»‡u tham kháº£o

1. **Vaswani, A., et al. (2017).** *Attention is all you need.* NIPS. (Äáº·t ngÃ²i ná»• cho chuá»—i thá»i gian phÃ¢n Ä‘oáº¡n ngá»¯ Ä‘oáº¡n).
2. **Peters, M. E., et al. (2018).** *Deep contextualized word representations.* NAACL (MÃ´ hÃ¬nh hÃ³a Context Dependency ELMo).
3. TÃ i liá»‡u mÃ´ phá»ng logic máº¡ng há»c sÃ¢u *Cosine similarity in word sequences.*
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| [aero llm 01 codechallenge cosine similarity advanced part 1](aero_llm_01_codechallenge_cosine_similarity_advanced_part_1_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_01_codechallenge_cosine_similarity_advanced_part_1_.md) |
| [aero llm 02 codechallenge cosine similarity advanced part 2](aero_llm_02_codechallenge_cosine_similarity_advanced_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_02_codechallenge_cosine_similarity_advanced_part_2_.md) |
| ğŸ“Œ **[Theo DÃµi DÃ²ng Cháº£y Cosine Similarity TrÃªn Trá»¥c VÄƒn Báº£n ChuyÃªn Tuáº§n Tá»± (Word Sequences)](aero_llm_03_codechallenge_cosine_similarity_in_word_sequences.md)** | [Xem bÃ i viáº¿t â†’](aero_llm_03_codechallenge_cosine_similarity_in_word_sequences.md) |
| [Nghá»‡ Thuáº­t Váº½ Báº£n Äá»“ Nhiá»‡t Ma Tráº­n NhÃºng Báº±ng CÆ°á»ng Äá»™ Tá»« (Coloring Cosine Similarity)](aero_llm_04_codechallenge_coloring_cosine_similarity.md) | [Xem bÃ i viáº¿t â†’](aero_llm_04_codechallenge_coloring_cosine_similarity.md) |
| [áº¢o áº¢nh Cá»§a TrÃ­ Tuá»‡ ToÃ¡n Há»c Trong NgÃ´n Ngá»¯: Sá»©c Máº¡nh Cá»§a Random Embeddings](aero_llm_05_codechallenge_can_random_embeddings_be_interpreted.md) | [Xem bÃ i viáº¿t â†’](aero_llm_05_codechallenge_can_random_embeddings_be_interpreted.md) |
| [PhÆ°Æ¡ng PhÃ¡p T-SNE VÃ  Thuáº­t ToÃ¡n PhÃ¢n Cá»¥m DBSCAN: Chiáº¿u KhÃ´ng Gian Äa Chiá»u Cho LLMs](aero_llm_06_t_sne_projection_and_dbscan_clustering_theory_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_06_t_sne_projection_and_dbscan_clustering_theory_.md) |
| [PhÃ¢n Cá»¥m Ngá»¯ NghÄ©a Qua PhÃ©p Chiáº¿u t-SNE & Máº­t Äá»™ DBSCAN (Python)](aero_llm_07_t_sne_projection_and_dbscan_clustering_python_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_07_t_sne_projection_and_dbscan_clustering_python_.md) |
| [ThÃ¡ch Thá»©c Code: TÃ¬m Lá»— Há»•ng PhÃ¢n Cá»¥m Báº±ng Bá»™ Lá»c Báº£ng Chá»¯ CÃ¡i Chá»¯ X](aero_llm_08_codechallenge_cluster_the_x_terms.md) | [Xem bÃ i viáº¿t â†’](aero_llm_08_codechallenge_cluster_the_x_terms.md) |
| [PhÃ¢n RÃ£ Token, NhÃºng VÃ  PhÃ¢n Cá»¥m Biá»ƒu TÆ°á»£ng Emojis Báº±ng Äá»“ Thá»‹ Máº­t Äá»™](aero_llm_09_codechallenge_tokenize_embed_and_cluster_happy_emojis.md) | [Xem bÃ i viáº¿t â†’](aero_llm_09_codechallenge_tokenize_embed_and_cluster_happy_emojis.md) |
| [PhÃ¢n TÃ­ch RSA (Representational Similarity Analysis) Giá»¯a CÃ¡c MÃ´ HÃ¬nh NgÃ´n Ngá»¯](aero_llm_10_rsa_representational_similarity_analysis_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_10_rsa_representational_similarity_analysis_.md) |
| [PhÃ¢n TÃ­ch Äá»™ Lá»‡ch RSA (Part 1): So SÃ¡nh Sá»± Báº¥t Äá»“ng Giá»¯a KhÃ´ng Gian GloVe 50D vÃ  300D](aero_llm_11_codechallenge_compare_embeddings_with_rsa_part_1_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_11_codechallenge_compare_embeddings_with_rsa_part_1_.md) |
| [PhÃ¢n TÃ­ch Äá»™ Lá»‡ch RSA (Part 2): Äá»‘i Chiáº¿u TÆ°Æ¡ng Quan Pearson Cho Khoáº£ng CÃ¡ch Cosine](aero_llm_12_codechallenge_compare_embeddings_with_rsa_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_12_codechallenge_compare_embeddings_with_rsa_part_2_.md) |
| [So SÃ¡nh KhÃ´ng Gian NhÃºng: Word2Vec VÃ  GPT-2 Qua PhÃ¢n TÃ­ch RSA](aero_llm_13_codechallenge_word2vec_vs_gpt2.md) | [Xem bÃ i viáº¿t â†’](aero_llm_13_codechallenge_word2vec_vs_gpt2.md) |
| [Bá»‘ Cá»¥c Äá»“ Thá»‹ Máº¡ng (Network Graph) ThÃ´ng Qua Ma Tráº­n Cosine Similarity](aero_llm_14_codechallenge_graph_representation_of_cosine_similarities.md) | [Xem bÃ i viáº¿t â†’](aero_llm_14_codechallenge_graph_representation_of_cosine_similarities.md) |
| [Sá»‘ Há»c Tuyáº¿n TÃ­nh vÃ  RÃºt TrÃ­ch TÆ°Æ¡ng Äá»“ng Giá»¯a CÃ¡c Tá»« NhÃºng (Word Embeddings Analogies)](aero_llm_15_embeddings_arithmetic_and_analogies.md) | [Xem bÃ i viáº¿t â†’](aero_llm_15_embeddings_arithmetic_and_analogies.md) |
| [Vá»¡ Má»™ng Vá» Sá»‘ Há»c Vector TÆ°Æ¡ng ÄÆ°Æ¡ng (Soft-Coded Analogies) TrÃªn Word2Vec](aero_llm_16_codechallenge_soft_coded_analogies_in_word2vec.md) | [Xem bÃ i viáº¿t â†’](aero_llm_16_codechallenge_soft_coded_analogies_in_word2vec.md) |
| [Thiáº¿t Láº­p VÃ  Diá»…n Giáº£i Trá»¥c Ngá»¯ NghÄ©a Tuyáº¿n TÃ­nh (Linear Semantic Axes)](aero_llm_17_creating_and_interpreting_linear_semantic_axes.md) | [Xem bÃ i viáº¿t â†’](aero_llm_17_creating_and_interpreting_linear_semantic_axes.md) |
| [Khai ThÃ¡c Thuáº­t ToÃ¡n k-NN Cho TÃ¬m Kiáº¿m Tá»« Äá»“ng NghÄ©a TrÃªn BERT](aero_llm_18_knn_for_synonym_searching_in_bert.md) | [Xem bÃ i viáº¿t â†’](aero_llm_18_knn_for_synonym_searching_in_bert.md) |
| [Cáº¡nh Tranh TÃ¬m Tá»« Äá»“ng NghÄ©a BERT vs GPT: CÆ¡ Cháº¿ Tokenization Äa KÃ½ Tá»±](aero_llm_19_codechallenge_bert_v_gpt_knn_kompetition.md) | [Xem bÃ i viáº¿t â†’](aero_llm_19_codechallenge_bert_v_gpt_knn_kompetition.md) |
| [Sá»± Dá»‹ch Chuyá»ƒn VÃ  Äá»“ng Tá»“n Biá»ƒu Diá»…n Giá»¯a CÃ¡c KhÃ´ng Gian NhÃºng](aero_llm_20_research_on_translating_embeddings_spaces.md) | [Xem bÃ i viáº¿t â†’](aero_llm_20_research_on_translating_embeddings_spaces.md) |
| [PhÃ¢n TÃ­ch ChÃ¹m Quang Phá»• Suy Biáº¿n (Singular Value Spectrum) Cá»§a KhÃ´ng Gian NhÃºng](aero_llm_21_singular_value_spectrum_of_embeddings_submatrices.md) | [Xem bÃ i viáº¿t â†’](aero_llm_21_singular_value_spectrum_of_embeddings_submatrices.md) |
| [Ãnh Xáº¡ SVD CÃ¡c Dáº£i Äiá»ƒm NhÃºng CÃ³ Quan Há»‡ ChÃ©o](aero_llm_22_codechallenge_svd_projections_of_related_embeddings.md) | [Xem bÃ i viáº¿t â†’](aero_llm_22_codechallenge_svd_projections_of_related_embeddings.md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
