WEBVTT

00:02.120 --> 00:09.640
There are two concepts that you are going to learn in this video activation patching and the indirect

00:09.640 --> 00:15.160
object identification task, which is often abbreviated to I, o.

00:16.560 --> 00:18.000
And actually activation.

00:18.000 --> 00:23.400
Patching is just another term for editing the internal activations.

00:23.400 --> 00:26.880
So there's really only one concept to learn in this video.

00:27.720 --> 00:36.440
The I o test is often used to study language models, and it basically just assesses the model's ability

00:36.440 --> 00:41.080
to understand grammar and in particular, indirect objects.

00:41.720 --> 00:45.280
Let me start by telling you about activation patching.

00:46.040 --> 00:51.560
So imagine you have some language model that is processing a text sequence.

00:52.080 --> 00:53.600
And that's what I'm depicting here.

00:53.680 --> 01:00.780
So we have text sequence A and I'm using this one letter to refer to a whole sequence of tokens, like

01:00.860 --> 01:01.820
a whole sentence.

01:02.380 --> 01:09.780
And here I'm just depicting the embeddings vectors traversing from one transformer block to the next

01:09.780 --> 01:12.620
and being slightly modified at each step.

01:13.020 --> 01:13.460
Okay.

01:13.860 --> 01:14.660
All fine.

01:14.820 --> 01:21.980
Now imagine we have exactly the same model, but processing a slightly different token sequence.

01:22.260 --> 01:26.380
Maybe A and B are the same sentence, but they differ by one word.

01:26.980 --> 01:33.820
So that means that the embeddings vectors from this sequence will be at least a little bit different.

01:34.620 --> 01:43.940
Okay, so now the idea of activation patching is to transplant the activations from this sequence onto

01:44.060 --> 01:45.340
this sequence.

01:45.980 --> 01:51.420
So we take the actual activations from one block, let's say transformer block T plus one.

01:51.820 --> 01:59.600
And we literally just copy those activation vectors and paste them onto the output of transformer block

01:59.640 --> 02:01.360
T plus one over here.

02:02.520 --> 02:09.200
In practice, this is generally done only for one key token that carries a lot of information.

02:09.800 --> 02:17.480
So now going forwards we have what is sometimes called the corrupted information for this model by patching

02:17.480 --> 02:23.920
in the activations from a different model or well it's the same model but processing a different token

02:23.920 --> 02:24.680
sequence.

02:25.680 --> 02:32.280
So on the one hand this is literally just editing the activations, just like lots of other examples

02:32.280 --> 02:35.720
and techniques that you are learning about in this section.

02:36.360 --> 02:44.560
But the reason why they call this patching is because you are taking like a patch of activations from

02:44.560 --> 02:48.800
one token sequence and transplanting it into another.

02:49.320 --> 02:54.480
You could also think of this as like the donor model and the recipient model.

02:55.960 --> 02:59.660
Here is another diagram that illustrates this concept.

02:59.660 --> 03:03.020
So there's a lot of stuff going on in this whole figure.

03:03.180 --> 03:03.820
That's fine.

03:03.820 --> 03:08.620
I just want to draw your attention up to here to this depiction here.

03:08.940 --> 03:16.260
So the idea is that you take the activations from processing one token from one model, and you implant

03:16.260 --> 03:23.100
it into the same position when the model is processing a slightly different sequence of tokens.

03:23.940 --> 03:31.580
And it turns out that depending on exactly where you perform this patching, you might observe no impact

03:31.580 --> 03:35.660
or a really significant impact on the final output.

03:35.660 --> 03:37.100
Logits of the model.

03:37.940 --> 03:43.460
Okay, so you are going to see exactly how this works in in code in a few minutes.

03:43.700 --> 03:48.020
But first let me switch to explaining the IOI task.

03:48.900 --> 03:55.560
So an indirect object refers to a noun that receives the direct object from the subject.

03:56.000 --> 04:00.960
If you're not so familiar with English grammar, or maybe it's been several years since you studied

04:00.960 --> 04:04.960
all these grammar terms, then that definition might sound really abstract.

04:04.960 --> 04:06.000
Here's an example.

04:06.480 --> 04:08.880
Bob and Barbara went to the beach.

04:09.160 --> 04:12.040
Bob gave the umbrella to her.

04:13.040 --> 04:22.440
So in this sentence, Bob is the subject, the umbrella is the direct object, and Barbara is the indirect

04:22.440 --> 04:23.120
object.

04:23.720 --> 04:30.360
And you know from context that the pronoun her here refers to Barbara.

04:30.840 --> 04:37.440
In fact, if I would even drop the word her altogether and just stop the sentence with two, you would

04:37.440 --> 04:41.240
still be able to predict what the most likely next word was.

04:41.240 --> 04:48.600
It would be either Barbara or her, and the fact that you can identify the indirect object from the

04:48.600 --> 04:56.010
context of these two sentences is exactly the indirect object identification task.

04:56.770 --> 05:03.810
And when we run this test through the model, then the idea is that we grab the final output logits

05:04.010 --> 05:10.730
and literally just subtract the logits for Barbara versus Bob or her versus him.

05:10.730 --> 05:14.930
There's a couple of different ways you can set it up, but that's the basic idea.

05:15.090 --> 05:23.250
So, uh, in an experiment, we craft a sentence such that the indirect object is the final word, like

05:23.290 --> 05:24.650
in this example here.

05:25.890 --> 05:32.730
Then we drop the indirect object, run a forward pass, and then we calculate this delta value here

05:32.730 --> 05:36.530
for the two possibilities of indirect objects.

05:36.650 --> 05:40.570
So for example her minus him or maybe Bob minus Barbara.

05:41.210 --> 05:43.690
So this is the basic version of the task.

05:43.890 --> 05:52.510
And what I will show you in the code demo is how to measure changes in this task performance metric

05:52.510 --> 05:55.750
when we patch different parts of the model.

05:56.870 --> 06:02.870
So the purpose of this video is to introduce you to setting up the experiment and how patching works.

06:03.270 --> 06:10.230
And then we will return to this experiment in the next section of the course when we start manipulating

06:10.230 --> 06:12.150
individual attention heads.

06:12.910 --> 06:17.110
I'm going to work with GPT two XL here.

06:17.390 --> 06:25.350
And I'll put it on the GPU because the text sequence is short, but we do process it once per transformer

06:25.350 --> 06:29.230
block, which means we need to do 48 forward passes.

06:30.350 --> 06:33.310
So here is the token sequence.

06:33.310 --> 06:35.030
Here's the text that we will use.

06:35.270 --> 06:43.070
So in an I o test you always have a pair of sentences that you have the subject and indirect objects

06:43.070 --> 06:43.750
swapped.

06:44.190 --> 06:45.830
And why do we want them swapped.

06:46.070 --> 06:52.650
Well the idea is that we grab the internal activations Deviations from this token here for Mike, and

06:52.650 --> 06:59.570
then patch that onto this sentence in the same token index position in place of Emma.

07:00.450 --> 07:07.410
And the thing is that in this second sentence, the correct token after two would really be Mike.

07:07.770 --> 07:15.450
However, if we take the activations for this word Mike over here and patch that onto the second sentence,

07:15.690 --> 07:22.730
and then maybe the model will start preferring the token for Emma at the end of this sequence.

07:23.290 --> 07:25.450
So that's the idea of this manipulation.

07:25.890 --> 07:32.370
Before getting there, we can calculate the IOI on clean versions of the model, which means no patching,

07:32.570 --> 07:33.810
no manipulations.

07:34.250 --> 07:41.930
Here you can see I'm calculating the logit differences of the final tokens for these two target words.

07:42.370 --> 07:46.930
Now in the first sentence the correct token is the word Emma.

07:47.490 --> 07:53.390
So the token logit for Emma should have a higher logit value than Mike.

07:53.510 --> 07:59.550
And you see that indeed, the IOI value there is -3.3.

07:59.590 --> 08:03.510
And then when we swap the order, the model should prefer Mike over Emma.

08:03.710 --> 08:08.230
And there we see a positive IOI value of 2.1.

08:08.790 --> 08:16.550
So these values are our clean estimates of the model's understanding of grammar and indirect objects.

08:17.150 --> 08:19.830
Now we are ready for the experiment.

08:19.950 --> 08:24.630
Here you see a for loop over all of the layers in the model.

08:25.030 --> 08:32.870
Now so far in this section of the course I have separated defining and implanting the hook function

08:33.190 --> 08:36.270
from the rest of the code to test the manipulation.

08:36.710 --> 08:40.110
But now here I'm setting it up slightly differently.

08:40.510 --> 08:48.890
So here I'm creating the hook function, implanting it, and then removing it all at each iteration

08:48.890 --> 08:50.490
within this for loop.

08:50.930 --> 08:57.930
So these hook functions only go into the model exactly when we need them, and then they are immediately

08:57.930 --> 09:00.650
obliterated after we no longer need them.

09:01.290 --> 09:03.970
And what is happening inside this for loop.

09:04.370 --> 09:07.410
Well here you can see I'm running a forward pass.

09:07.410 --> 09:13.730
This is a forward pass for the M tokens, which means Emma gave the coffee to Mike.

09:14.370 --> 09:19.770
So the correct token to predict here at the end of this sequence is Mike.

09:20.490 --> 09:23.330
And then I'm grabbing the hidden states here.

09:23.810 --> 09:26.970
So the outputs of the transformer blocks.

09:27.570 --> 09:32.290
Now this code is exactly the same for every layer of the model.

09:32.570 --> 09:36.730
And what differs for each layer is the hook function up here.

09:37.250 --> 09:44.770
So here you can see I'm implanting the hook into the entire transformer block, so that when I grab

09:44.770 --> 09:46.710
the hidden states up here.

09:46.710 --> 09:49.710
That is the output of the transformer block.

09:49.710 --> 09:56.310
And that's exactly the same as the hidden states that I am grabbing in the forward pass down here on

09:56.310 --> 09:57.110
this line.

09:57.230 --> 10:00.470
And also what I got earlier from the clean run.

10:00.830 --> 10:08.870
And then here on this line of code, I am replacing the final token and all of the embeddings vectors

10:09.070 --> 10:12.230
with the hidden states from layer I plus one.

10:12.470 --> 10:16.430
And then also the final token and all the embeddings vectors.

10:16.790 --> 10:23.750
Now these hidden states were taken from the me text, which means Mike gave the coffee to Emma.

10:24.030 --> 10:28.230
So Emma is the correct output in this token sequence.

10:28.990 --> 10:31.470
So that is the line that does the patching.

10:31.470 --> 10:39.150
I'm taking the activations from the donor model and transplanting them onto the activations in the recipient

10:39.150 --> 10:39.750
model.

10:40.270 --> 10:41.830
Now here's a question for you.

10:42.190 --> 10:50.530
Why am I looping over layer I up here but I write I plus one over here for this index.

10:50.970 --> 10:52.450
Something for you to think about.

10:52.490 --> 10:58.610
And when I discuss and when I switch to code, I will explain why that plus one is there anyway.

10:58.650 --> 11:01.050
So that's the main part of this for loop.

11:01.330 --> 11:06.530
There's a couple of additional lines down here that I didn't put into the screenshot, but that just

11:06.530 --> 11:10.370
calculates the IOI metric as I showed a moment ago.

11:10.930 --> 11:18.010
So this means that we will have an IOI measure for each of the layers that we patch.

11:18.410 --> 11:20.450
And then we can visualize them like this.

11:20.450 --> 11:23.490
So the x axis is the transformer block.

11:23.850 --> 11:31.370
The y axis is the logit difference which is just the difference in the output logits for the token for

11:31.410 --> 11:39.210
Mike versus the token for Emma, I set up the subtraction such that mike is associated with positive

11:39.210 --> 11:42.970
numbers, and Emma corresponds to negative numbers.

11:43.670 --> 11:50.350
The blue horizontal line and the red horizontal line are reference values from the clean version of

11:50.350 --> 11:51.190
the text.

11:51.190 --> 11:52.950
So no manipulations.

11:53.350 --> 12:00.950
And of course the purple circles show the IOI values after patching each of the transformer blocks.

12:01.590 --> 12:08.070
It's pretty striking that you see this really strong and fairly sudden phase transition somewhere around

12:08.070 --> 12:14.790
halfway through the model from basically, you know, ignoring the patched information and still preferring

12:14.790 --> 12:21.830
the correct token, the contextually correct token to being strongly impacted by the corrupting patch

12:21.950 --> 12:29.430
and preferring the token that is actually incorrect in this text sequence, but was correct from the

12:29.470 --> 12:30.710
donor sequence.

12:31.310 --> 12:37.310
So this is a pretty typical finding for the IOI task, and you get the same effect with the smaller

12:37.310 --> 12:39.110
versions of the model as well.

12:39.110 --> 12:41.270
So smaller versions of GPT two.

12:42.410 --> 12:48.050
I'm not actually demonstrating that here in this code demo, but very easy for you to explore.

12:48.650 --> 12:55.570
Anyway, there's more to discuss, so let's now switch to code some libraries.

12:55.570 --> 12:59.290
Here I am importing GPT two XL.

12:59.610 --> 13:00.650
If you are curious.

13:00.650 --> 13:07.050
I certainly encourage you to try different versions of the model and so on, but you can do that after

13:07.050 --> 13:07.690
the lecture.

13:07.970 --> 13:11.370
I will stick to the XL version for now.

13:11.770 --> 13:16.210
And here I'm defining this variable and layers is yeah, the number of layers.

13:16.490 --> 13:21.770
And just as a reminder we have 48 transformer blocks in this model.

13:21.770 --> 13:27.770
This is convenient because we really want to see this sudden phase shift, this sudden transition in

13:27.810 --> 13:28.570
the model.

13:28.570 --> 13:33.650
So it's nice to have a higher resolution to for the plotting.

13:34.170 --> 13:34.450
Okay.

13:34.490 --> 13:35.330
So here are the text.

13:35.370 --> 13:43.940
The way I have organized these variables is that M means Mike gave the coffee to Emma and M means Emma

13:43.980 --> 13:45.380
gave the coffee to.

13:45.780 --> 13:51.540
Well, it's not actually here, but of course you know what should come here is either the word her

13:51.580 --> 13:52.620
or the word Emma.

13:52.660 --> 13:56.820
That would be the most appropriate given the rest of this context.

13:57.980 --> 13:58.300
Okay.

13:58.340 --> 14:02.620
Here are the token indices for SpaceX, Mike and SpaceX.

14:02.620 --> 14:02.900
Emma.

14:02.940 --> 14:08.620
Of course we need the space in here because we do not expect the model to make this prediction.

14:08.620 --> 14:12.460
We expect the model to make this prediction also.

14:12.460 --> 14:18.220
By the way, I'm not going to demonstrate this here, but if you would like you could also try rerunning

14:18.380 --> 14:18.860
the code.

14:18.900 --> 14:20.220
Oops, that should be her.

14:20.220 --> 14:21.060
And that should be him.

14:21.300 --> 14:25.740
Uh, using these target tokens instead of the proper names.

14:25.740 --> 14:28.540
And so yeah, that's also pretty interesting to run.

14:28.700 --> 14:33.540
I won't tell you what you'll find, but you probably won't be surprised at the results.

14:33.980 --> 14:34.300
Okay.

14:34.340 --> 14:42.040
So then here I tokenize the text, uh, transform it into PyTorch tensors and push it to the GPU.

14:42.560 --> 14:47.800
Here I'm getting the clean versions of the output the hidden states.

14:48.120 --> 14:52.760
And as you know, these will be our baseline comparison values.

14:53.320 --> 15:02.960
Okay, so uh, it is so one of these hidden states is one for one sequence 14 tokens, 1600 is the embeddings

15:02.960 --> 15:06.440
dimensionality of GPT two XL.

15:06.800 --> 15:14.200
And so here is where I'm calculating the main dependent variable the metric I'm calling it logit diff.

15:15.240 --> 15:18.880
So remember me is Mike gave the coffee to Emma.

15:19.200 --> 15:25.680
So here we would expect that the model should have a prediction for the token after the final token

15:25.680 --> 15:27.800
in the sequence of Emma.

15:28.120 --> 15:35.960
Therefore, this token this logit value should be larger and this one should be relatively smaller.

15:36.120 --> 15:38.700
So here we expect a negative value.

15:38.980 --> 15:45.900
And when the sequence the text sequence is Emma gave the coffee to blank, then we expect blank to be

15:45.900 --> 15:46.340
Mike.

15:46.620 --> 15:50.260
And so therefore this value should be larger than this logit.

15:50.260 --> 15:53.060
And so this result should be positive.

15:53.180 --> 15:55.580
And that is what we see here.

15:56.020 --> 15:56.340
Okay.

15:56.380 --> 15:59.700
So now we are ready for running the analysis.

15:59.820 --> 16:04.420
I also have this variable here that I call confirm manipulation.

16:04.420 --> 16:05.780
This is just a variable.

16:05.780 --> 16:12.820
And a quick analysis that I incorporated into this code as a way to confirm the manipulation.

16:12.860 --> 16:18.300
Of course, just a bit of a sanity check to make sure that what we are, what we think we're manipulating,

16:18.300 --> 16:19.740
we are really manipulating.

16:19.780 --> 16:21.460
Okay, I'll explain this in a moment.

16:21.860 --> 16:30.020
So here, looping over layers, here is the patch where I grab the output of the transformer block.

16:30.420 --> 16:33.020
And then I replace that output.

16:33.020 --> 16:34.140
But not all of it.

16:34.140 --> 16:44.000
Only the final token in the sequence, with the corresponding final token in the sequence from the model,

16:44.160 --> 16:44.760
and then.

16:45.040 --> 16:50.160
This is relevant because here, when I run the forward pass through the model, I'm pushing through

16:50.160 --> 16:51.480
the token sequence.

16:51.720 --> 16:56.880
Emma gave the coffee to Mike and here it's Mike gave the coffee to Emma.

16:57.080 --> 17:05.080
So the idea is we are seeing if we can corrupt the model's prediction for the token after the last token

17:05.400 --> 17:12.720
by giving it incorrect information or transplanted information that it was actually Mike who gave the

17:12.720 --> 17:15.160
coffee, and not Emma who gave the coffee.

17:16.360 --> 17:19.040
Okay, so why do we have layer I plus one?

17:19.440 --> 17:25.360
I think I've asked you this multiple times before in the course, but it is a subtle but important point,

17:25.360 --> 17:26.920
which is why I keep repeating it.

17:27.240 --> 17:33.160
The hidden states that you get out of these models when you say output hidden states equals true.

17:33.640 --> 17:42.100
The first index corresponds to the embeddings layer, and index one corresponds to the first transformer

17:42.100 --> 17:42.740
block.

17:42.980 --> 17:48.220
On the other hand, the first transformer block here has index zero.

17:48.420 --> 17:51.740
So if you want these to match, you have to add one over here.

17:52.220 --> 17:52.620
Okay.

17:52.980 --> 17:53.780
Straightforward enough.

17:53.780 --> 17:58.460
So here I implant the hook I get a handle because I want to remove it over here.

17:58.740 --> 18:03.300
And then I do the forward pass and just grab the hidden states over here.

18:04.260 --> 18:08.020
And here I'm calculating the IOI score.

18:08.220 --> 18:10.420
So it's the output logits for M.

18:10.460 --> 18:13.140
That is the token sequence that I pushed through.

18:13.460 --> 18:20.140
And then for the logit for the token MC and the logit for the token Emma.

18:20.500 --> 18:22.300
Now what do we expect here.

18:22.460 --> 18:29.740
Well if the manipulation here, if this manipulation has no impact whatsoever, it doesn't do anything

18:29.780 --> 18:37.880
to the model, then we expect that this model with this token sequence predicts that Mike should be

18:37.880 --> 18:42.240
the proper the appropriate token after the end of the sequence.

18:42.360 --> 18:46.960
So therefore, we expect this difference to be positive and large.

18:46.960 --> 18:48.280
So larger than zero.

18:48.800 --> 18:54.640
On the other hand, if the model gets totally confused and the model starts thinking that it's actually

18:54.640 --> 19:01.600
Mike who gave the coffee to, and then the token to predict after two should be Emma.

19:02.080 --> 19:08.680
If that is the case, then this logit should be large and this one should be small, in which case we

19:08.680 --> 19:10.720
would expect a negative value.

19:10.800 --> 19:15.280
So positive values would mean the manipulation didn't work.

19:15.280 --> 19:18.640
And negative values means that the manipulation did work.

19:19.120 --> 19:19.480
Okay.

19:19.520 --> 19:25.800
And then the final thing for me to explain here is this sanity check here this confirm manipulation.

19:26.000 --> 19:32.660
So what I am doing here is grabbing the hidden states from M and subtracting that from the hidden states

19:32.660 --> 19:33.540
from me.

19:34.060 --> 19:35.420
And it's the same layer.

19:35.420 --> 19:38.260
I just picked this one dimension at random.

19:38.260 --> 19:41.060
It doesn't really matter, we just want any one dimension.

19:41.220 --> 19:42.820
And I'm getting these.

19:42.900 --> 19:49.260
I'm doing this subtraction twice for the final token and for the penultimate token.

19:49.540 --> 19:50.820
And why am I doing this?

19:50.820 --> 19:53.340
And what do we expect these values to be?

19:53.900 --> 20:01.340
Well, uh, remember that what we're doing up here in the hook is replacing the hidden states from the

20:01.380 --> 20:04.300
donor model only for the final token.

20:04.300 --> 20:10.380
So if this really works, if this code really works, this is not about the experiment or like how language

20:10.380 --> 20:11.820
models process grammar.

20:11.860 --> 20:16.820
This is really just about making sure that this code does what I want it to do.

20:17.220 --> 20:22.980
Okay, so if the code really works, if the hook works, then these two should be the same, right?

20:22.980 --> 20:29.260
Because I took these, uh, activations and plugged them into these activations.

20:29.320 --> 20:30.800
So this should be zero.

20:31.240 --> 20:37.280
On the other hand, what I did not do in the hook function is manipulate any other token.

20:37.520 --> 20:45.040
So therefore exactly the same difference should be non-zero because yeah, why would you expect these

20:45.040 --> 20:46.000
to be the same.

20:46.200 --> 20:47.320
They are different tokens.

20:47.320 --> 20:48.680
They come from different models.

20:48.680 --> 20:52.680
They're processing slightly different versions of the text sequence.

20:52.800 --> 20:55.600
And I didn't include this token in the hook.

20:55.920 --> 20:56.240
Okay.

20:56.280 --> 21:00.920
So basically I expect these to be zero and these to be non-zero.

21:01.640 --> 21:01.960
Okay.

21:02.000 --> 21:03.320
So now we can run this.

21:03.680 --> 21:08.160
I don't know how long this takes on the CPU, but it's one second on the GPU.

21:08.240 --> 21:09.400
So pretty good.

21:10.440 --> 21:12.040
Here's our sanity check.

21:12.200 --> 21:13.640
All of these are zeros.

21:13.680 --> 21:15.240
All of these are non-zero.

21:15.360 --> 21:17.760
And when we get to the end, huh?

21:18.120 --> 21:21.160
We get one non-zero value here.

21:21.360 --> 21:22.840
What is going on there?

21:22.880 --> 21:30.330
If you would like to pause the video and think about why this confirmation check worked for every single

21:30.330 --> 21:34.010
layer except for the very, very last transformer block.

21:34.410 --> 21:38.730
Feel free to pause the video to give it some time to think about it.

21:39.370 --> 21:45.850
This is related to, uh, something a feature of the way that hugging face models work.

21:46.210 --> 21:49.370
And in particular, this output, hidden states equals true.

21:49.770 --> 21:54.530
What is actually being returned when you set this toggle to be true?

21:54.810 --> 21:58.090
I discussed this a bit earlier in the course.

21:58.130 --> 22:04.810
I think it was in the beginning of the section on observational mechanistic interpretability.

22:05.050 --> 22:12.250
When I introduced you to working with hook functions and the relationship between hooks and output hidden

22:12.250 --> 22:12.730
states.

22:12.770 --> 22:17.130
Anyway, the point is, let me go back up to this model architecture up here.

22:17.570 --> 22:26.370
So the point is that the output of the hidden states is exactly the output of H or the transformer blocks

22:26.510 --> 22:31.110
for every transformer block except for the very, very last one.

22:31.350 --> 22:36.150
That last one also includes the layer norm over here.

22:36.550 --> 22:38.030
And so what does that mean?

22:38.190 --> 22:45.630
That means that all of this works exactly as intended for all of the transformer blocks, except for

22:45.630 --> 22:47.950
the very last one and the very last one.

22:47.950 --> 22:55.590
There is this kind of additional layer normalization that gets imposed on this model, because it's

22:55.590 --> 22:57.990
already in this model from the hidden states.

22:58.990 --> 23:02.870
That probably is a little bit suboptimal, but it's not so bad.

23:02.870 --> 23:07.790
It only impacts the very, very last layer in this for loop.

23:08.150 --> 23:15.990
Probably a slightly better idea would be instead of getting these hidden states vectors from the output

23:16.030 --> 23:23.630
hidden states, you could implant another hook and that would just read out the output of the transformer

23:23.630 --> 23:27.170
blocks Uh, without the layer norm at the end.

23:27.210 --> 23:29.050
Anyway, it's a minor point.

23:29.130 --> 23:33.010
Uh, it's important that you know about it, but I'm going to ignore it for now.

23:33.450 --> 23:33.770
Okay.

23:33.810 --> 23:42.130
And then, yeah, I'm just plotting all of these logit differences and showing those, as I showed in

23:42.130 --> 23:43.290
the slides.

23:43.330 --> 23:49.330
So yeah, again, this final point here is slightly awkward to interpret because it gets like double

23:49.370 --> 23:50.010
layered norm.

23:50.330 --> 23:51.090
But it's okay.

23:51.290 --> 23:57.650
Uh, that certainly doesn't break the overall pattern or the interpretation of this result.

23:57.650 --> 23:58.450
Quite striking.

23:58.450 --> 24:04.970
The model went from really preferring MC exactly as it did in the clean version, which means that when

24:04.970 --> 24:11.970
we transplanted from the donor sequence to the recipient sequence, it had basically no impact on the

24:11.970 --> 24:13.890
model's token prediction.

24:13.890 --> 24:21.650
And yet the later into the model we pushed it, the more we have corrupted the model's endogenous processing

24:21.650 --> 24:29.470
so that it starts to prefer what is incorrect in what the token sequence should be, but yet we've corrupted

24:29.470 --> 24:34.310
it by giving it a patched activation from the other token sequence.

24:35.830 --> 24:43.190
I hope you agree that this was a pretty cool lecture, and a really neat demo of when grammatical structure

24:43.230 --> 24:45.430
gets extracted in the model.

24:46.230 --> 24:52.630
On the one hand, copying over all of the embeddings vectors at the output of a transformer is a rather

24:52.630 --> 24:58.030
coarse manipulation, in that it's like bringing a sledgehammer to the experiment.

24:58.670 --> 25:05.670
The neat thing about this task is that it's quite versatile and amenable to lots of other, more targeted

25:05.670 --> 25:07.630
and more precise manipulations.

25:08.110 --> 25:15.150
For example, in the next section on manipulating the attention heads and the attention mechanism,

25:15.470 --> 25:21.310
you will see this task again, and we're going to do much more subtle and precise manipulations.
