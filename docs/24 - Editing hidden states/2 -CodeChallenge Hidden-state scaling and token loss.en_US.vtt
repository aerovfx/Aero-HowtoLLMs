WEBVTT

00:02.200 --> 00:04.560
And now for a code challenge.

00:05.120 --> 00:12.320
Here we will follow up on what you have learned so far, while focusing more on the impact of editing

00:12.320 --> 00:20.520
the hidden states on the model's output in terms of token selection and log softmax values of a target

00:20.560 --> 00:21.240
token.

00:21.800 --> 00:28.080
You're also going to get a nice little reminder of how to calculate the loss per token.

00:29.120 --> 00:37.120
The goal of exercise one is to set up the model and the experiment with some tokens and some baseline

00:37.320 --> 00:38.440
activations.

00:38.960 --> 00:46.280
So import the GPT two model and we will work with the medium size in this code challenge.

00:46.720 --> 00:49.400
We won't be doing that many forward passes.

00:49.400 --> 00:52.240
So I actually ran this whole thing on the CPU.

00:52.800 --> 00:57.080
Of course you can put the model and the tokens on the GPU if you like.

00:57.680 --> 01:05.050
Next, create a hook function that is similar to the function that I showed in the code demo in the

01:05.050 --> 01:13.970
previous video, except this one here can be implanted into all of the layers, and the idea is that

01:13.970 --> 01:21.730
you get to specify dynamically during the experiment which layer you want to scale, and by how much.

01:22.290 --> 01:28.930
So you have seen code that allows you to pick one layer to manipulate before in the previous section.

01:30.010 --> 01:37.610
The idea of running the code here is that you create a dictionary called scaling, fact dict, or whatever

01:37.610 --> 01:38.890
else you would like to call it.

01:39.290 --> 01:46.170
Anyway, the keys in this dictionary would be the layer number, and the value associated with that

01:46.170 --> 01:53.730
key is also a number, and that indicates how much to scale the vectors in that layer.

01:54.370 --> 02:00.350
So for example, if we would use this in the previous demo if we set up the previous demo like this.

02:00.790 --> 02:07.030
Then the key would be the number two, and the value of that key would be the number 0.5.

02:07.790 --> 02:14.830
Remember that because we are working with the hidden states here, you don't need to extract the activations

02:14.830 --> 02:19.710
inside this hook because we can get them in the forward pass from setting output.

02:19.710 --> 02:21.270
Hidden states equals true.

02:22.150 --> 02:29.430
Once you have this hook set up, you can tokenize this quote from Einstein except the final word.

02:29.910 --> 02:31.550
In other words, tokenize.

02:31.550 --> 02:33.030
I have no special talents.

02:33.030 --> 02:40.630
I am only passionately and basically what we are going to do in the rest of this code challenge is examine

02:40.670 --> 02:48.350
the final model logits for the word passionately to see if the model can correctly predict that the

02:48.350 --> 02:50.430
next word should be curious.

02:51.710 --> 02:58.840
Okay, the last thing to do for exercise one is to run a forward pass with no scaling on any of the

02:58.840 --> 03:06.440
transformer outputs, so that you have a baseline version of the hidden states that we can use for comparison

03:06.440 --> 03:08.520
in later exercises.

03:09.600 --> 03:12.480
Now you can pause the video and work through this exercise.

03:12.640 --> 03:18.440
I don't think you will find it too challenging, considering that almost everything you need to do here,

03:18.440 --> 03:21.720
we've already done in the last several videos.

03:22.200 --> 03:25.800
Anyway, now I will switch to code and discuss my solution.

03:27.440 --> 03:29.400
Import lots of libraries and so on.

03:29.400 --> 03:34.640
Here I'm importing GPT two medium and also the tokenizer.

03:34.640 --> 03:40.280
It doesn't actually matter if you do it with medium or just the GPT two small.

03:40.320 --> 03:46.240
All of the GPT two tokenizers are the same, regardless of whether you use the small, medium, large,

03:46.240 --> 03:47.520
or xlarge version.

03:47.720 --> 03:52.880
Anyway, so while that is loading in, I can discuss the solution to this hook.

03:53.160 --> 04:00.980
Okay, so here this code is all the same as what you saw in the code file in the previous video.

04:01.180 --> 04:02.740
There's only two changes.

04:02.740 --> 04:11.700
One is here that I get the scaling factor not from a variable, but from a value in this dictionary

04:11.900 --> 04:13.660
associated with the key.

04:14.020 --> 04:15.540
For layer number.

04:15.980 --> 04:22.940
And then the second difference compared to the previous code demo is that I have this if statement here,

04:22.940 --> 04:27.820
where I say if the layer number is in this in the keys here.

04:28.140 --> 04:36.100
And the reason why this is useful is that we do not want to scale all of the hidden states vectors for

04:36.100 --> 04:37.260
every single layer.

04:37.260 --> 04:39.020
That's what would happen if you did this.

04:39.140 --> 04:41.180
This would impact every single layer.

04:42.180 --> 04:49.940
Instead, what we want to do is only modify the one layer that this hook is implanted in, only if it

04:49.940 --> 04:52.980
has a corresponding key in this dictionary.

04:53.420 --> 04:59.150
And when this is false, then of course all of this is skipped and then the output is exactly the same

04:59.150 --> 05:00.310
as the output here.

05:01.070 --> 05:01.430
Okay.

05:01.470 --> 05:08.790
So now we can run this and implant this hook into all of the hidden modules.

05:08.790 --> 05:10.230
All of the hidden layers.

05:10.430 --> 05:12.070
Okay I have no special talent.

05:12.070 --> 05:15.110
I'm only passionately blank okay.

05:15.150 --> 05:19.350
And then we want to know what is the model going to predict.

05:20.030 --> 05:22.590
Now we know that the correct answer is curious.

05:22.590 --> 05:29.150
But there is another possible set of outcomes here, which is that the model gives a different word

05:29.350 --> 05:32.430
that is not curious, but a word that also makes sense.

05:32.430 --> 05:34.950
For example, I have no special talent.

05:34.950 --> 05:38.150
I am only passionately interested, for example.

05:38.630 --> 05:42.510
Okay, anyway, here is the target token index.

05:42.670 --> 05:50.110
So what we are going to look for is the model's loss on this particular token 11,040 okay.

05:50.150 --> 05:58.120
And then the last thing for exercise one is to run the model once with the tokens with no scaling factors

05:58.120 --> 05:58.800
applied.

05:58.800 --> 06:01.160
And here I call this pure logits.

06:01.200 --> 06:02.200
That's the variable name.

06:02.200 --> 06:11.080
That's the logits for this outcome here, the goal of exercise two is to scale one layer and examine

06:11.080 --> 06:14.120
the impact on the final output logits.

06:14.480 --> 06:22.920
So change the dictionary that the hook function reads to scale transformer layer two by a factor of

06:22.920 --> 06:24.080
0.6.

06:24.760 --> 06:31.320
Then you want to do a forward pass again with the same Einstein quote, and you get the output logits.

06:31.320 --> 06:37.080
From that, you can make a scatter plot of the logits for all the vocab elements.

06:37.200 --> 06:41.840
Now you've seen plots that look like this plenty of times earlier in the course.

06:42.320 --> 06:49.760
The blue dots here are for the unscaled forward pass that you did in exercise one, and this is coming

06:49.760 --> 06:53.460
from the last token in the sequence.

06:53.980 --> 07:01.700
As you know, the model prediction for the next token is the vocab item that has the largest logit here.

07:01.940 --> 07:06.820
Now, for now, don't worry about actually picking out that largest element.

07:06.820 --> 07:08.340
We will get to that later.

07:08.780 --> 07:16.140
For now, the goal is to compare the impact of scaling down layer two by a factor of 0.6.

07:16.660 --> 07:22.220
I have switched off the red dots here so that you don't see what they look like.

07:22.220 --> 07:27.380
But of course your plot will have red dots here in addition to these blue dots.

07:27.940 --> 07:35.620
So now we have the final output logits for the two versions of the model on exactly the same tokens.

07:36.020 --> 07:43.260
And so the next thing you can do is make a scatter plot of the scaled by the unscaled logits.

07:43.700 --> 07:50.700
You can already see that the numerical range is at least slightly different for these two runs through

07:50.700 --> 07:51.300
the model.

07:51.430 --> 07:56.390
so scaled and the original or pure or clean unscaled logits.

07:56.870 --> 07:59.150
So you also saw that in the previous video.

07:59.150 --> 08:05.830
But the question is whether that difference in numbers has any meaningful impact.

08:06.150 --> 08:10.110
So this scatterplot shows the two sets of logits.

08:10.350 --> 08:17.270
And the idea is that if the correlation is one then it would mean that the numbers might be globally

08:17.270 --> 08:18.070
shifted.

08:18.070 --> 08:25.390
But that really had no impact on the model's behavior because all of the relative values are preserved

08:25.390 --> 08:26.710
when scaling down.

08:27.310 --> 08:30.590
Here you can see the correlation coefficient in the title.

08:30.750 --> 08:35.070
And again this is the correlation between the blue dots and the red dots here.

08:35.830 --> 08:36.070
Okay.

08:36.110 --> 08:37.750
So that's for exercise two.

08:37.910 --> 08:40.470
Now you can pause the video and switch to code.

08:40.590 --> 08:45.390
And now I will switch to code and discuss the solution and what the results might mean.

08:46.550 --> 08:53.930
Here I am recreating the dictionary to have the key of two and the value of 0.6.

08:54.250 --> 09:01.170
As I mentioned in the previous video, it's super duper ultra mega important that this has exactly the

09:01.170 --> 09:08.090
same spelling as what variables are being looked through inside this hook function.

09:08.690 --> 09:09.170
Okay.

09:09.210 --> 09:10.490
And let's see.

09:10.530 --> 09:12.450
So then I just defined this.

09:12.490 --> 09:14.330
And now this code is the same.

09:14.330 --> 09:19.250
We don't need to do anything special inside the forward pass okay.

09:19.290 --> 09:21.170
And then I'm getting the logits here.

09:21.170 --> 09:26.850
And I'm calling them a different variable name from what we had in exercise one okay.

09:26.890 --> 09:28.010
So now we can plot that.

09:28.010 --> 09:31.890
And I showed you half of this plot already in the slides.

09:31.890 --> 09:34.090
So now we can see what the other half looks like.

09:34.930 --> 09:38.930
So you see there is a global downward shift.

09:38.930 --> 09:41.170
So scaling the layer.

09:41.330 --> 09:41.810
What was it.

09:41.810 --> 09:42.530
Layer two.

09:43.010 --> 09:48.410
Scaling down layer two by a factor of 0.6 had a pretty significant impact.

09:48.410 --> 09:50.660
That's a pretty noticeable change.

09:50.780 --> 09:57.900
It's a global suppression of all of the activity in the model, propagating forward all the way until

09:57.900 --> 10:04.940
the very, very end of the model, until the UN embeddings matrix that calculates the final output logits.

10:05.340 --> 10:06.700
So it's pretty significant.

10:06.740 --> 10:07.060
Okay.

10:07.100 --> 10:10.180
So now the question is does that matter.

10:10.380 --> 10:10.660
Right.

10:10.700 --> 10:16.780
When we are thinking about choosing the next token, what we do is we pick out whatever token has the

10:16.780 --> 10:18.420
largest value here.

10:18.620 --> 10:22.540
So does it matter that they are globally pushed down?

10:22.900 --> 10:24.780
Uh, and yeah.

10:24.780 --> 10:29.500
So to address that question, uh, it's a complicated question.

10:29.500 --> 10:31.060
There's multiple factors to it.

10:31.060 --> 10:34.420
But one thing we can do is look at the correlation between them.

10:34.580 --> 10:38.060
So you see the correlation is 0.995.

10:38.100 --> 10:44.220
Let me actually, uh I want to just expand this out a little bit further.

10:44.540 --> 10:46.540
So it's nine nine.

10:46.580 --> 10:49.440
What is this 994792.

10:49.480 --> 10:52.280
This is a really strong correlation.

10:52.280 --> 10:53.440
That said, it's not one.

10:53.440 --> 10:54.760
It's not a perfect correlation.

10:54.760 --> 10:58.760
So there actually was a little bit of wiggling and adjusting in here.

10:59.120 --> 11:08.000
Uh, but the next token selection the generation procedure is not purely based on the maximum.

11:08.200 --> 11:08.400
Right.

11:08.440 --> 11:11.880
So that would be the case if we have a deterministic system.

11:12.040 --> 11:19.360
But very often when generating model outputs, we don't just look at the top, we do a softmax.

11:19.720 --> 11:20.920
Uh logsoftmax.

11:20.920 --> 11:24.880
We probabilistically pick based on some probabilities.

11:24.880 --> 11:32.320
And that actually means that this global suppression could have an impact on the values that are selected

11:32.320 --> 11:37.640
probabilistically, if it has an impact on the log softmax.

11:38.920 --> 11:43.600
Now let's switch from looking at numbers to looking at words.

11:44.040 --> 11:52.170
The goal of exercise three is to pick out the top ten logits for each of the two versions of the model.

11:52.530 --> 11:55.530
You can create a table that looks like this.

11:55.530 --> 11:59.810
So I picked out the ten largest for the two models.

11:59.810 --> 12:05.170
And here I'm showing how this model would complete the sentence.

12:05.530 --> 12:10.770
So it turns out that the top logit for both models is exactly the same token.

12:10.930 --> 12:12.370
Categorically incorrect.

12:12.370 --> 12:19.170
But it is sort of semantically related and certainly seems contextually accurate.

12:19.530 --> 12:23.090
So then the question is what happens after that?

12:23.370 --> 12:26.530
So this is the first part of exercise three.

12:27.050 --> 12:32.650
The second part of exercise three is to calculate the loss for the token.

12:32.890 --> 12:33.730
Curious.

12:34.250 --> 12:40.810
Now we know for a fact that the next token in this sequence should be the word curious.

12:41.450 --> 12:43.250
Technically space curious.

12:43.890 --> 12:51.860
So calculate the loss in the scaled and the unscaled models for the token corresponding to the word

12:52.100 --> 12:57.020
curious again with a space in front so that it fits in the sentence.

12:57.260 --> 13:01.020
And remember that smaller numbers are better.

13:01.380 --> 13:08.300
And of course, the question here is whether interfering with the model made it perform worse overall,

13:08.420 --> 13:14.900
which would mean that the loss would be higher in the scaled version compared to the unscaled version

13:15.020 --> 13:15.900
of the model.

13:16.780 --> 13:23.060
I hope you enjoy working through this exercise, and now I will switch to code and discuss my solution.

13:24.180 --> 13:31.500
Here I'm applying Argsort to get the sorting indices from the pure logits and the scaled logits, and

13:31.500 --> 13:35.620
we are only interested in the final token because we.

13:35.660 --> 13:38.740
Yeah, this tells us about the prediction for the next token.

13:39.380 --> 13:43.460
Descending equals true so that we get the largest value in the beginning.

13:43.460 --> 13:48.160
And here's where I format and then print out the text information.

13:48.440 --> 13:54.320
Okay, so you've already seen that the top token is interested.

13:54.320 --> 13:56.200
And also the next one is passionate.

13:56.200 --> 13:58.360
But then we start getting some differences.

13:58.560 --> 14:00.240
I am passionately committed.

14:00.280 --> 14:01.720
I'm passionately trying.

14:01.880 --> 14:06.040
All these words are sort of, you know, they they could kind of fit in here.

14:06.040 --> 14:08.560
But here we know that this is the correct word.

14:08.560 --> 14:09.320
Curious.

14:09.520 --> 14:17.680
So curious is in both of these versions in the top ten, but curiously, curious actually appears higher

14:17.680 --> 14:22.120
in the list for the scaled version compared to the Unscaled version.

14:22.120 --> 14:29.640
So it kind of seems like the scaled version, like manipulating the interior dynamics of the model,

14:29.840 --> 14:34.400
actually had a beneficial impact, at least in this particular example.

14:35.480 --> 14:38.120
Okay, so next we calculate the loss.

14:38.280 --> 14:43.000
The loss for one token is pretty simple to calculate.

14:43.000 --> 14:43.130
We calculate.

14:43.130 --> 14:48.210
We just get the log softmax over all of the tokens.

14:48.250 --> 14:52.970
Again, for the Or sorry, all of the elements in the vocab for the final token.

14:53.250 --> 14:55.170
So that is the log softmax.

14:55.170 --> 14:59.170
And then we want to know just the one for the target token.

14:59.250 --> 15:00.490
And then we take minus that.

15:00.490 --> 15:05.970
So this is the negative log likelihood loss for this one token here.

15:06.290 --> 15:13.810
And consistent with this curious finding up here, we actually see that the loss is lower in the scaled

15:13.810 --> 15:16.290
model compared to the Unscaled model.

15:16.570 --> 15:22.810
And that means that even though the model would not have picked out curious as if it's just picking

15:22.810 --> 15:30.330
out the largest logit token, it actually was closer to being correct when we scaled it down compared

15:30.330 --> 15:32.410
to the Unscaled version.

15:33.490 --> 15:36.970
This is the final exercise in this code challenge.

15:37.410 --> 15:44.550
The goal here is to repeat the loss calculation and the correlation that you have computed in exercise

15:44.550 --> 15:49.070
two and three, but now doing it over all of the layers.

15:49.470 --> 15:53.990
There are 24 layers in the medium version of this model.

15:54.430 --> 15:58.190
So in a for loop you want to scale each layer at a time.

15:58.190 --> 16:01.710
So you're just scaling one layer at a time in a for loop.

16:01.750 --> 16:04.630
You can also use a scaling factor of 0.6.

16:05.230 --> 16:11.790
Calculate the target loss just like in the previous exercise, and also the correlation between all

16:11.790 --> 16:18.710
of the logits for the scaled and the unscaled versions of the model, as you did in exercise two.

16:19.710 --> 16:24.310
And then you can visualize those results in two plots like what you see here.

16:24.670 --> 16:27.950
So here on the left we have the target losses.

16:28.070 --> 16:31.990
It's always the same number for the Unscaled model of course.

16:31.990 --> 16:34.750
So therefore you can draw that as a horizontal line.

16:34.750 --> 16:36.150
That's what you see here.

16:36.750 --> 16:42.880
And here you see the result for what happens when you scale down the final transformer block by a factor

16:42.880 --> 16:43.960
of 0.6.

16:44.360 --> 16:47.720
And the question is what do all of the earlier blocks look like?

16:48.520 --> 16:54.280
And over here on the right are the correlations between the scaled and unscaled logits.

16:54.320 --> 16:56.840
Again for each transformer block.

16:57.720 --> 17:01.000
So now you can pause the video and wrap up this code challenge.

17:01.000 --> 17:03.760
And now I will switch to code and bring us home.

17:06.080 --> 17:09.680
Here is where I initialize the output variables.

17:09.680 --> 17:17.440
So for the losses and the correlations here I'm getting the log softmax for the pure unscaled version

17:17.440 --> 17:18.880
of this model.

17:19.120 --> 17:21.800
And yeah again this is for the final token.

17:21.800 --> 17:26.120
We want to know what is the prediction for the subsequent token.

17:26.680 --> 17:30.560
Okay then here I'm looping over the layers in the model.

17:30.560 --> 17:33.080
Here I'm recreating the scaling dictionary.

17:33.320 --> 17:36.240
The value is always fixed at 0.6.

17:36.240 --> 17:38.720
And what I'm changing is the key.

17:38.760 --> 17:40.210
So the layer I.

17:40.250 --> 17:44.290
This is the layer index from zero up to the number of layers.

17:44.810 --> 17:46.330
Forward pass etc..

17:46.370 --> 17:48.610
Here I'm getting the output logits.

17:48.650 --> 17:52.530
Also softmax log softmax defying them.

17:52.570 --> 17:53.450
Is that a real word.

17:53.930 --> 17:57.250
Uh and then picking out the target token and.

17:57.290 --> 17:57.570
Yeah.

17:57.610 --> 18:00.970
Minus the negative log likelihood of that.

18:01.210 --> 18:03.650
And here I'm correlating using torch.

18:04.850 --> 18:12.850
This is slightly awkward syntax but the torch function doesn't take two vectors.

18:12.890 --> 18:19.530
You know you would like to be able to input two vectors a and B like this and calculate the correlation

18:19.530 --> 18:20.930
coefficient between them.

18:21.250 --> 18:24.130
That is not how Torch Cove works.

18:24.250 --> 18:32.330
Instead, you have to input a matrix, and PyTorch will calculate the correlation matrix based on all

18:32.330 --> 18:34.890
of the columns in that matrix.

18:35.010 --> 18:41.990
So therefore I have to actually create that matrix using torch, dot, concatenate and then yeah, it

18:41.990 --> 18:43.270
also needs to be unsqueezed.

18:43.270 --> 18:43.790
This is.

18:43.830 --> 18:52.310
Yeah, to be honest, I think it's easier to transform everything into numpy and then use numpy coef.

18:52.550 --> 19:00.950
But I wanted to include this formulation here just as a reminder of how this works in PyTorch.

19:01.630 --> 19:07.510
Okay, so anyway, then we get the correlations and then that won't take too long to go through.

19:08.550 --> 19:13.110
We can visualize all of those results as you see here.

19:13.510 --> 19:13.790
Okay.

19:13.830 --> 19:19.910
So again the red line up here is the loss for the uh target token.

19:19.910 --> 19:22.710
Curious from the Unscaled model.

19:22.710 --> 19:24.430
This is our reference point.

19:24.430 --> 19:32.030
And you see most of the time a few outliers notwithstanding, most of the time the scaled model actually

19:32.030 --> 19:36.550
had a lower loss compared to the Unscaled model.

19:36.870 --> 19:42.120
And it kind of seems like the loss is increasing as we get deeper into the model.

19:42.120 --> 19:49.840
It's not really a perfect monotonic function, so I certainly wouldn't make a big deal out of that particular

19:49.840 --> 19:50.520
finding.

19:50.840 --> 19:52.320
And here you see the correlations.

19:52.320 --> 19:53.840
They are really, really high.

19:54.000 --> 19:57.960
So 0.992 is like the lowest correlation.

19:57.960 --> 20:00.720
That is a crazy high correlation coefficient.

20:02.320 --> 20:10.160
Doing lots of detailed circuit analysis can be interesting and fun and insightful, but ultimately it's

20:10.160 --> 20:16.720
also important to try to link the internal dynamics to model outputs whenever possible.

20:17.280 --> 20:23.200
And that's because at the end of the day, what we really care about is the kinds of text that the model

20:23.200 --> 20:24.160
produces.

20:24.520 --> 20:31.760
Now, that's not always possible or necessary to focus your analyses on the final model output and text

20:31.760 --> 20:32.680
generation.

20:32.680 --> 20:40.980
But when you can link your Internal model manipulations and investigations to token selection, then

20:40.980 --> 20:45.700
that will help your findings be more interpretable and more impactful.

20:46.580 --> 20:53.220
The last point I want to mention is that global scaling is kind of like decreasing the temperature in

20:53.220 --> 20:54.100
softmax.

20:54.820 --> 21:00.980
It's not exactly literally what happens because there are still multiple stages of transformations and

21:00.980 --> 21:02.020
normalizations.

21:02.020 --> 21:10.820
But decreasing the softmax temperature is one way to think about the impact of global scaling of these

21:10.820 --> 21:12.220
embeddings vectors.

21:12.740 --> 21:18.780
The model seems to be doing better, but really what's happening is that the model distribution is getting

21:18.780 --> 21:19.500
sharper.

21:19.860 --> 21:24.220
So that happened to be a good thing in this particular example.

21:24.460 --> 21:31.460
But as I've discussed earlier in the course, having a more restricted and less stochastic token selection

21:31.660 --> 21:34.300
is not always a desired property.
