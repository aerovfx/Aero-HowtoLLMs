
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../index.md) > [12 investigating neurons dimensions](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../index.md)
- [ğŸ“š Module 01: LLM Course](../../01_llm_course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../02_words_to_tokens_to_numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../04_buildgpt/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../07_fine_tune_pretrained_models/index.md)
- [ğŸ” Module 19: AI Safety](../../19_ai_safety/index.md)
- [ğŸ Module 20: Python for AI](../../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Thá»­ thÃ¡ch Láº­p trÃ¬nh: TÃ­nh Chá»n lá»c Ngá»¯ phÃ¡p cá»§a NÆ¡-ron MLP (Pháº§n 1)

## TÃ³m táº¯t (Abstract)
BÃ¡o cÃ¡o nÃ y trÃ¬nh bÃ y giai Ä‘oáº¡n Ä‘áº§u cá»§a thá»­ thÃ¡ch tÃ¬m kiáº¿m cÃ¡c nÆ¡-ron chuyÃªn biá»‡t cho cÃ¡c tá»« loáº¡i (parts of speech) trong phÃ¢n Ä‘oáº¡n má»Ÿ rá»™ng cá»§a lá»›p MLP trÃªn mÃ´ hÃ¬nh GPT-Neo. NghiÃªn cá»©u táº­p trung vÃ o viá»‡c so sÃ¡nh hoáº¡t hÃ³a cá»§a nÆ¡-ron trÆ°á»›c hai danh má»¥c tá»« vá»±ng: Danh tá»« (Nouns) vÃ  Äá»™ng tá»« (Verbs). Quy trÃ¬nh thá»±c nghiá»‡m bao gá»“m viá»‡c cáº¥y Hooks vÃ o cÃ¡c nÆ¡-ron má»Ÿ rá»™ng (expansion neurons) â€“ nÆ¡i Ä‘Æ°á»£c giáº£ thuyáº¿t lÃ  trÃ­ch xuáº¥t cÃ¡c Ä‘áº·c trÆ°ng phi tuyáº¿n tá»« residual stream â€“ vÃ  thu tháº­p dá»¯ liá»‡u pháº£n há»“i tá»« 200 tá»« vá»±ng phá»• biáº¿n. Káº¿t quáº£ sÆ¡ bá»™ cho tháº¥y sá»± tá»“n táº¡i cá»§a cÃ¡c thiÃªn kiáº¿n (biases) vÃ  sá»± biáº¿n thiÃªn nÆ¡-ron rÃµ rá»‡t, Ä‘áº·t ná»n táº£ng cho phÃ¢n tÃ­ch thá»‘ng kÃª chuyÃªn sÃ¢u á»Ÿ pháº§n tiáº¿p theo.

---

## 1. Má»Ÿ Äáº§u (Introduction)
Má»™t cÃ¢u há»i trung tÃ¢m trong Diá»…n giáº£i há»c lÃ : CÃ¡c LLM cÃ³ sá»Ÿ há»¯u nhá»¯ng "nÆ¡-ron ngÃ´n ngá»¯" chuyÃªn biá»‡t khÃ´ng? VÃ­ dá»¥, cÃ³ tá»“n táº¡i má»™t nÆ¡-ron chá»‰ kÃ­ch hoáº¡t máº¡nh khi nhÃ¬n tháº¥y danh tá»« mÃ  im láº·ng trÆ°á»›c Ä‘á»™ng tá»«? BÃ¡o cÃ¡o nÃ y thiáº¿t láº­p mÃ´i trÆ°á»ng thá»±c nghiá»‡m Ä‘á»ƒ kiá»ƒm chá»©ng giáº£ thuyáº¿t Ä‘Ã³, táº­p trung vÃ o lá»›p MLP (Multi-Layer Perceptron) â€“ thÃ nh pháº§n Ä‘Æ°á»£c coi lÃ  "kho tri thá»©c" vÃ  "bá»™ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng" cá»§a kiáº¿n trÃºc Transformer.

---

## 2. CÆ¡ sá»Ÿ LÃ½ thuyáº¿t: Táº¡i sao láº¡i lÃ  MLP?
Trong má»™t khá»‘i Transformer:
- **Lá»›p Attention:** ÄÃ³ng vai trÃ² tÃ­ch há»£p ngá»¯ cáº£nh tá»« cÃ¡c token xung quanh (ai Ä‘ang lÃ m gÃ¬ cho ai).
- **Lá»›p MLP:** ÄÃ³ng vai trÃ² nháº­n diá»‡n cÃ¡c thuá»™c tÃ­nh ná»™i táº¡i cá»§a token (Ä‘Ã¢y lÃ  má»™t váº­t thá»ƒ hay má»™t hÃ nh Ä‘á»™ng).
Äáº·c biá»‡t, lá»›p má»Ÿ rá»™ng (C_FC) tÄƒng sá»‘ chiá»u lÃªn gáº¥p 4 láº§n (tá»« 768 lÃªn 3072 trong GPT-2 Small), táº¡o ra má»™t khÃ´ng gian rá»™ng lá»›n Ä‘á»ƒ mÃ´ hÃ¬nh phÃ¢n tÃ¡ch cÃ¡c khÃ¡i niá»‡m ngá»¯ nghÄ©a vÃ  ngá»¯ phÃ¡p.

---

## 3. Thiáº¿t láº­p Thá»±c nghiá»‡m (Methodology)

### 3.1. Chuáº©n bá»‹ Dá»¯ liá»‡u vÃ  MÃ´ hÃ¬nh
- **MÃ´ hÃ¬nh:** GPT-Neo 125M (sá»­ dá»¥ng tokenizer EleutherAI).
- **Dá»¯ liá»‡u:** Danh sÃ¡ch 100 Ä‘á»™ng tá»« vÃ  100 danh tá»« thÃ´ng dá»¥ng nháº¥t Ä‘Æ°á»£c trÃ­ch xuáº¥t tá»« cÃ¡c nguá»“n cÃ´ng khai.
- **Tráº¡ng thÃ¡i:** MÃ´ hÃ¬nh Ä‘Æ°á»£c thiáº¿t láº­p á»Ÿ cháº¿ Ä‘á»™ `eval()` Ä‘á»ƒ Ä‘áº£m báº£o tÃ­nh á»•n Ä‘á»‹nh cá»§a cÃ¡c hoáº¡t hÃ³a.

### 3.2. Cáº¥y Hook vÃ o Lá»›p Má»Ÿ rá»™ng (Expansion Layer)
Sá»­ dá»¥ng `register_forward_hook` vÃ o thÃ nh pháº§n `c_fc` cá»§a Transformer Block thá»© 9 (index 8). Äiá»ƒm thu tháº­p dá»¯ liá»‡u náº±m ngay sau khi thá»±c hiá»‡n phÃ©p nhÃ¢n ma tráº­n trá»ng sá»‘ nhÆ°ng trÆ°á»›c khi Ä‘i qua hÃ m kÃ­ch hoáº¡t phi tuyáº¿n (GELU). Äiá»u nÃ y cho phÃ©p ta quan sÃ¡t "tÆ° duy thÃ´" cá»§a nÆ¡-ron trÆ°á»›c khi bá»‹ nÃ©n bá»Ÿi cÆ¡ cháº¿ thÆ°a thá»›t (sparsity).

### 3.3. Thu tháº­p Hoáº¡t hÃ³a Diá»‡n rá»™ng
Dá»¯ liá»‡u Ä‘Æ°á»£c lÆ°u trá»¯ trong má»™t máº£ng 3 chiá»u cÃ³ kÃ­ch thÆ°á»›c `[2, 100, 3072]`:
- `2`: Danh má»¥c (0: Äá»™ng tá»«, 1: Danh tá»«).
- `100`: Sá»‘ lÆ°á»£ng tá»« trong má»—i danh má»¥c.
- `3072`: Sá»‘ lÆ°á»£ng nÆ¡-ron MLP.
*Ká»¹ thuáº­t quan trá»ng:* Sá»­ dá»¥ng `mean(dim=1)` Ä‘á»ƒ xá»­ lÃ½ cÃ¡c tá»« bá»‹ tÃ¡ch thÃ nh nhiá»u tokens, Ä‘áº£m báº£o má»—i tá»« (word) chá»‰ Ä‘áº¡i diá»‡n bá»Ÿi má»™t vector hoáº¡t hÃ³a duy nháº¥t.

---

## 4. Káº¿t Quáº£ SÆ¡ Bá»™ vÃ  Quan SÃ¡t
Äá»“ thá»‹ phÃ¢n bá»‘ hoáº¡t hÃ³a cho tháº¥y:
1. **Sá»± ThiÃªn lá»‡ch Há»‡ thá»‘ng (Systematic Offsets):** CÃ¡c nÆ¡-ron khÃ´ng hoáº¡t Ä‘á»™ng quanh má»©c 0 mÃ  thÆ°á»ng cÃ³ má»™t Ä‘iá»ƒm dá»«ng (mean offset) cá»‘ Ä‘á»‹nh cho háº§u háº¿t cÃ¡c tá»« (thÆ°á»ng lÃ  giÃ¡ trá»‹ Ã¢m).
2. **CÃ¡c BÄƒng dá»c (Vertical Bands):** Má»™t sá»‘ nÆ¡-ron cho tháº¥y biÃªn Ä‘á»™ hoáº¡t hÃ³a khÃ¡c biá»‡t rÃµ rá»‡t so vá»›i sá»‘ Ä‘Ã´ng trÃªn toÃ n bá»™ dáº£i tá»« vá»±ng thá»­ nghiá»‡m.
3. **TÃ­nh Biáº¿n thiÃªn:** Máº·c dÃ¹ nhÃ¬n tá»•ng thá»ƒ cÃ³ váº» Ä‘á»“ng nháº¥t, nhÆ°ng cÃ¡c nÆ¡-ron riÃªng láº» báº¯t Ä‘áº§u bá»™c lá»™ sá»± Æ°u tiÃªn nháº¹ Ä‘á»‘i vá»›i danh tá»« hoáº·c Ä‘á»™ng tá»« khi nhÃ¬n chi tiáº¿t vÃ o cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u.

---

## 5. Káº¿t Luáº­n Pháº§n 1
ChÃºng ta Ä‘Ã£ thÃ nh cÃ´ng trong viá»‡c xÃ¢y dá»±ng há»‡ thá»‘ng trÃ­ch xuáº¥t hoáº¡t hÃ³a quy mÃ´ lá»›n tá»« nÆ¡-ron MLP. Viá»‡c quan sÃ¡t tháº¥y cÃ¡c dáº£i hoáº¡t hÃ³a á»•n Ä‘á»‹nh lÃ  dáº¥u hiá»‡u tÃ­ch cá»±c cho tháº¥y cÃ¡c nÆ¡-ron nÃ y Ä‘ang "mÃ£ hÃ³a" nhá»¯ng thuá»™c tÃ­nh nháº¥t Ä‘á»‹nh cá»§a ngÃ´n ngá»¯. Pháº§n tiáº¿p theo sáº½ triá»ƒn khai cÃ¡c phÃ©p kiá»ƒm Ä‘á»‹nh thá»‘ng kÃª (t-test) Ä‘á»ƒ xÃ¡c Ä‘á»‹nh xem sá»± khÃ¡c biá»‡t giá»¯a danh tá»« vÃ  Ä‘á»™ng tá»« cÃ³ Ä‘áº¡t má»©c Ã½ nghÄ©a khoa há»c hay khÃ´ng.

---

## TÃ i liá»‡u tham kháº£o (Citations)
1. Thá»­ thÃ¡ch vá» Grammar tuning trÃªn GPT-Neo dá»±a trÃªn `aero_LLM_08_CodeChallenge Grammar tuning in MLP neurons (part 1).md`. Thiáº¿t láº­p Hooks vÃ  quy trÃ¬nh thu tháº­p dá»¯ liá»‡u nÆ¡-ron má»Ÿ rá»™ng.
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| [ğŸ“‚ Module: 12-Investigating-neurons-dimensions](README.md) | [Xem bÃ i viáº¿t â†’](README.md) |
| [Cá»±c Ä‘áº¡i hÃ³a Hoáº¡t hÃ³a (Activation Maximization): CÆ¡ sá»Ÿ LÃ½ thuyáº¿t vÃ  Nhá»¯ng thÃ¡ch thá»©c trong LLM](aero_llm_01_activation_maximization_via_gradient_ascent_theory_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_01_activation_maximization_via_gradient_ascent_theory_.md) |
| [Triá»ƒn khai Cá»±c Ä‘áº¡i hÃ³a Hoáº¡t hÃ³a: Tá»« Gradient Ascent Ä‘áº¿n Giáº£i mÃ£ Token (Activation Maximization Implementation)](aero_llm_02_activation_maximization_code_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_02_activation_maximization_code_.md) |
| [Cá»±c Ä‘áº¡i hÃ³a Hoáº¡t hÃ³a qua Láº¥y máº«u Dá»¯ liá»‡u (Activation Maximization via Data Sampling)](aero_llm_03_activation_maximization_via_data_sampling.md) | [Xem bÃ i viáº¿t â†’](aero_llm_03_activation_maximization_via_data_sampling.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Kiá»ƒm chá»©ng TÃ­nh láº·p láº¡i cá»§a Cá»±c Ä‘áº¡i hÃ³a Hoáº¡t hÃ³a (Reproducibility of Activation Maximization)](aero_llm_04_codechallenge_reproducibility_of_activation_maximization.md) | [Xem bÃ i viáº¿t â†’](aero_llm_04_codechallenge_reproducibility_of_activation_maximization.md) |
| [Giáº£i pháº«u Ná»™i táº¡i MÃ´ hÃ¬nh báº±ng Hooks: Ká»¹ thuáº­t TrÃ­ch xuáº¥t Hoáº¡t hÃ³a (Extracting Activations via Hooks)](aero_llm_05_extracting_activations_using_hooks.md) | [Xem bÃ i viáº¿t â†’](aero_llm_05_extracting_activations_using_hooks.md) |
| [Má»‘i tÆ°Æ¡ng quan giá»¯a Hooks vÃ  Hidden States: Giáº£i cáº¥u trÃºc Khá»‘i Transformer (Reconstructing Transformer Blocks)](aero_llm_06_relation_between_hooks_and_output_hidden_states.md) | [Xem bÃ i viáº¿t â†’](aero_llm_06_relation_between_hooks_and_output_hidden_states.md) |
| [LÃ m rÃµ vá» Hidden States Táº§ng cuá»‘i: Vai trÃ² cá»§a LayerNorm (Clarification of Final Hidden States)](aero_llm_07_clarification_of_final_hidden_states_output.md) | [Xem bÃ i viáº¿t â†’](aero_llm_07_clarification_of_final_hidden_states_output.md) |
| ğŸ“Œ **[Thá»­ thÃ¡ch Láº­p trÃ¬nh: TÃ­nh Chá»n lá»c Ngá»¯ phÃ¡p cá»§a NÆ¡-ron MLP (Pháº§n 1)](aero_llm_08_codechallenge_grammar_tuning_in_mlp_neurons_part_1_.md)** | [Xem bÃ i viáº¿t â†’](aero_llm_08_codechallenge_grammar_tuning_in_mlp_neurons_part_1_.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: TÃ­nh Chá»n lá»c Ngá»¯ phÃ¡p cá»§a NÆ¡-ron MLP (Pháº§n 2)](aero_llm_09_codechallenge_grammar_tuning_in_mlp_neurons_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_09_codechallenge_grammar_tuning_in_mlp_neurons_part_2_.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Sá»± Äiá»u cháº¿ Ngá»¯ cáº£nh trong Hoáº¡t hÃ³a MLP (Context-modulated Activation)](aero_llm_10_codechallenge_context_modulated_activation_in_mlp.md) | [Xem bÃ i viáº¿t â†’](aero_llm_10_codechallenge_context_modulated_activation_in_mlp.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Äá»™ dÃ i Token vÃ  Äáº·c tÃ­nh Hoáº¡t hÃ³a (Pháº§n 1)](aero_llm_11_codechallenge_activation_histograms_by_token_length_part_1_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_11_codechallenge_activation_histograms_by_token_length_part_1_.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Äá»™ dÃ i Token vÃ  Äáº·c tÃ­nh Hoáº¡t hÃ³a (Pháº§n 2)](aero_llm_12_codechallenge_activation_histograms_by_token_length_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_12_codechallenge_activation_histograms_by_token_length_part_2_.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Äá»™ dÃ i Token vÃ  Äáº·c tÃ­nh Hoáº¡t hÃ³a (Pháº§n 3)](aero_llm_13_codechallenge_activation_histograms_by_token_length_part_3_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_13_codechallenge_activation_histograms_by_token_length_part_3_.md) |
| [Xá»­ lÃ½ Biá»ƒu diá»…n NÆ¡-ron cho cÃ¡c Tá»« Ä‘a Token (Multi-token Words)](aero_llm_14_dealing_with_multitoken_word_embeddings.md) | [Xem bÃ i viáº¿t â†’](aero_llm_14_dealing_with_multitoken_word_embeddings.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: HÃ¬nh chiáº¿u MLP Äiá»u chá»‰nh theo Danh má»¥c (Pháº§n 1)](aero_llm_15_codechallenge_category_tuned_mlp_projections_part_1_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_15_codechallenge_category_tuned_mlp_projections_part_1_.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: HÃ¬nh chiáº¿u MLP Äiá»u chá»‰nh theo Danh má»¥c (Pháº§n 2)](aero_llm_16_codechallenge_category_tuned_mlp_projections_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_16_codechallenge_category_tuned_mlp_projections_part_2_.md) |
| [Há»“i quy Logistic: LÃ½ thuyáº¿t vÃ  Triá»ƒn khai PhÃ¢n loáº¡i NÆ¡-ron](aero_llm_17_classification_via_logistic_regression_theory_and_code.md) | [Xem bÃ i viáº¿t â†’](aero_llm_17_classification_via_logistic_regression_theory_and_code.md) |
| [Äá»‘i chiáº¿u Há»“i quy Logistic vÃ  Kiá»ƒm Ä‘á»‹nh T-test: Giáº£ Ä‘á»‹nh vÃ  á»¨ng dá»¥ng](aero_llm_18_logistic_regression_vs_t_test_assumptions_and_applications.md) | [Xem bÃ i viáº¿t â†’](aero_llm_18_logistic_regression_vs_t_test_assumptions_and_applications.md) |
| [Äiá»u chá»‰nh Danh tá»« riÃªng trong GPT-2 Medium](aero_llm_19_proper_noun_tuning_in_gpt2_medium.md) | [Xem bÃ i viáº¿t â†’](aero_llm_19_proper_noun_tuning_in_gpt2_medium.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Äiá»u chá»‰nh Phá»§ Ä‘á»‹nh trong NÆ¡-ron MLP (Pháº§n 1)](aero_llm_20_codechallenge_negation_tuning_in_mlp_neurons_part_1_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_20_codechallenge_negation_tuning_in_mlp_neurons_part_1_.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Äiá»u chá»‰nh Phá»§ Ä‘á»‹nh trong NÆ¡-ron MLP (Pháº§n 2)](aero_llm_21_codechallenge_negation_tuning_in_mlp_neurons_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_21_codechallenge_negation_tuning_in_mlp_neurons_part_2_.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Äiá»u chá»‰nh Phá»§ Ä‘á»‹nh trong NÆ¡-ron MLP (Pháº§n 3)](aero_llm_22_codechallenge_negation_tuning_in_mlp_neurons_part_3_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_22_codechallenge_negation_tuning_in_mlp_neurons_part_3_.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Äiá»u chá»‰nh Phá»§ Ä‘á»‹nh trong NÆ¡-ron QVK (Attention)](aero_llm_23_codechallenge_negation_tuning_in_qvk_neurons.md) | [Xem bÃ i viáº¿t â†’](aero_llm_23_codechallenge_negation_tuning_in_qvk_neurons.md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
