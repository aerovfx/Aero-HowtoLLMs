
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../index.md) > [12 investigating neurons dimensions](index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../index.md)
- [ğŸ“š Module 01: LLM Course](../01_llm_course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../02_words_to_tokens_to_numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../04_buildgpt/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../07_fine_tune_pretrained_models/index.md)
- [ğŸ” Module 19: AI Safety](../19_ai_safety/index.md)
- [ğŸ Module 20: Python for AI](../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Xá»­ lÃ½ Biá»ƒu diá»…n NÆ¡-ron cho cÃ¡c Tá»« Ä‘a Token (Multi-token Words)

## TÃ³m táº¯t (Abstract)
BÃ¡o cÃ¡o nÃ y giáº£i quyáº¿t má»™t thÃ¡ch thá»©c thá»±c tiá»…n trong Diá»…n giáº£i há»c (Mechanistic Interpretability): CÃ¡ch trÃ­ch xuáº¥t hoáº¡t hÃ³a cho cÃ¡c tá»« bá»‹ chia thÃ nh nhiá»u tokens bá»Ÿi tokenizer (vÃ­ dá»¥: "toothpaste" $\rightarrow$ ["tooth", "paste"]). Qua phÃ¢n tÃ­ch lÃ½ thuyáº¿t vÃ  thá»±c nghiá»‡m trÃªn GPT-2, nghiÃªn cá»©u kháº³ng Ä‘á»‹nh ráº±ng viá»‡c táº­p trung vÃ o **token cuá»‘i cÃ¹ng** lÃ  phÆ°Æ¡ng phÃ¡p tá»‘i Æ°u. LÃ½ do cá»‘t lÃµi náº±m á»Ÿ báº£n cháº¥t nhÃ¢n quáº£ (causal) cá»§a mÃ´ hÃ¬nh: táº¡i token cuá»‘i, biá»ƒu diá»…n Ä‘Ã£ tÃ­ch há»£p toÃ n bá»™ thÃ´ng tin tá»« cÃ¡c token thÃ nh pháº§n phÃ­a trÆ°á»›c, táº¡o thÃ nh má»™t khÃ¡i niá»‡m ngá»¯ nghÄ©a hoÃ n chá»‰nh. BÃ¡o cÃ¡o cÅ©ng cung cáº¥p khung mÃ£ nguá»“n Python Ä‘á»ƒ xÃ¡c Ä‘á»‹nh vá»‹ trÃ­ vÃ  phÃ¢n tÃ­ch sá»± biáº¿n thiÃªn cá»§a cÃ¡c multi-token embeddings xuyÃªn suá»‘t cÃ¡c táº§ng.

---

## 1. Má» Äáº§u (Introduction)
Trong tiáº¿ng Anh vÃ  nhiá»u ngÃ´n ngá»¯ khÃ¡c, khÃ´ng pháº£i tá»« nÃ o cÅ©ng tÆ°Æ¡ng á»©ng vá»›i má»™t token duy nháº¥t. CÃ¡c tá»« ghÃ©p ("toothpaste"), tá»« phá»©c hoáº·c tá»« hiáº¿m thÆ°á»ng bá»‹ báº» gÃ£y. Khi nghiÃªn cá»©u tÃ­nh chá»n lá»c cá»§a nÆ¡-ron Ä‘á»‘i vá»›i má»™t "tá»«", cÃ¢u há»i Ä‘áº·t ra lÃ  chÃºng ta nÃªn láº¥y dá»¯ liá»‡u tá»« token nÃ o? BÃ¡o cÃ¡o nÃ y thiáº¿t láº­p má»™t quy trÃ¬nh chuáº©n hÃ³a Ä‘á»ƒ xá»­ lÃ½ cÃ¡c "Ä‘Æ¡n vá»‹ ngá»¯ nghÄ©a Ä‘a thÃ nh pháº§n" nÃ y.

---

## 2. Giáº£ thuyáº¿t "Token cuá»‘i cÃ¹ng lÃ  chÃ¬a khÃ³a"

### 2.1. CÆ¡ cháº¿ TÃ­ch há»£p Ngá»¯ cáº£nh
XÃ©t tá»« "toothpaste":
1. Khi mÃ´ hÃ¬nh xá»­ lÃ½ token "tooth", nÃ³ chÆ°a biáº¿t tá»« tiáº¿p theo lÃ  gÃ¬ (cÃ³ thá»ƒ lÃ  "ache", "brush", hoáº·c "paste"). Biá»ƒu diá»…n táº¡i Ä‘Ã¢y chá»‰ mang tÃ­nh dá»± Ä‘oÃ¡n (predictive).
2. Khi mÃ´ hÃ¬nh xá»­ lÃ½ token "paste" (Ä‘áº·c biá»‡t lÃ  khi khÃ´ng cÃ³ khoáº£ng tráº¯ng phÃ­a trÆ°á»›c vÃ  Ä‘i sau "tooth"), lá»›p Attention sáº½ Ä‘iá»u cháº¿ vector nÃ y dá»±a trÃªn thÃ´ng tin "tooth" Ä‘Ã£ cÃ³ trong residual stream.
3. **Káº¿t luáº­n:** Táº¡i vá»‹ trÃ­ "paste", mÃ´ hÃ¬nh má»›i thá»±c sá»± sá»Ÿ há»¯u biá»ƒu diá»…n cá»§a khÃ¡i niá»‡m "toothpaste" hoÃ n chá»‰nh. "Tooth" khÃ´ng biáº¿t gÃ¬ vá» "paste", nhÆ°ng "paste" biáº¿t ráº¥t nhiá»u vá» "tooth".

---

## 3. Quy trÃ¬nh Thá»±c nghiá»‡m vÃ  Triá»ƒn khai MÃ£ nguá»“n

### 3.1. XÃ¡c Ä‘á»‹nh vá»‹ trÃ­ Thuáº­t toÃ¡n (Algorithmic Indexing)
Trong má»™t batch vÄƒn báº£n phá»©c táº¡p, viá»‡c tÃ¬m vá»‹ trÃ­ cá»§a má»™t cá»¥m token Ä‘Ã­ch (target sequence) Ä‘Ã²i há»i má»™t quy trÃ¬nh kiá»ƒm duyá»‡t nghiÃªm ngáº·t:
- Duyá»‡t qua tá»«ng cÃ¢u trong batch.
- Kiá»ƒm tra sá»± trÃ¹ng khá»›p cá»§a token hiá»‡n táº¡i vÃ  $k$ tokens phÃ­a trÆ°á»›c vá»›i chuá»—i Ä‘Ã­ch.
- LÆ°u trá»¯ index cá»§a token cuá»‘i cÃ¹ng Ä‘á»ƒ phá»¥c vá»¥ trÃ­ch xuáº¥t `hidden_states`.

### 3.2. Quáº£n lÃ½ Batch vÃ  Padding
Äá»ƒ xá»­ lÃ½ cÃ¡c cÃ¢u cÃ³ Ä‘á»™ dÃ i khÃ¡c nhau, nghiÃªn cá»©u sá»­ dá»¥ng ká»¹ thuáº­t padding vÃ  `attention_mask`. Viá»‡c unpack dictionary thÃ´ng qua toÃ¡n tá»­ `**` trong PyTorch giÃºp Ä‘áº©y dá»¯ liá»‡u qua mÃ´ hÃ¬nh má»™t cÃ¡ch hiá»‡u quáº£, Ä‘áº£m báº£o cÃ¡c token padding khÃ´ng lÃ m nhiá»…u káº¿t quáº£ phÃ¢n tÃ­ch.

---

## 4. PhÃ¢n tÃ­ch Sá»± biáº¿n thiÃªn Vector (Vector Displacement)
NghiÃªn cá»©u giá»›i thiá»‡u má»™t phÃ©p Ä‘o thá»±c nghiá»‡m: Äá»™ dÃ i quá»¹ Ä‘áº¡o cá»§a vector nhÃºng khi Ä‘i qua mÃ´ hÃ¬nh.
- **CÃ´ng thá»©c:** $\\mid $v_l$ - v_{l-1}\\mid$, trong Ä‘Ã³ $v_l$ lÃ  biá»ƒu diá»…n táº¡i táº§ng $l$.
- **Quan sÃ¡t:** Sá»± thay Ä‘á»•i nÃ y pháº£n Ã¡nh khá»‘i lÆ°á»£ng cÃ´ng viá»‡c tÃ­nh toÃ¡n mÃ  cÃ¡c lá»›p Attention vÃ  MLP Ä‘Ã£ thá»±c hiá»‡n Ä‘á»ƒ tinh chá»‰nh Ã½ nghÄ©a cá»§a token. Äá»‘i vá»›i cÃ¡c tá»« Ä‘a token, token cuá»‘i cÃ¹ng thÆ°á»ng bá»™c lá»™ sá»± biáº¿n thiÃªn lá»›n á»Ÿ cÃ¡c táº§ng giá»¯a, nÆ¡i "phÃ©p cá»™ng ngá»¯ nghÄ©a" thá»±c sá»± diá»…n ra.

---

## 5. Káº¿t Luáº­n
Viá»‡c hiá»ƒu rÃµ cÃ¡ch tokenizer phÃ¢n rÃ£ ngÃ´n ngá»¯ lÃ  Ä‘iá»u kiá»‡n tiÃªn quyáº¿t cho má»i nghiÃªn cá»©u ná»™i soi mÃ´ hÃ¬nh. BÃ¡o cÃ¡o xÃ¡c láº­p quy táº¯c: Äá»ƒ phÃ¢n tÃ­ch má»™t khÃ¡i niá»‡m, hÃ£y luÃ´n nhÃ¬n vÃ o token káº¿t thÃºc chuá»—i biá»ƒu diá»…n khÃ¡i niá»‡m Ä‘Ã³. PhÆ°Æ¡ng phÃ¡p nÃ y khÃ´ng chá»‰ Ä‘áº£m báº£o tÃ­nh chÃ­nh xÃ¡c vá» máº·t ngá»¯ nghÄ©a mÃ  cÃ²n nháº¥t quÃ¡n vá»›i cÆ¡ cáº¥u váº­n hÃ nh cá»§a kiáº¿n trÃºc Transformer.

---

## TÃ i liá»‡u tham kháº£o (Citations)
1. Ká»¹ thuáº­t xá»­ lÃ½ multi-token word embeddings trÃªn GPT-2 dá»±a trÃªn `aero_LLM_14_Dealing with multitoken word embeddings.md`. LÃ½ thuyáº¿t vá» tÃ­ch há»£p thÃ´ng tin táº¡i token cuá»‘i vÃ  quy trÃ¬nh trÃ­ch xuáº¥t vector.
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| [ğŸ“‚ Module: 12_investigating_neurons_dimensions](README.md) | [Xem bÃ i viáº¿t â†’](README.md) |
| [Cá»±c Ä‘áº¡i hÃ³a Hoáº¡t hÃ³a (Activation Maximization): CÆ¡ sá»Ÿ LÃ½ thuyáº¿t vÃ  Nhá»¯ng thÃ¡ch thá»©c trong LLM](aero_llm_01_activation_maximization_via_gradient_ascent_theory_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_01_activation_maximization_via_gradient_ascent_theory_.md) |
| [Triá»ƒn khai Cá»±c Ä‘áº¡i hÃ³a Hoáº¡t hÃ³a: Tá»« Gradient Ascent Ä‘áº¿n Giáº£i mÃ£ Token (Activation Maximization Implementation)](aero_llm_02_activation_maximization_code_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_02_activation_maximization_code_.md) |
| [Cá»±c Ä‘áº¡i hÃ³a Hoáº¡t hÃ³a qua Láº¥y máº«u Dá»¯ liá»‡u (Activation Maximization via Data Sampling)](aero_llm_03_activation_maximization_via_data_sampling.md) | [Xem bÃ i viáº¿t â†’](aero_llm_03_activation_maximization_via_data_sampling.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Kiá»ƒm chá»©ng TÃ­nh láº·p láº¡i cá»§a Cá»±c Ä‘áº¡i hÃ³a Hoáº¡t hÃ³a (Reproducibility of Activation Maximization)](aero_llm_04_codechallenge_reproducibility_of_activation_maximization.md) | [Xem bÃ i viáº¿t â†’](aero_llm_04_codechallenge_reproducibility_of_activation_maximization.md) |
| [Giáº£i pháº«u Ná»™i táº¡i MÃ´ hÃ¬nh báº±ng Hooks: Ká»¹ thuáº­t TrÃ­ch xuáº¥t Hoáº¡t hÃ³a (Extracting Activations via Hooks)](aero_llm_05_extracting_activations_using_hooks.md) | [Xem bÃ i viáº¿t â†’](aero_llm_05_extracting_activations_using_hooks.md) |
| [Má»‘i tÆ°Æ¡ng quan giá»¯a Hooks vÃ  Hidden States: Giáº£i cáº¥u trÃºc Khá»‘i Transformer (Reconstructing Transformer Blocks)](aero_llm_06_relation_between_hooks_and_output_hidden_states.md) | [Xem bÃ i viáº¿t â†’](aero_llm_06_relation_between_hooks_and_output_hidden_states.md) |
| [LÃ m rÃµ vá» Hidden States Táº§ng cuá»‘i: Vai trÃ² cá»§a LayerNorm (Clarification of Final Hidden States)](aero_llm_07_clarification_of_final_hidden_states_output.md) | [Xem bÃ i viáº¿t â†’](aero_llm_07_clarification_of_final_hidden_states_output.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: TÃ­nh Chá»n lá»c Ngá»¯ phÃ¡p cá»§a NÆ¡-ron MLP (Pháº§n 1)](aero_llm_08_codechallenge_grammar_tuning_in_mlp_neurons_part_1_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_08_codechallenge_grammar_tuning_in_mlp_neurons_part_1_.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: TÃ­nh Chá»n lá»c Ngá»¯ phÃ¡p cá»§a NÆ¡-ron MLP (Pháº§n 2)](aero_llm_09_codechallenge_grammar_tuning_in_mlp_neurons_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_09_codechallenge_grammar_tuning_in_mlp_neurons_part_2_.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Sá»± Äiá»u cháº¿ Ngá»¯ cáº£nh trong Hoáº¡t hÃ³a MLP (Context-modulated Activation)](aero_llm_10_codechallenge_context_modulated_activation_in_mlp.md) | [Xem bÃ i viáº¿t â†’](aero_llm_10_codechallenge_context_modulated_activation_in_mlp.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Äá»™ dÃ i Token vÃ  Äáº·c tÃ­nh Hoáº¡t hÃ³a (Pháº§n 1)](aero_llm_11_codechallenge_activation_histograms_by_token_length_part_1_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_11_codechallenge_activation_histograms_by_token_length_part_1_.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Äá»™ dÃ i Token vÃ  Äáº·c tÃ­nh Hoáº¡t hÃ³a (Pháº§n 2)](aero_llm_12_codechallenge_activation_histograms_by_token_length_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_12_codechallenge_activation_histograms_by_token_length_part_2_.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Äá»™ dÃ i Token vÃ  Äáº·c tÃ­nh Hoáº¡t hÃ³a (Pháº§n 3)](aero_llm_13_codechallenge_activation_histograms_by_token_length_part_3_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_13_codechallenge_activation_histograms_by_token_length_part_3_.md) |
| ğŸ“Œ **[Xá»­ lÃ½ Biá»ƒu diá»…n NÆ¡-ron cho cÃ¡c Tá»« Ä‘a Token (Multi-token Words)](aero_llm_14_dealing_with_multitoken_word_embeddings.md)** | [Xem bÃ i viáº¿t â†’](aero_llm_14_dealing_with_multitoken_word_embeddings.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: HÃ¬nh chiáº¿u MLP Äiá»u chá»‰nh theo Danh má»¥c (Pháº§n 1)](aero_llm_15_codechallenge_category_tuned_mlp_projections_part_1_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_15_codechallenge_category_tuned_mlp_projections_part_1_.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: HÃ¬nh chiáº¿u MLP Äiá»u chá»‰nh theo Danh má»¥c (Pháº§n 2)](aero_llm_16_codechallenge_category_tuned_mlp_projections_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_16_codechallenge_category_tuned_mlp_projections_part_2_.md) |
| [Há»“i quy Logistic: LÃ½ thuyáº¿t vÃ  Triá»ƒn khai PhÃ¢n loáº¡i NÆ¡-ron](aero_llm_17_classification_via_logistic_regression_theory_and_code.md) | [Xem bÃ i viáº¿t â†’](aero_llm_17_classification_via_logistic_regression_theory_and_code.md) |
| [Äá»‘i chiáº¿u Há»“i quy Logistic vÃ  Kiá»ƒm Ä‘á»‹nh T-test: Giáº£ Ä‘á»‹nh vÃ  á»¨ng dá»¥ng](aero_llm_18_logistic_regression_vs_t_test_assumptions_and_applications.md) | [Xem bÃ i viáº¿t â†’](aero_llm_18_logistic_regression_vs_t_test_assumptions_and_applications.md) |
| [Äiá»u chá»‰nh Danh tá»« riÃªng trong GPT-2 Medium](aero_llm_19_proper_noun_tuning_in_gpt2_medium.md) | [Xem bÃ i viáº¿t â†’](aero_llm_19_proper_noun_tuning_in_gpt2_medium.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Äiá»u chá»‰nh Phá»§ Ä‘á»‹nh trong NÆ¡-ron MLP (Pháº§n 1)](aero_llm_20_codechallenge_negation_tuning_in_mlp_neurons_part_1_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_20_codechallenge_negation_tuning_in_mlp_neurons_part_1_.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Äiá»u chá»‰nh Phá»§ Ä‘á»‹nh trong NÆ¡-ron MLP (Pháº§n 2)](aero_llm_21_codechallenge_negation_tuning_in_mlp_neurons_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_21_codechallenge_negation_tuning_in_mlp_neurons_part_2_.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Äiá»u chá»‰nh Phá»§ Ä‘á»‹nh trong NÆ¡-ron MLP (Pháº§n 3)](aero_llm_22_codechallenge_negation_tuning_in_mlp_neurons_part_3_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_22_codechallenge_negation_tuning_in_mlp_neurons_part_3_.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Äiá»u chá»‰nh Phá»§ Ä‘á»‹nh trong NÆ¡-ron QVK (Attention)](aero_llm_23_codechallenge_negation_tuning_in_qvk_neurons.md) | [Xem bÃ i viáº¿t â†’](aero_llm_23_codechallenge_negation_tuning_in_qvk_neurons.md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
