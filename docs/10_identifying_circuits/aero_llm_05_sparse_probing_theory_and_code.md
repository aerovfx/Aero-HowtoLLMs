
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../index.md) > [10 identifying circuits](index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../index.md)
- [ğŸ“š Module 01: LLM Course](../01_llm_course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../02_words_to_tokens_to_numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../04_buildgpt/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../07_fine_tune_pretrained_models/index.md)
- [ğŸ” Module 19: AI Safety](../19_ai_safety/index.md)
- [ğŸ Module 20: Python for AI](../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# LÃ½ Thuyáº¿t VÃ  á»¨ng Dá»¥ng Cá»§a Ká»¹ Thuáº­t DÃ² ThÆ°a (Sparse Probing)

## TÃ³m táº¯t (Abstract)
Ká»¹ thuáº­t "DÃ² thÆ°a" (Sparse probing) lÃ  má»™t thuáº­t toÃ¡n á»©ng dá»¥ng há»“i quy logistic tÃ­ch há»£p cÆ¡ cháº¿ Ã©p chuáº©n L1 (L1 Regularization / Lasso regression). Má»¥c Ä‘Ã­ch cá»§a phÆ°Æ¡ng phÃ¡p nÃ y lÃ  Ã©p pháº§n lá»›n cÃ¡c há»‡ sá»‘ há»“i quy vá» 0 tuyá»‡t Ä‘á»‘i, chá»‰ vinh danh má»™t sá»‘ lÆ°á»£ng cá»±c nhá» cÃ¡c biáº¿n sá»‘ (Táº¿ bÃ o nÆ¡-ron). BÃ¡o cÃ¡o nÃ y trÃ¬nh bÃ y ná»n táº£ng toÃ¡n há»c cá»§a viá»‡c tá»‘i Æ°u hÃ³a hÃ m máº¥t mÃ¡t báº±ng thuáº­t toÃ¡n Stochastic Average Gradient Descent (SAGA), cÃ¹ng thá»±c nghiá»‡m Ã¡p dá»¥ng trÃªn 3072 nÆ¡-ron MLP cá»§a mÃ´ hÃ¬nh GPT-2 Small. Má»¥c tiáº¿u trÃ­ch xuáº¥t vÃ  cÃ´ láº­p má»™t Tá»• há»£p vi nÃ£o bá»™ (Ensemble circuit) siÃªu nhá» cÃ³ kháº£ nÄƒng bÃ¡o hiá»‡u Máº¡o tá»« xÃ¡c Ä‘á»‹nh ("The") vÃ  Máº¡o tá»« khÃ´ng xÃ¡c Ä‘á»‹nh ("An").

---

## 1. Má»Ÿ Äáº§u (Introduction)
Trong bá»‘i cáº£nh phÃ¢n loáº¡i truyá»n thá»‘ng, ta thÆ°á»ng dÃ¹ng Há»“i quy Logistic Ä‘á»ƒ xem xÃ©t Ä‘á»™c láº­p tá»«ng tÃ­nh nÄƒng: liá»‡u NÆ¡-ron X cÃ³ biá»ƒu hiá»‡n má»©c Ä‘á»™ pháº£n á»©ng máº¡nh máº½ hÆ¡n cho tháº» loáº¡i A so vá»›i háº¡ng má»¥c B hay khÃ´ng. 
NhÆ°ng vá»›i Sparse Probing, ta láº­t ngÆ°á»£c lÄƒng kÃ­nh: Äáº§u vÃ o lÃ  má»™t ma tráº­n khá»•ng lá»“ lÃªn tá»›i hÃ ng ngÃ n NÆ¡-ron ($K = 3000+$). Äáº§u ra lÃ  cÃ¢u há»i: ÄÃ¢u lÃ  **Tá»• há»£p Ä‘a Táº¿ bÃ o** (Cluster/Circuit/Ensemble) tá»‘i giáº£n nháº¥t mÃ  sá»± phá»‘i há»£p toÃ¡n há»c cá»§a chÃºng Ä‘á»§ Ä‘á»ƒ Ä‘Æ°a ra dá»± bÃ¡o chÃ­nh xÃ¡c tuyá»‡t Ä‘á»‘i? 
Thá»§ thuáº­t nÃ y cho phÃ©p Ä‘i sÃ¢u tÃ¬m kiáº¿m nhá»¯ng cáº¥u trÃºc hÃ m sá»‘ tinh giáº£n giáº¥u kÃ­n trong biá»ƒn tham sá»‘ khá»•ng lá»“, má»™t khÃ¡i niá»‡m sá»‘ng cÃ²n cá»§a CÆ¡ há»c Giáº£i diá»…n.

---

## 2. Tiáº¿t Thiáº¿t Láº­p ToÃ¡n Há»c (Methodology)

### 2.1. Cáº¥u TrÃºc HÃ m Máº¥t MÃ¡t KÃ©o Giáº£m Chiá»u L1
Giáº£ Ä‘á»‹nh ta cÃ³ táº­p há»‡ sá»‘ há»“i quy (Regression Coefficients) $B = \{\beta_1, \beta_2, ..., \beta_K\}$ Ã¡nh xáº¡ vá»›i táº­p má»©c kÃ­ch hoáº¡t (Activations) $A$ cá»§a má»™t táº­p máº«u.
HÃ m máº¥t mÃ¡t gá»‘c cho bÃ i toÃ¡n Logistic Regression lÃ  **Binary Cross-Entropy (BCE)**:

$$

Loss_{BCE} = -\frac{1}{n} \sum_{i=1}^{n} \left[ y_i \log(p_i) + (1 - y_i) \log(1 - p_i) \right]

$$


Sá»©c máº¡nh cá»§a DÃ² ThÆ°a náº±m á»Ÿ HÃ m Pháº¡t L1 (L1 Penalty) cÃ³ nhiá»‡m vá»¥ trá»«ng trá»‹ tÃ­nh Ä‘a biáº¿n:

$$

Loss_{Reg} = \lambda \sum_{k=1}^{K} |\beta_k|

$$


Tá»•ng há»£p quÃ¡ trÃ¬nh tá»‘i Æ°u hÃ m má»¥c tiÃªu: $\text{Minimize} \left( Loss_{BCE} + Loss_{Reg} \right)$. 
Tham sá»‘ SiÃªu Ä‘á»‹nh hÃ¬nh (Hyperparameter) $\lambda$ quyáº¿t Ä‘á»‹nh cÆ°á»ng Ä‘á»™ cá»§a Ä‘á»™ ThÆ°a (Sparsity). $\lambda$ cÃ ng lá»›n, Ã¡p lá»±c dáº­p $\beta_k \to 0$ cÃ ng gáº¯t, tá»· lá»‡ Máº­t Ä‘á»™ cÃ¡c nÆ¡-ron cÃ²n sá»‘ng sÃ³t (Density constraint) cÃ ng nhá». ThÆ° viá»‡n `scikit-learn` sá»­ dá»¥ng nghá»‹ch Ä‘áº£o cÆ°á»ng Ä‘á»™ cá»±c biÃªn $C = \frac{1}{\lambda}$. 

### 2.2. Huáº¥n Luyá»‡n Cáº­p Nháº­t Äáº¡o HÃ m SAGA
Thuáº­t toÃ¡n leo dá»‘c gradient truyá»n thá»‘ng gáº·p trá»Ÿ ngáº¡i vá»›i hÃ m L1 do Ä‘áº·c Ä‘iá»ƒm Ä‘áº¡o hÃ m khÃ´ng giÃ¡n Ä‘oáº¡n (Non-differentiable) táº¡i tá»a Ä‘á»™ Ä‘iá»ƒm 0. Do váº­y, ná»n táº£ng tá»‘i Æ°u hÃ³a Solver SAGA (Stochastic Average Gradient) Ä‘Æ°á»£c lá»±a chá»n. Nháº±m Ä‘áº£m báº£o quÃ¡ trÃ¬nh dáº­p Ä‘á»‰nh há»™i tá»¥ hoÃ n toÃ n (Convergence), ngÆ°á»¡ng tá»‘i Ä‘a chu ká»³ há»c (Max iterations/epochs) Ä‘Æ°á»£c Ä‘áº©y lÃªn con sá»‘ hÃ ng váº¡n. 

---

## 3. Kháº£o SÃ¡t & Giáº£i Pháº«u MÃ´ HÃ¬nh (Analysis)

### 3.1. Thiáº¿t Láº­p Tiá»n Xá»­ LÃ½ Dá»¯ Liá»‡u NgÃ´n Ngá»¯ Há»c
TrÃªn bá»™ sinh khá»‘i FineWeb, ta trÃ­ch lá»¥c $100$ chuá»—i vÄƒn báº£n xoay quanh máº¡o tá»« xÃ¡c Ä‘á»‹nh "the" vÃ  $100$ nhÃ£n cho "an". YÃªu cáº§u ká»¹ nÄƒng xá»­ lÃ½ BPE Tokenizer kháº¯t khe: pháº£i phÃ¢n biá»‡t rÃµ chá»¯ "the" náº±m Ä‘á»™c láº­p cÃ³ dáº¥u cÃ¡ch Ä‘i kÃ¨m (Prefix spaces logic), tÃ¡ch biá»‡t khá»i chÃ¹m phá»¥ Ã¢m khá»Ÿi Ä‘áº§u (Prefix substring) cá»§a nhá»¯ng tá»« dÃ i nhÆ° "Theology".
Tiáº¿n hÃ nh chÃ­ch xuáº¥t ma tráº­n giÃ¡ trá»‹ Activation táº¡i Ä‘uÃ´i Module $MLP$ hÃ m kÃ­ch hoáº¡t hÃ m `GELU`. 

### 3.2. Hiá»‡n TÆ°á»£ng Sáº­p Máº­t Äá»™ NÆ¡-ron (Extreme Sparsity Density)
Bá»™ Dataset 200 Ä‘iá»ƒm máº«u Ä‘Æ°á»£c phÃ¢n tÃ¡ch theo tá»· lá»‡ Test/Train $140/60$.
Sau khi huáº¥n luyá»‡n mÃ´ hÃ¬nh Logistic kÃ­ch hoáº¡t má»©c pháº¡t háº±ng sá»‘ $C = 10$, mÃ´ hÃ¬nh sinh ra Dá»± bÃ¡o $Accuracy / F1 Score$ tuyá»‡t Ä‘á»‘i $100\%$. 
Viá»…n cáº£nh siÃªu phÃ¢n giáº£i hiá»‡n ra tá»« há»‡ sá»‘ $B$:
- Há»‡ sá»‘ **Sparsity = 99.6%** (2987 trÃªn 3000 NÆ¡-ron bá»‹ vÃ´ hiá»‡u hÃ³a triá»‡t Ä‘á»ƒ cÃ³ $\beta = 0$).
- Há»‡ sá»‘ **Density = 0.4%** (Chá»‰ duy trÃ¬ $13$ táº¿ bÃ o NÆ¡-ron sá»‘ng sÃ³t tham chiáº¿n).
Biá»ƒu Ä‘á»“ phá»• (Scatter scatter plot) chá»©ng minh: Thay vÃ¬ má»™t Máº¡ch dÃ i vÃ´ táº­n, táº­p há»£p chá»‰ vá»n váº¹n $13$ chiáº¿c cÃ´ng táº¯c ToÃ¡n há»c siÃªu nhá» nÃ y Ä‘Ã£ lÄ©nh xÆ°á»›ng trá»n váº¹n toÃ n bá»™ gÃ¡nh náº·ng Logic Ä‘á»ƒ bá»™ mÃ¡y LLM phÃ¢n Ä‘á»‹nh chÃ­nh xÃ¡c khÃ¡i niá»‡m "Máº¡o tá»« xÃ¡c Ä‘á»‹nh" (Definite) vÃ  "Máº¡o tá»« phi xÃ¡c Ä‘á»‹nh" (Indefinite).  

---

## 4. Káº¿t Luáº­n
Báº±ng viá»‡c sá»­ dá»¥ng L1 Regularization, Logistic Regression Ä‘Ã£ Ä‘Æ°á»£c biáº¿n Ä‘á»•i hÃ¬nh thÃ¡i tá»« má»™t cÃ´ng cá»¥ PhÃ¢n loáº¡i Ä‘Æ¡n giáº£n thÃ nh ThÃ¡p dÃ² mÃ¬n (Sparse Probe). Biá»‡n phÃ¡p nÃ y mang Ä‘áº¿n gÃ³c nhÃ¬n Ä‘á»‹nh biÃªn (Framing constraint): Báº¥t cháº¥p khá»‘i lÆ°á»£ng tham sá»‘ ná»Ÿ phÃ¬nh á»Ÿ cÃ¡c Model quy mÃ´ lá»›n, luáº­n lÃ½ bÃªn trong cÃ¡c cáº¥u trÃºc áº©n (Latent constructs) hoÃ n toÃ n cÃ³ thá»ƒ Ä‘Æ°á»£c cÃ´ Ä‘á»ng quy vá» má»™t bÃ³ tia Máº¡ch (Circuit Ensembles) há»¯u háº¡n, vÃ´ cÃ¹ng tinh giáº£n gá»n nháº¹. Giai Ä‘oáº¡n tiáº¿p theo sáº½ Ä‘Ã²i há»i giáº£i quyáº¿t hiá»‡n tÆ°á»£ng Thá»‘ng kÃª Ä‘Ã n Ã¡p (Statistical suppression) náº£y sinh tá»« cÃ¡c phÃ©p thá»­ máº«u quy mÃ´ nhá» cá»§a hÃ m pháº¡t L1.

---

## TÃ i Liá»‡u Tham Kháº£o (Citations)
1. ThÃ­ nghiá»‡m Ä‘o lÆ°á»ng Há»“i quy Logistic L1 vÃ  thá»§ thuáº­t giáº£i quyáº¿t tiá»n xá»­ lÃ½ BPE Whitespace Tokenization tá»« `aero_LLM_05_Sparse probing theory and code.md`. Triá»ƒn khai cá»¥ thá»ƒ qua thuáº­t toÃ¡n SAGA cá»§a `sklearn.linear_model.LogisticRegression(penalty='l1')`.
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| [Máº¡ng Máº¡ch Thuáº­t ToÃ¡n (Circuits) Trong MÃ´ HÃ¬nh Há»c SÃ¢u](aero_llm_01_what_is_a_circuit_in_a_dl_model.md) | [Xem bÃ i viáº¿t â†’](aero_llm_01_what_is_a_circuit_in_a_dl_model.md) |
| [CÃ´ Láº­p VÃ  ThÄƒm DÃ² Khá»‘i ChÃº Ã (Attention Heads)](aero_llm_02_isolating_and_investigating_attention_heads.md) | [Xem bÃ i viáº¿t â†’](aero_llm_02_isolating_and_investigating_attention_heads.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh: Biá»ƒu Diá»…n PhÃ¢n Bá»‘ Nhiá»‡t Laminar Cá»§a Trá»ng Sá»‘ ChÃº Ã](aero_llm_03_codechallenge_laminar_profile_of_attention_head_weights.md) | [Xem bÃ i viáº¿t â†’](aero_llm_03_codechallenge_laminar_profile_of_attention_head_weights.md) |
| [Kháº£o SÃ¡t TÆ°Æ¡ng Quan Cá»¥m (Clustering) Vi Máº¡ch (Circuits) Trong KhÃ´ng Gian Giáº£m Chiá»u](aero_llm_04_are_circuits_clustered_in_low_dimensional_space.md) | [Xem bÃ i viáº¿t â†’](aero_llm_04_are_circuits_clustered_in_low_dimensional_space.md) |
| ğŸ“Œ **[LÃ½ Thuyáº¿t VÃ  á»¨ng Dá»¥ng Cá»§a Ká»¹ Thuáº­t DÃ² ThÆ°a (Sparse Probing)](aero_llm_05_sparse_probing_theory_and_code.md)** | [Xem bÃ i viáº¿t â†’](aero_llm_05_sparse_probing_theory_and_code.md) |
| [ThÃ¡ch Thá»©c Cá»§a TÃ­n Hiá»‡u ThÆ°a Trong Dá»¯ Liá»‡u Táº­p Lá»›n (Statistical Suppression)](aero_llm_06_challenges_with_sparse_logistic_regression_in_large_datasets.md) | [Xem bÃ i viáº¿t â†’](aero_llm_06_challenges_with_sparse_logistic_regression_in_large_datasets.md) |
| [Biáº¿n Tiá»m áº¨n (Latent) VÃ  Biáº¿n Hiá»ƒn NgÃ´n (Manifest) Trong Giáº£i Diá»…n AI](aero_llm_07_latent_vs_manifest_variables.md) | [Xem bÃ i viáº¿t â†’](aero_llm_07_latent_vs_manifest_variables.md) |
| [MÃ´ HÃ¬nh Sparse Autoencoders (SAEs): LÃ½ Thuyáº¿t VÃ  Kiáº¿n TrÃºc KhÃ´i Phá»¥c Vi Máº¡ch Tiá»m áº¨n](aero_llm_08_sparse_autoencoders_theory_and_code.md) | [Xem bÃ i viáº¿t â†’](aero_llm_08_sparse_autoencoders_theory_and_code.md) |
| [Huáº¥n Luyá»‡n Sparse Autoencoder TrÃ­ch Xuáº¥t KhÃ¡i Niá»‡m Ngá»¯ Cáº£nh Palinka TrÃªn GPT-2](aero_llm_09_sae_in_gpt2_learns_about_hungarian_palinka.md) | [Xem bÃ i viáº¿t â†’](aero_llm_09_sae_in_gpt2_learns_about_hungarian_palinka.md) |
| [Kháº£o SÃ¡t PhÃ¢n Táº§ng KÃ­ch Hoáº¡t (Laminar Profile) Qua Sparse Autoencoder](aero_llm_10_codechallenge_laminar_profile_of_autoencoder_sparsity.md) | [Xem bÃ i viáº¿t â†’](aero_llm_10_codechallenge_laminar_profile_of_autoencoder_sparsity.md) |
| [Nháº­n Diá»‡n KhÃ¡i Niá»‡m XuyÃªn TÃ¢m Vá»›i PhÃ¢n RÃ£ GiÃ¡ Trá»‹ RiÃªng Suy Rá»™ng (Generalized Eigendecomposition - GED)](aero_llm_11_non_orthogonal_latent_components_via_eigendecomposition_theory_and_demo_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_11_non_orthogonal_latent_components_via_eigendecomposition_theory_and_demo_.md) |
| [Ráº¡ch RÃ²i Giá»›i TÃ­nh (Him vs Her) Báº±ng Generalized Eigendecomposition Trong MLP](aero_llm_12_generalized_eigendecomposition_separates_him_from_her_in_mlp.md) | [Xem bÃ i viáº¿t â†’](aero_llm_12_generalized_eigendecomposition_separates_him_from_her_in_mlp.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): TÃ¡ch NhÃ³m GED Äa Táº§ng (Pháº§n 1)](aero_llm_13_codechallenge_ged_for_category_isolation_across_layers_part_1_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_13_codechallenge_ged_for_category_isolation_across_layers_part_1_.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): TÃ¡ch NhÃ³m GED Äa Táº§ng (Pháº§n 2) & Kiá»ƒm Chá»©ng ChÃ©o](aero_llm_14_codechallenge_ged_for_category_isolation_across_layers_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_14_codechallenge_ged_for_category_isolation_across_layers_part_2_.md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
