
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../index.md) > [10 identifying circuits](index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../index.md)
- [ğŸ“š Module 01: LLM Course](../01_llm_course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../02_words_to_tokens_to_numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../04_buildgpt/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../07_fine_tune_pretrained_models/index.md)
- [ğŸ” Module 19: AI Safety](../19_ai_safety/index.md)
- [ğŸ Module 20: Python for AI](../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Biáº¿n Tiá»m áº¨n (Latent) VÃ  Biáº¿n Hiá»ƒn NgÃ´n (Manifest) Trong Giáº£i Diá»…n AI

## TÃ³m táº¯t (Abstract)
BÃ¡o cÃ¡o nÃ y lÃ m rÃµ phÆ°Æ¡ng phÃ¡p luáº­n thá»‘ng kÃª Ã¡p dá»¥ng trong ngÃ nh Khoa há»c Há»‡ thá»‘ng phá»©c táº¡p, cá»¥ thá»ƒ lÃ  Mechanistic Interpretability cho LLM. Äá»ƒ mÃ´ phá»ng vÃ  Ä‘á»‹nh lÆ°á»£ng cÃ¡c khÃ¡i niá»‡m trá»«u tÆ°á»£ng bÃªn trong KhÃ´ng gian NÆ¡-ron (NhÆ° "Sá»± chÃº Ã½", "Lá»«a dá»‘i", hay "áº¢o giÃ¡c"), ta khÃ´ng thá»ƒ dÃ¹ng thÆ°á»›c Ä‘o váº­t lÃ½ hay sá»‘ liá»‡u hiá»ƒn ngÃ´n (Manifest variables) Ä‘á»ƒ ghi nháº­n trá»±c tiáº¿p. Thay vÃ o Ä‘Ã³, chÃºng báº¯t buá»™c pháº£i Ä‘Æ°á»£c quy Ä‘á»•i thÃ nh cÃ¡c Cáº¥u trÃºc hÃ m tiá»m áº©n (Latent Constructs). BÃ i viáº¿t phÃ¢n tÃ¡ch giá»›i háº¡n cá»§a phÆ°Æ¡ng trÃ¬nh Manifest vÃ  má»Ÿ Ä‘áº§u cho sá»± cáº¥p thiáº¿t cá»§a cÃ¡c mÃ´ hÃ¬nh Há»“i quy trung gian nhÆ° Sparse Autoencoders (SAE) hay Generalized Eigen Decomposition (GED) trong viá»‡c ná»™i suy hÃ nh vi Ä‘a chiá»u.

---

## 1. Má»Ÿ Äáº§u (Introduction)
Trong Khoa há»c nháº­n thá»©c vÃ  Thá»‘ng kÃª há»c phÃ¢n tÃ­ch, cÃ³ má»™t láº±n ranh rÃµ rá»‡t giá»¯a hai thá»ƒ cháº¿ dá»¯ liá»‡u:
1. **Biáº¿n Hiá»ƒn NgÃ´n (Manifest Variables/Observable Data):** LÃ  nhá»¯ng Ä‘áº¡i lÆ°á»£ng váº­t lÃ½ cÃ³ thá»ƒ Ä‘áº¿m, Ä‘o Ä‘áº¡c hoáº·c tÃ­nh toÃ¡n tuyá»‡t Ä‘á»‘i thÃ´ng qua thiáº¿t bá»‹ mÃ¡y mÃ³c hoáº·c hÃ m sá»‘. VÃ­ dá»¥: Chiá»u cao $(cm)$, LÆ°Æ¡ng thÃ¡ng $(VND)$, GiÃ¡ trá»‹ pháº§n trÄƒm (Logits output), hay Sá»‘ há»‡ sá»‘ phÃ¢n phá»‘i KÃ­ch hoáº¡t Ä‘iá»‡n Ã¡p cá»§a lá»›p MLP.
2. **Biáº¿n Tiá»m áº¨n (Latent Variables/Constructs):** LÃ  cÃ¡c khÃ¡i niá»‡m/há»c thuyáº¿t mÃ  tÆ° duy con ngÆ°á»i Ä‘á»“ng thuáº­n sá»± tá»“n táº¡i cá»§a nÃ³, tá»· lá»‡ tuyáº¿n tÃ­nh/phi tuyáº¿n vá»›i cÃ¡c Ä‘áº¡i lÆ°á»£ng váº­t lÃ½, nhÆ°ng khÃ´ng thá»ƒ Ä‘Æ°á»£c Ä‘á»‹nh vá»‹ bá»Ÿi má»™t thiáº¿t bá»‹ cáº£m biáº¿n thuáº§n tÃºy. VÃ­ dá»¥: Sá»©c khá»e tim máº¡ch, Äá»™ báº¡o lá»±c, Niá»m tá»± hÃ o, vÃ  quan trá»ng nháº¥t trong AI: KhÃ¡i niá»‡m "Sá»± Lá»«a dá»‘i" (Deception) hay "Ná»‹nh hÃ³t" (Sycophancy).

## 2. Tiáº¿t Thiáº¿t Láº­p Cáº¥u TrÃºc (Methodology)

### 2.1. Cáº¥u Kiáº¿n Bá»©c Tranh Tá»•ng Thá»ƒ Báº±ng RÃ¡p Ná»‘i PhÆ°Æ¡ng TrÃ¬nh
Má»¥c Ä‘Ã­ch cá»§a CÆ¡ há»c Giáº£i diá»…n (Mechanistic Interpretability) khÃ´ng bao giá» lÃ  viá»‡c Ä‘á»c hiá»ƒu cáº¥u trÃºc NÆ¡-ron Ä‘á»™c láº­p (Manifest). Thay vÃ o Ä‘Ã³, má»¥c tiÃªu lÃ  sá»­ dá»¥ng má»™t hÃ m Biáº¿n Ä‘á»•i (Transformation matrix) lÃªn cÃ¡c vector Biáº¿n Hiá»ƒn NgÃ´n Ä‘á»ƒ trÃ­ch xuáº¥t ra Vector Tiá»m áº¨n (Latent Vector).

PhÆ°Æ¡ng trÃ¬nh tá»•ng quÃ¡t cho viá»‡c suy diá»…n nÃ y cÃ³ dáº¡ng:

$$

Latent\_Knowledge = Function(Weights, \ Activation\_Patterns\_of\_Neurons)

$$


Trong Ä‘Ã³, hÃ m $Function()$ lÃ  sá»± Káº¿t há»£p trá»ng sá»‘ tuyáº¿n tÃ­nh (Linear weighted combination) hoáº·c má»™t biáº¿n Ä‘á»•i mÃ ng phi tuyáº¿n tÃ­nh, tÃ¹y thuá»™c vÃ o bÃ i toÃ¡n.

### 2.2. Sá»± Äá»• Vá»¡ Tuyáº¿n TÃ­nh (Imperfect Correlations)
TÆ°Æ¡ng tá»± nhÆ° TÃ¢m lÃ½ há»c, nÆ¡i bÃ i kiá»ƒm tra tÃ­nh cÃ¡ch (Manifest) thÆ°á»ng khÃ´ng pháº£i lÃ  pháº£n Ã¡nh chuáº©n táº¯c 100% cá»§a KhÃ­ cháº¥t Extraversion (Latent) bÃªn trong nÃ£o bá»™, CÆ¡ há»c Giáº£i diá»…n váº¥p pháº£i Nghá»‹ch lÃ½ TÃ­nh TÆ°Æ¡ng quan KÃ©m. MÃ´ hÃ¬nh cÃ³ thá»ƒ mang láº¡i káº¿t quáº£ "Ãnh máº¯t (Gaze)" táº­p trung vÃ o á»‘ng kÃ­nh camera vá»›i sá»‘ Ä‘iá»ƒm 10/10, nhÆ°ng "Sá»± táº­p trung" (Attention) cá»§a sinh thá»ƒ láº¡i á»Ÿ má»©c $\approx 0$. 

Äiá»u nÃ y cÅ©ng Ä‘Ãºng vá»›i AI: Model cÃ³ thá»ƒ cho ra káº¿t quáº£ Logit Output 99% phÃ¹ há»£p vá»›i khÃ¡i niá»‡m "Äá»“ng Ã½" (Manifest), nhÆ°ng báº£n thá»ƒ Latent bÃªn trong nÃ³ Ä‘ang cháº¡y má»™t cá»¥m Vi nÃ£o Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ "Lá»«a Dá»‘i" (Deception mode). ÄÃ¢y lÃ  sá»± Ä‘e dá»a sinh tá»­ cho AI Safety.

---

## 3. Kháº£o SÃ¡t PhÆ°Æ¡ng LÃ½ (Analysis)

Viá»‡c khai thÃ¡c Máº¡ch Tiá»m áº¨n (Latent Circuit) dá»±a ráº­p khuÃ´n vÃ o phÆ°Æ¡ng thá»©c gom cá»¥m Táº¿ bÃ o hiá»ƒn mÃ´n (Manifest neurons) Ä‘Ã£ váº¥p pháº£i giá»›i háº¡n (nhÆ° chá»©ng minh tá»« sá»± tháº¥t báº¡i cá»§a Thuáº­t toÃ¡n T-SNE Ä‘á»‘i vá»›i sá»± phÃ¢n máº£nh Circuit ngá»¯ phÃ¡p). Do Ä‘Ã³, giá»›i nghiÃªn cá»©u AI Ä‘Ã£ chuyá»ƒn dá»‹ch á»©ng dá»¥ng sang cÃ¡c thiáº¿t cháº¿ HÃ m Tá»‘i Æ¯u khÃ´ng gian Latent Ä‘a chiá»u cá»±c ká»³ hiá»‡n Ä‘áº¡i:
- **PhÃ¢n tÃ­ch chiá»u gá»‘c (PCA) / PhÃ¢n rÃ£ giÃ¡ trá»‹ áº£o (SVD):** CÆ¡ báº£n cho cÃ¡c mÃ´ hÃ¬nh nhá».
- **Autoencoders (Äáº·c biá»‡t lÃ  Sparse Autoencoders - SAE):** Tá»± xÃ© nhá» vÃ  nÃ©n Vector biá»ƒu diá»…n Ä‘á»ƒ lá»c láº¥y cÃ¡c tÃ­nh nÄƒng phi cáº¥u trÃºc trong siÃªu khÃ´ng gian Ä‘a chiá»u.
- **PhÃ¢n rÃ£ Eigen suy rá»™ng (Generalized Eigen-Decomposition - GED):** DÃ² tÃ¬m cÃ¡c Äiá»ƒm cá»™ng hÆ°á»Ÿng quang phá»• thay vÃ¬ Táº¿ bÃ o cÆ¡ há»c váº­t lÃ½.

---

## 4. Káº¿t Luáº­n
Viá»‡c ná»— lá»±c trÃ­ch xuáº¥t cÃ¡c Biáº¿n sá»‘ Tiá»m áº¨n tá»« cÃ¡c Sá»‘ liá»‡u Hiá»ƒn ngÃ´n lÃ  bÃ i toÃ¡n khÃ³ báº­c nháº¥t, luÃ´n tá»“n táº¡i rá»§i ro vá» sai lá»‡ch suy diá»…n khÃ´ng thá»ƒ Ä‘o Ä‘áº¡c do "thá»±c thá»ƒ Tiá»m áº©n Ä‘Ã³ náº±m ngoÃ i vÃ¹ng tiáº¿p cáº­n váº­t lÃ½". Äáº·c biá»‡t trong AI Safety, kháº£ nÄƒng diá»…n giáº£i Latent lÃ  vÅ© khÃ­ Ä‘á»™c quyá»n Ä‘á»ƒ truy thu cÃ¡c khÃ¡i niá»‡m nguy hiá»ƒm mÃ  mÃ´ hÃ¬nh LLM Ä‘Ã£ tá»± Ä‘á»™ng tÃ­ch lÅ©y (Lá»«a lá»c, Cáº£o giÃ¡c, Rá»‘i loáº¡n phÃ¢n ly). Trong cÃ¡c bÃ¡o cÃ¡o káº¿ tiáº¿p, cÆ¡ cháº¿ trÃ­ch xuáº¥t Sparse Autoencoder vÃ  Generalized Eigendecomposition sáº½ Ä‘Æ°á»£c lÃ m rÃµ vá» máº·t hÃ¬nh thÃ¡i sá»‘ há»c.

---

## TÃ i Liá»‡u Tham Kháº£o (Citations)
1. Thuyáº¿t Biáº¿n Trá»«u TÆ°á»£ng táº¡i `aero_LLM_07_Latent vs. manifest variables.md`. Giáº£i trÃ¬nh sá»± chuyá»ƒn Ä‘á»•i vá»‹ trÃ­ tá»« dá»¯ liá»‡u Manifest (NhÆ° Activations Neurons, Next-token Logits) sang hÃ m há»c thuyáº¿t Latent (Deception, Concept Abstraction).
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| [Máº¡ng Máº¡ch Thuáº­t ToÃ¡n (Circuits) Trong MÃ´ HÃ¬nh Há»c SÃ¢u](aero_llm_01_what_is_a_circuit_in_a_dl_model.md) | [Xem bÃ i viáº¿t â†’](aero_llm_01_what_is_a_circuit_in_a_dl_model.md) |
| [CÃ´ Láº­p VÃ  ThÄƒm DÃ² Khá»‘i ChÃº Ã (Attention Heads)](aero_llm_02_isolating_and_investigating_attention_heads.md) | [Xem bÃ i viáº¿t â†’](aero_llm_02_isolating_and_investigating_attention_heads.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh: Biá»ƒu Diá»…n PhÃ¢n Bá»‘ Nhiá»‡t Laminar Cá»§a Trá»ng Sá»‘ ChÃº Ã](aero_llm_03_codechallenge_laminar_profile_of_attention_head_weights.md) | [Xem bÃ i viáº¿t â†’](aero_llm_03_codechallenge_laminar_profile_of_attention_head_weights.md) |
| [Kháº£o SÃ¡t TÆ°Æ¡ng Quan Cá»¥m (Clustering) Vi Máº¡ch (Circuits) Trong KhÃ´ng Gian Giáº£m Chiá»u](aero_llm_04_are_circuits_clustered_in_low_dimensional_space.md) | [Xem bÃ i viáº¿t â†’](aero_llm_04_are_circuits_clustered_in_low_dimensional_space.md) |
| [LÃ½ Thuyáº¿t VÃ  á»¨ng Dá»¥ng Cá»§a Ká»¹ Thuáº­t DÃ² ThÆ°a (Sparse Probing)](aero_llm_05_sparse_probing_theory_and_code.md) | [Xem bÃ i viáº¿t â†’](aero_llm_05_sparse_probing_theory_and_code.md) |
| [ThÃ¡ch Thá»©c Cá»§a TÃ­n Hiá»‡u ThÆ°a Trong Dá»¯ Liá»‡u Táº­p Lá»›n (Statistical Suppression)](aero_llm_06_challenges_with_sparse_logistic_regression_in_large_datasets.md) | [Xem bÃ i viáº¿t â†’](aero_llm_06_challenges_with_sparse_logistic_regression_in_large_datasets.md) |
| ğŸ“Œ **[Biáº¿n Tiá»m áº¨n (Latent) VÃ  Biáº¿n Hiá»ƒn NgÃ´n (Manifest) Trong Giáº£i Diá»…n AI](aero_llm_07_latent_vs_manifest_variables.md)** | [Xem bÃ i viáº¿t â†’](aero_llm_07_latent_vs_manifest_variables.md) |
| [MÃ´ HÃ¬nh Sparse Autoencoders (SAEs): LÃ½ Thuyáº¿t VÃ  Kiáº¿n TrÃºc KhÃ´i Phá»¥c Vi Máº¡ch Tiá»m áº¨n](aero_llm_08_sparse_autoencoders_theory_and_code.md) | [Xem bÃ i viáº¿t â†’](aero_llm_08_sparse_autoencoders_theory_and_code.md) |
| [Huáº¥n Luyá»‡n Sparse Autoencoder TrÃ­ch Xuáº¥t KhÃ¡i Niá»‡m Ngá»¯ Cáº£nh Palinka TrÃªn GPT-2](aero_llm_09_sae_in_gpt2_learns_about_hungarian_palinka.md) | [Xem bÃ i viáº¿t â†’](aero_llm_09_sae_in_gpt2_learns_about_hungarian_palinka.md) |
| [Kháº£o SÃ¡t PhÃ¢n Táº§ng KÃ­ch Hoáº¡t (Laminar Profile) Qua Sparse Autoencoder](aero_llm_10_codechallenge_laminar_profile_of_autoencoder_sparsity.md) | [Xem bÃ i viáº¿t â†’](aero_llm_10_codechallenge_laminar_profile_of_autoencoder_sparsity.md) |
| [Nháº­n Diá»‡n KhÃ¡i Niá»‡m XuyÃªn TÃ¢m Vá»›i PhÃ¢n RÃ£ GiÃ¡ Trá»‹ RiÃªng Suy Rá»™ng (Generalized Eigendecomposition - GED)](aero_llm_11_non_orthogonal_latent_components_via_eigendecomposition_theory_and_demo_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_11_non_orthogonal_latent_components_via_eigendecomposition_theory_and_demo_.md) |
| [Ráº¡ch RÃ²i Giá»›i TÃ­nh (Him vs Her) Báº±ng Generalized Eigendecomposition Trong MLP](aero_llm_12_generalized_eigendecomposition_separates_him_from_her_in_mlp.md) | [Xem bÃ i viáº¿t â†’](aero_llm_12_generalized_eigendecomposition_separates_him_from_her_in_mlp.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): TÃ¡ch NhÃ³m GED Äa Táº§ng (Pháº§n 1)](aero_llm_13_codechallenge_ged_for_category_isolation_across_layers_part_1_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_13_codechallenge_ged_for_category_isolation_across_layers_part_1_.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): TÃ¡ch NhÃ³m GED Äa Táº§ng (Pháº§n 2) & Kiá»ƒm Chá»©ng ChÃ©o](aero_llm_14_codechallenge_ged_for_category_isolation_across_layers_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_14_codechallenge_ged_for_category_isolation_across_layers_part_2_.md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
