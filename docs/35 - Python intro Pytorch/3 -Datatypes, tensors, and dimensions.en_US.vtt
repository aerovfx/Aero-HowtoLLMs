WEBVTT

00:02.080 --> 00:10.920
There are two main libraries that are used in Python for building and training, and working with large

00:11.080 --> 00:14.400
language models, and basically all deep learning models.

00:14.480 --> 00:19.840
One is called PyTorch and the other one is called TensorFlow.

00:20.160 --> 00:21.040
TensorFlow.

00:21.040 --> 00:21.680
Like this.

00:21.920 --> 00:28.800
Now in this course I'm only using PyTorch because, um, it's a little bit of an arbitrary choice,

00:28.800 --> 00:35.720
but it is more widely used and it's a little bit easier to learn compared to TensorFlow in terms of

00:35.720 --> 00:37.040
the syntax and so on.

00:37.560 --> 00:37.880
Okay.

00:37.920 --> 00:43.520
So to import the main PyTorch library you write import torch.

00:43.800 --> 00:45.000
So it's called torch.

00:45.160 --> 00:48.920
This will import the library into your Python workspace.

00:49.160 --> 00:56.120
There are submodules in the torch library that are also often abbreviated.

00:56.120 --> 01:01.430
So for example there's torch and that is often abbreviated as PN.

01:01.750 --> 01:04.630
The N stands for Neural Networks.

01:04.790 --> 01:11.830
This module contains a lot of classes and other properties that are often used when building models

01:11.830 --> 01:12.670
from scratch.

01:12.670 --> 01:17.070
So you will see this when we start building from scratch.

01:17.270 --> 01:22.190
And then there is import torch dot functional.

01:22.550 --> 01:29.990
And this is a module that contains a lot of individual functions that are used outside or separately

01:29.990 --> 01:31.190
from classes.

01:31.190 --> 01:34.790
And that one is often abbreviated just using the capital letter F.

01:36.030 --> 01:41.270
Now in the next several videos I'm not going to be using these modules.

01:41.270 --> 01:45.590
I'm just going to be introducing you to the main torch library.

01:45.590 --> 01:48.550
So in fact, we don't actually need these for now.

01:48.550 --> 01:49.230
But that's okay.

01:49.230 --> 01:50.150
You see them anyway.

01:50.710 --> 01:56.750
Okay, so the idea of PyTorch is to represent numbers as tensors.

01:56.750 --> 01:57.910
What is a tensor.

01:58.390 --> 02:05.700
So in linear algebra we have different terms for different sizes of collections of numbers.

02:05.700 --> 02:12.340
So for example, if you just have one number we call this a scalar, a scalar like this.

02:12.340 --> 02:18.740
So this is the linear algebra term for just an individual number floating about in the ether.

02:19.100 --> 02:25.620
If you have a one dimensional list of numbers that can be like something like this.

02:25.900 --> 02:27.340
So this is just one dimensional.

02:27.340 --> 02:28.700
These are all in a row.

02:28.900 --> 02:31.180
This is called a vector.

02:31.340 --> 02:33.780
And vectors can be in rows like this.

02:34.140 --> 02:37.100
Vectors can also be in columns like this.

02:37.100 --> 02:40.140
This would be a column vector technically in Python.

02:40.140 --> 02:46.540
If you wanted to make this a column, you need another set of brackets around each of these numbers

02:46.540 --> 02:48.660
so that each of these is its own row.

02:49.300 --> 02:50.780
So there are vectors.

02:50.980 --> 02:54.380
And then we have matrices.

02:54.500 --> 02:58.420
And a matrix is where you have multiple rows.

02:58.420 --> 03:01.130
So I'm just making up random numbers here.

03:01.450 --> 03:02.770
Let's just leave it at this.

03:02.850 --> 03:05.290
So this is a matrix.

03:05.290 --> 03:09.250
And in particular this is a two by three matrix.

03:09.250 --> 03:16.170
I'll write that down two by three because there are two rows and each row has three columns.

03:16.330 --> 03:19.490
So this would be considered a two by three matrix.

03:19.650 --> 03:26.330
Now I'm cheating a little bit because the way I'm writing this down, it's actually a list not a matrix.

03:26.330 --> 03:27.810
But I could do something like this.

03:27.810 --> 03:31.250
I could make this be a numpy array.

03:31.250 --> 03:33.570
And then this is I haven't imported numpy.

03:34.170 --> 03:38.570
Let me see import numpy as np okay.

03:38.610 --> 03:42.610
And now you see this looks like a matrix okay.

03:42.850 --> 03:44.210
So we have a scalar.

03:44.210 --> 03:45.370
We have a vector.

03:45.370 --> 03:46.650
We have a matrix.

03:46.810 --> 03:55.050
And then the idea of PyTorch is to represent everything using tensors a tensor is a three dimensional

03:55.050 --> 03:58.970
cube of numbers or any higher dimension than two.

03:59.810 --> 04:00.840
So uh.

04:00.840 --> 04:01.120
Yeah.

04:01.160 --> 04:03.000
A scalar is just a point.

04:03.040 --> 04:04.640
A vector is a line.

04:04.960 --> 04:07.360
A matrix is like a sheet of paper.

04:07.360 --> 04:12.080
Like a spreadsheet, like an Excel spreadsheet where you have rows and columns.

04:12.480 --> 04:18.840
Now, when you stack a bunch of spreadsheets on top of each other, you get a cube of data.

04:19.080 --> 04:23.520
So that would be like a two by three by four matrix.

04:23.520 --> 04:26.480
And now we're starting to talk about tensors.

04:26.680 --> 04:26.880
Okay.

04:26.920 --> 04:30.800
I will show you examples of tensors in a little bit.

04:30.840 --> 04:37.200
But first I just want to, uh, introduce you to the data type in PyTorch.

04:37.200 --> 04:38.320
It's called a tensor.

04:38.480 --> 04:41.760
So v equals torch dot tensor.

04:42.040 --> 04:43.840
And let's just start with the number one.

04:44.080 --> 04:45.560
So here we see v.

04:45.600 --> 04:47.960
It is a tensor that is the type.

04:47.960 --> 04:55.040
And in this case it's uh like a zero dimensional tensor because it doesn't have any length breadth or

04:55.040 --> 04:55.440
width.

04:55.440 --> 04:57.840
It's just the scalar one okay.

04:57.880 --> 05:03.990
And then I can make this 10.4 for something and it's still just a single element tensor.

05:04.430 --> 05:06.950
Let's see the type of v.

05:06.990 --> 05:10.070
So the type is a torch dot tensor.

05:10.750 --> 05:11.030
Okay.

05:11.070 --> 05:12.790
So now I want to try something else.

05:12.830 --> 05:16.070
V equals torch dot tensor.

05:16.390 --> 05:19.110
And now I'm going to write one.

05:19.110 --> 05:21.750
So this is really similar to what I had up here.

05:21.790 --> 05:23.110
Let me go back to this.

05:23.750 --> 05:28.230
And then in fact I'm just going to copy and paste like this.

05:28.510 --> 05:28.750
Okay.

05:28.790 --> 05:34.230
Now these two code cells are really really similar to each other, but they're not identical.

05:34.630 --> 05:40.230
And they are not identical because this one is contained in a bracket.

05:40.390 --> 05:42.190
So this is a scalar.

05:42.390 --> 05:45.270
And this is actually now a vector.

05:45.470 --> 05:47.350
It is a one dimensional vector.

05:47.350 --> 05:51.590
It has a one row and that contains the number one.

05:51.590 --> 05:53.950
So these two are not exactly the same.

05:54.190 --> 05:55.670
And we can do even more.

05:55.710 --> 05:58.430
I can put in another bracket here.

05:58.430 --> 06:00.550
And now actually let me start also.

06:00.550 --> 06:02.310
So you see the type is tenser.

06:02.470 --> 06:03.710
That's less interesting.

06:04.230 --> 06:05.630
V dot shape.

06:05.630 --> 06:10.270
And then I will also write again here V dot shape.

06:10.510 --> 06:10.990
Okay.

06:11.190 --> 06:16.430
So here the shape is empty because it's just a zero dimensional scalar.

06:16.750 --> 06:18.910
Here the shape is one by one.

06:18.910 --> 06:20.550
Let me go back to here.

06:20.830 --> 06:24.510
So here the shape is one because this is a vector.

06:24.670 --> 06:28.630
There's only one element in this vector but it's still a vector here.

06:28.670 --> 06:31.310
Now I have A2A matrix.

06:31.310 --> 06:32.790
It's a one by one matrix.

06:32.790 --> 06:37.230
It only contains one element but it's one row and one column.

06:37.390 --> 06:45.550
So internally PyTorch represents this as a matrix which we can also call a two dimensional tensor.

06:46.030 --> 06:47.790
And you know we can go nuts with this.

06:47.790 --> 06:50.990
So here we have a three dimensional tensor.

06:50.990 --> 06:56.750
Now here you see the shape of this piece of information is actually a cube.

06:56.750 --> 06:58.870
It has three dimensions.

06:59.190 --> 07:07.340
It's still only one element in each dimension, but it is represented internally inside PyTorch as a

07:07.340 --> 07:08.820
cube of numbers.

07:08.820 --> 07:10.620
So a three dimensional tensor.

07:10.900 --> 07:12.780
Let's do a little bit more with this.

07:12.780 --> 07:18.180
How about let's create a variable w1 torch dot tensor.

07:18.660 --> 07:24.220
And now I'm going to make a slightly bigger variable here.

07:24.220 --> 07:30.180
So 123 and then 456 like this.

07:30.580 --> 07:32.060
And actually I'll put this up here.

07:32.700 --> 07:33.020
Okay.

07:33.060 --> 07:35.300
So here I have let me print this out now.

07:35.820 --> 07:37.660
So here we have a tensor.

07:37.700 --> 07:40.740
This is a two dimensional tensor.

07:40.900 --> 07:48.420
In linear algebra we would more frequently call this a matrix but a two by three matrix.

07:48.620 --> 07:55.460
But in in the parlance of PyTorch we refer to this as a two dimensional tensor.

07:55.620 --> 07:57.420
So it has two rows.

07:57.580 --> 08:04.250
The first row is one, two, three and the second row is four, five, six, and it has three columns,

08:04.250 --> 08:05.770
so one and then four.

08:05.810 --> 08:09.010
That's the first column two and five and three and six.

08:09.010 --> 08:15.850
So when we look at the shape of this variable, this tensor, we can see that it is indeed two by three

08:15.850 --> 08:18.250
two rows and three columns.

08:19.130 --> 08:19.490
Okay.

08:19.530 --> 08:25.010
So what I'm going to do now is copy and paste this.

08:25.010 --> 08:28.410
And I'm going to create a new variable called w2.

08:28.730 --> 08:37.250
And w2 is going to be almost exactly the same as W1, except I'm adding another set of square brackets

08:37.250 --> 08:37.770
here.

08:37.930 --> 08:38.330
Okay.

08:38.370 --> 08:41.330
So the rows are exactly the same.

08:41.330 --> 08:42.450
The numbers are the same.

08:42.450 --> 08:49.770
The number of numbers is exactly the same, but this one has an additional set of brackets around each

08:49.770 --> 08:51.010
of these rows.

08:51.170 --> 08:53.890
So now let's look at the shape of w2.

08:54.410 --> 08:56.130
This is the shape of w1.

08:56.330 --> 08:57.450
It is two by three.

08:57.490 --> 08:59.010
It's what we already discovered.

08:59.010 --> 09:02.760
Now the shape of W2 is one by two by three.

09:03.160 --> 09:04.920
By the way, do not confuse this.

09:04.920 --> 09:08.920
Maybe I'll change this just to make sure that this is very clear.

09:09.440 --> 09:11.920
1012 and I don't know, minus three.

09:12.120 --> 09:18.080
I don't want you to accidentally confuse these numbers with the numbers that were in the first row.

09:18.080 --> 09:20.360
Completely, completely separate numbers.

09:20.680 --> 09:24.640
This is the information that's stored in this tensor.

09:24.960 --> 09:31.840
And this is the the number of elements along each dimension in the tensor.

09:32.880 --> 09:37.800
So what we have here in W2 is a three dimensional tensor.

09:38.000 --> 09:40.040
So it's a cube of numbers.

09:40.200 --> 09:49.040
But the first element the first dimension only has one set of matrices which is this one here.

09:49.800 --> 09:54.640
And to make that very clear what I'm going to do now is create another one.

09:54.640 --> 09:56.480
So let's do 543.

09:56.920 --> 10:00.430
And how about I don't know 946.

10:00.470 --> 10:02.030
Okay, so the spacing is different.

10:02.070 --> 10:03.790
Actually maybe I'll make the spacing the same.

10:04.390 --> 10:04.790
Okay.

10:04.830 --> 10:07.310
That will hopefully make it more clear.

10:07.310 --> 10:10.710
So let's see if I lined up all of the brackets here.

10:10.710 --> 10:11.390
Yes I have.

10:11.430 --> 10:11.750
Okay.

10:11.790 --> 10:14.070
So notice this gets really confusing.

10:14.070 --> 10:19.630
But notice I have the rows all come in these individual brackets.

10:19.630 --> 10:27.430
And then I have another level of organization that's grouping these two and and these two right.

10:27.470 --> 10:27.670
Okay.

10:27.710 --> 10:29.710
So I need another bracket here.

10:29.990 --> 10:32.150
And then another closing bracket here.

10:32.190 --> 10:32.630
Okay.

10:33.230 --> 10:34.830
You can see this gets very confusing.

10:34.830 --> 10:40.030
So now the size of this cube of numbers is two by two by three.

10:40.350 --> 10:43.670
So this is the first element here.

10:43.830 --> 10:47.230
This is the second element in the first dimension.

10:47.230 --> 10:52.550
So the first dimension here contains these two two by three matrices.

10:52.550 --> 10:57.790
So two rows and three columns inside each of these first two elements here.

10:58.390 --> 11:05.380
So how can we index all of these rows and matrices inside this tensor.

11:05.740 --> 11:08.300
So we can write let's see w1.

11:08.740 --> 11:12.780
If I just index zero that's going to give me the first row.

11:13.020 --> 11:13.260
Okay.

11:13.300 --> 11:17.060
So this and also let me change this to nine just to make sure that's clear.

11:17.540 --> 11:17.860
Okay.

11:17.900 --> 11:23.260
So now I am indexing the first row of this tensor.

11:23.460 --> 11:27.780
And that's just the numbers 923 because that's the first row here.

11:28.100 --> 11:28.380
Okay.

11:28.420 --> 11:35.380
But then if I ask for the same index from W2 what is that going to return.

11:35.620 --> 11:42.820
Well that's still going to return just the first like sub super row here from this first dimension.

11:42.820 --> 11:46.740
And that actually contains a two by three matrix.

11:46.740 --> 11:50.780
So that result is all of these numbers over here.

11:51.180 --> 11:52.420
I hope that makes sense.

11:52.460 --> 11:54.060
Think about it as a cube.

11:54.060 --> 11:58.620
And we are slicing the cube in different orientations in different ways.
