WEBVTT

00:01.840 --> 00:09.480
I mentioned in the previous section that we are going to take an experimental approach to understanding

00:09.480 --> 00:10.320
deep learning.

00:10.680 --> 00:14.680
That means that we are going to be running lots of experiments.

00:14.920 --> 00:21.240
And when running experiments, one of the things that we need to do is determine whether one particular

00:21.240 --> 00:27.960
model, architecture or set of meta parameters is better than a different architecture or a different

00:27.960 --> 00:29.800
set of meta parameters.

00:30.040 --> 00:34.080
So how do we determine whether our experiment was successful?

00:34.120 --> 00:39.760
How do we determine whether one model architecture is significantly better than another?

00:40.200 --> 00:43.000
So the answer to that question is a t test.

00:43.000 --> 00:45.880
We are going to be performing t tests.

00:46.160 --> 00:47.520
So what is a t test?

00:47.560 --> 00:55.480
A t test is a way to determine whether data drawn from one distribution is significantly different from

00:55.640 --> 00:59.480
data drawn from another distribution or another sample.

01:00.000 --> 01:07.500
So imagine each of these little circles here corresponds to the accuracy of a model with architecture

01:07.540 --> 01:10.300
A, and this is model architecture B.

01:10.700 --> 01:15.420
So we have a bunch of prediction or categorization accuracies here and here.

01:15.660 --> 01:21.620
And we want to know whether, you know, model A is significantly better than model B, which would

01:21.620 --> 01:28.460
mean that the accuracies for model A are significantly higher than the accuracies for model B.

01:28.860 --> 01:32.300
And the way that we test this is using a t test.

01:32.740 --> 01:38.380
So h a here corresponds to stands for the alternative hypothesis.

01:38.380 --> 01:44.420
So the hypothesis is that this model is significantly different from this model.

01:44.620 --> 01:46.620
So this is the alternative hypothesis.

01:46.620 --> 01:52.980
And we evaluate the alternative hypothesis relative to what's called a null hypothesis.

01:53.020 --> 01:58.420
It's often written down as h sub zero for h naught or h null.

01:58.420 --> 02:00.100
So this is the null hypothesis.

02:00.520 --> 02:06.880
The null hypothesis states that the two models perform equally well, so that means that we could mix

02:06.880 --> 02:13.560
up all of the accuracies from the two models, and it doesn't change the average accuracy from model

02:13.560 --> 02:19.000
from this collection versus this collection, because the two models perform equally well.

02:19.440 --> 02:25.160
So the goal of the T test is to provide evidence against the null hypothesis.

02:25.640 --> 02:32.480
And if there is enough evidence strong enough evidence against the null hypothesis, then we go with

02:32.480 --> 02:38.040
the alternative hypothesis, which would be that this model is significantly better than this model.

02:38.040 --> 02:43.200
And that's how we distinguish between different kinds of models and their performance on data sets.

02:43.640 --> 02:52.480
By the way, it's also possible to use a t test for one set of model performance data against some arbitrary

02:52.520 --> 02:55.560
null value, for example, 50% accuracy.

02:55.560 --> 03:02.260
Let's say if the model is doing, you know, two two alternative choice discrimination than 50% would

03:02.260 --> 03:05.700
be would correspond to accuracy of chance.

03:05.860 --> 03:11.620
So we can test whether the model is doing significantly better than chance level of 50%.

03:11.660 --> 03:18.180
However, in this course, we are mostly going to be using the t test to compare different model architectures

03:18.180 --> 03:22.060
or different model parameters directly against each other, like this.

03:22.420 --> 03:25.420
So here is the basic formula for the t test.

03:25.460 --> 03:28.620
The t test gives us one single value.

03:28.660 --> 03:29.980
That's the t value.

03:30.260 --> 03:33.180
And it's governed by this pretty simple equation.

03:33.180 --> 03:40.460
So we have the mean of x minus the mean of y divided by s which corresponds to the standard deviation

03:40.740 --> 03:44.460
itself normalized by the square root of n and n.

03:44.660 --> 03:48.380
Here corresponds to the number of times that we repeat the model.

03:48.500 --> 03:54.140
So if we rerun the model let's say 20 times then this would be the square root of 20.

03:54.580 --> 04:01.490
Now don't worry too much about the math because we are going to be we're going to allow SciPy, a Python

04:01.490 --> 04:05.170
library to implement to compute the t value for us.

04:05.370 --> 04:06.890
What I want you to remember.

04:06.890 --> 04:11.130
The important thing to remember here is what this formula means.

04:11.290 --> 04:12.210
So the t test.

04:12.250 --> 04:17.730
The t value is the difference of the means divided by the standard deviations.

04:17.770 --> 04:18.010
All.

04:18.050 --> 04:21.090
You just have to remember this concept.

04:21.130 --> 04:25.970
The difference of the means divided by or normalized by the standard deviations.

04:26.090 --> 04:27.730
That gives us a t value.

04:28.010 --> 04:30.250
And then what do we do with this t value.

04:30.530 --> 04:37.410
Well we have to evaluate this t value relative to a distribution of t values that we would expect under

04:37.410 --> 04:38.890
the null hypothesis.

04:39.170 --> 04:45.770
Again the null hypothesis is that there are no differences between the two different model architectures.

04:45.890 --> 04:48.450
So the two model architectures are the same.

04:48.850 --> 04:50.970
And any differences we might observe.

04:50.970 --> 04:57.690
Any minor differences between the two models in terms of their performance is not actually due to the

04:57.690 --> 05:01.590
models, it's actually just due to random sampling variability.

05:01.590 --> 05:06.390
So here you see again this concept of sampling variability and randomness appearing.

05:06.870 --> 05:14.190
So given random sampling variability you would expect that the model accuracies would differ a little

05:14.230 --> 05:16.270
bit just by random chance.

05:16.390 --> 05:24.310
And so what you see here is a t distribution a distribution of t statistic values that we expect under

05:24.310 --> 05:25.750
the null hypothesis.

05:26.270 --> 05:27.990
This is not something that we compute.

05:27.990 --> 05:31.710
This is something we analytically derive from a formula.

05:32.070 --> 05:34.270
Of course SciPy implements that.

05:34.270 --> 05:37.070
So SciPy is taking care of the details of this for us.

05:37.630 --> 05:42.350
So then we compute our observed t value in the real data.

05:42.350 --> 05:46.750
These are the real data that we have measured in our deep learning models.

05:47.070 --> 05:48.630
And we compare this value.

05:48.670 --> 05:51.150
Let's say this t value is 1.5.

05:51.390 --> 05:55.870
We compare this value against a statistical significance threshold.

05:56.070 --> 06:02.410
And this threshold comes from specifying a p value threshold of, for example, 0.05.

06:02.610 --> 06:04.850
So 0.05 is a pretty typical value.

06:04.890 --> 06:14.490
0.05 means that there is a 5% chance that we observed a statistic of this size, given these data purely

06:14.490 --> 06:17.770
by chance, just by random sampling variability.

06:18.330 --> 06:23.770
So in this particular example, we have a t value of 1.5.

06:23.970 --> 06:25.730
And that is below the threshold.

06:25.730 --> 06:27.810
So below the significance threshold.

06:27.810 --> 06:30.090
So the p value is 0.065.

06:30.250 --> 06:31.370
And what does this mean.

06:32.130 --> 06:39.250
Well this means that our two different models are two different deep learning model architectures actually

06:39.250 --> 06:44.450
gave the same performance, which means that the models perform equally well.

06:44.450 --> 06:51.130
There is no real significant meaningful difference between the two models in terms of how they perform

06:51.130 --> 06:52.690
on a given data set.

06:53.210 --> 06:59.950
Now, if the models were more different from each other, then the T value would be larger, which means

06:59.950 --> 07:05.310
that this yellow arrow here would be to the right of this significance threshold.

07:05.430 --> 07:08.310
This corresponding p value would be below 0.05.

07:08.310 --> 07:13.750
And then we would interpret that result as saying that one model is significantly better.

07:13.750 --> 07:17.110
It has better higher accuracy than the other models.

07:17.110 --> 07:20.870
So therefore we should prefer the model that has higher accuracy.

07:21.110 --> 07:27.830
Now let's switch to Python and I will show you how to implement a t test using SciPy.

07:29.750 --> 07:35.190
So here we import our libraries pretty standard to import numpy and matplotlib.

07:35.470 --> 07:39.070
Here I'm also importing scipy.stats.

07:39.070 --> 07:43.390
So this is actually a submodule of the scipy library.

07:43.750 --> 07:46.750
And we're going to abbreviate it as stats.

07:46.790 --> 07:46.950
Okay.

07:46.990 --> 07:51.350
So let's run the code in this cell to import all of these libraries.

07:51.550 --> 07:54.270
Here what I'm doing is generating random data.

07:54.310 --> 08:01.530
This is just, you know, just coming up with some fake data just to illustrate how the SciPy dot stats

08:01.570 --> 08:02.690
library works.

08:03.090 --> 08:09.410
So here you can see I'm generating random numbers with some number of samples.

08:09.410 --> 08:11.810
And here it's actually a different number of samples.

08:11.810 --> 08:14.370
And then I'm adding a mean offset.

08:14.370 --> 08:16.890
So this is the the mean of data set one.

08:16.890 --> 08:18.970
And this is the mean of data set two.

08:19.170 --> 08:22.330
And then we're going to plot those two samples.

08:22.770 --> 08:26.930
So here we see all of the samples from group one samples from group two.

08:27.050 --> 08:32.570
So visually it's obvious that group two is a little bit higher than group one.

08:32.810 --> 08:38.890
But the question is is this a statistically significant difference between these two groups?

08:38.930 --> 08:39.050
Right.

08:39.090 --> 08:43.450
It's not so obvious that every single data point is higher.

08:43.450 --> 08:43.650
Right.

08:43.650 --> 08:45.610
You can see there's quite a bit of overlap here.

08:45.650 --> 08:45.890
Okay.

08:45.930 --> 08:51.570
So is this difference in the means between the two groups a statistically significant difference.

08:52.130 --> 08:57.090
So to do that we are going to use stats dot t test I.

08:57.090 --> 09:00.710
And the IND is for independent samples.

09:00.710 --> 09:03.790
Now there are several different varieties of t tests.

09:03.790 --> 09:09.230
There are several different formulas that you would use depending on the nature of the data.

09:09.550 --> 09:15.910
Explaining all these different variants of a T test is something you would get into in a statistics

09:15.910 --> 09:19.950
course or machine learning, like a traditional statistics or machine learning course.

09:20.150 --> 09:26.710
Here in this deep learning course, we're only going to be using the independent samples t test okay.

09:26.790 --> 09:30.870
So we call the t test function input the two data set.

09:30.910 --> 09:37.270
So again in the context of this course this is going to be all of the accuracies from model one.

09:37.270 --> 09:40.630
And this will be all of the accuracies of model two.

09:41.030 --> 09:49.150
And the outputs of the stats dot t test function is t and p comes out as a tuple.

09:49.390 --> 09:52.390
And the the first output is the t value.

09:52.390 --> 09:54.390
And then we get the p value.

09:54.750 --> 10:00.610
So in this case the t value is minus four and the p value is less than 0.05.

10:00.610 --> 10:02.850
It's actually much, much less than 0.05.

10:03.010 --> 10:09.810
So in this case, the t test is telling us that group two has a significant, statistically significantly

10:09.810 --> 10:12.490
larger mean than group one.

10:12.970 --> 10:15.730
Now why is this T value negative here?

10:15.850 --> 10:19.690
Well the sign of a t statistic is pretty arbitrary.

10:19.890 --> 10:25.330
It just depends on the order that you input the two sets of samples.

10:25.410 --> 10:29.130
So for example now I'm going to change this to data two and data one.

10:29.130 --> 10:32.490
So now it's the larger mean minus the smaller mean.

10:32.610 --> 10:35.970
So now you'll see this number is going to be exactly the same.

10:36.170 --> 10:39.650
But it's going to be plus four instead of minus four.

10:40.130 --> 10:40.490
Okay.

10:40.530 --> 10:42.530
So this is one way to show the data.

10:42.530 --> 10:48.570
But notice that you know it's kind of hard to see all of the data values here because they are all overlapping,

10:48.570 --> 10:51.770
particularly in this case where I'm plotting them as squares.

10:51.890 --> 10:58.200
So what I'm going to show you now is a different way of visualizing the data, which just makes it a

10:58.200 --> 11:00.160
little bit easier to look at.

11:00.440 --> 11:05.080
So here what I'm doing is adding an x coordinate value.

11:05.240 --> 11:06.880
That is just random numbers.

11:06.880 --> 11:08.480
These are pure random numbers.

11:08.760 --> 11:10.560
I'm scaling them down by 15.

11:10.600 --> 11:12.440
There's nothing special about 15.

11:12.480 --> 11:16.520
It's an arbitrary number that I just came up with based on visualization.

11:16.560 --> 11:18.520
And let me show you what this does.

11:19.280 --> 11:25.120
So here you see it just gives some random x axis offsets to these data points.

11:25.120 --> 11:29.920
That just makes it a little bit easier to visualize what the distribution looks like.

11:29.920 --> 11:31.440
This is pretty commonly done.

11:32.520 --> 11:33.240
A few other things.

11:33.240 --> 11:35.400
Or one more thing I want to mention about this plotting.

11:35.480 --> 11:41.760
I said, by the way, earlier in this course that if you are relatively new to Python, then you can

11:41.760 --> 11:47.040
also use this course as an opportunity to improve your Python coding skills.

11:47.040 --> 11:52.640
And throughout the rest of this course, I'm going to try to slowly and gently introduce you to new

11:53.000 --> 11:58.580
and more advanced features of Python coding and Python visualization.

11:58.580 --> 12:02.300
So here I am modifying the built in parameters.

12:02.300 --> 12:05.300
I'm updating the the Python parameters.

12:05.300 --> 12:08.180
And in particular I'm inputting a dictionary.

12:08.540 --> 12:14.300
And the dictionary is going to specify that the font size should be 12.

12:14.340 --> 12:17.700
So just to illustrate what happens here we can change this to 20.

12:17.900 --> 12:21.380
And now you know it's a little the font size is a little too big I think.

12:21.380 --> 12:23.340
But you know it gets the point home.

12:23.820 --> 12:30.860
Now after this video, what I would like you to do is spend a few moments with this code.

12:31.060 --> 12:36.020
Actually, the whole code script, not just this cell, and play around with some of these parameters

12:36.020 --> 12:37.300
that I have specified here.

12:37.300 --> 12:42.940
For example, you can try changing this value now just increasing this to 150.

12:43.180 --> 12:46.740
This also looks pretty good I think maybe it's a little bit too tight.

12:46.900 --> 12:48.860
So this is something you can play around with.

12:49.140 --> 12:55.620
And more importantly, I would like you to play around with some of these parameters the ends and the

12:55.620 --> 12:56.300
muse.

12:56.300 --> 13:00.640
So for example, let's see if we set this to 1.2.

13:01.080 --> 13:08.560
So now the two samples are they differ in their population means by a value a distance of 0.2 instead

13:08.560 --> 13:09.080
of two.

13:09.520 --> 13:13.240
So that's going to create two distributions that are closer to each other.

13:13.480 --> 13:19.000
And we can see now this is not at all statistically significantly different right.

13:19.040 --> 13:25.520
The p value has to be below 0.05 in order for the result to be significant.

13:27.520 --> 13:35.000
In this video I introduce you to the general idea of the t test and the basic formula of the T test.

13:35.040 --> 13:38.720
There are many different variations of a t test in this course.

13:38.720 --> 13:41.600
We are going to keep it pretty simple, pretty straightforward.

13:41.760 --> 13:49.000
And we're going to be using the t test as a means to explore and run experiments on different deep learning

13:49.000 --> 13:49.680
models.

13:49.680 --> 13:55.400
And that's a way for us to learn more about different kinds of architectures and how they perform.
