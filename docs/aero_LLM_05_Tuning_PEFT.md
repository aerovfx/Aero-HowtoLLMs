# Lecture 5: LLM Tuning (SFT & Parameter Efficient) ğŸ›ï¸

> **TÃ³m táº¯t tá»« khÃ³a há»c Stanford CME 295: Transformers & Large Language Models.**
> BÃ i giáº£ng nÃ y táº­p trung vÃ o giai Ä‘oáº¡n sau Pre-training: Supervised Fine-Tuning (SFT) Ä‘á»ƒ biáº¿n mÃ´ hÃ¬nh thÃ nh trá»£ lÃ½, vÃ  cÃ¡c ká»¹ thuáº­t Fine-tuning hiá»‡u quáº£ (PEFT/LoRA).

---

## ğŸ“š Má»¥c Lá»¥c
1. [Supervised Fine-Tuning (SFT)](#1-supervised-fine-tuning-sft)
2. [Instruction Tuning](#2-instruction-tuning)
3. [Dá»¯ liá»‡u cho SFT](#3-dá»¯-liá»‡u-cho-sft)
4. [Parameter-Efficient Fine-Tuning (PEFT)](#4-parameter-efficient-fine-tuning-peft)
5. [LoRA (Low-Rank Adaptation)](#5-lora-low-rank-adaptation)
6. [QLoRA (Quantized LoRA)](#6-qlora-quantized-lora)

---

## 1. Supervised Fine-Tuning (SFT)
Sau Pre-training, mÃ´ hÃ¬nh giá»‘ng nhÆ° má»™t "con váº¹t thÃ´ng thÃ¡i" - biáº¿t ráº¥t nhiá»u nhÆ°ng chá»‰ biáº¿t dá»± Ä‘oÃ¡n tá»« tiáº¿p theo chá»© khÃ´ng biáº¿t tráº£ lá»i cÃ¢u há»i hay lÃ m theo lá»‡nh.

**Má»¥c tiÃªu cá»§a SFT:**
*   Dáº¡y mÃ´ hÃ¬nh cÃ¡ch **hÃ nh xá»­** (Behavior) mong muá»‘n.
*   Biáº¿n Base model -> Chat/Instruct model.

**Quy trÃ¬nh:**
*   Input: CÃ¡c cáº·p cÃ¢u há»i - cÃ¢u tráº£ lá»i (Prompt - Response) cháº¥t lÆ°á»£ng cao.
*   Loss: Váº«n dÃ¹ng Next token prediction, nhÆ°ng chá»‰ tÃ­nh loss trÃªn pháº§n cÃ¢u tráº£ lá»i (Response), khÃ´ng tÃ­nh trÃªn pháº§n cÃ¢u há»i (Prompt).

---

## 2. Instruction Tuning
LÃ  má»™t dáº¡ng cá»§a SFT, táº­p trung vÃ o viá»‡c dáº¡y mÃ´ hÃ¬nh tuÃ¢n theo cÃ¡c chá»‰ dáº«n (instructions) Ä‘a dáº¡ng.

*   **TÃ¡c vá»¥:** TÃ³m táº¯t, dá»‹ch, viáº¿t code, giáº£i toÃ¡n, viáº¿t thÆ¡, danh sÃ¡ch...
*   **Zero-shot Generalization:** Sau khi Ä‘Æ°á»£c Instruction Tuning trÃªn nhiá»u tÃ¡c vá»¥, mÃ´ hÃ¬nh cÃ³ kháº£ nÄƒng thá»±c hiá»‡n cáº£ nhá»¯ng tÃ¡c vá»¥ má»›i mÃ  nÃ³ chÆ°a tá»«ng tháº¥y trong quÃ¡ trÃ¬nh training (nhá» kháº£ nÄƒng suy luáº­n tá»•ng quÃ¡t).

---

## 3. Dá»¯ liá»‡u cho SFT
Cháº¥t lÆ°á»£ng quan trá»ng hÆ¡n sá»‘ lÆ°á»£ng ("Quality is King").

*   **Nguá»“n dá»¯ liá»‡u:**
    *   *Human-generated:* Do con ngÆ°á»i viáº¿t (Ä‘áº¯t Ä‘á», cháº¥t lÆ°á»£ng cao).
    *   *LLM-generated (Synthetic data):* DÃ¹ng mÃ´ hÃ¬nh máº¡nh (GPT-4) Ä‘á»ƒ táº¡o dá»¯ liá»‡u training cho mÃ´ hÃ¬nh nhá» hÆ¡n. (Ráº», nhanh, nhÆ°ng cáº§n kiá»ƒm soÃ¡t cháº¥t lÆ°á»£ng).
*   **Quy mÃ´:** Chá»‰ cáº§n hÃ ng nghÃ¬n Ä‘áº¿n hÃ ng trÄƒm nghÃ¬n máº«u (Ã­t hÆ¡n nhiá»u so vá»›i hÃ ng tá»· tokens cá»§a Pre-training).
*   **VÃ­ dá»¥:** Dataset phá»• biáº¿n: Alpaca, Vicuna, Lima.

---

## 4. Parameter-Efficient Fine-Tuning (PEFT)
Fine-tuning toÃ n bá»™ mÃ´ hÃ¬nh (Full Fine-tuning) ráº¥t tá»‘n kÃ©m (cáº§n VRAM gáº¥p nhiá»u láº§n kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh Ä‘á»ƒ lÆ°u Optimizer states).

**PEFT:** Chá»‰ cáº­p nháº­t má»™t pháº§n nhá» tham sá»‘ hoáº·c thÃªm cÃ¡c module nhá» vÃ o mÃ´ hÃ¬nh, giá»¯ Ä‘Ã´ng cá»©ng (freeze) pháº§n lá»›n trá»ng sá»‘ gá»‘c.

**Lá»£i Ã­ch:**
*   Giáº£m yÃªu cáº§u VRAM.
*   TrÃ¡nh hiá»‡n tÆ°á»£ng "Catastrophic Forgetting" (QuÃªn kiáº¿n thá»©c cÅ©).
*   Dá»… dÃ ng chia sáº» cÃ¡c Adapter nhá» (vÃ i chá»¥c MB) thay vÃ¬ cáº£ mÃ´ hÃ¬nh GB.

---

## 5. LoRA (Low-Rank Adaptation)
Ká»¹ thuáº­t PEFT phá»• biáº¿n nháº¥t hiá»‡n nay.

**Ã tÆ°á»Ÿng:**
Thay vÃ¬ cáº­p nháº­t trá»±c tiáº¿p ma tráº­n trá»ng sá»‘ $W$ (kÃ­ch thÆ°á»›c $d \times d$), ta cáº­p nháº­t thÃ´ng qua 2 ma tráº­n nhá» $A$ vÃ  $B$:
$$ W' = W + \Delta W = W + BA $$
Trong Ä‘Ã³:
*   $B$: kÃ­ch thÆ°á»›c $d \times r$
*   $A$: kÃ­ch thÆ°á»›c $r \times d$
*   $r$ (rank): ráº¥t nhá» (vÃ­ dá»¥ 8, 16, 64) so vá»›i $d$.

**Káº¿t quáº£:** Sá»‘ lÆ°á»£ng tham sá»‘ cáº§n train giáº£m hÃ ng nghÃ¬n láº§n, nhÆ°ng hiá»‡u quáº£ tÆ°Æ¡ng Ä‘Æ°Æ¡ng Full Fine-tuning.

---

## 6. QLoRA (Quantized LoRA)
Káº¿t há»£p Quantization vÃ  LoRA Ä‘á»ƒ train mÃ´ hÃ¬nh lá»›n trÃªn GPU nhá».

*   **4-bit NormalFloat (NF4):** Má»™t kiá»ƒu dá»¯ liá»‡u má»›i tá»‘i Æ°u cho trá»ng sá»‘ phÃ¢n phá»‘i chuáº©n cá»§a Neural Network.
*   **Double Quantization:** Quantize cáº£ cÃ¡c háº±ng sá»‘ quantization Ä‘á»ƒ tiáº¿t kiá»‡m thÃªm bá»™ nhá»›.
*   **Paged Optimizers:** Sá»­ dá»¥ng CPU RAM Ä‘á»ƒ offload optimizer states khi GPU bá»‹ trÃ n bá»™ nhá»› (OOM).

-> Cho phÃ©p train mÃ´ hÃ¬nh 65B parameters trÃªn má»™t GPU 48GB.

---
*BiÃªn soáº¡n bá»Ÿi Pixiboss - Dá»±a trÃªn Stanford CME 295.*
