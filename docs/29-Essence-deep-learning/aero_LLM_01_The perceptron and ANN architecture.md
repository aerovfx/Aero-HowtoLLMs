
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../index.md) > [29 Essence deep learning](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../index.md)
- [ğŸ“š Module 01: LLM Course](../../01-LLM_Course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../02-Words-to-tokens-to-numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../04-buildGPT/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../07-Fine-tune-pretrained-models/index.md)
- [ğŸ” Module 19: AI Safety](../../19-AI-safety/index.md)
- [ğŸ Module 20: Python for AI](../../20-Python-Colab-notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Há»c sÃ¢u: Perceptron vÃ  Kiáº¿n trÃºc Máº¡ng NÆ¡-ron NhÃ¢n táº¡o (ANN)

## TÃ³m táº¯t (Abstract)
BÃ¡o cÃ¡o nÃ y nghiÃªn cá»©u vá» cÃ¡c khá»‘i xÃ¢y dá»±ng cÆ¡ báº£n cá»§a máº¡ng nÆ¡-ron nhÃ¢n táº¡o (Artificial Neural Networks - ANN), báº¯t Ä‘áº§u tá»« mÃ´ hÃ¬nh Perceptron. chÃºng ta phÃ¢n tÃ­ch cáº¥u trÃºc cá»§a má»™t Ä‘Æ¡n vá»‹ tÃ­nh toÃ¡n cÆ¡ báº£n bao gá»“m: cÃ¡c nÃºt Ä‘áº§u vÃ o (input nodes), cÃ¡c trá»ng sá»‘ liÃªn káº¿t (weights), phÃ©p toÃ¡n tÃ­ch vÃ´ hÆ°á»›ng (dot product) vÃ  vai trÃ² cá»§a hÃ m kÃ­ch hoáº¡t phi tuyáº¿n (activation function). NghiÃªn cá»©u giáº£i mÃ£ lÃ½ do táº¡i sao má»™t mÃ´ hÃ¬nh tuyáº¿n tÃ­nh thuáº§n tÃºy lÃ  khÃ´ng Ä‘á»§ Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n phá»©c táº¡p trong tháº¿ giá»›i thá»±c vÃ  thuyáº¿t minh vá» táº§m quan trá»ng cá»§a thÃ nh pháº§n Ä‘á»‹nh kiáº¿n (bias term) â€“ tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i há»‡ sá»‘ cháº·n (intercept) trong thá»‘ng kÃª â€“ Ä‘á»ƒ tá»‘i Æ°u hÃ³a kháº£ nÄƒng phÃ¢n tÃ¡ch cá»§a cÃ¡c siÃªu pháº³ng trong khÃ´ng gian dá»¯ liá»‡u.

---

## 1. Cáº¥u trÃºc cá»§a má»™t Perceptron

Perceptron lÃ  "táº¿ bÃ o" cÆ¡ báº£n cá»§a má»i kiáº¿n trÃºc há»c sÃ¢u. NÃ³ hoáº¡t Ä‘á»™ng nhÆ° má»™t cá»— mÃ¡y tÃ­nh toÃ¡n Ä‘Æ¡n giáº£n vá»›i quy trÃ¬nh ba bÆ°á»›c:
1. **Tiáº¿p nháº­n Äáº§u vÃ o:** Má»™t táº­p há»£p cÃ¡c sá»‘ thá»±c Ä‘áº¡i diá»‡n cho dá»¯ liá»‡u Ä‘áº§u vÃ o ($x_1, x_2, ..., x_n$).
2. **Trá»ng sá»‘ vÃ  TÃ­nh toÃ¡n:** Má»—i Ä‘áº§u vÃ o Ä‘Æ°á»£c nhÃ¢n vá»›i má»™t trá»ng sá»‘ tÆ°Æ¡ng á»©ng ($w_1, w_2, ..., w_n$), sau Ä‘Ã³ Ä‘Æ°á»£c cá»™ng dá»“n láº¡i.
3. **Äáº§u ra:** Káº¿t quáº£ tá»•ng há»£p (weighted sum) Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i thÃ nh má»™t giÃ¡ trá»‹ Ä‘áº§u ra duy nháº¥t.

Vá» báº£n cháº¥t toÃ¡n há»c, Perceptron thá»±c hiá»‡n phÃ©p tÃ­nh **tÃ­ch vÃ´ hÆ°á»›ng** giá»¯a vÃ©c-tÆ¡ Ä‘áº§u vÃ o $x$ vÃ  vÃ©c-tÆ¡ trá»ng sá»‘ $w$:
$$y = x^T w = \sum_{i=1}^{n} x_i w_i$$

---

## 2. TÃ­nh Tuyáº¿n tÃ­nh vÃ  Giá»›i háº¡n phÃ¢n tÃ¡ch

Perceptron thuáº§n tÃºy lÃ  má»™t **mÃ´ hÃ¬nh tuyáº¿n tÃ­nh**. Äiá»u nÃ y cÃ³ nghÄ©a lÃ  nÃ³ chá»‰ thá»±c hiá»‡n cÃ¡c phÃ©p cá»™ng vÃ  nhÃ¢n vÃ´ hÆ°á»›ng:
- **Æ¯u Ä‘iá»ƒm:** Cá»±c ká»³ hiá»‡u quáº£ trong viá»‡c giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n "tuyáº¿n tÃ­nh kháº£ phÃ¢n" (linearly separable), nÆ¡i chÃºng ta cÃ³ thá»ƒ tÃ¡ch biá»‡t hai nhÃ³m dá»¯ liá»‡u báº±ng má»™t Ä‘Æ°á»ng tháº³ng.
- **Háº¡n cháº¿:** KhÃ´ng thá»ƒ giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n phá»©c táº¡p hÆ¡n nÆ¡i dá»¯ liá»‡u bá»‹ trá»™n láº«n theo cÃ¡c mÃ´ hÃ¬nh cong hoáº·c xoáº¯n á»‘c.
- **Quy táº¯c vÃ ng:** KhÃ´ng nÃªn dÃ¹ng mÃ´ hÃ¬nh phi tuyáº¿n cho bÃ i toÃ¡n tuyáº¿n tÃ­nh (gÃ¢y phá»©c táº¡p hÃ³a vÃ´ Ã­ch) vÃ  tuyá»‡t Ä‘á»‘i khÃ´ng thá»ƒ dÃ¹ng mÃ´ hÃ¬nh tuyáº¿n tÃ­nh cho bÃ i toÃ¡n phi tuyáº¿n (khÃ´ng thá»ƒ giáº£i quyáº¿t Ä‘Æ°á»£c).

---

## 3. HÃ m KÃ­ch hoáº¡t (Activation Function)

Äá»ƒ má»Ÿ rá»™ng kháº£ nÄƒng cá»§a máº¡ng nÆ¡-ron, chÃºng ta Ä‘Æ°a káº¿t quáº£ cá»§a phÃ©p tÃ­nh tuyáº¿n tÃ­nh qua má»™t hÃ m phi tuyáº¿n $\sigma$ (thÆ°á»ng Ä‘Æ°á»£c gá»i lÃ  hÃ m kÃ­ch hoáº¡t):
$$\hat{y} = \sigma(x^T w)$$
- **VÃ­ dá»¥ cÆ¡ báº£n:** HÃ m signum (hÃ m dáº¥u) tráº£ vá» +1 náº¿u tá»•ng lá»›n hÆ¡n 0 vÃ  -1 náº¿u ngÆ°á»£c láº¡i.
- **Vai trÃ²:** PhÃ¡ vá»¡ tÃ­nh tuyáº¿n tÃ­nh, cho phÃ©p mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c cÃ¡c ranh giá»›i quyáº¿t Ä‘á»‹nh phá»©c táº¡p hÆ¡n. Trong há»c sÃ¢u hiá»‡n Ä‘áº¡i, chÃºng ta thÆ°á»ng sá»­ dá»¥ng cÃ¡c hÃ m nhÆ° ReLU, Sigmoid hoáº·c Tanh.

---

## 4. Vai trÃ² cá»§a ThÃ nh pháº§n Äá»‹nh kiáº¿n (Bias Term)

ThÃ nh pháº§n Ä‘á»‹nh kiáº¿n (bias) lÃ  má»™t tham sá»‘ Ä‘á»™c láº­p khÃ´ng liÃªn káº¿t vá»›i dá»¯ liá»‡u Ä‘áº§u vÃ o. NÃ³ tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i biáº¿n $b$ trong phÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»ng tháº³ng $y = mx + b$:
- **LÃ½ do cáº§n thiáº¿t:** Náº¿u khÃ´ng cÃ³ bias, má»i "Ä‘Æ°á»ng ranh giá»›i" mÃ  mÃ´ hÃ¬nh táº¡o ra buá»™c pháº£i Ä‘i qua gá»‘c tá»a Ä‘á»™ $(0,0)$. Äiá»u nÃ y lÃ m háº¡n cháº¿ kháº£ nÄƒng phÃ¢n loáº¡i náº¿u cÃ¡c cá»¥m dá»¯ liá»‡u náº±m á»Ÿ nhá»¯ng vá»‹ trÃ­ xa gá»‘c tá»a Ä‘á»™.
- **Thá»±c thi:** Trong cÃ¡c thÆ° viá»‡n nhÆ° PyTorch, bias Ä‘Æ°á»£c tÃ­ch há»£p sáºµn theo máº·c Ä‘á»‹nh. NÃ³ cho phÃ©p mÃ´ hÃ¬nh dá»‹ch chuyá»ƒn Ä‘Æ°á»ng ranh giá»›i linh hoáº¡t trÃªn khÃ´ng gian dá»¯ liá»‡u Ä‘á»ƒ tÃ¬m ra vá»‹ trÃ­ phÃ¢n tÃ¡ch tá»‘i Æ°u nháº¥t.

---

## 5. Káº¿t luáº­n
Perceptron lÃ  sá»± káº¿t há»£p hoÃ n háº£o giá»¯a giáº£i tÃ­ch tuyáº¿n tÃ­nh vÃ  cÃ¡c phÃ©p toÃ¡n phi tuyáº¿n Ä‘Æ¡n giáº£n. ToÃ n bá»™ sá»©c máº¡nh cá»§a cÃ¡c mÃ´ hÃ¬nh LLM khá»•ng lá»“ thá»±c cháº¥t lÃ  sá»± chá»“ng cháº¥t cá»§a hÃ ng tá»· Ä‘Æ¡n vá»‹ Perceptron nÃ y theo cÃ¡c kiáº¿n trÃºc Ä‘a táº§ng phá»©c táº¡p. Tháº¥u hiá»ƒu báº£n cháº¥t cá»§a trá»ng sá»‘, tÃ­ch vÃ´ hÆ°á»›ng vÃ  bias lÃ  bÆ°á»›c Ä‘i Ä‘áº§u tiÃªn Ä‘á»ƒ lÃ m chá»§ quÃ¡ trÃ¬nh huáº¥n luyá»‡n vÃ  tá»‘i Æ°u hÃ³a cÃ¡c máº¡ng nÆ¡-ron nhÃ¢n táº¡o trong tÆ°Æ¡ng lai.

---

## TÃ i liá»‡u tham kháº£o (Citations)
1. NguyÃªn lÃ½ kiáº¿n trÃºc vÃ  cÃ´ng thá»©c toÃ¡n há»c cá»§a Perceptron dá»±a trÃªn `aero_LL_01_The perceptron and ANN architecture.md`. PhÃ¢n tÃ­ch vai trÃ² cá»§a tÃ­ch vÃ´ hÆ°á»›ng, hÃ m kÃ­ch hoáº¡t phi tuyáº¿n vÃ  thÃ nh pháº§n Ä‘á»‹nh kiáº¿n trong tá»‘i Æ°u hÃ³a máº¡ng nÆ¡-ron.
<!-- Aero-Footer-Start -->
---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
