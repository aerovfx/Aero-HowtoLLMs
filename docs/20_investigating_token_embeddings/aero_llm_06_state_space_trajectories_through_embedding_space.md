
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../index.md) > [20 investigating token embeddings](index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../index.md)
- [ğŸ“š Module 01: LLM Course](../01_llm_course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../02_words_to_tokens_to_numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../04_buildgpt/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../07_fine_tune_pretrained_models/index.md)
- [ğŸ” Module 19: AI Safety](../19_ai_safety/index.md)
- [ğŸ Module 20: Python for AI](../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Quá»¹ Äáº¡o KhÃ´ng Gian Tráº¡ng ThÃ¡i (State-Space Trajectories) Cá»§a Há»‡ Vector NgÃ´n Ngá»¯

## TÃ³m táº¯t (Abstract)
BÃ¡o cÃ¡o trÃ¬nh bÃ y phÆ°Æ¡ng phÃ¡p phÃ¢n tÃ­ch Quá»¹ Ä‘áº¡o khÃ´ng gian tráº¡ng thÃ¡i (State-space trajectories), má»™t ká»¹ thuáº­t phÃ¢n rÃ£ chiá»u dá»¯ liá»‡u Ã¡p dá»¥ng cho khá»‘i Embeddings cá»§a mÃ´ hÃ¬nh ngÃ´n ngá»¯. Thá»±c nghiá»‡m trÃªn GPT-2 Medium tÃ­ch há»£p thuáº­t toÃ¡n PCA (Principal Component Analysis) Ä‘á»ƒ ngÆ°ng tá»¥ khÃ´ng gian ngÃ n chiá»u (1024 dimensions) cá»§a Token vectors xuá»‘ng máº·t pháº³ng tá»a Ä‘á»™ 2D. Báº±ng cÃ¡ch quan sÃ¡t chuyá»ƒn Ä‘á»™ng tá»‹nh tiáº¿n cá»§a ba biáº¿n thá»ƒ Ä‘áº¡i tá»« (`him`, `her`, vÃ  lá»—i ngá»¯ phÃ¡p `round`) bÄƒng qua 24 khá»‘i Transformer, nghiÃªn cá»©u Ä‘o Ä‘áº¡c má»©c Ä‘á»™ phÃ¢n ká»³ khoáº£ng cÃ¡ch khÃ´ng gian (Euclidean distance). DÃ¹ giáº£i thÃ­ch Ä‘Æ°á»£c 80% tá»•ng phÆ°Æ¡ng sai, phÆ°Æ¡ng phÃ¡p PCA váº«n tiá»m áº©n rá»§i ro diá»…n giáº£i sai lá»‡ch do Ä‘Ã¡nh Ä‘á»“ng phÆ°Æ¡ng sai vá»›i sá»± liÃªn quan ngá»¯ nghÄ©a (variance vs relevance).

---

## 1. Má»Ÿ Äáº§u (Introduction)
Sá»± phá»©c táº¡p cá»§a há»™p Ä‘en má»• xáº» LLM chá»§ yáº¿u Ä‘áº¿n tá»« rÃ o cáº£n Ä‘a chiá»u (High-dimensionality). Viá»‡c pháº£i theo dÃµi sá»± chuyá»ƒn Ä‘á»™ng cá»§a Vector Embeddings trong khÃ´ng gian 1000 chiá»u lÃ  Ä‘iá»u báº¥t kháº£ thi vá»›i nháº­n thá»©c trá»±c quan.
Äá»ƒ giáº£i pháº«u quÃ¡ trÃ¬nh Ä‘á»‹nh hÆ°á»›ng, ta cÃ³ thá»ƒ dÃ¹ng ká»¹ thuáº­t Giáº£m chiá»u dá»¯ liá»‡u (Dimensionality Reduction) - Ä‘áº·c trÆ°ng lÃ  PhÃ¢n tÃ­ch thÃ nh pháº§n chÃ­nh (PCA) Ä‘á»ƒ dáº­p cÃ¡c vector vá» chung má»™t bÃ¬nh diá»‡n khÃ´ng gian 2 trá»¥c/3 trá»¥c (Principal Components). Sá»± tá»‹nh tiáº¿n cá»§a Vector Ä‘i tá»« Tráº¡m sinh tá»« Ä‘áº§u tiÃªn (Embeddings Matrix) Ä‘áº¿n chá»‘t xáº£ lÅ© cuá»‘i (Final Transformer block) sáº½ váº½ nÃªn má»™t "Quá»¹ Ä‘áº¡o KhÃ´ng gian tráº¡ng thÃ¡i".

---

## 2. Thiáº¿t Láº­p ThÃ­ Nghiá»‡m & PhÆ°Æ¡ng PhÃ¡p Chuyá»ƒn Äá»•i (Methodology)

### 2.1. Cáº¥u TrÃºc Biáº¿n Thá»ƒ VÄƒn Báº£n
Lá»±a chá»n má»™t táº­p há»£p 54 cÃ¢u vÄƒn báº£n tÄ©nh. Sau Ä‘Ã³ ngá»¥y táº¡o 3 há»‡ dá»¯ liá»‡u (Datasets) Ä‘á»™c láº­p dá»±a trÃªn viá»‡c Ä‘Ã¡nh trÃ¡o Token Má»¥c TiÃªu (Target Token):
1. NhÃ³m 1: Äáº¡i tá»« nhÃ¢n xÆ°ng `"her"` (Chuáº©n ngá»¯ phÃ¡p).
2. NhÃ³m 2: Äáº¡i tá»« nhÃ¢n xÆ°ng `"him"` (Chuáº©n ngá»¯ phÃ¡p).
3. NhÃ³m 3: TÃ­nh tá»« `"round"` (Lá»—i sai ngá»¯ phÃ¡p báº» gÃ£y cáº¥u trÃºc cÃ¢u, vÃ­ dá»¥: "we invited *round* to dinner").

### 2.2. NhÃºng Tá»a Äá»™ Há»‡ Tham Chiáº¿u Chung (Common Projection Space)
Má»™t lá»—i sai nghiÃªm trá»ng khi lÃ m PCA lÃ  cháº¡y hÃ m Fit tÃ¡ch biá»‡t cho tá»«ng lá»›p layer. Náº¿u lÃ m váº­y, má»—i lá»›p layer sáº½ sinh ra má»™t táº­p tá»a Ä‘á»™ cÆ¡ sá»Ÿ (Basis Vectors) hÆ°á»›ng khÃ¡c nhau, lÃ m gÃ£y Ä‘á»©t sá»± liÃªn káº¿t so sÃ¡nh trá»±c tiáº¿p.
Giáº£i phÃ¡p: GhÃ©p ná»‘i toÃ n bá»™ dá»¯ liá»‡u (Concatenation) dá»c theo trá»¥c Token tá»« táº¥t cáº£ cÃ¡c cÃ¢u vÄƒn vÃ  táº¥t cáº£ cÃ¡c Transformer Layers ($4050 \text{ vectors} \times 1024 \text{ dimensions}$). Sau Ä‘Ã³ náº¡p vÃ o bá»™ hÃ m `sklearn.decomposition.PCA` Ä‘á»ƒ láº¥y vá» trá»¥c Tá»a Ä‘á»™ cá»‘t lÃµi duy nháº¥t chá»©a Ä‘á»±ng quy luáº­t chung nháº¥t cho há»‡ dá»¯ liá»‡u.

---

## 3. Kháº£o SÃ¡t ÄÃ¡nh GiÃ¡: Quá»¹ Äáº¡o & Äiá»ƒm MÃ¹ (Analysis)

### 3.1. Sá»± TrÆ°Æ¡ng Ná»Ÿ Cá»§a Quá»¹ Äáº¡o Chuyá»ƒn Äá»™ng (Trajectory Distances)
Khi ráº£i Ä‘Æ°á»ng viá»n theo Layer:
- á» cÃ¡c Ä‘iá»ƒm Ä‘áº§u (lÃºc má»›i nhÃºng Embedding), váº¡ch tá»a Ä‘á»™ chung cá»§a cáº£ 3 chá»¯ `"him", "her", "round"` náº±m chen chÃºc cháº­t chá»™i láº¥y nhau.
- CÃ ng Ä‘i sÃ¢u vÃ o cÃ¡c Transform block ná»™i Ä‘Ä©a, máº¡ng Neural báº¯t Ä‘áº§u cÃ y xá»›i ngá»¯ cáº£nh. Khoáº£ng cÃ¡ch (Euclidean Distance) váº¡ch ra trÃªn bÃ¬nh diá»‡n Trá»¥c PC1 vÃ  PC2 báº¯t Ä‘áº§u phÃ¢n nhÃ¡nh táº½ xa nhau. 
- *Hiá»‡n tÆ°á»£ng báº¥t Ä‘á»“ng thuáº­n:* Tá»« sai ngá»¯ phÃ¡p (`"round"`) bá»™c lá»™ sá»± nhiá»…u loáº¡n xa cÃ¡ch so vá»›i trá»¥c bÃ¬nh quÃ¢n cá»§a hai Ä‘áº¡i tá»« chuáº©n. MÃ´ hÃ¬nh Ã½ thá»©c Ä‘Æ°á»£c rá»§i ro ngá»¯ nghÄ©a cá»§a `"round"` vÃ  xoay xá»Ÿ xá»­ lÃ½ nÃ³ báº±ng sá»± váº·n xoáº¯n phá»©c táº¡p hÆ¡n (Additional rotations). Sá»± phÃ¢n rÃ£ á»Ÿ Final Layer cá»±c ká»³ dá»‹ dáº¡ng, bung rá»™ng mÃ£nh liá»‡t nhÆ° má»™t lÆ°á»›i sao ráº£i rÃ¡c.

### 3.2. Giá»›i Háº¡n Cá»§a ThÃ nh Pháº§n ChÃ­nh (The Scree Plot Trade-off)
Äá»“ thá»‹ phÃ¢n bá»• Scree Plot thá»ƒ hiá»‡n: 3 thÃ¡p ThÃ nh pháº§n Ä‘áº§u tiÃªn náº¯m giá»¯ khá»‘ng cháº¿ $\approx 80\%$ tÃ­n hiá»‡u cá»‘t lÃµi (PC1 cáº¯n 62%, PC2 10%, PC3 7.5%).
Tuy tá»· lá»‡ nÃ©n vÆ°á»£t má»‘c Ä‘a sá»‘, 20% phÆ°Æ¡ng sai ráº£i rÃ¡c á»Ÿ Ä‘áº±ng sau Ä‘Ã£ bá»‹ cáº¯t cá»¥t khÃ´ng thÆ°Æ¡ng tiáº¿c. Máº·c Ä‘á»‹nh cá»§a PCA coi: "Sá»± phÃ¢n tÃ¡n cÃ ng rá»™ng thÃ¬ cÃ ng chá»©a vá»±a thÃ´ng tin máº¡nh nháº¥t" (Variance = Relevance). Thá»±c táº¿ váº­n hÃ nh LLMs phá»§ quyáº¿t Ä‘iá»u nÃ y: Nhá»¯ng quy luáº­t Ã½ nghÄ©a má»ng nhÆ° tá» giáº¥y (chiáº¿m 0.1% phÆ°Æ¡ng sai) cÃ³ thá»ƒ Ä‘á»‹nh hÃ¬nh toÃ n bá»™ tÆ° duy logic cá»§a mÃ´ hÃ¬nh Ä‘á»‘i vá»›i Token. NÃªn viá»‡c giáº£n lÆ°á»£c State-space trajectories chá»©a Ä‘á»±ng má»™t rá»§i ro Diá»…n dá»‹ch QuÃ¡ Má»©c (Overinterpreting).

---

## 4. Káº¿t Luáº­n
Quá»¹ Ä‘áº¡o khÃ´ng gian tráº¡ng thÃ¡i biáº¿n thuáº­t toÃ¡n vÄ© mÃ´ thÃ nh má»™t thÆ°á»›c phim cÃ³ thá»ƒ theo dÃµi. Nhá» giáº£m chiá»u, ta chá»©ng kiáº¿n táº­n máº¯t cÃ¡ch má»™t mÃ´ hÃ¬nh tÃ¡ch dáº§n má»™t tá»« sai ngá»¯ phÃ¡p tÃ¡ch xa khá»i cÃ¡c tá»« vá»±ng há»£p chuáº©n khi nÃ³ Ä‘i qua tá»«ng tráº¡m kiá»ƒm duyá»‡t ná»™i vi cá»§a Transformer. Dáº«u váº­y, phÆ°Æ¡ng phÃ¡p nÃ y chá»‰ Ä‘Ã³ng vai trÃ² lÃ  cá»™t Ä‘Ã¨n dáº«n lá»‘i trá»±c quan (Insightful starting points), khÃ´ng Ä‘Æ°á»£c phÃ©p dÃ¹ng lÃ m káº¿t luáº­n tá»‘i thÆ°á»£ng cuá»‘i cÃ¹ng cho kiáº¿n trÃºc LLM vÃ¬ há»‡ lá»¥y Ä‘Ã¡nh máº¥t thÃ´ng tin cá»§a PCA.

---

## TÃ i Liá»‡u Tham Kháº£o (Citations)
1. ThÃ­ nghiá»‡m Ä‘o Ä‘áº¡c khoáº£ng cÃ¡ch vÃ  biá»ƒu diá»…n tá»a Ä‘á»™ quá»¹ Ä‘áº¡o hai chiá»u PCA trong `aero_LLM_06_State-space trajectories through embedding space.md` (CÃ¡ch sá»­ dá»¥ng há»‡ chiáº¿u chung Common Space thay vÃ¬ tÃ¡ch láº» cho Transformer Layers).
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| [PhÃ¢n Kháº£o Token Embeddings: Äo LÆ°á»ng GÃ³c Quay Cá»§a Vector Biá»ƒu Diá»…n](aero_llm_01_calculating_rotations_of_embeddings_vectors.md) | [Xem bÃ i viáº¿t â†’](aero_llm_01_calculating_rotations_of_embeddings_vectors.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): Tiáº¿n HÃ³a Äa Táº§ng Cá»§a CÃ¡c Äiá»u Chá»‰nh GÃ³c Quay Tuáº§n Tá»±](aero_llm_02_codechallenge_laminar_evolution_of_sequential_angular_adjustments.md) | [Xem bÃ i viáº¿t â†’](aero_llm_02_codechallenge_laminar_evolution_of_sequential_angular_adjustments.md) |
| [Äo LÆ°á»ng Äá»™ DÃ i ÄÆ°á»ng Dáº«n (Path Length) Sá»± TÆ°Æ¡ng Quan Vá»›i Dá»± ÄoÃ¡n Token](aero_llm_03_path_length_and_logit_token_prediction.md) | [Xem bÃ i viáº¿t â†’](aero_llm_03_path_length_and_logit_token_prediction.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh: PhÃ¢n RÃ£ Äá»™ DÃ i ÄÆ°á»ng Dáº«n Luá»“ng Sá»‘ DÆ° (Pháº§n 1)](aero_llm_04_codechallenge_residual_stream_path_length_decomposition_part_1_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_04_codechallenge_residual_stream_path_length_decomposition_part_1_.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh: PhÃ¢n RÃ£ Äá»™ DÃ i ÄÆ°á»ng Dáº«n Luá»“ng Sá»‘ DÆ° (Pháº§n 2)](aero_llm_05_codechallenge_residual_stream_path_length_decomposition_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_05_codechallenge_residual_stream_path_length_decomposition_part_2_.md) |
| ğŸ“Œ **[Quá»¹ Äáº¡o KhÃ´ng Gian Tráº¡ng ThÃ¡i (State-Space Trajectories) Cá»§a Há»‡ Vector NgÃ´n Ngá»¯](aero_llm_06_state_space_trajectories_through_embedding_space.md)** | [Xem bÃ i viáº¿t â†’](aero_llm_06_state_space_trajectories_through_embedding_space.md) |
| [PhÃ¢n Loáº¡i Tá»« Loáº¡i Báº±ng ThÆ° Viá»‡n SpaCy Trong PhÃ¢n TÃ­ch Mechanistic Interpretability](aero_llm_07_parts_of_speech_with_spacy_library.md) | [Xem bÃ i viáº¿t â†’](aero_llm_07_parts_of_speech_with_spacy_library.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh: So SÃ¡nh Äá»™ DÃ i Quá»¹ Äáº¡o Cá»§a Danh Tá»« VÃ  TÃ­nh Tá»« (Pháº§n 1)](aero_llm_08_codechallenge_do_nouns_or_adjectives_have_longer_trajectories_part_1_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_08_codechallenge_do_nouns_or_adjectives_have_longer_trajectories_part_1_.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh: So SÃ¡nh Äá»™ DÃ i Quá»¹ Äáº¡o Cá»§a Danh Tá»« VÃ  TÃ­nh Tá»« (Pháº§n 2)](aero_llm_09_codechallenge_do_nouns_or_adjectives_have_longer_trajectories_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_09_codechallenge_do_nouns_or_adjectives_have_longer_trajectories_part_2_.md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
