
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../index.md) > [20 investigating token embeddings](index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../index.md)
- [ğŸ“š Module 01: LLM Course](../01_llm_course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../02_words_to_tokens_to_numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../04_buildgpt/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../07_fine_tune_pretrained_models/index.md)
- [ğŸ” Module 19: AI Safety](../19_ai_safety/index.md)
- [ğŸ Module 20: Python for AI](../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Thá»­ ThÃ¡ch Láº­p TrÃ¬nh: So SÃ¡nh Äá»™ DÃ i Quá»¹ Äáº¡o Cá»§a Danh Tá»« VÃ  TÃ­nh Tá»« (Pháº§n 2)

## TÃ³m táº¯t (Abstract)
Tiáº¿p ná»‘i cháº·ng thiáº¿t láº­p PCA, pháº§n hai Ä‘i sÃ¢u vÃ o phÃ¡c há»a quá»¹ Ä‘áº¡o biá»ƒu diá»…n cá»§a Danh tá»« so vá»›i TÃ­nh tá»« trÃªn bÃ¬nh diá»‡n ThÃ nh pháº§n chÃ­nh (PC1, PC2). Kháº£o sÃ¡t ghi nháº­n má»™t sá»± tÃ¡ch biá»‡t quá»¹ Ä‘áº¡o cá»±c lá»›n giá»¯a hai loáº¡i tá»« nÃ y, chá»©ng tá» mÃ´ hÃ¬nh sinh ra nhá»¯ng phÃ©p nhÃºng phÃ¢n máº£nh (divergence) cho cÃ¡c tÃ­n hiá»‡u ngá»¯ phÃ¡p khÃ¡c nhau. HÆ¡n ná»¯a, báº±ng viá»‡c sá»­ dá»¥ng phÃ©p tÃ­nh khoáº£ng cÃ¡ch Euclide chÃ©o lá»›p (Layer-to-layer Euclidean distance) vÃ  biáº¿n Ä‘á»•i Logarit, bÃ¡o cÃ¡o Ä‘á»‹nh lÆ°á»£ng tá»‘c Ä‘á»™ dá»‹ch chuyá»ƒn (Path length trajectory) cá»§a tá»«ng vector. Thá»­ nghiá»‡m trÃªn mÃ´ hÃ¬nh siÃªu lá»›n (GPT-2 XL) chá»©ng thá»±c giáº£ thuyáº¿t lÃµi: Tá»« loáº¡i ÄÃ³ng vai trÃ² trá»¥c xoay cáº¥u trÃºc (Danh Tá»«) báº¯t buá»™c há»‡ thá»‘ng pháº£i kÃ©o thÃ´ng tin tá»« khoáº£ng context rá»™ng dÃ i hÆ¡n, nÃªn nÃ³ sinh ra quá»¹ Ä‘áº¡o dá»‹ch chuyá»ƒn dÃ i vÃ  ká»‹ch liá»‡t hÆ¡n so vá»›i tá»« loáº¡i MÃ´ táº£ vá»‡ tinh cá»¥c bá»™ (TÃ­nh Tá»«).

---

## 1. Má»Ÿ Äáº§u (Introduction)
CÃ³ tá»a Ä‘á»™ PCA trong tay, giá» lÃ  lÃºc truy váº¿t láº¡i chuyá»ƒn Ä‘á»™ng cá»§a cÃ¡c Ä‘iá»ƒm háº¡t (Particles) theo tuyáº¿n tÃ­nh thá»i gian cá»§a máº¡ng Transformer (Layer $0 \to 36$). 
Dá»± phÃ³ng ban Ä‘áº§u (Hypothesis): "Äá»™ uá»‘n náº¯n" Ä‘á»‘i vá»›i TÃ­nh tá»« sáº½ nháº¹ nhÃ ng hÆ¡n so vá»›i Danh tá»«. Bá»Ÿi trong Tiáº¿ng Anh, tÃ­nh tá»« thÆ°á»ng chá»‰ quan tÃ¢m Ä‘áº¿n danh tá»« Ä‘á»©ng ngay sÃ¡t vÃ¡ch nÃ³ (vÃ­ dá»¥ "a *happy* sentence"), nÃªn cá»­a sá»• táº­p trung (Context Window Demands) ráº¥t háº¹p. NhÆ°ng má»™t Danh tá»« (Noun) mang sá»©c náº·ng cáº¥u trÃºc, nÃ³ cáº§n pháº£i liÃªn káº¿t vá»›i cÃ¡c Ä‘áº¡i tá»« bá»• nghÄ©a phÃ­a trÆ°á»›c, Ä‘á»™ng tá»« theo sau, vÃ  Ä‘á»‘i tÆ°á»£ng há»‡ quáº£ á»Ÿ tuá»‘t cuá»‘i cÃ¢u. Sá»± háº¥p thá»¥ ngá»¯ cáº£nh phong phÃº nÃ y cháº¯c cháº¯n sáº½ lÃ m quá»¹ Ä‘áº¡o tÃ­nh toÃ¡n Vector cá»§a Danh tá»« di chuyá»ƒn quÃ£ng Ä‘Æ°á»ng dÃ i hÆ¡n.

---

## 2. TrÃ¬nh BÃ y Quá»¹ Äáº¡o Äá»™ng (Trajectory Projections)

### 2.1. Sá»± PhÃ¢n Cá»±c TrÃªn TÃ²a Äá»™ PC2 (Divergence in PC Space)
Khi chiáº¿u bÃ³ng Token Vectors lÃªn há»‡ trá»¥c PC1-PC2:
- á» trá»¥c PC1, quá»¹ Ä‘áº¡o cá»§a Nouns vÃ  Adjectives váº­n Ä‘á»™ng cháº¡y song song giáº±ng co vá» cÃ¹ng má»™t phÆ°Æ¡ng hÆ°á»›ng, háº¥p thá»¥ nÄƒng lÆ°á»£ng tá»•ng quan.
- á» trá»¥c PC2, xuáº¥t hiá»‡n má»™t cuá»™c "Äáº¡i phÃ¢n ly" (Striking Divergence). Danh tá»« vÃ  TÃ­nh tá»« bay tháº³ng vá» hai cá»±c chÃ³p trÃ¡i ngÆ°á»£c nhau. Äiá»u nÃ y xÃ¡c thá»±c sá»± tinh táº¿ cá»§a GPT-2: MÃ´ hÃ¬nh tá»« ná»™i táº¡i Ä‘Ã£ hÃ¬nh thÃ nh má»™t lÆ°á»›i phÃ¢n Ä‘á»‹nh rÃµ rÃ ng cÃ¡ch hÃ nh xá»­ chuyÃªn biá»‡t cho hai vÃ¹ng trá»i tá»« loáº¡i (Grammar part of speech paths).

### 2.2. Nghá»‹ch LÃ½ á» Táº§ng Xáº£ Cuá»‘i (Final-layer Drop-off)
Táº¡i tráº¡m Transformer cuá»‘i cÃ¹ng trÆ°á»›c khi Ä‘Æ°a vÃ o Vocab Output, khoáº£ng cÃ¡ch cá»§a chÃºng tá»¥t dá»‘c tháº£m háº¡i, cáº£ hai Quá»¹ Ä‘áº¡o há»£p nháº¥t vÃ  vÃ³n cá»¥c láº¡i vá»›i nhau. ÄÃ¢y lÃ  Ä‘áº·c tÃ­nh láº·p láº¡i (Consistent feature) Ä‘áº·c trÆ°ng cá»§a viá»‡c xáº£ Ã¡p suáº¥t (Unembedding projection compression) thÆ°á»ng tháº¥y trong máº¡ng Transformer. 

---

## 3. Khoáº£ng CÃ¡ch Quá»¹ Äáº¡o VÆ°á»£t Táº§ng (Layer Inter-Distance Analysis)

### 3.1. PhÆ°Æ¡ng PhÃ¡p Luáº­n Logarit Euclid
Äá»ƒ Ä‘á»‹nh lÆ°á»£ng giáº£ thuyáº¿t Ä‘áº§u bÃ i, ta Ä‘o quÃ£ng Ä‘Æ°á»ng vector di chuyá»ƒn báº±ng khoáº£ng cÃ¡ch Euclide tá»« Layer I sang Layer I-1. Code Ä‘Æ°á»£c Vector hÃ³a (Vectorization Arrays) Ä‘á»ƒ trá»« triá»‡t tiÃªu tá»«ng khá»‘i mÃ  khÃ´ng cáº§n cÃ¡c vÃ²ng láº·p For tá»‘n kÃ©m pháº§n cá»©ng `numpy.sqrt(numpy.sum(numpy.diff(points)^2))`.
Máº·c dÃ¹ váº­y, sá»± váº­n Ä‘á»™ng á»Ÿ cÃ¡c cháº·ng Layer sÃ¢u lÃ  cá»±c ká»³ báº¡o liá»‡t (Big Leaps), nÃ³ Ä‘Ã¨ báº¹p xáº¹p lÃ©p thÃ´ng sá»‘ á»Ÿ cÃ¡c cháº·ng Ä‘áº§u náº¿u Ä‘á»ƒ nguyÃªn Ä‘á»“ thá»‹ tá»· lá»‡ tuyáº¿n tÃ­nh (Linear scaling). Do Ä‘Ã³, phÃ©p logarit cÆ¡ sá»‘ e (Log-scaling) Ä‘Æ°á»£c sá»­ Ä‘á»¥ng Ä‘á»ƒ dÃ n Ä‘á»u sáº¯c thÃ¡i Ä‘á»™ng há»c. Má»i sai sá»‘ Ä‘Æ°á»£c xá»­ lÃ½ qua cÃ´ng thá»©c Ä‘áº¡i sá»‘ $Log(A) - Log(B) = Log(A/B)$.

### 3.2. Kiá»ƒm Chá»©ng Cross-model (Thá»­ Thá»­ Vá»›i GPT-2 XL)
Khi thi hÃ nh bá»™ quy táº¯c trÃªn báº£n thá»ƒ cÃ³ trá»ng lÆ°á»£ng cao nháº¥t (GPT-2 XL - $1.5$ Billion Parameters):
1. **Äá»™ á»•n Ä‘á»‹nh PCA tÄƒng:** Component Scree Plot náº¯m giá»¯ tá»‘t hÆ¡n, 2 Trá»¥c PC1, PC2 nay thÃ¢u tÃ³m trÃªn $\approx 55\%$ Variance (so vá»›i dÆ°á»›i 40% cá»§a GPT-2 Large). 
2. **XÃ¡c nháº­n giáº£ thuyáº¿t:** Äá»“ thá»‹ Ä‘Æ°á»ng chÃªnh lá»‡ch $\Delta = Log(Path_{Nouns}) - Log(Path_{Adjs})$ náº±m cáº¯m rá»… hoÃ n toÃ n á»Ÿ lÃ£nh Ä‘á»‹a DÆ°Æ¡ng (Positive Zone) trÃªn toÃ n bá»™ má»i tuyáº¿n Layer. 
NghÄ©a lÃ : **Vector Danh tá»« luÃ´n pháº£i di chuyá»ƒn nhiá»u hÆ¡n, tá»± thay Ä‘á»•i mÃ£nh liá»‡t hÆ¡n Vector TÃ­nh tá»« á»Ÿ tá»«ng náº¥c cá»§a mÃ´ hÃ¬nh**. LÆ°á»£ng bá»“i Ä‘áº¯p thÃ´ng tin (Integration tokens context) Ä‘á»• dá»“n vÃ o Danh tá»« cao hÆ¡n háº³n TÃ­nh tá»« nhÆ° Ä‘Ãºng Logic ngÃ´n ngá»¯ há»c con ngÆ°á»i.

---

## 4. Káº¿t Luáº­n
Báº±ng viá»‡c há»£p rÃ¨n hai tháº¿ vÃµ: BÃ³c tÃ¡ch tá»± Ä‘á»™ng (spaCy POS) vÃ  Biá»ƒu diá»…n quá»¹ Ä‘áº¡o nÃ©n (PCA Path length), ká»¹ thuáº­t nÃ y lÃ  má»™t kÃ­nh quang phá»• hiá»‡u nÄƒng cao giÃºp chá»©ng minh LLM hiá»ƒu cáº¥u trÃºc ngá»¯ phÃ¡p ngÃ´n ngá»¯ ngÆ°á»i sÃ¢u sáº¯c hÆ¡n viá»‡c chá»‰ Ä‘oÃ¡n bá»«a chá»¯ tiáº¿p theo. Lá»±c chÃº Ã½ context window (Attention heads) cáº¥p phÃ¡t thÃ´ng lá»±c cá»±c ká»³ uyá»ƒn chuyá»ƒn tÃ¹y thuá»™c vÃ o gÃ¡nh náº·ng vai váº¿ cá»§a tá»«. Cáº£nh bÃ¡o nhá» duy nháº¥t lÃ  máº«u thá»­ Frankenstein lÃ  má»™t tá»‡p tiá»ƒu thuyáº¿t cá»• ngá»¯, phÃ¢n tÃ­ch thá»±c Ä‘á»‹a (Research application) cáº§n má»Ÿ rá»™ng trÃªn cÃ¡c thÆ° viá»‡n máº¡ng Modern Text Ä‘á»ƒ trÃ¡nh thiÃªn vá»‹ (Bias text limit).

---

## TÃ i Liá»‡u Tham Kháº£o (Citations)
1. ThÃ­ nghiá»‡m mÃ£ hÃ³a Log-distance vÃ  ká»¹ thuáº­t vector hÃ³a theo máº£ng numpy trong `aero_LLM_09_CodeChallenge Do nouns or adjectives have longer trajectories (part 2).md`. TÃ¡i láº­p sá»± bÃ¹ng ná»• hiá»‡u nÄƒng báº±ng mÃ´ hÃ¬nh GPT-2 XL.
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| [PhÃ¢n Kháº£o Token Embeddings: Äo LÆ°á»ng GÃ³c Quay Cá»§a Vector Biá»ƒu Diá»…n](aero_llm_01_calculating_rotations_of_embeddings_vectors.md) | [Xem bÃ i viáº¿t â†’](aero_llm_01_calculating_rotations_of_embeddings_vectors.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): Tiáº¿n HÃ³a Äa Táº§ng Cá»§a CÃ¡c Äiá»u Chá»‰nh GÃ³c Quay Tuáº§n Tá»±](aero_llm_02_codechallenge_laminar_evolution_of_sequential_angular_adjustments.md) | [Xem bÃ i viáº¿t â†’](aero_llm_02_codechallenge_laminar_evolution_of_sequential_angular_adjustments.md) |
| [Äo LÆ°á»ng Äá»™ DÃ i ÄÆ°á»ng Dáº«n (Path Length) Sá»± TÆ°Æ¡ng Quan Vá»›i Dá»± ÄoÃ¡n Token](aero_llm_03_path_length_and_logit_token_prediction.md) | [Xem bÃ i viáº¿t â†’](aero_llm_03_path_length_and_logit_token_prediction.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh: PhÃ¢n RÃ£ Äá»™ DÃ i ÄÆ°á»ng Dáº«n Luá»“ng Sá»‘ DÆ° (Pháº§n 1)](aero_llm_04_codechallenge_residual_stream_path_length_decomposition_part_1_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_04_codechallenge_residual_stream_path_length_decomposition_part_1_.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh: PhÃ¢n RÃ£ Äá»™ DÃ i ÄÆ°á»ng Dáº«n Luá»“ng Sá»‘ DÆ° (Pháº§n 2)](aero_llm_05_codechallenge_residual_stream_path_length_decomposition_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_05_codechallenge_residual_stream_path_length_decomposition_part_2_.md) |
| [Quá»¹ Äáº¡o KhÃ´ng Gian Tráº¡ng ThÃ¡i (State-Space Trajectories) Cá»§a Há»‡ Vector NgÃ´n Ngá»¯](aero_llm_06_state_space_trajectories_through_embedding_space.md) | [Xem bÃ i viáº¿t â†’](aero_llm_06_state_space_trajectories_through_embedding_space.md) |
| [PhÃ¢n Loáº¡i Tá»« Loáº¡i Báº±ng ThÆ° Viá»‡n SpaCy Trong PhÃ¢n TÃ­ch Mechanistic Interpretability](aero_llm_07_parts_of_speech_with_spacy_library.md) | [Xem bÃ i viáº¿t â†’](aero_llm_07_parts_of_speech_with_spacy_library.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh: So SÃ¡nh Äá»™ DÃ i Quá»¹ Äáº¡o Cá»§a Danh Tá»« VÃ  TÃ­nh Tá»« (Pháº§n 1)](aero_llm_08_codechallenge_do_nouns_or_adjectives_have_longer_trajectories_part_1_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_08_codechallenge_do_nouns_or_adjectives_have_longer_trajectories_part_1_.md) |
| ğŸ“Œ **[Thá»­ ThÃ¡ch Láº­p TrÃ¬nh: So SÃ¡nh Äá»™ DÃ i Quá»¹ Äáº¡o Cá»§a Danh Tá»« VÃ  TÃ­nh Tá»« (Pháº§n 2)](aero_llm_09_codechallenge_do_nouns_or_adjectives_have_longer_trajectories_part_2_.md)** | [Xem bÃ i viáº¿t â†’](aero_llm_09_codechallenge_do_nouns_or_adjectives_have_longer_trajectories_part_2_.md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
