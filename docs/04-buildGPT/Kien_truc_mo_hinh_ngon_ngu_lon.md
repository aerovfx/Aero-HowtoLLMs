## Định nghĩa về hệ thống AI xử lý và tạo ngôn ngữ giống con người (cụ thể là LLM) đại diện cho bước tiến hóa cao nhất hiện tại trong lĩnh vực Xử lý Ngôn ngữ Tự nhiên (NLP).

Dưới đây là các điểm cốt lõi trong bối cảnh rộng hơn:

*   **Vượt xa quy tắc cứng nhắc:** Khác với các hệ thống NLP truyền thống chỉ tập trung vào ngữ pháp hoặc từ khóa cụ thể, LLM được thiết kế để nắm bắt **ngữ cảnh, các ẩn ý tinh tế và sắc thái** của ngôn ngữ nhờ được huấn luyện trên tập dữ liệu khổng lồ.
*   **Mô phỏng não bộ:** Khả năng "giống con người" này xuất phát từ việc sử dụng các mạng thần kinh học sâu (Deep Neural Networks) mô phỏng cấu trúc xử lý thông tin của não bộ, cho phép tạo ra văn bản có độ phức tạp cao thay vì chỉ lắp ghép từ đơn giản.
*   **Tính đa năng:** Hệ thống này không chỉ là một công cụ ngôn ngữ đơn thuần mà có thể thực hiện các tác vụ tư duy phức tạp như viết mã (coding), lý luận và duy trì hội thoại tự nhiên, đánh dấu sự chuyển dịch từ các mô hình thống kê sang trí tuệ nhân tạo tổng quát hơn.

## Sự tiến hóa: Từ rule-based đến Deep Learning quy mô lớn, trong bối cảnh rộng hơn của Giới thiệu & Khái niệm.

*   **Hệ thống dựa trên quy tắc (Rule-based):** Đây là giai đoạn khởi đầu, nơi các mô hình tuân theo các luật lệ nghiêm ngặt do lập trình viên đặt ra (ví dụ: "nếu thấy từ này, hãy làm điều kia"). Chúng tạo nền móng nhưng rất cứng nhắc và thiếu linh hoạt,.
*   **Mô hình thống kê (Statistical Models):** Bước chuyển dịch sang việc sử dụng xác suất để diễn giải ngôn ngữ. Thay vì các luật lệ cố định, mô hình bắt đầu tính toán khả năng xuất hiện của từ, mang lại độ chính xác cao hơn,.
*   **Học máy & Mạng thần kinh (Machine Learning & Neural Networks):** Một bước đột phá lớn khi thuật toán có thể tự học từ dữ liệu. Việc giới thiệu mạng thần kinh (mô phỏng cấu trúc não bộ) giúp AI bắt đầu xử lý và tạo ra ngôn ngữ giống con người hơn,.
*   **Học sâu quy mô lớn (Deep Learning/LLMs):** Đây là đỉnh cao hiện tại (như GPT, Gemini). Nhờ sử dụng các mạng thần kinh sâu và tập dữ liệu khổng lồ, chúng không chỉ xử lý từ ngữ mà còn hiểu được **ngữ cảnh, các ẩn ý tinh tế và sắc thái** phức tạp, vượt xa khả năng của các mô hình NLP truyền thống,,.

Sự tiến hóa này đã mở ra những khả năng chưa từng có, như việc AI có thể viết code, làm thơ hoặc dịch thuật trôi chảy.

## Khác biệt với NLP truyền thống: Hiểu ngữ cảnh sâu sắc hơn, trong bối cảnh rộng hơn của Giới thiệu & Khái niệm.

Dưới đây là các điểm khác biệt chính trong bối cảnh rộng hơn:

*   **Phạm vi và Dữ liệu huấn luyện:**
    *   **NLP truyền thống:** Thường tập trung vào các tác vụ cụ thể (như phân tích ngữ pháp, trích xuất từ khóa) và được huấn luyện trên các tập dữ liệu nhỏ hẹp. Chúng thiếu khả năng hiểu biết rộng về thế giới.
    *   **LLM:** Được huấn luyện trên các tập dữ liệu văn bản khổng lồ (như toàn bộ internet). Điều này cho phép chúng nắm bắt được **ngữ cảnh, các ẩn ý tinh tế (subtleties) và sắc thái (nuances)** của ngôn ngữ ở mức độ sâu sắc hơn nhiều,.
*   **Cơ chế hoạt động:**
    *   **NLP truyền thống:** Trước đây dựa vào các hệ thống quy tắc cứng nhắc (Rule-based) hoặc mô hình thống kê đơn giản. Chúng xử lý ngôn ngữ một cách máy móc và thường gặp khó khăn với các cấu trúc câu phức tạp hoặc mơ hồ,.
    *   **LLM (Deep Learning):** Sử dụng mạng thần kinh nhân tạo (như Transformer) để mô phỏng cách não bộ xử lý thông tin. Nhờ đó, chúng không chỉ "đọc" từ ngữ mà còn hiểu được mối liên hệ giữa các từ trong một đoạn văn dài, giúp tạo ra phản hồi mạch lạc và tự nhiên giống con người,.
*   **Tính đa năng:** Khả năng hiểu ngữ cảnh sâu cho phép LLM thực hiện đa dạng nhiệm vụ (dịch thuật, viết mã, lý luận, sáng tạo nội dung) mà không cần được lập trình riêng biệt cho từng việc, vượt xa giới hạn đơn nhiệm của các mô hình cũ.

## Mô hình tiêu biểu: GPT, Gemini, Claude, Falcon, trong bối cảnh rộng hơn của Giới thiệu & Khái niệm.

Dựa trên các tài liệu, các mô hình như GPT, Gemini, Claude và Falcon đại diện cho đỉnh cao hiện tại của sự tiến hóa từ các hệ thống quy tắc sang **Học sâu (Deep Learning)**.

*   **GPT (OpenAI) & Falcon (TII): Đại diện Causal LM**
    *   Cả hai đều sử dụng kiến trúc **Decoder-only (Chỉ có bộ giải mã)**, hoạt động dựa trên cơ chế cốt lõi là **dự đoán token tiếp theo**.
    *   **GPT:** Được nhắc đến như tiêu chuẩn của ngành. Từ GPT-2 (mô hình mở) đến GPT-4 (Blackbox), chúng thể hiện sự tiến bộ trong việc hiểu ngữ cảnh và tạo văn bản mạch lạc.
    *   **Falcon:** Được sử dụng trong tài liệu như một ví dụ điển hình cho các mô hình mã nguồn mở hiệu suất cao (ví dụ Falcon 7B, 180B) và thường là đối tượng để thực hành kỹ thuật **Lượng tử hóa (Quantization)** nhằm chạy trên phần cứng giới hạn.

*   **Gemini (Google) & Claude (Anthropic): Trợ lý & Căn chỉnh**
    *   Các mô hình này được thảo luận nhiều trong bối cảnh **Instruction Tuning** và **An toàn (Safety)**.
    *   **Claude:** Nổi bật với các **System Prompts (Lời nhắc hệ thống)** rất dài và chi tiết nhằm định hướng hành vi an toàn, tuân thủ các quy tắc đạo đức nghiêm ngặt.
    *   **Gemini:** Được giới thiệu với các chỉ dẫn hệ thống để trở thành trợ lý hữu ích, tránh "ảo giác" (hallucination) và cung cấp thông tin chính xác.

*   **Phân loại Hộp đen (Blackbox) vs. Mã nguồn mở:**
    *   Tài liệu phân biệt rõ **GPT-4, Gemini, Claude** là các mô hình **Blackbox**, nơi người dùng chỉ gửi đầu vào và nhận đầu ra mà không biết trọng số bên trong.
    *   Ngược lại, **GPT-2** và **Falcon** thường được dùng làm ví dụ cho **Graybox** hoặc mô hình mở để người học có thể tải về và tinh chỉnh trực tiếp.

## Kiến trúc & Cơ chế kỹ thuật, 
### Dựa trên các nguồn tài liệu, **Tokenization (Mã hóa)** không chỉ là việc cắt nhỏ văn bản mà là một phần không thể tách rời của kiến trúc kỹ thuật, quyết định hiệu suất và cách mô hình "nhìn" dữ liệu.

**1. Cơ chế BPE (Byte Pair Encoding) và Subwords**
*   **Điểm cân bằng:** Đây là phương pháp tiêu chuẩn cho LLM hiện đại. Nó bắt đầu từ các ký tự đơn lẻ và lặp đi lặp lại việc gộp các cặp ký tự xuất hiện thường xuyên nhất thành các token mới.
*   **Hiệu quả:** Cách này giúp mô hình xử lý được các từ hiếm (bằng cách tách chúng ra) mà không làm bộ từ vựng phình to quá mức, giữ kích thước bộ từ vựng ở mức quản lý được (ví dụ: GPT-4 khoảng 100k token, GPT-2 khoảng 50k).

**2. Các sắc thái kỹ thuật quan trọng (Technical Nuances)**
*   **Khoảng trắng là một phần của Token:** Tokenizer xử lý rất khác biệt giữa một từ đứng đầu câu và một từ đứng giữa câu có dấu cách phía trước. Ví dụ: " tooth" (có dấu cách) và "tooth" (không dấu cách) là hai token hoàn toàn khác nhau với vector nhúng khác nhau.
*   **Sự "mù chữ" của mô hình:** Vì mô hình nhìn thấy các Token ID (số nguyên) chứ không phải chuỗi ký tự, nó gặp khó khăn với các tác vụ đơn giản như đếm số chữ cái (ví dụ: không đếm đúng số chữ "r" trong "Strawberry" vì từ này được mã hóa thành các token `str`, `aw`, `berry` không chứa ký tự `r` riêng lẻ).
*   **Hiệu suất đa ngôn ngữ:** Tokenizer thường tối ưu cho tiếng Anh. Với các ngôn ngữ ít dữ liệu hơn như tiếng Tamil hay tiếng Trung, việc mã hóa kém hiệu quả hơn hẳn, đôi khi số lượng token còn nhiều hơn số ký tự gốc (hiện tượng "nở" thay vì nén), làm tốn tài nguyên bộ nhớ của mô hình.

**3. Tùy biến theo kiến trúc (BERT vs. GPT)**
*   **GPT (Generative):** Cần giữ lại tất cả khoảng trắng, tab, và dấu xuống dòng để có thể tái tạo văn bản gốc hoàn chỉnh khi sinh nội dung.
*   **BERT (Classification):** Thường bỏ qua các dấu cách và xuống dòng vì mục tiêu của nó là hiểu ý nghĩa để phân loại, nơi mà định dạng văn bản ít quan trọng hơn.

## Transformer, trong bối cảnh rộng hơn của Kiến trúc & Cơ chế kỹ thuật.
Dựa trên các nguồn tài liệu, **Transformer** là kiến trúc nền tảng của mọi LLM hiện đại (ra mắt năm 2017), hoạt động dựa trên cơ chế xử lý song song thay vì tuần tự như các mạng RNN trước đó.

Dưới đây là các điểm cốt lõi về Transformer trong bối cảnh kỹ thuật:

*   **Hai biến thể kiến trúc:**
    *   **Seq2Seq (Encoder-Decoder):** Gồm cả bộ mã hóa và giải mã (ví dụ: BART, T5). Luồng dữ liệu đi từ Input $\rightarrow$ Encoder $\rightarrow$ Vector ngữ nghĩa $\rightarrow$ Decoder $\rightarrow$ Output. Thường dùng cho dịch thuật hoặc tóm tắt.
    *   **Causal LM (Decoder-only):** Chỉ có bộ giải mã (ví dụ: GPT, Falcon). Dữ liệu đi thẳng vào Decoder để dự đoán token tiếp theo. Đây là kiến trúc chủ đạo của các mô hình tạo sinh (Generative AI) hiện nay,.
*   **Cấu trúc Khối Transformer (Transformer Block):** Một mô hình được xếp chồng bởi nhiều khối này (ví dụ: GPT-2 Small có 12 khối, GPT-3 có 96 khối). Mỗi khối gồm hai tiểu phần chính,:
    1.  **Lớp Attention:** Nơi các token "trò chuyện" với nhau để hiểu ngữ cảnh và tính toán sự phụ thuộc lẫn nhau.
    2.  **Lớp MLP (Feed Forward):** Mở rộng chiều dữ liệu (thường gấp 4 lần) để xử lý phi tuyến tính, sau đó nén lại, giúp mô hình "suy nghĩ" và xử lý thông tin cục bộ,.
*   **Cơ chế dòng dư (Residual Stream):** Thông tin không bị thay thế hoàn toàn qua mỗi lớp mà được cộng dồn (Input + Attention + MLP). Điều này giúp tín hiệu được bảo toàn xuyên suốt mạng lưới sâu,.

## Softmax: Chuyển Logits thành xác suất, trong bối cảnh rộng hơn của Kiến trúc & Cơ chế kỹ thuật.
Dựa trên các tài liệu, **Softmax** là một hàm toán học đóng vai trò "người phiên dịch", chuyển đổi các con số thô (Logits) thành ngôn ngữ mà chúng ta có thể hiểu và sử dụng: **Xác suất**.

Dưới đây là vai trò của Softmax trong bối cảnh kỹ thuật rộng hơn:

*   **Chuyển đổi Logits:** Đầu ra thô của các lớp mạng thần kinh là **Logits** — các con số vô hướng có thể là âm hoặc dương tùy ý. Softmax sử dụng hàm mũ ($e^x$) để biến tất cả thành số dương, sau đó chia cho tổng để đảm bảo toàn bộ giá trị cộng lại bằng 1 (100%),.
*   **Vai trò trong Attention (Sự chú ý):** Trong lớp Attention, Softmax quyết định mức độ "quan tâm" của token hiện tại đối với các token trong quá khứ. Nó phối hợp với **Mặt nạ nhân quả** (gán giá trị $-\infty$ cho các vị trí tương lai). Vì $e^{-\infty} \approx 0$, Softmax giúp triệt tiêu hoàn toàn thông tin từ tương lai, đảm bảo mô hình không "nhìn trộm" đáp án,.
*   **Thúc đẩy sự thưa thớt (Sparsity):** Hàm số mũ trong Softmax có xu hướng khuếch đại các giá trị lớn nhất và nén các giá trị nhỏ xuống gần bằng 0. Điều này giúp mô hình đưa ra quyết định dứt khoát hơn thay vì phân vân giữa quá nhiều lựa chọn "nhạt nhòa",.

Sau khi có được xác suất từ Softmax, chúng ta không nhất thiết phải luôn chọn từ có xác suất cao nhất (Greedy). 

## Pre-training

Dưới đây là các điểm cốt lõi về giai đoạn này trong bối cảnh chung:

*   **Cơ chế học tập:** Mô hình được "nuôi" bằng một lượng dữ liệu văn bản khổng lồ (ví dụ bộ dữ liệu FineWeb chứa tới 15 nghìn tỷ token). Nhiệm vụ duy nhất của nó là **dự đoán token tiếp theo** trong chuỗi văn bản.
*   **Kết quả đạt được:** Quá trình này giúp mô hình tự học được ngữ pháp, cấu trúc ngôn ngữ và một lượng tri thức thế giới khổng lồ (như sự kiện lịch sử, kiến thức khoa học). Tuy nhiên, kết quả đầu ra chỉ là một **Base Model** (Mô hình nền tảng) — nó giống như một công cụ "tự động hoàn thiện" (autocomplete) cực mạnh chứ chưa biết cách trò chuyện hay làm trợ lý.
*   **Chi phí khổng lồ:** Đây là rào cản lớn nhất. Việc huấn luyện một mô hình như GPT-3 từ đầu tiêu tốn khoảng **10 triệu USD** và đòi hỏi hạ tầng GPU cực mạnh mà cá nhân không thể đáp ứng.

Vì Base Model chỉ giỏi "nói leo" theo văn bản chứ chưa biết cách phục vụ, người ta cần bước tiếp theo là **Fine-tuning**. 

## Fine-tuning


*   **Chuyển đổi mục đích:** Nếu *Pre-training* tạo ra một "sinh viên mới tốt nghiệp" có kiến thức rộng nhưng chung chung, thì *Fine-tuning* là bước đào tạo chuyên sâu để biến mô hình thành chuyên gia trong một lĩnh vực hẹp (như y tế, tài chính, hoặc viết code),.
*   **Dữ liệu đặc thù:** Khác với lượng dữ liệu khổng lồ của pre-training, fine-tuning sử dụng các tập dữ liệu nhỏ hơn nhưng được tuyển chọn kỹ lưỡng (curated) và đặc thù cho từng miền.
*   **Phương pháp thực hiện:** Có hai hướng tiếp cận chính:
    *   **Full Fine-tuning:** Cập nhật toàn bộ tham số của mô hình. Cách này tốn kém tài nguyên và dễ gây ra hiện tượng "quên thảm họa" (mất kiến thức nền cũ).
    *   **PEFT (như LoRA):** Chỉ cập nhật một phần rất nhỏ tham số (thường < 1%) và đóng băng phần còn lại. Cách này tiết kiệm phần cứng, nhanh hơn và giúp bảo tồn tri thức nền tảng.


## Intruction finetuning
    Dựa trên các tài liệu, **Instruction Tuning (Tinh chỉnh theo chỉ dẫn)** là bước chuyển đổi quan trọng thứ hai trong quy trình huấn luyện, nằm giữa giai đoạn Huấn luyện sơ bộ (Pre-training) và RLHF.

*   **Chuyển đổi mục đích:** Sau *Pre-training*, mô hình (Base Model) chỉ giỏi việc "tự động hoàn thiện" văn bản (autocomplete) dựa trên xác suất. *Instruction Tuning* thay đổi hành vi này, dạy mô hình cách hiểu và thực hiện các mệnh lệnh cụ thể như "tóm tắt", "dịch", hoặc "trả lời câu hỏi", biến nó thành một trợ lý hữu ích (Chatbot),.
*   **Dữ liệu huấn luyện:** Khác với văn bản thô của pre-training, giai đoạn này sử dụng các tập dữ liệu được biên soạn kỹ lưỡng dưới dạng các kịch bản tương tác (cặp câu hỏi - trả lời) để mô hình học cấu trúc đối thoại,.
*   **Thiết lập rào cản:** Đây là lúc mô hình bắt đầu học các quy tắc ứng xử, bao gồm việc tuân thủ các ràng buộc đạo đức và từ chối các yêu cầu gây hại hoặc bất hợp pháp.

