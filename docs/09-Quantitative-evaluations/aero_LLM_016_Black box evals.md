
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../index.md) > [09 Quantitative evaluations](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../index.md)
- [ğŸ“š Module 01: LLM Course](../../01-LLM_Course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../02-Words-to-tokens-to-numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../04-buildGPT/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../07-Fine-tune-pretrained-models/index.md)
- [ğŸ” Module 19: AI Safety](../../19-AI-safety/index.md)
- [ğŸ Module 20: Python for AI](../../20-Python-Colab-notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# ÄÃ¡nh GiÃ¡ Há»™p Äen (Black-box Evaluations) trong MÃ´ HÃ¬nh NgÃ´n Ngá»¯ Lá»›n

## TÃ³m táº¯t

ÄÃ¡nh giÃ¡ há»™p Ä‘en (Black-box evaluation) lÃ  phÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) dá»±a trÃªn cÃ¡c pháº£n há»“i tá»« Ä‘áº§u ra mÃ  khÃ´ng cáº§n truy cáº­p vÃ o kiáº¿n trÃºc ná»™i táº¡i, trá»ng sá»‘ hay dá»¯ liá»‡u huáº¥n luyá»‡n. PhÆ°Æ¡ng phÃ¡p nÃ y Ä‘Ã³ng vai trÃ² quan trá»ng trong viá»‡c phÃ¡t hiá»‡n cÃ¡c rá»§i ro báº£o máº­t thá»±c táº¿ nhÆ° jailbreaking. BÃ i viáº¿t phÃ¢n tÃ­ch cÃ¡c cáº¥p Ä‘á»™ tiáº¿p cáº­n mÃ´ hÃ¬nh (Black, White, Gray Box), Æ°u Ä‘iá»ƒm vá» tÃ­nh á»©ng dá»¥ng thá»±c tiá»…n vÃ  nhá»¯ng háº¡n cháº¿ vá» máº·t khoa há»c cá»§a phÆ°Æ¡ng phÃ¡p nÃ y.

---

## 1. CÃ¡c Cáº¥p Äá»™ Tiáº¿p Cáº­n MÃ´ HÃ¬nh

Trong há»c mÃ¡y, má»©c Ä‘á»™ truy cáº­p vÃ o mÃ´ hÃ¬nh Ä‘Æ°á»£c chia thÃ nh ba loáº¡i chÃ­nh:

### 1.1 Há»™p Äen (Black Box)
NgÆ°á»i dÃ¹ng chá»‰ cÃ³ quyá»n cung cáº¥p Ä‘áº§u vÃ o (prompts) vÃ  nháº­n Ä‘áº§u ra (outputs). KhÃ´ng cÃ³ thÃ´ng tin vá»:
- Trá»ng sá»‘ (weights) vÃ  tham sá»‘ (parameters).
- Kiáº¿n trÃºc mÃ´ hÃ¬nh.
- Dá»¯ liá»‡u huáº¥n luyá»‡n vÃ  cÃ¡c tinh chá»‰nh sau huáº¥n luyá»‡n (post-training fine-tuning).
- VÃ­ dá»¥: ChatGPT (OpenAI), Claude (Anthropic).

### 1.2 Há»™p Tráº¯ng (White Box)
NgÆ°á»i dÃ¹ng cÃ³ quyá»n truy cáº­p toÃ n diá»‡n:
- ToÃ n bá»™ trá»ng sá»‘ vÃ  kiáº¿n trÃºc.
- Dá»¯ liá»‡u huáº¥n luyá»‡n vÃ  giao thá»©c huáº¥n luyá»‡n.
- CÃ¡c há»‡ thá»‘ng rÃ o cháº¯n (guardrails) vÃ  system prompts.

### 1.3 Há»™p XÃ¡m (Gray Box)
Má»©c Ä‘á»™ trung gian, thÆ°á»ng tháº¥y á»Ÿ cÃ¡c mÃ´ hÃ¬nh mÃ£ nguá»“n má»Ÿ nhÆ°ng dá»¯ liá»‡u huáº¥n luyá»‡n váº«n Ä‘Æ°á»£c giá»¯ kÃ­n.
- CÃ³ thá»ƒ truy cáº­p trá»ng sá»‘ nhÆ°ng khÃ´ng cÃ³ dá»¯ liá»‡u huáº¥n luyá»‡n hoáº·c cÃ¡c tinh chá»‰nh báº£o máº­t ná»™i bá»™.
- VÃ­ dá»¥: CÃ¡c phiÃªn báº£n GPT-2 mÃ£ nguá»“n má»Ÿ.

---

## 2. Ká»¹ Thuáº­t ÄÃ¡nh GiÃ¡ Há»™p Äen

Ká»¹ thuáº­t phá»• biáº¿n nháº¥t lÃ  sá»­ dá»¥ng cÃ¡c máº¹o Ä‘áº·t cÃ¢u há»i (prompting tricks) Ä‘á»ƒ kÃ­ch hoáº¡t cÃ¡c hÃ nh vi khÃ´ng an toÃ n cá»§a mÃ´ hÃ¬nh.

### 2.1 Báº» khÃ³a MÃ´ hÃ¬nh (Jailbreaking)
Jailbreaking lÃ  ká»¹ thuáº­t lÃ¡ch qua cÃ¡c rÃ o cháº¯n báº£o máº­t báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c ngá»¯ cáº£nh sÃ¡ng táº¡o. 
- **VÃ­ dá»¥ Ä‘iá»ƒn hÃ¬nh:** YÃªu cáº§u mÃ´ hÃ¬nh Ä‘Ã³ng vai má»™t ngÆ°á»i bÃ  ká»ƒ chuyá»‡n vá» cÃ´ng thá»©c cháº¿ táº¡o bom hoáº·c napalm (Bedtime story attack).

### 2.2 CÃ¡c lá»—i logic vÃ  tÃ­nh toÃ¡n
ÄÃ¡nh giÃ¡ há»™p Ä‘en cÅ©ng giÃºp phÃ¡t hiá»‡n cÃ¡c khiáº¿m khuyáº¿t trong cÃ¡ch mÃ´ hÃ¬nh xá»­ lÃ½ thÃ´ng tin so vá»›i con ngÆ°á»i:
- **Lá»—i Ä‘áº¿m kÃ½ tá»±:** KhÃ³ khÄƒn trong viá»‡c Ä‘áº¿m sá»‘ chá»¯ "r" trong tá»« "strawberry".
- **Lá»—i so sÃ¡nh sá»‘ tháº­p phÃ¢n:** MÃ´ hÃ¬nh cÃ³ thá»ƒ cho ráº±ng $8.11 > 8.9$ do nháº§m láº«n vá»›i quy luáº­t Ä‘Ã¡nh sá»‘ phiÃªn báº£n pháº§n má»m.

---

## 3. Æ¯u Ä‘iá»ƒm vÃ  Háº¡n cháº¿

### 3.1 Æ¯u Ä‘iá»ƒm
- **TÃ­nh thá»±c táº¿ cao:** Pháº£n Ã¡nh Ä‘Ãºng cÃ¡ch ngÆ°á»i dÃ¹ng phá»• thÃ´ng tÆ°Æ¡ng tÃ¡c vá»›i AI.
- **RÃ o cáº£n gia nháº­p tháº¥p:** KhÃ´ng yÃªu cáº§u ká»¹ nÄƒng ká»¹ thuáº­t sÃ¢u, cho phÃ©p hÃ ng triá»‡u ngÆ°á»i tham gia tÃ¬m lá»—i.
- **PhÃ¡t hiá»‡n nhanh rá»§i ro:** GiÃºp cÃ¡c cÃ´ng ty AI vÃ¡ lá»— há»•ng ká»‹p thá»i.

### 3.2 Háº¡n cháº¿
- **Thiáº¿u tÃ­nh khoa há»c:** ThÆ°á»ng dá»±a trÃªn sá»± ngáº«u nhiÃªn hoáº·c tÃ­nh sÃ¡ng táº¡o cÃ¡ nhÃ¢n (serendipitous), khÃ´ng cÃ³ nguyÃªn lÃ½ toÃ¡n há»c cháº·t cháº½.
- **KhÃ´ng giáº£i quyáº¿t táº­n gá»‘c:** Chá»‰ phÃ¡t hiá»‡n triá»‡u chá»©ng (hÃ nh vi lá»—i) mÃ  khÃ´ng thá»ƒ giáº£i thÃ­ch cÆ¡ cháº¿ ná»™i táº¡i Ä‘á»ƒ sá»­a lá»—i trá»±c tiáº¿p trong kiáº¿n trÃºc.
- **Kháº£ nÄƒng mÃ´ hÃ¬nh Ä‘Ã¡nh lá»«a:** CÃ¡c mÃ´ hÃ¬nh máº¡nh máº½ cÃ³ kháº£ nÄƒng nÃ³i dá»‘i vá» nÄƒng lá»±c cá»§a chÃ­nh chÃºng Ä‘á»ƒ trÃ¡nh bá»‹ tinh chá»‰nh hoáº·c táº¯t bá».

---

## 4. CÆ¡ sá»Ÿ ToÃ¡n há»c liÃªn quan

DÃ¹ lÃ  há»™p Ä‘en, viá»‡c Ä‘Ã¡nh giÃ¡ váº«n dá»±a trÃªn xÃ¡c suáº¥t cá»§a chuá»—i token Ä‘áº§u ra:

$$P(T_{target} | T_{context}) = \text{Softmax}(Z)$$

Trong Ä‘Ã³ $Z$ lÃ  logit Ä‘áº§u ra. ÄÃ¡nh giÃ¡ há»™p Ä‘en táº­p trung vÃ o viá»‡c lÃ m tháº¿ nÃ o Ä‘á»ƒ thay Ä‘á»•i $T_{context}$ sao cho $P(T_{unsafe})$ Ä‘áº¡t giÃ¡ trá»‹ cá»±c Ä‘áº¡i.

---

## TÃ i liá»‡u tham kháº£o

1. **Anthropic (2022).** *Red Teaming Language Models to Reduce Harms.*
2. **OpenAI (2023).** *GPT-4 Technical Report.*
3. **Wei, J., et al. (2022).** *Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.*
4. **Ganguli, D., et al. (2022).** *Predictability and Surprise in Large Language Models.*
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| ğŸ“Œ **[ÄÃ¡nh GiÃ¡ Há»™p Äen (Black-box Evaluations) trong MÃ´ HÃ¬nh NgÃ´n Ngá»¯ Lá»›n](aero_LLM_016_Black box evals.md)** | [Xem bÃ i viáº¿t â†’](aero_LLM_016_Black box evals.md) |
| [Red Teaming: Äá»™i Äá» vÃ  Thá»­ Nghiá»‡m Äá»‘i KhÃ¡ng trong AI Safety](aero_LLM_017_Red-teaming.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_017_Red-teaming.md) |
| [Äá»™ ChÃ­nh XÃ¡c, TÃ­nh Máº¡ch Láº¡c vÃ  Sá»± PhÃ¹ Há»£p trong ÄÃ¡nh GiÃ¡ MÃ´ HÃ¬nh NgÃ´n Ngá»¯](aero_LLM_018_Accuracy, coherence, and relevance.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_018_Accuracy, coherence, and relevance.md) |
| [PhÃ¢n Phá»‘i Cá»§a CÃ¡c KÃ­ch Hoáº¡t Tráº¡ng ThÃ¡i áº¨n Trong MÃ´ HÃ¬nh NgÃ´n Ngá»¯](aero_LLM_019_Distributions of hidden-state activations.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_019_Distributions of hidden-state activations.md) |
| [Há»©a Háº¹n vÃ  ThÃ¡ch Thá»©c cá»§a ÄÃ¡nh GiÃ¡ Äá»‹nh LÆ°á»£ng trong MÃ´ HÃ¬nh Há»c MÃ¡y](aero_LLM_01_Promises and challenges of quantitative evaluations.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_01_Promises and challenges of quantitative evaluations.md) |
| [Báº£n Äá»“ Nhiá»‡t Cá»§a Token Cho CÃ¢n Nháº¯c Äá»‹nh TÃ­nh (Text Heatmaps)](aero_LLM_020_Heatmaps of tokens for qualitative inspection.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_020_Heatmaps of tokens for qualitative inspection.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh: Trá»±c Quan HÃ³a Dá»± ÄoÃ¡n ÄÆ¡n Token](aero_LLM_021_CodeChallenge Visualize single-token predictions.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_021_CodeChallenge Visualize single-token predictions.md) |
| [CÃ¡c Váº¥n Äá» Sá»‘ Há»c trong Logits vÃ  Softmax: PhÃ¢n TÃ­ch ToÃ¡n Há»c vÃ  Giáº£i PhÃ¡p á»”n Äá»‹nh](aero_LLM_02_Numerical issues in logits and softmax.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_02_Numerical issues in logits and softmax.md) |
| [Perplexity trong MÃ´ HÃ¬nh NgÃ´n Ngá»¯: CÆ¡ Sá»Ÿ ToÃ¡n Há»c, Diá»…n Giáº£i vÃ  Giá»›i Háº¡n](aero_LLM_03_Perplexity.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_03_Perplexity.md) |
| [aero_LLM_04_CodeChallenge Perplexing perplexities.md](aero_LLM_04_CodeChallenge Perplexing perplexities.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_04_CodeChallenge Perplexing perplexities.md) |
| [aero_LLM_05_Masked word prediction accuracy.md](aero_LLM_05_Masked word prediction accuracy.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_05_Masked word prediction accuracy.md) |
| [aero_LLM_06_HellaSwag.md](aero_LLM_06_HellaSwag.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_06_HellaSwag.md) |
| [aero_LLM_07_Import large models using bitsandbytes.md](aero_LLM_07_Import large models using bitsandbytes.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_07_Import large models using bitsandbytes.md) |
| [aero_LLM_08_CodeChallenge HellaSwag evals in two models (part 1).md](aero_LLM_08_CodeChallenge HellaSwag evals in two models (part 1).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_08_CodeChallenge HellaSwag evals in two models (part 1).md) |
| [aero_LLM_09_CodeChallenge HellaSwag evals in two models (part 2).md](aero_LLM_09_CodeChallenge HellaSwag evals in two models (part 2).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_09_CodeChallenge HellaSwag evals in two models (part 2).md) |
| [aero_LLM_10_KL (Kullback-Leibler) divergence.md](aero_LLM_10_KL (Kullback-Leibler) divergence.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_10_KL (Kullback-Leibler) divergence.md) |
| [aero_LLM_11_MAUVE.md](aero_LLM_11_MAUVE.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_11_MAUVE.md) |
| [aero_LLM_12_CodeChallenge Large and small MAUVE explorations.md](aero_LLM_12_CodeChallenge Large and small MAUVE explorations.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_12_CodeChallenge Large and small MAUVE explorations.md) |
| [aero_LLM_13_SuperGLUE and other amalgamations.md](aero_LLM_13_SuperGLUE and other amalgamations.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_13_SuperGLUE and other amalgamations.md) |
| [aero_LLM_14_Assessing bias and fairness.md](aero_LLM_14_Assessing bias and fairness.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_14_Assessing bias and fairness.md) |
| [aero_LLM_15_Non-technical benchmarks.md](aero_LLM_15_Non-technical benchmarks.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_15_Non-technical benchmarks.md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
