
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../index.md) > [09 Quantitative evaluations](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../index.md)
- [ğŸ“š Module 01: LLM Course](../../01-LLM_Course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../02-Words-to-tokens-to-numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../04-buildGPT/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../07-Fine-tune-pretrained-models/index.md)
- [ğŸ” Module 19: AI Safety](../../19-AI-safety/index.md)
- [ğŸ Module 20: Python for AI](../../20-Python-Colab-notebooks/index.md)
---
<!-- Aero-Navigation-End -->
ÄÃ¡nh giÃ¡ nÄƒng lá»±c suy luáº­n thÆ°á»ng thá»©c cá»§a mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n thÃ´ng qua bá»™ dá»¯ liá»‡u HellaSwag

PhÃ¢n tÃ­ch phÆ°Æ¡ng phÃ¡p, cÆ¡ sá»Ÿ toÃ¡n há»c vÃ  cÃ¡c thÃ¡ch thá»©c Ä‘á»‹nh lÆ°á»£ng

â¸»

TÃ³m táº¯t

BÃ i viáº¿t nÃ y phÃ¢n tÃ­ch bá»™ dá»¯ liá»‡u HellaSwag â€“ má»™t chuáº©n Ä‘Ã¡nh giÃ¡ nÄƒng lá»±c suy luáº­n thÆ°á»ng thá»©c (commonsense reasoning) cá»§a mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLMs). Dá»±a trÃªn ná»™i dung tÃ i liá»‡u Ä‘Ã­nh kÃ¨m, chÃºng tÃ´i má»Ÿ rá»™ng phÃ¢n tÃ­ch báº±ng cÃ¡ch tham chiáº¿u Ä‘áº¿n cÃ¡c nghiÃªn cá»©u cá»§a Rowan Zellers et al. (2019), kiáº¿n trÃºc Transformer cá»§a Ashish Vaswani et al. (2017), cÃ¹ng cÃ¡c phÆ°Æ¡ng phÃ¡p tiá»n huáº¥n luyá»‡n trong OpenAI vÃ  Google.

ChÃºng tÃ´i trÃ¬nh bÃ y:
	â€¢	Cáº¥u trÃºc vÃ  nguyÃªn lÃ½ cá»§a HellaSwag
	â€¢	CÃ¡ch tÃ­nh xÃ¡c suáº¥t lá»±a chá»n Ä‘Ã¡p Ã¡n
	â€¢	CÃ´ng thá»©c toÃ¡n há»c cá»§a accuracy vÃ  log-likelihood
	â€¢	So sÃ¡nh giá»¯a con ngÆ°á»i vÃ  mÃ´ hÃ¬nh
	â€¢	CÃ¡c thÃ¡ch thá»©c vá» adversarial filtering

â¸»

1. Giá»›i thiá»‡u

HellaSwag Ä‘Æ°á»£c Ä‘á» xuáº¥t nháº±m kiá»ƒm tra kháº£ nÄƒng:
	â€¢	Suy luáº­n tiáº¿p diá»…n hÃ nh Ä‘á»™ng (physical commonsense)
	â€¢	Hiá»ƒu bá»‘i cáº£nh
	â€¢	PhÃ¢n biá»‡t káº¿t thÃºc há»£p lÃ½ vÃ  vÃ´ lÃ½

VÃ­ dá»¥ (rÃºt gá»n):

â€œA person is cooking in the kitchen. They pick up a knife andâ€¦â€
A. start slicing vegetables
B. jump into a swimming pool
C. fly into space
D. dissolve into smoke

Con ngÆ°á»i dá»… dÃ ng chá»n A.
Tuy nhiÃªn mÃ´ hÃ¬nh ngÃ´n ngá»¯ pháº£i tÃ­nh xÃ¡c suáº¥t cho tá»«ng lá»±a chá»n.

â¸»

2. Cáº¥u trÃºc toÃ¡n há»c cá»§a bÃ i toÃ¡n

Cho:
	â€¢	Ngá»¯ cáº£nh: c
	â€¢	Táº­p 4 Ä‘Ã¡p Ã¡n: \{a_1, a_2, a_3, a_4\}

MÃ´ hÃ¬nh Æ°á»›c lÆ°á»£ng:

P(a_i \mid c)

ÄÃ¡p Ã¡n Ä‘Æ°á»£c chá»n:

\hat{a} = \arg\max_{a_i} P(a_i \mid c)

â¸»

3. TÃ­nh xÃ¡c suáº¥t trong mÃ´ hÃ¬nh tá»± há»“i quy

Vá»›i mÃ´ hÃ¬nh kiá»ƒu GPT:

P(a_i \mid c) = \prod_{t=1}^{T_i} P(w_t \mid c, w_{<t})

Trong thá»±c nghiá»‡m, ta dÃ¹ng log-likelihood:

\log P(a_i \mid c) = \sum_{t=1}^{T_i} \log P(w_t \mid c, w_{<t})

Äá»ƒ trÃ¡nh thiÃªn vá»‹ Ä‘á»™ dÃ i, thÆ°á»ng dÃ¹ng chuáº©n hoÃ¡:

Score(a_i) = \frac{1}{T_i} \sum_{t=1}^{T_i} \log P(w_t \mid c, w_{<t})

â¸»

4. Accuracy trong HellaSwag

Vá»›i N cÃ¢u há»i:

Accuracy = \frac{1}{N} \sum_{j=1}^{N} \mathbf{1}(\hat{a}^{(j)} = a^{(j)}_{\text{true}})

Baseline ngáº«u nhiÃªn:

P_{\text{random}} = \frac{1}{4} = 25\%

Hiá»‡u nÄƒng con ngÆ°á»i â‰ˆ 95%
CÃ¡c mÃ´ hÃ¬nh cÅ© (trÆ°á»›c Transformer lá»›n) â‰ˆ 30â€“40%

â¸»

5. Adversarial Filtering

Theo Rowan Zellers, HellaSwag sá»­ dá»¥ng Adversarial Filtering (AF):
	1.	Sinh nhiá»u káº¿t thÃºc sai báº±ng mÃ´ hÃ¬nh ngÃ´n ngá»¯.
	2.	Lá»c bá» nhá»¯ng Ä‘Ã¡p Ã¡n mÃ  mÃ´ hÃ¬nh hiá»‡n táº¡i dá»… phÃ¢n biá»‡t.
	3.	Giá»¯ láº¡i nhá»¯ng Ä‘Ã¡p Ã¡n â€œÄ‘Ã¡nh lá»«aâ€ mÃ´ hÃ¬nh.

MÃ´ hÃ¬nh lá»c:

f_\theta(c, a_i)

Giá»¯ láº¡i cÃ¡c máº«u mÃ :

f_\theta(c, a_{\text{true}}) - f_\theta(c, a_{\text{false}}) \approx 0

Äiá»u nÃ y lÃ m bá»™ dá»¯ liá»‡u ngÃ y cÃ ng khÃ³.

â¸»

6. LiÃªn há»‡ vá»›i Self-Attention

Kiáº¿n trÃºc Transformer:

Attention(Q,K,V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V

Self-attention cho phÃ©p mÃ´ hÃ¬nh:
	â€¢	Hiá»ƒu quan há»‡ dÃ i háº¡n
	â€¢	Náº¯m báº¯t chuá»—i hÃ nh Ä‘á»™ng
	â€¢	PhÃ¢n biá»‡t logic váº­t lÃ½

â¸»

7. So sÃ¡nh HellaSwag vÃ  Perplexity

Perplexity Ä‘o:

PP = \exp\left(- \frac{1}{N} \sum \log P(w_i)\right)

Trong khi HellaSwag Ä‘o:
	â€¢	Kháº£ nÄƒng so sÃ¡nh nhiá»u chuá»—i hoÃ n chá»‰nh
	â€¢	Suy luáº­n cáº¥p cao

MÃ´ hÃ¬nh cÃ³ perplexity tháº¥p chÆ°a cháº¯c cÃ³ accuracy cao trÃªn HellaSwag.

â¸»

8. PhÃ¢n tÃ­ch thá»‘ng kÃª

Giáº£ sá»­ mÃ´ hÃ¬nh Ä‘áº¡t accuracy \hat{p} trÃªn N máº«u:

Sai sá»‘ chuáº©n:

SE = \sqrt{\frac{\hat{p}(1-\hat{p})}{N}}

Khoáº£ng tin cáº­y 95%:

\hat{p} \pm 1.96 \cdot SE

VÃ­ dá»¥:
	â€¢	N = 10,000
	â€¢	Accuracy = 0.80

SE = \sqrt{\frac{0.8(0.2)}{10000}} = 0.004

Khoáº£ng tin cáº­y:

0.80 \pm 0.008

â¸»

9. Nhá»¯ng háº¡n cháº¿ cá»§a HellaSwag

9.1 Bias ngÃ´n ngá»¯

MÃ´ hÃ¬nh cÃ³ thá»ƒ há»c:
	â€¢	Máº«u vÄƒn phong
	â€¢	Cáº¥u trÃºc cÃ¢u há»£p lÃ½ hÆ¡n

Chá»© khÃ´ng thá»±c sá»± hiá»ƒu váº­t lÃ½.

â¸»

9.2 Overfitting Benchmark

Náº¿u mÃ´ hÃ¬nh Ä‘Æ°á»£c fine-tune trá»±c tiáº¿p trÃªn HellaSwag:

D_{train} \cap D_{test} \neq \varnothing

Káº¿t quáº£ khÃ´ng cÃ²n pháº£n Ã¡nh kháº£ nÄƒng tá»•ng quÃ¡t.

â¸»

9.3 Scaling Law

Theo cÃ¡c nghiÃªn cá»©u cá»§a OpenAI:

Loss(N) = A N^{-\alpha} + B

Khi sá»‘ tham sá»‘ tÄƒng â†’ accuracy trÃªn HellaSwag tÄƒng gáº§n theo hÃ m lÅ©y thá»«a.

â¸»

10. Ã nghÄ©a Ä‘á»‘i vá»›i Ä‘Ã¡nh giÃ¡ LLM

HellaSwag:
	â€¢	KhÃ´ng chá»‰ Ä‘o xÃ¡c suáº¥t tá»«
	â€¢	MÃ  Ä‘o kháº£ nÄƒng suy luáº­n hÃ nh Ä‘á»™ng
	â€¢	Giáº£m thiá»ƒu shortcut learning

Do Ä‘Ã³ nÃ³ lÃ  benchmark quan trá»ng bÃªn cáº¡nh:
	â€¢	MMLU
	â€¢	ARC
	â€¢	Winogrande

â¸»

11. Káº¿t luáº­n

HellaSwag lÃ  má»™t bÆ°á»›c tiáº¿n quan trá»ng trong Ä‘Ã¡nh giÃ¡ nÄƒng lá»±c suy luáº­n thÆ°á»ng thá»©c cá»§a mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n.

CÃ¡c Ä‘iá»ƒm chÃ­nh:
	â€¢	Dá»±a trÃªn multiple choice completion
	â€¢	Sá»­ dá»¥ng adversarial filtering
	â€¢	ÄÃ¡nh giÃ¡ báº±ng log-likelihood vÃ  accuracy
	â€¢	PhÃ¢n biá»‡t rÃµ giá»¯a fluency vÃ  reasoning

Trong tÆ°Æ¡ng lai, cáº§n káº¿t há»£p:
	â€¢	ÄÃ¡nh giÃ¡ Ä‘á»™ng (interactive reasoning)
	â€¢	PhÃ¢n tÃ­ch attention map
	â€¢	Äo calibration vÃ  uncertainty

â¸»

TÃ i liá»‡u tham kháº£o
	1.	Zellers, R. et al. (2019). HellaSwag: Can a Machine Really Finish Your Sentence?
	2.	Vaswani, A. et al. (2017). Attention is All You Need.
	3.	Brown et al. (2020). Language Models are Few-Shot Learners.
	4.	Kaplan et al. (2020). Scaling Laws for Neural Language Models.
	5.	Jurafsky & Martin. Speech and Language Processing.
<!-- Aero-Footer-Start -->
---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
