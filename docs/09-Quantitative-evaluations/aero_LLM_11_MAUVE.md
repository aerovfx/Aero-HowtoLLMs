
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../index.md) > [09 Quantitative evaluations](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../index.md)
- [ğŸ“š Module 01: LLM Course](../../01-LLM_Course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../02-Words-to-tokens-to-numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../04-buildGPT/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../07-Fine-tune-pretrained-models/index.md)
- [ğŸ” Module 19: AI Safety](../../19-AI-safety/index.md)
- [ğŸ Module 20: Python for AI](../../20-Python-Colab-notebooks/index.md)
---
<!-- Aero-Navigation-End -->
MAUVE: Äo lÆ°á»ng cháº¥t lÆ°á»£ng vÃ  Ä‘a dáº¡ng cá»§a mÃ´ hÃ¬nh sinh ngÃ´n ngá»¯ thÃ´ng qua hÃ¬nh há»c phÃ¢n phá»‘i

PhÃ¢n tÃ­ch lÃ½ thuyáº¿t, cÃ´ng thá»©c toÃ¡n há»c vÃ  á»©ng dá»¥ng trong Ä‘Ã¡nh giÃ¡ LLM

â¸»

TÃ³m táº¯t

BÃ i viáº¿t nÃ y trÃ¬nh bÃ y phÆ°Æ¡ng phÃ¡p MAUVE â€“ má»™t thÆ°á»›c Ä‘o hiá»‡n Ä‘áº¡i Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh sinh ngÃ´n ngá»¯ dá»±a trÃªn so sÃ¡nh hÃ¬nh há»c giá»¯a hai phÃ¢n phá»‘i xÃ¡c suáº¥t: phÃ¢n phá»‘i dá»¯ liá»‡u tháº­t vÃ  phÃ¢n phá»‘i do mÃ´ hÃ¬nh sinh ra. Ná»™i dung Ä‘Æ°á»£c phÃ¡t triá»ƒn dá»±a trÃªn tÃ i liá»‡u Ä‘Ã­nh kÃ¨m vÃ  má»Ÿ rá»™ng tá»« cÃ´ng trÃ¬nh cá»§a Krishna Pillutla et al. (2021), ná»n táº£ng lÃ½ thuyáº¿t phÃ¢n ká»³ thÃ´ng tin cá»§a Solomon Kullback vÃ  Richard Leibler, cÃ¹ng á»©ng dá»¥ng trong cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n táº¡i OpenAI.

â¸»

1. Giá»›i thiá»‡u

ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh sinh ngÃ´n ngá»¯ (text generation) lÃ  bÃ i toÃ¡n khÃ³ vÃ¬ cáº§n cÃ¢n báº±ng:
	â€¢	Cháº¥t lÆ°á»£ng (quality): cÃ¢u cÃ³ há»£p lÃ½, trÃ´i cháº£y?
	â€¢	Äa dáº¡ng (diversity): mÃ´ hÃ¬nh cÃ³ sinh láº·p láº¡i khÃ´ng?

CÃ¡c thÆ°á»›c Ä‘o truyá»n thá»‘ng nhÆ°:
	â€¢	Perplexity
	â€¢	BLEU
	â€¢	ROUGE

khÃ´ng pháº£n Ã¡nh Ä‘áº§y Ä‘á»§ sá»± khÃ¡c biá»‡t phÃ¢n phá»‘i toÃ n cá»¥c.

MAUVE giáº£i quyáº¿t báº±ng cÃ¡ch:
	â€¢	So sÃ¡nh phÃ¢n phá»‘i embedding cá»§a vÄƒn báº£n tháº­t vÃ  vÄƒn báº£n sinh
	â€¢	XÃ¢y dá»±ng Ä‘Æ°á»ng cong trade-off giá»¯a precision vÃ  recall

â¸»

2. CÆ¡ sá»Ÿ lÃ½ thuyáº¿t

Giáº£ sá»­:
	â€¢	P: phÃ¢n phá»‘i dá»¯ liá»‡u tháº­t
	â€¢	Q: phÃ¢n phá»‘i mÃ´ hÃ¬nh sinh

Ta muá»‘n Ä‘o má»©c gáº§n nhau giá»¯a P vÃ  Q.

â¸»

3. KL Divergence vÃ  háº¡n cháº¿

PhÃ¢n ká»³ KL:

D_{KL}(P \| Q) = \sum_x P(x)\log \frac{P(x)}{Q(x)}

Váº¥n Ä‘á»:
	â€¢	KhÃ´ng Ä‘á»‘i xá»©ng
	â€¢	KhÃ´ng Ä‘o Ä‘á»“ng thá»i precision vÃ  recall
	â€¢	KhÃ´ng pháº£n Ã¡nh hÃ¬nh há»c phÃ¢n phá»‘i

â¸»

4. Ã tÆ°á»Ÿng cá»§a MAUVE

MAUVE dá»±a trÃªn há» phÃ¢n ká»³:

D_\lambda(P \| Q)

Táº¡o phÃ¢n phá»‘i trá»™n:

R_\lambda = \lambda P + (1-\lambda) Q

Sau Ä‘Ã³ tÃ­nh:

D_{KL}(P \| R_\lambda)
\quad \text{vÃ } \quad
D_{KL}(Q \| R_\lambda)

Khi thay Ä‘á»•i \lambda \in [0,1], ta thu Ä‘Æ°á»£c má»™t Ä‘Æ°á»ng cong trong khÃ´ng gian hai chiá»u.

â¸»

5. Precisionâ€“Recall Curve trong khÃ´ng gian phÃ¢n phá»‘i

MAUVE xÃ¢y dá»±ng Ä‘á»“ thá»‹:

x(\lambda) = D_{KL}(P \| R_\lambda)
y(\lambda) = D_{KL}(Q \| R_\lambda)

Diá»‡n tÃ­ch dÆ°á»›i Ä‘Æ°á»ng cong nÃ y Ä‘Æ°á»£c chuáº©n hoÃ¡ thÃ nh Ä‘iá»ƒm MAUVE:

MAUVE \in [0,1]

GiÃ¡ trá»‹ gáº§n 1 â†’ phÃ¢n phá»‘i gáº§n nhau.

â¸»

6. Triá»ƒn khai thá»±c táº¿

6.1 Embedding

VÄƒn báº£n Ä‘Æ°á»£c Ã¡nh xáº¡ vÃ o khÃ´ng gian embedding:

x_i = f_{\text{LM}}(text_i)

Trong Ä‘Ã³ f_{\text{LM}} lÃ  encoder tá»« Transformer cá»§a Ashish Vaswani et al.

â¸»

6.2 Rá»i ráº¡c hoÃ¡ khÃ´ng gian

KhÃ´ng gian embedding Ä‘Æ°á»£c phÃ¢n cá»¥m (k-means):

\min \sum_{i=1}^{N} ||x_i - c_{z_i}||^2

Sau Ä‘Ã³ Æ°á»›c lÆ°á»£ng phÃ¢n phá»‘i rá»i ráº¡c trÃªn cÃ¡c cluster.

â¸»

7. So sÃ¡nh vá»›i Perplexity

Perplexity:

PP = \exp\left(- \frac{1}{N} \sum \log P(w_i)\right)

Perplexity:
	â€¢	Äo cháº¥t lÆ°á»£ng token-level
	â€¢	KhÃ´ng Ä‘o Ä‘a dáº¡ng toÃ n cá»¥c

MAUVE:
	â€¢	Äo phÃ¢n phá»‘i toÃ n vÄƒn báº£n
	â€¢	CÃ¢n báº±ng precisionâ€“recall

â¸»

8. PhÃ¢n tÃ­ch hÃ¬nh há»c

Giáº£ sá»­:
	â€¢	P = Q

â†’ Vá»›i má»i \lambda:

D_{KL}(P \| R_\lambda) = D_{KL}(Q \| R_\lambda)

â†’ MAUVE = 1

Náº¿u:
	â€¢	Q collapse (mode collapse)

â†’ D_{KL}(P \| Q) lá»›n
â†’ MAUVE giáº£m máº¡nh.

â¸»

9. PhÃ¢n tÃ­ch giá»›i háº¡n

9.1 Khi Q thiáº¿u Ä‘a dáº¡ng

Recall tháº¥p:

D_{KL}(P \| R_\lambda) \uparrow

â¸»

9.2 Khi Q sinh nhiá»…u

Precision tháº¥p:

D_{KL}(Q \| R_\lambda) \uparrow

â¸»

10. So sÃ¡nh vá»›i Jensenâ€“Shannon Divergence

JSD:

JSD(P \| Q) =
\frac{1}{2} D_{KL}(P \| M)
+
\frac{1}{2} D_{KL}(Q \| M)

vá»›i:

M = \frac{1}{2}(P+Q)

MAUVE cÃ³ thá»ƒ xem nhÆ° má»Ÿ rá»™ng hÃ¬nh há»c cá»§a JSD khi thay Ä‘á»•i \lambda.

â¸»

11. Ã nghÄ©a trong Ä‘Ã¡nh giÃ¡ LLM

MAUVE Ä‘áº·c biá»‡t há»¯u Ã­ch khi:
	â€¢	So sÃ¡nh hai mÃ´ hÃ¬nh sinh vÄƒn báº£n
	â€¢	ÄÃ¡nh giÃ¡ fine-tuning
	â€¢	Äo hiá»‡u quáº£ RLHF

Trong pipeline huáº¥n luyá»‡n táº¡i OpenAI, MAUVE cÃ³ thá»ƒ bá»• sung cho perplexity.

â¸»

12. Háº¡n cháº¿
	1.	Phá»¥ thuá»™c embedding model
	2.	Phá»¥ thuá»™c sá»‘ cluster
	3.	Tá»‘n chi phÃ­ tÃ­nh toÃ¡n

â¸»

13. Káº¿t luáº­n

MAUVE lÃ  thÆ°á»›c Ä‘o tiÃªn tiáº¿n:
	â€¢	Dá»±a trÃªn hÃ¬nh há»c phÃ¢n phá»‘i
	â€¢	CÃ¢n báº±ng cháº¥t lÆ°á»£ng vÃ  Ä‘a dáº¡ng
	â€¢	Kháº¯c phá»¥c háº¡n cháº¿ cá»§a perplexity

NÃ³ káº¿t ná»‘i lÃ½ thuyáº¿t phÃ¢n ká»³ KL vá»›i Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh sinh hiá»‡n Ä‘áº¡i.

â¸»

TÃ i liá»‡u tham kháº£o
	1.	Pillutla, K. et al. (2021). MAUVE: Measuring the Gap Between Neural Text and Human Text.
	2.	Kullback, S., Leibler, R. (1951). On Information and Sufficiency.
	3.	Shannon, C. (1948). A Mathematical Theory of Communication.
	4.	Vaswani, A. et al. (2017). Attention is All You Need.
	5.	Goodfellow, I. et al. (2016). Deep Learning.
<!-- Aero-Footer-Start -->
---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
