
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../index.md) > [09 Quantitative evaluations](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../index.md)
- [ğŸ“š Module 01: LLM Course](../../01-LLM_Course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../02-Words-to-tokens-to-numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../04-buildGPT/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../07-Fine-tune-pretrained-models/index.md)
- [ğŸ” Module 19: AI Safety](../../19-AI-safety/index.md)
- [ğŸ Module 20: Python for AI](../../20-Python-Colab-notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Báº£n Äá»“ Nhiá»‡t Cá»§a Token Cho CÃ¢n Nháº¯c Äá»‹nh TÃ­nh (Text Heatmaps)

## TÃ³m táº¯t

CÃ¡c phÃ¢n tÃ­ch ná»™i táº¡i cá»§a má»™t MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n sinh ra lÆ°á»£ng lá»›n thÃ´ng tin vá» sá»‘ liá»‡u vÃ´ tri khÃ¡ trá»«u tÆ°á»£ng. Äá»ƒ cÃ³ cáº£m quan (intuition) vá» cÃ¡ch LLM hoáº¡t Ä‘á»™ng trÃªn vÄƒn báº£n con ngÆ°á»i, phÆ°Æ¡ng phÃ¡p táº¡o ra **Báº£n Ä‘á»“ nhiá»‡t vÄƒn báº£n** (Text Heatmaps) trá»Ÿ nÃªn phá»• biáº¿n. BÃ i viáº¿t nÃªu báº­t sá»± liÃªn káº¿t sá»‘ tÄ©nh vÃ o ná»n cá»§a chuá»—i con tá»« tá»± nhiÃªn, chuyá»ƒn hÃ³a thÃ´ng sá»‘ phÃ¢n rÃ£ Ä‘á»‹nh lÆ°á»£ng trá»Ÿ thÃ nh trá»±c quan Ä‘á»‹nh tÃ­nh.

---

## 1. PhÆ°Æ¡ng PhÃ¡p Láº­p Báº£n Äá»“ Nhiá»‡t VÄƒn Báº£n

Má»—i má»™t `token` ($t_i$) á»©ng vá»›i má»™t con sá»‘ cá»¥ thá»ƒ thá»ƒ hiá»‡n má»™t Ä‘áº¡i lÆ°á»£ng $X_i$ cho LLM. Ká»¹ thuáº­t sau sá»­ dá»¥ng sá»± Ä‘á»‘i sÃ¡nh trá»±c tiáº¿p Ä‘á»ƒ tÃ´ mÃ u vÃ o há»™p vÄƒn báº£n theo thÃ´ng sá»‘ liÃªn káº¿t.

### 1.1 TÃ­nh ToÃ¡n KÃ­ch Cá»¡

Do mÃ´i trÆ°á»ng láº­p trÃ¬nh thÆ°á»ng xuáº¥t dá»¯ liá»‡u thÃ´ng qua cá»­a sá»• hiá»ƒn thá»‹ (nhÆ° matplotlib), cÃ¡c chá»¯ cÃ¡i (characters) cáº§n sá»­ dá»¥ng má»™t font Ä‘á»“ng nhá»‹p nhÆ° Monospace Ä‘á»ƒ tÃ­nh diá»‡n tÃ­ch.

Vá»›i thiáº¿t láº­p: `Figure = 10 \times 2`, tá»· lá»‡ cá»‘ Ä‘á»‹nh cá»§a 1 token sáº½ Ä‘Æ°á»£c chuyá»ƒn thÃ nh giÃ¡ trá»‹ hÃ¬nh há»™p (bounding box) cá»¥ thá»ƒ cÃ³ tá»a Ä‘á»™ vÃ  chiá»u dÃ i Ä‘Æ°á»£c láº¥y trá»±c tiáº¿p bá»Ÿi thuáº­t toÃ¡n Ä‘á»“ há»a. Tá»« Ä‘Ã³ láº¥y lÃ m Ä‘Æ¡n vá»‹ cho $t_1, t_2...$

### 1.2 Biáº¿n Äá»•i Tá»· Lá»‡ (Min-Max Scaling)

Äá»ƒ váº½ báº£n Ä‘á»“ nhiá»‡t dá»±a trÃªn sá»± chuyá»ƒn sáº¯c (color map - nhÆ° Ä‘á» nháº¡t sang Ä‘Ã´), táº­p sá»‘ ná»™i táº¡i cáº§n Ä‘Æ°á»£c liÃªn káº¿t lÃªn má»™t khoáº£ng giÃ¡ trá»‹ tiÃªu chuáº©n tá»« $0$ tá»›i $1$. PhÃ©p biáº¿n Ä‘á»•i chuáº©n Ä‘Æ°á»£c sá»­ dá»¥ng lÃ  **Min-Max Scaling**.

Giáº£ sá»­ $x_i$ lÃ  sá»‘ lÆ°á»£ng kÃ½ tá»± trong chuá»—i chá»¯ $i$:

$$x_{norm} = \frac{x_i - X_{min}}{X_{max} - X_{min}}$$

PhÃ©p Ä‘á»•i chuáº©n lÃ  tuyáº¿n tÃ­nh (linear transformation). NÃ³ khÃ´ng phÃ¡ vá»¡ tÃ­nh tÆ°Æ¡ng quan gá»‘c rá»… mÃ  chá»‰ co Ã©p sá»‘ liá»‡u vÃ o khuÃ´n khá»• $[0,1]$ nháº±m káº¿t xuáº¥t mÃ u thÃ´ng qua há»‡ sá»‘ RGB.

---

## 2. á»¨ng Dá»¥ng vÃ o VÃ­ Dá»¥ Thá»±c Táº¿

Ban Ä‘áº§u, thay vÃ¬ gáº¯n kÃ­ch hoáº¡t (activations) tá»« máº¡ng Neural, báº£n váº½ Heatmap Ä‘Æ°á»£c giáº£ láº­p thÃ´ng qua Ä‘á»™ dÃ i dÃ²ng chá»¯ `Lorem Ipsum`. Chá»¯ cÃ³ mÃ u Ä‘á» cÃ ng Ä‘áº­m á»©ng vá»›i cÃ¡c tá»« kÃ©o dÃ i (nhiá»u kÃ½ tá»±), chá»¯ sÃ¡ng tráº¯ng thuá»™c cÃ¡c pháº§n tá»­ tá»« vá»¥n ngáº¯n.

Äiá»u nÃ y mÃ´ phá»ng cÃ¡c giÃ¡ trá»‹ logit ná»™i bá»™ $Z$ (sáº½ Ä‘Æ°á»£c tÃ¬m trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n/trÃ­ch xuáº¥t mÃ´ hÃ¬nh):
$$Z \rightarrow \text{Softmax}(\cdot) \rightarrow P_i \rightarrow X_i$$
CÃ ng Ä‘áº­m mÃ u tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i nÄƒng lá»±c dá»± Ä‘oÃ¡n tiáº¿p theo cÃ ng chÃ­nh xÃ¡c Ä‘á»‹nh tÃ­nh.

---

## 3. Thuáº­n Lá»£i VÃ  Rá»§i Ro

Máº·c dÃ¹ cÃ³ nhiá»u lá»£i Ã­ch:
- LÃ m trá»±c quan sá»± liÃªn káº¿t cá»§a vÃ´ vÃ n chá»‰ sá»‘ máº¡ng NN vá»›i quÃ¡ trÃ¬nh sinh ra chá»¯ cá»§a trÃ­ thÃ´ng minh.
- PhÃ¢n tÃ¡ch ra tá»«ng tá»« (hoáº·c Sub-word) rÃµ rÃ ng.

NhÆ°ng cÅ©ng hiá»‡n diá»‡n cáº£ nguy cÆ¡ diá»…n giáº£i sai lá»‡ch (over interpretation) vÃ¬ nhiá»…u hoáº·c cÃ¡c máº«u ngáº«u nhiÃªn (noise and unrepresentative examples). Con ngÆ°á»i ráº¥t nháº¡y cáº£m vá»›i hÃ¬nh áº£nh mÃ u sáº¯c vÃ  dá»… gáº¯n cho nÃ³ cÃ¡c quy luáº­t giáº£ (Phantom patterns), dÃ¹ cho Ä‘Ã´i khi sá»‘ liá»‡u Ä‘Ã³ bá»‹ sai hoáº·c lá»—i.

---

## TÃ i liá»‡u tham kháº£o

1. **Rethmeier, N. et al. (2020).** *Visualizing and Understanding the Interpretability of Natural Language.*
2. **Karpathy, A. (2015).** *The Unreasonable Effectiveness of Recurrent Neural Networks.* Blog.
3. **Elhage, N. et al. (2021).** *A Mathematical Framework for Transformer Circuits.* Anthropic.
<!-- Aero-Footer-Start -->
---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
