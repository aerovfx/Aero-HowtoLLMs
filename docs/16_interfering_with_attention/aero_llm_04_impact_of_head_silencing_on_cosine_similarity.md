
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../index.md) > [16 interfering with attention](index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../index.md)
- [ğŸ“š Module 01: LLM Course](../01_llm_course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../02_words_to_tokens_to_numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../04_buildgpt/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../07_fine_tune_pretrained_models/index.md)
- [ğŸ” Module 19: AI Safety](../19_ai_safety/index.md)
- [ğŸ Module 20: Python for AI](../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# TÃ¡c Ä‘á»™ng cá»§a viá»‡c "Táº¯t tiáº¿ng" Head lÃªn Äá»™ tÆ°Æ¡ng Ä‘á»“ng Cosine (Impact of Head-Silencing on Cosine Similarity)

## TÃ³m táº¯t (Abstract)
BÃ¡o cÃ¡o nÃ y khÃ¡m phÃ¡ tÃ¡c Ä‘á»™ng cá»§a viá»‡c cáº¯t bá» Attention Head lÃªn má»‘i quan há»‡ khÃ´ng gian giá»¯a cÃ¡c token embeddings, sá»­ dá»¥ng chá»‰ sá»‘ Äá»™ tÆ°Æ¡ng Ä‘á»“ng Cosine (Cosine Similarity). Thay vÃ¬ Ä‘o lÆ°á»ng káº¿t quáº£ dá»± Ä‘oÃ¡n cuá»‘i cÃ¹ng, nghiÃªn cá»©u táº­p trung vÃ o viá»‡c quan sÃ¡t cÃ¡ch cÃ¡c Representation cá»§a token "co láº¡i" hoáº·c "giÃ£n ra" trong residual stream sau khi má»™t Head bá»‹ vÃ´ hiá»‡u hÃ³a. Sá»­ dá»¥ng mÃ´ hÃ¬nh GPT-2 Medium vÃ  tÃ¡c vá»¥ vá»›i cÃ¢u máº«u hÃ i hÆ°á»›c vá» Pizza, thá»±c nghiá»‡m chá»‰ ra ráº±ng cÃ¡c can thiá»‡p nhá» á»Ÿ táº§ng sá»›m cÃ³ thá»ƒ táº¡o ra "hiá»‡u á»©ng gá»£n sÃ³ng" (ripple effect) kÃ©o dÃ i Ä‘áº¿n táº­n cÃ¡c táº§ng cuá»‘i cá»§a mÃ´ hÃ¬nh, minh chá»©ng cho tÃ­nh cháº¥t cá»§a má»™t há»‡ thá»‘ng há»—n loáº¡n táº¥t Ä‘á»‹nh.

---

## 1. Má»Ÿ Äáº§u (Introduction)
Má»¥c tiÃªu cá»‘t lÃµi cá»§a tiá»ƒu khá»‘i Attention lÃ  tÃ­ch há»£p thÃ´ng tin ngá»¯ cáº£nh giá»¯a cÃ¡c token. Náº¿u giáº£ thuyáº¿t nÃ y Ä‘Ãºng, viá»‡c vÃ´ hiá»‡u hÃ³a (silencing) má»™t Attention Head sáº½ trá»±c tiáº¿p lÃ m thay Ä‘á»•i Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng giá»¯a cÃ¡c vector Ä‘áº¡i diá»‡n cá»§a cÃ¡c token. NghiÃªn cá»©u nÃ y sá»­ dá»¥ng Äá»™ tÆ°Æ¡ng Ä‘á»“ng Cosine Ä‘á»ƒ Ä‘á»‹nh lÆ°á»£ng sá»± thay Ä‘á»•i nÃ y, cung cáº¥p má»™t gÃ³c nhÃ¬n ná»™i táº¡i hÆ¡n vá» cÃ¡ch cÃ¡c máº¡ch tháº§n kinh tÆ°Æ¡ng tÃ¡c vá»›i nhau trÆ°á»›c khi Ä‘Æ°a ra dá»± Ä‘oÃ¡n.

---

## 2. PhÆ°Æ¡ng PhÃ¡p Thá»±c Nghiá»‡m (Methodology)

### 2.1. Cáº¥u trÃºc Thá»±c nghiá»‡m vÃ  Chá»‰ sá»‘ Äo lÆ°á»ng
- **Ká»¹ thuáº­t:** Sá»­ dá»¥ng Forward Pre-hook Ä‘á»ƒ triá»‡t tiÃªu má»™t Head báº¥t ká»³ trong táº§ng `c_proj`.
- **Chá»‰ sá»‘:** Äá»™ tÆ°Æ¡ng Ä‘á»“ng Cosine giá»¯a táº¥t cáº£ cÃ¡c cáº·p token trong cÃ¢u: $CS(\mathbf{v}_i, \mathbf{v}_j) = \frac{\mathbf{v}_i \cdot \mathbf{v}_j}{\|\mathbf{v}_i\| \|\mathbf{v}_j\|}$.
- **CÃ´ng thá»©c pháº§n tá»­ duy nháº¥t:** Äá»‘i vá»›i ma tráº­n Ä‘á»‘i xá»©ng $M \times M$, sá»‘ cáº·p token duy nháº¥t (loáº¡i trá»« Ä‘Æ°á»ng chÃ©o) lÃ  $\frac{M(M-1)}{2}$.

### 2.2. PhÃ¢n tÃ­ch T-test vÃ  Hiá»‡u chá»‰nh Äa so sÃ¡nh
Äá»ƒ xÃ¡c Ä‘á»‹nh xem sá»± thay Ä‘á»•i Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng lÃ  cÃ³ Ã½ nghÄ©a thá»‘ng kÃª hay chá»‰ lÃ  nhiá»…u, chÃºng ta thá»±c hiá»‡n phÃ©p thá»­ T-test trÃªn táº­p há»£p cÃ¡c cáº·p token.
- **Hiá»‡u chá»‰nh Bonferroni:** NgÆ°á»¡ng Ã½ nghÄ©a Ä‘Æ°á»£c Ä‘iá»u chá»‰nh thÃ nh $p < 0.05 / 24$ (sá»‘ táº§ng) Ä‘á»ƒ trÃ¡nh sai sá»‘ loáº¡i I khi thá»±c hiá»‡n nhiá»u phÃ©p thá»­ Ä‘á»“ng thá»i.

---

## 3. Káº¿t Quáº£ VÃ  PhÃ¢n TÃ­ch (Results & Analysis)

### 3.1. Quá»¹ Ä‘áº¡o cá»§a Äá»™ tÆ°Æ¡ng Ä‘á»“ng Cosine (Clean Model)
- **Xu hÆ°á»›ng:** Äá»™ tÆ°Æ¡ng Ä‘á»“ng thÆ°á»ng giáº£m dáº§n á»Ÿ cÃ¡c táº§ng Ä‘áº§u (decoupling) khi mÃ´ hÃ¬nh Ä‘ang cá»‘ gáº¯ng phÃ¢n hÃ³a Ã½ nghÄ©a cÃ¡c token dá»±a trÃªn ngá»¯ cáº£nh riÃªng biá»‡t.
- **Há»™i tá»¥:** á» cÃ¡c táº§ng cuá»‘i, Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng tÄƒng máº¡nh hÆ°á»›ng tá»›i giÃ¡ trá»‹ 1, cho tháº¥y cÃ¡c embeddings Ä‘ang há»™i tá»¥ vá» má»™t khÃ´ng gian biá»ƒu diá»…n chung Ä‘á»ƒ chuáº©n bá»‹ dá»± Ä‘oÃ¡n token tiáº¿p theo.

### 3.2. Hiá»‡u á»©ng Gá»£n sÃ³ng (Ripple Effect)
ThÃ­ nghiá»‡m "Táº¯t tiáº¿ng" Head táº¡i Layer 3 cho tháº¥y:
- **TÃ¡c Ä‘á»™ng tá»©c thá»i:** Thay Ä‘á»•i nhá» vÃ  Ä‘Ã´i khi khÃ´ng cÃ³ Ã½ nghÄ©a thá»‘ng kÃª ngay táº¡i táº§ng bá»‹ can thiá»‡p.
- **Lan truyá»n:** Tuy nhiÃªn, sai lá»‡ch nÃ y khÃ´ng biáº¿n máº¥t mÃ  lan truyá»n qua cÃ¡c táº§ng tiáº¿p theo. Äáº¿n cÃ¡c táº§ng cuá»‘i (Layer 20-24), hiá»‡u á»©ng trá»Ÿ nÃªn nháº¥t quÃ¡n vÃ  cÃ³ Ã½ nghÄ©a thá»‘ng kÃª rÃµ rá»‡t.
- **Ã nghÄ©a:** Äiá»u nÃ y chá»©ng minh ráº±ng trong má»™t há»‡ thá»‘ng phá»©c táº¡p, cÃ¡c sai sá»‘ nhá» á»Ÿ Ä‘áº§u chuá»—i cÃ³ thá»ƒ tÃ­ch tá»¥ vÃ  Ä‘á»‹nh hÃ¬nh láº¡i toÃ n bá»™ tráº¡ng thÃ¡i cuá»‘i cá»§a há»‡ thá»‘ng.

---

## 4. Tháº£o Luáº­n: Decoupling vs. Coupling
- **Decoupling:** Viá»‡c táº¯t Head Ä‘Ã´i khi lÃ m giáº£m Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng, cho tháº¥y Head Ä‘Ã³ Ä‘Ã³ng vai trÃ² "káº¿t ná»‘i" cÃ¡c Ã½ niá»‡m.
- **Coupling:** NgÆ°á»£c láº¡i, á»Ÿ má»™t sá»‘ táº§ng khÃ¡c, viá»‡c táº¯t Head láº¡i lÃ m tÄƒng Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng, gá»£i Ã½ ráº±ng Head Ä‘Ã³ vá»‘n dÄ© cÃ³ chá»©c nÄƒng "phÃ¢n biá»‡t" vÃ  giá»¯ cÃ¡c token xa nhau trong khÃ´ng gian vector.

---

## 5. Káº¿t Luáº­n
Viá»‡c phÃ¢n tÃ­ch Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng Cosine cung cáº¥p cÃ¡i nhÃ¬n chi tiáº¿t hÆ¡n vá» Ä‘á»™ng lá»±c há»c bÃªn trong cá»§a Transformer so vá»›i viá»‡c chá»‰ nhÃ¬n vÃ o xÃ¡c suáº¥t Ä‘áº§u ra. Káº¿t quáº£ cá»§ng cá»‘ quan niá»‡m vá» LLM nhÆ° má»™t há»‡ thá»‘ng há»—n loáº¡n táº¥t Ä‘á»‹nh, nÆ¡i má»i thÃ nh pháº§n dÃ¹ nhá» nháº¥t Ä‘á»u Ä‘Ã³ng gÃ³p vÃ o cáº¥u trÃºc vÄ© mÃ´ cá»§a sá»± hiá»ƒu biáº¿t ngÃ´n ngá»¯.

---

## TÃ i liá»‡u tham kháº£o (Citations)
1. ThÃ­ nghiá»‡m Cosine Similarity trÃªn GPT-2 Medium dá»±a trÃªn `aero_LLM_04_Impact of head-silencing on cosine similarity.md`. PhÃ¢n tÃ­ch hiá»‡u á»©ng Ripple vÃ  quá»¹ Ä‘áº¡o há»™i tá»¥ embeddings.
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| [Cáº¯t bá» Attention Head vÃ  Dá»± Ä‘oÃ¡n Token (Head Ablation and Token Prediction)](aero_llm_01_head_ablation_and_token_prediction.md) | [Xem bÃ i viáº¿t â†’](aero_llm_01_head_ablation_and_token_prediction.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Dá»± Ä‘oÃ¡n Token sau khi Cáº¯t bá» Head (Pháº§n 1)](aero_llm_02_codechallenge_token_prediction_after_head_ablations_part_1_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_02_codechallenge_token_prediction_after_head_ablations_part_1_.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Dá»± Ä‘oÃ¡n Token sau khi Cáº¯t bá» Head (Pháº§n 2)](aero_llm_03_codechallenge_token_prediction_after_head_ablations_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_03_codechallenge_token_prediction_after_head_ablations_part_2_.md) |
| ğŸ“Œ **[TÃ¡c Ä‘á»™ng cá»§a viá»‡c "Táº¯t tiáº¿ng" Head lÃªn Äá»™ tÆ°Æ¡ng Ä‘á»“ng Cosine (Impact of Head-Silencing on Cosine Similarity)](aero_llm_04_impact_of_head_silencing_on_cosine_similarity.md)** | [Xem bÃ i viáº¿t â†’](aero_llm_04_impact_of_head_silencing_on_cosine_similarity.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: GPT-2 cÃ³ thá»±c sá»± thÃ­ch Pizza Dá»©a? (Má»™t nghiÃªn cá»©u vá» can thiá»‡p Attention chÃ­nh xÃ¡c)](aero_llm_05_codechallenge_does_gpt2_like_pineapple_pizza.md) | [Xem bÃ i viáº¿t â†’](aero_llm_05_codechallenge_does_gpt2_like_pineapple_pizza.md) |
| [VÃ¡ lá»—i Attention Head trong tÃ¡c vá»¥ Nháº­n dáº¡ng TÃ¢n ngá»¯ GiÃ¡n tiáº¿p (Attention Head Patching in IOI)](aero_llm_06_attention_head_patching_in_ioi.md) | [Xem bÃ i viáº¿t â†’](aero_llm_06_attention_head_patching_in_ioi.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: VÃ¡ lá»—i Head vÃ  Token trong tÃ¡c vá»¥ IOI (Head and Token Patching in IOI)](aero_llm_07_codechallenge_head_and_token_patching_in_ioi.md) | [Xem bÃ i viáº¿t â†’](aero_llm_07_codechallenge_head_and_token_patching_in_ioi.md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
