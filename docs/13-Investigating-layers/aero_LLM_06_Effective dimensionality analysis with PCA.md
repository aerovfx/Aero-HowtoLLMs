
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../index.md) > [13 Investigating layers](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../index.md)
- [ğŸ“š Module 01: LLM Course](../../01-LLM_Course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../02-Words-to-tokens-to-numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../04-buildGPT/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../07-Fine-tune-pretrained-models/index.md)
- [ğŸ” Module 19: AI Safety](../../19-AI-safety/index.md)
- [ğŸ Module 20: Python for AI](../../20-Python-Colab-notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# PhÃ¢n TÃ­ch Sá»‘ Chiá»u Hiá»‡u Quáº£ (Effective Dimensionality) ThÃ´ng Qua PCA

## TÃ³m táº¯t (Abstract)
Ká»¹ thuáº­t PhÃ¢n TÃ­ch ThÃ nh Pháº§n ChÃ­nh (PCA) káº¿t há»£p vá»›i PhÃ¢n RÃ£ GiÃ¡ Trá»‹ Äáº·c Dá»‹ (SVD) Ä‘Æ°á»£c á»©ng dá»¥ng Ä‘á»ƒ Ä‘á»‹nh lÆ°á»£ng "Sá»‘ Chiá»u Hiá»‡u Quáº£" (Effective Dimensionality) cá»§a cÃ¡c ma tráº­n biá»ƒu diá»…n trong LLMs. NghiÃªn cá»©u thá»±c hiá»‡n trÃªn GPT-2 XL, Ä‘á»‘i chá»©ng chuá»—i token thá»±c táº¿ vÃ  chuá»—i token bá»‹ xÃ¡o trá»™n ngáº«u nhiÃªn (shuffled tokens) xuyÃªn suá»‘t khu vá»±c $Hidden\ States$ tá»« Táº§ng Embeddings lÃªn 48 Transformer Blocks. Káº¿t quáº£ xÃ¢y dá»±ng má»™t Ä‘á»“ thá»‹ biáº¿n thiÃªn khÃ´ng gian nhiá»u chiá»u (laminar profile) thá»ƒ hiá»‡n kháº£ nÄƒng co giÃ£n (expansion and contraction) tÃ­nh cháº¥t dá»¯ liá»‡u khi mÃ´ hÃ¬nh báº¯t Ä‘áº§u tá»• há»£p ngá»¯ cáº£nh ngÃ´n ngá»¯.

---

## 1. Má»Ÿ Äáº§u (Introduction)
Dá»¯ liá»‡u nhÃºng cá»§a má»™t token cÃ³ thá»ƒ tá»“n táº¡i trong má»™t ma tráº­n ráº¥t rá»™ng, vÃ­ dá»¥ GPT-2 XL cÃ³ sá»‘ chiá»u khÃ´ng gian xung quanh (ambient dimensionality) lÃªn tá»›i 1600. Tuy nhiÃªn, thÃ´ng tin thá»±c sá»± há»¯u Ã­ch láº¡i thÆ°á»ng ráº£i rÃ¡c cháº¡y trÃªn má»™t Ä‘a táº¡p (manifold) Ã­t chiá»u hÆ¡n ráº¥t nhiá»u. TÃ­nh cháº¥t nÃ y Ä‘Æ°á»£c gá»i lÃ  **Sá»‘ Chiá»u Hiá»‡u Quáº£ (Effective Dimensionality)**. Äo lÆ°á»ng chÃ­nh xÃ¡c cÃ¡c biÃªn Ä‘á»™ khÃ´ng gian nÃ y cung cáº¥p lá»£i tháº¿ phÃ¢n tÃ­ch lÆ°á»£ng thÃ´ng tin mang tÃ­nh táº­p trung cao, Ä‘á»“ng thá»i theo dÃµi sÃ¡t Ä‘Æ°á»£c nÄƒng lá»±c nhá»“i nÃ©n vÃ  thu phÃ³ng ngá»¯ cáº£nh á»Ÿ tá»«ng cháº¡m (layers) cá»§a Large Language Models.

---

## 2. PhÆ°Æ¡ng PhÃ¡p ToÃ¡n Há»c (Mathematical Methodology)

### 2.1. PhÃ¢n RÃ£ SVD VÃ  Khai Váº¥n PCA
Ma tráº­n kÃ­ch hoáº¡t Ä‘Ã£ Ä‘Æ°á»£c chuáº©n hÃ³a trung tÃ¢m (Mean-Centering) $X$ Ä‘Æ°á»£c phÃ¢n rÃ£ $SVD$:
$$ X = U \Sigma V^T $$
Vá»›i má»¥c tiÃªu tÃ¬m kiáº¿m má»©c phÃ¢n tÃ¡n dá»¯ liá»‡u, PCA gáº¡t bá» ma tráº­n vector Unit ( $U, V$ ) vÃ  chá»‰ sá»­ dá»¥ng **Singular Values** $(\sigma_i)$ trÃªn Ä‘Æ°á»ng chÃ©o $\Sigma$ lÃ m trá»ng sá»‘ tÃ­nh toÃ¡n phÆ°Æ¡ng sai. Do 100% biáº¿n thiÃªn dá»¯ liá»‡u náº±m ngá»n á»Ÿ Ä‘Ã¢y, Pháº§n trÄƒm phÆ°Æ¡ng sai Ä‘Æ°á»£c giáº£i thÃ­ch (Percent Variance Explained) cá»§a má»™t thÃ nh pháº§n (component) thá»© $i$ Ä‘Æ°á»£c láº­p cÃ´ng thá»©c:
$$ r^2_i = \left( \frac{\sigma_i^2}{\sum_{j} \sigma_j^2} \right) \times 100\% $$

### 2.2. Äo LÆ°á»ng Má»‘c Sá»‘ Chiá»u Hiá»‡u Quáº£
Thay vÃ¬ giá»¯ sá»‘ chiá»u cháº¿t 1600, ta tÃ­nh luá»¹ káº¿ pháº§n trÄƒm phÆ°Æ¡ng sai (Cumulative Sum) vÃ  Ä‘áº·t má»™t ngÆ°á»¡ng cáº¯t lá»c nhiá»…u (VÃ­ dá»¥ 95%). "Sá»‘ Chiá»u Hiá»‡u Quáº£" chÃ­nh thá»©c lÃ  sá»‘ hiá»‡u component nhá» nháº¥t sao cho rÃ o cáº£n luá»¹ káº¿ $\ge 95\%$ vá»«a bá»‹ vÆ°á»£t qua. CÃ¡c chiá»u khÃ´ng gian dÆ° tháº·ng Ä‘áº±ng sau cÃ³ ná»“ng Ä‘á»™ thÃ´ng tin quÃ¡ nhá», sáº½ bá»‹ xem lÃ  vi táº¡p (Noise).

---

## 3. Thá»±c Nghiá»‡m Äá»™ng Chuyá»ƒn Token (Tokens Shuffling Setup)

Äá»ƒ chá»©ng minh chiá»u khÃ´ng gian ná»Ÿ ra nhá» cÃ³ "cÃº phÃ¡p" cÃ¢u tá»«, ta sá»­ dá»¥ng 1000 tokens vÄƒn báº£n thá»±c (TrÃ­ch xuáº¥t tá»« sÃ¡ch *Through the Looking Glass*). TÆ°Æ¡ng pháº£n Ä‘á»‘i diá»‡n lÃ  khá»‘i 1000 tokens Ä‘Ã³ nhÆ°ng bá»‹ Ä‘áº£o tung vá»‹ trÃ­ (Shuffled Token sequences).

Thiáº¿t láº­p Ä‘o sá»‘ chiá»u táº¡i cáº£ 49 tráº¡m (1 lá»›p embeddings khá»Ÿi Ä‘iá»ƒm + 48 vÃ²ng láº·p Transformer Blocks):
NgÆ°á»¡ng Effective Dimensionality Ä‘Æ°á»£c há»‡ thá»‘ng dÃ² tÃ¬m tá»± Ä‘á»™ng tÆ°Æ¡ng á»©ng $95\%$ Variances.

---

## 4. KhÃ¡m PhÃ¡ Sá»± Co GiÃ£n Äa KhÃ´ng Gian (Analysis & Results)

Laminar Profile hiá»‡n thá»±c hÃ³a cÃ¡c Ä‘Æ°á»ng cong biáº¿n Ä‘á»™ng (Dimensionality Expansion and Contraction):

1. **Khá»Ÿi Ä‘iá»ƒm - Táº§ng Embeddings (Layer 0):** Dá»¯ liá»‡u hoÃ n toÃ n chÆ°a Ä‘i qua ma tráº­n quy náº¡p $Attention$, cáº£ cÃ¢u tá»« chuáº©n gá»‘c hay cÃ¢u xÃ¡o trá»™n Ä‘á»u chá»‰ lÃ  tá»« ghÃ©p cÆ¡ há»c. Biáº¿n Ä‘á»™ng khÃ´ng gian xuáº¥t phÃ¡t (effective dimensionality) cá»§a hai dÃ£y dá»¯ liá»‡u báº±ng y há»‡t nhau.
2. **Khu vá»±c phÃ¬nh ná»Ÿ (Expansion) - Táº§ng NÃ´ng:** LÃªn cÃ¡c block tiáº¿p theo, khi $Q, K, V$ lÃ m viá»‡c hÃºt ngá»¯ cáº£nh cáº¥u trÃºc Ä‘á»©ng trÆ°á»›c, dÃ£y Token chuáº©n gá»‘c Ã©p máº¡ng khÃ´ng gian pháº£i má»Ÿ rá»™ng nhanh chÃ³ng nháº±m dung náº¡p Ä‘a liÃªn káº¿t ngá»¯ phÃ¡p. 
3. **Khu vá»±c giá»›i háº¡n (Contraction) - Äi sÃ¢u há»‡ thá»‘ng:** Dá»¯ liá»‡u dáº§n bá»‹ tháº¯t cá»• chai, gom nÃ©n láº¡i vÃ o nhá»¯ng Ä‘áº·c trÆ°ng ngá»¯ nghÄ©a mang Ä‘á»‹nh hÆ°á»›ng dá»± Ä‘oÃ¡n tá»« tiáº¿p theo. Sá»‘ chiá»u thay vÃ¬ ná»Ÿ to, báº¯t Ä‘áº§u thu háº¹p cá»¥c bá»™ dáº§n xuá»‘ng.
4. **Äá»‘i chiáº¿u vÄƒn báº£n má»• cÃ² (Shuffled Differences):** ÄÃ¡ng ngáº¡c nhiÃªn, luá»“ng token xÃ¡o trá»™n bá»‹ mÃ´ hÃ¬nh Ä‘á»‹nh giÃ¡ lÃ  thÃ´ng tin rá»‘i loáº¡n ngÃ´n ngá»¯. Do báº£n cháº¥t rá»i ráº¡c, khÃ´ng chá»©a máº¥u chá»‘t cáº¥u trÃºc vÄƒn pháº¡m cÃ³ thá»ƒ dá»± Ä‘oÃ¡n, sá»‘ chiá»u Ä‘Æ°á»£c model huy Ä‘á»™ng Ã­t hÆ¡n ráº¥t rÃµ rá»‡t vÃ  quá»¹ Ä‘áº¡o co giÃ£n khÃ´ng mÆ°á»£t mÃ  nhÆ° dÃ£y dá»¯ liá»‡u sáº¡ch.

---

## 5. Káº¿t Luáº­n (Conclusion)
PhÃ¢n tÃ­ch giá»›i háº¡n sá»‘ chiá»u lÆ°u trá»¯ (Dimensionality PCA) hÃ© lá»™ mÃ´ hÃ¬nh tá»± Ä‘iá»u hÆ°á»›ng tÃ i nguyÃªn khÃ´ng gian ráº¥t khÃ´n khÃ©o. Sá»©c sá»‘ng cá»§a thuáº­t toÃ¡n Self-Attention khÃ´ng chá»‰ lÃ  nháº·t Ä‘iá»ƒm vector tá»« má»™t "TÃºi tá»«" (Bag-of-words) lá»›n, mÃ  lÃ  má»™t quy trÃ¬nh tÃ¡i cáº¥u trÃºc khÃ´ng gian hÃ¬nh há»c. CÃ¡c token cÃ³ há»‡ thá»‘ng vÄƒn pháº¡m Ä‘Ã²i há»i má»™t Ä‘áº¡i dÆ°Æ¡ng nhiá»u chiá»u hÆ¡n Ä‘á»ƒ tá»• há»£p biá»ƒu diá»…n hÆ¡n lÃ  cÃ¡c máº©u tá»« vá»±ng vÃ´ nghÄ©a Ä‘á»©ng rá»i ráº¡c.

---

## TÃ i Liá»‡u Tham Kháº£o (Citations)
1. Dá»¯ liá»‡u trÃ­ch xuáº¥t tá»« pháº§n phá»¥ Ä‘á» vÃ  mÃ£ lá»‡nh thÃ­ nghiá»‡m liÃªn káº¿t: `aero_LLM_06_Effective dimensionality analysis with PCA.md` (Giá»›i thiá»‡u cÃ¡c hÃ m tÃ­nh PCA, r-squared variances, SVD values vÃ  hiá»‡n tÆ°á»£ng má»Ÿ rá»™ng/thu háº¹p sá»‘ chiá»u trÃªn khÃ´ng gian Hidden States cá»§a LLM).
<!-- Aero-Footer-Start -->
---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
