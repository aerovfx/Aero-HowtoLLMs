
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../index.md) > [13 Investigating layers](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../index.md)
- [ğŸ“š Module 01: LLM Course](../../01-LLM_Course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../02-Words-to-tokens-to-numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../04-buildGPT/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../07-Fine-tune-pretrained-models/index.md)
- [ğŸ” Module 19: AI Safety](../../19-AI-safety/index.md)
- [ğŸ Module 20: Python for AI](../../20-Python-Colab-notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): á»¨ng Dá»¥ng Logit Lens Trong Máº¡ng BERT (Pháº§n 2)

## TÃ³m táº¯t (Abstract)
Tiáº¿p ná»‘i hÃ nh trÃ¬nh giáº£i mÃ£ quÃ¡ trÃ¬nh tiáº¿n hÃ³a quyáº¿t Ä‘á»‹nh ná»™i bá»™ (Internal Logits Evolutions), bÃ¡o cÃ¡o nÃ y mÃ´ táº£ phÆ°Æ¡ng phÃ¡p thiáº¿n láº­p Ä‘Ãºng Ä‘áº¯n thuáº­t toÃ¡n Logit Lens Ä‘á»‘i vá»›i ná»n táº£ng kiáº¿n trÃºc BERT. Báº¯t nguá»“n tá»« tÃ­nh phá»©c há»£p trong MÃ´-Ä‘un Giáº£i MÃ£ (Decoder Module/Predictions) cá»§a BERT â€“ Ä‘Ã²i há»i nhiá»u kÃ­ch hoáº¡t Gelu vÃ  LayerNorm chá»© khÃ´ng Ä‘Æ¡n thuáº§n lÃ  ma tráº­n trá»ng sá»‘ nhÆ° GPT, nghiÃªn cá»©u tÃ¡i thiáº¿t káº¿ luá»“ng quy chiáº¿u máº£ng (Tensor Projections) Ä‘Ãºng cÃ¡ch. Báº±ng viá»‡c phÃ¢n tÃ¡ch Z-score khuyáº¿t tá»« trÃªn 24 há»‡ biáº¿n thiÃªn, ta quan sÃ¡t Ä‘Æ°á»£c "khoáº£nh kháº¯c Eureka", nÆ¡i máº¡ng há»c sÃ¢u báº» gÃ£y quá»¹ Ä‘áº¡o rá»‘i ráº¯m sang Ä‘á»‹nh hÃ¬nh cháº¯c cháº¯n vá» tá»« ngá»¯, chá»©ng minh cÃ¡ch máº¡ng Neural láº¯p rÃ¡p ngá»¯ cáº£nh thÃ nh khá»‘i.

---

## 1. Má»Ÿ Äáº§u (Introduction)
Khi thá»±c nghiá»‡m Logit Lens trÃªn kiáº¿n trÃºc GPT, phÃ©p toÃ¡n thá»±c sá»± giáº£n Ä‘Æ¡n: Ãp dá»¥ng nhÃ¢n TÃ­ch vÃ´ hÆ°á»›ng (Dot product) giá»¯a Tráº¡ng thÃ¡i áº©n lá»›p trung gian $L_i$ vÃ  máº£ng Trá»ng sá»‘ tuyáº¿n tÃ­nh giáº£i mÃ£ $LM\_Head^T$. Tháº¿ nhÆ°ng cÆ¡ cháº¿ BERT (Bidirectional Encoder Representations from Transformers) cáº¥t giáº¥u Ä‘iá»u báº¥t ngá»: Khá»‘i `model.predictions` chá»‹u trÃ¡ch nhiá»‡m quy Ä‘á»•i (Unembeddings) Ä‘Æ°á»£c nhá»“i thÃªm hÃ m kÃ­ch hoáº¡t phi tuyáº¿n (Gelu), tinh chá»‰nh LayerNorm vÃ  hÃ ng loáº¡t biáº¿n Ä‘á»•i phá»©c táº¡p.
Náº¿u tiáº¿p tá»¥c chÃ©p nguyÃªn cÃ´ng thá»©c Logit Lens cá»• Ä‘iá»ƒn, há»‡ thá»‘ng Ä‘á»• nÃ¡t vÃ  Ä‘Ã¡p Ã¡n giáº£i mÃ£ chá»‰ lÃ  nhiá»…u vÃ´ nghÄ©a. 

NghiÃªn cá»©u nÃ y thiáº¿t láº­p **Báº£n nguyÃªn táº¯c chuáº©n** Ä‘á»ƒ soi Logit Lens trÃªn BERT, Ä‘á»“ng thá»i quÃ©t toÃ n bá»™ mÃ´ hÃ¬nh (Sweep layers) Ä‘á»ƒ phÆ¡i bÃ y táº¥m báº£n Ä‘á»“ Heatmap quÃ¡ trÃ¬nh Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh Masked Token.

---

## 2. PhÆ°Æ¡ng PhÃ¡p Chá»‰nh Vá»‹ (Methodology Corrections)

### 2.1. PhÃ©p Sai Láº§m PhÃ¢n Chiáº¿u VÃ´ HÆ°á»›ng (The Incorrect Dot-Product Approach)
Sá»­ dá»¥ng táº§ng áº©n Ã¡p chÃ³t (Layer 22/24), náº¿u ta trÃ­ch bÃ³c thÃ´ lá»— Ä‘oáº¡n mÃ£ trá»ng sá»‘ `model.predictions.decoder.weight` ra Ä‘á»ƒ nhÃ¢n ma tráº­n, token Ä‘Æ°á»£c dá»± giáº£i mÃ£ tráº£ vá» káº¿t quáº£ áº£o giÃ¡c (Hallucination) dÆ°á»›i dáº¡ng "hash", "wives" vÃ  Z-score chÃ¬m tháº£m báº¡i xuá»‘ng Ä‘Ã¡y rÃ£nh ($Z \approx 3$). NguyÃªn nhÃ¢n Ä‘áº¿n tá»« viá»‡c dÃ²ng vector kia Ä‘Ã£ lá»t sá»• khÃ¢u bÃ¹ trá»« phi tuyáº¿n Gelu vÃ  LayerNorm, lÃ m mÃ©o mÃ³ cÃ¡c vector khoáº£ng cÃ¡ch (Distance alignment).

### 2.2. PhÃ©p ÄÃºng Äáº¯n: Äáº©y Qua Tá»•ng MÃ´-Äun Äáº§u Báº£ng (Full-Module Forwarding)
CÃ´ng thá»©c Logits Lens chÃ¢n thá»±c cá»§a mÃ´ hÃ¬nh BERT báº¯t buá»™c pháº£i Ä‘áº©y vector áº©n $L_i$ Ä‘i qua toÃ n bá»™ khá»‘i module kiáº¿n trÃºc cuá»‘i cÃ¹ng thay vÃ¬ tá»± thá»±c hiá»‡n phÃ©p nhÃ¢n nhÃ¡p:
$$ \text{Logits}_{L_i} = \text{model.predictions}(\text{Hidden\_States}_{L_i}) $$
Khi thao tÃ¡c Ä‘Ãºng, káº¿t quáº£ láº­p tá»©c Ä‘á»“ng bá»™. á» Layer 22, phÆ°Æ¡ng phÃ¡p Ä‘áº©y Module cho ra Z-score khá»•ng lá»“ lÃªn tá»›i $\approx 25$ Ä‘áº¿n $30\ \sigma$, vÃ  tá»« Ä‘oÃ¡n giáº£i mÃ£ xuáº¥t hiá»‡n chÃ­nh xÃ¡c Ä‘Ã¡ng kinh ngáº¡c. 

---

## 3. PhÃ¢n Phá»‘i Trá»±c Quan Qua Táº§ng (Layer-wise Analysis & Heatmaps)

### 3.1. PhÃ¢n LÅ©y Tiáº¿n Biá»ƒu Äá»“ Tuyáº¿n (Z-Score Trajectories)
ÄÃ¡nh giÃ¡ Ä‘á»™ cháº¯c cháº¯n Z-Score (khoáº£ng cÃ¡ch Ä‘iá»ƒm ká»³ vá»ng cá»§a Predicted Token vá»›i báº§y Ä‘Ã n Vocab phÃ¢n bá»• xung quanh) táº¡i táº¥t cáº£ 24 Blocks Transformer, ta tháº¥y:
- **Táº§ng 0 - 10:** Z-score dao Ä‘á»™ng á»Ÿ má»©c nhiá»…u ngáº«u nhiÃªn. Máº¡ng liÃªn tá»¥c Ä‘oÃ¡n nhá»¯ng máº£nh tá»« ghÃ©p Ä‘iÃªn rá»“ nhÆ° "accreditation", "fellowship" dÃ¹ Ä‘áº§u vÃ o khÃ´ng há» mang tÃ­nh há»c thuáº­t.
- **Táº§ng 11 - 15:** Z-score nhÃºc nhÃ­ch tá»‹nh tiáº¿n lÃªn.
- **Táº§ng 15 - 24:** Má»™t khuá»·u bá»™c phÃ¡t (Knee curve) bÃ³p ngoáº·t gÃ³c Ä‘á»™ vÃ  chÄ©a tháº³ng lÃªn giá»i tháº³ng táº¯p. TÃ­n hiá»‡u nÃ y phÃ¡c tháº£o rÃµ "Khoáº£nh kháº¯c Eureka", nÆ¡i máº¡ng Neural tÃ¬m Ä‘á»§ manh má»‘i, thu tháº­p Ä‘á»§ lá»±c Ä‘ong bÃ¹ context 2 bÃªn trÃ¡i pháº£i, Ä‘á»“ng hÃ³a Ä‘á»ƒ chá»‘t háº¡ má»™t quyáº¿t Ä‘á»‹nh sáº¯c nhá»n (Token: "way").

### 3.2. Hiá»‡u á»¨ng Thuáº­t Cáº£nh (Visualizing The Snap)
Tráº£i pháº³ng Heatmap vá»›i trá»¥c Y (Layers) vÃ  trá»¥c X (Táº¥t cáº£ Masked tokens láº·p vÃ²ng), Ä‘Æ°á»£c Normalization Min-Max Scaling (tá»« $0 \to 1$). 
- Báº£n Ä‘á»“ mÃ u minh hoáº¡ sá»± vÃ´ thá»©c (Ä‘en mÃ¹ tá»‹t) kÃ©o dÃ i qua ná»­a Ä‘áº§u lá»™ trÃ¬nh. 
- Äáº¿n 1/3 cháº·ng cuá»‘i cÃ¹ng, Ã¡nh sÃ¡ng Softmax loÃ© lÃªn vá»›i mÃ u VÃ ng rá»±c. Má»™t sá»‘ Token ngá»¯ phÃ¡p dá»… ná»‘i (nhÆ° "do", "you") Ä‘Æ°á»£c mÃ´ hÃ¬nh bÃ³c tÃ¡ch vÃ  ngá»™ ra quyáº¿t Ä‘á»‹nh sá»›m hÆ¡n (Táº§m layer 10-12) so vá»›i cÃ¡c Token mang hÃ m nghÄ©a rá»™ng hÆ¡n. 

---

## 4. Káº¿t Luáº­n
Logit Lens khÃ´ng pháº£i thuáº­t toÃ¡n cÃ´ng thá»©c váº¡n nÄƒng. NÃ³ Ä‘Ã²i há»i nhÃ  nghiÃªn cá»©u pháº£i Ä‘á»c hiá»ƒu cáº¥u trÃºc "Unembeddings" cá»§a tá»«ng ná»n táº£ng LLM riÃªng biá»‡t. Báº±ng viá»‡c Ä‘á»‹nh tuyáº¿n Ä‘Ãºng qua khá»‘i lÆ°á»›i `predictions`, BERT phÆ¡i bÃ y váº» Ä‘áº¹p tÆ° duy káº¿t ná»‘i Ä‘áº·c trÆ°ng: Sá»± im lÃ¬m á»Ÿ táº§ng dÆ°á»›i vÃ  cÃº giáº­t bá»«ng sÃ¡ng máº¡nh máº½ á»Ÿ táº§ng trÃªn. PhÆ°Æ¡ng phÃ¡p váº½ Heatmap Z-Score cung á»©ng cá»— mÃ¡y quÃ©t sinh há»c MRI sáº¯c nÃ©t Ä‘o Ä‘áº¡c hÃ nh trÃ¬nh nháº­n thá»©c (Cognitive-like mapping) cá»§a AI qua chiá»u Ä‘á»™ TrÃ­ tuá»‡.

---

## TÃ i Liá»‡u Tham Kháº£o (Citations)
1. ThÃ­ nghiá»‡m Ä‘o lÆ°á»ng hiá»‡u lá»‡nh phÃ¢n Ä‘oáº¡n qua `aero_LLM_17_CodeChallenge Logit Lens in BERT (part 2).md` (Káº¿t ná»‘i thá»±c nghiá»‡m Logit Lens Full-Module qua 24 layers máº¡ng BERT Large, so Ä‘á»‘i chá»©ng vá»›i kiáº¿n trÃºc thÃ´ Dot-Product).
<!-- Aero-Footer-Start -->
---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
