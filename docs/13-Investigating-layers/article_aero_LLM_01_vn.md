
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../index.md) > [13 Investigating layers](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../index.md)
- [ğŸ“š Module 01: LLM Course](../../01-LLM_Course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../02-Words-to-tokens-to-numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../04-buildGPT/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../07-Fine-tune-pretrained-models/index.md)
- [ğŸ” Module 19: AI Safety](../../19-AI-safety/index.md)
- [ğŸ Module 20: Python for AI](../../20-Python-Colab-notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# PhÃ¢n TÃ­ch Sá»± TÆ°Æ¡ng Äá»“ng Tokens Trong vÃ  Giá»¯a CÃ¡c Ma Tráº­n Q, K, V (Pháº§n 1)

## TÃ³m táº¯t (Abstract)
BÃ i viáº¿t nÃ y Ä‘iá»u tra cÃ¡c cÆ¡ cháº¿ biá»ƒu diá»…n cá»§a máº¡ng nÆ¡-ron ngÃ´n ngá»¯ lá»›n (LLMs), cá»¥ thá»ƒ lÃ  mÃ´ hÃ¬nh GPT-2, á»Ÿ cáº¥p Ä‘á»™ táº§ng áº©n (layer-level). Trá»ng tÃ¢m nghiÃªn cá»©u lÃ  phÃ¢n tÃ­ch má»‘i quan há»‡ giá»¯a cÃ¡c vector kÃ­ch hoáº¡t Truy váº¥n (Query - $Q$), KhÃ³a (Key - $K$) vÃ  GiÃ¡ trá»‹ (Value - $V$) dá»±a trÃªn há»‡ sá»‘ tÆ°Æ¡ng quan (Correlation) vÃ  Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng Cosine (Cosine Similarity). ThÃ´ng qua phÆ°Æ¡ng phÃ¡p cÃ´ láº­p token Ä‘Ã­ch Ä‘á»‹nh sáºµn (tá»« "her") trong cÃ¡c ngá»¯ cáº£nh cÃ¢u khÃ¡c biá»‡t, chÃºng tÃ´i phÃ¡t hiá»‡n ra nhá»¯ng quy luáº­t phÃ¢n bá»‘ tÆ°Æ¡ng Ä‘á»“ng há»™i tá»¥ ráº¥t máº¡nh trong khÃ´ng gian biá»ƒu diá»…n cÆ¡ cáº¥u máº¡ng Attention.

---

## 1. Má»Ÿ Äáº§u (Introduction)
PhÃ¢n tÃ­ch mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n á»Ÿ cáº¥p Ä‘á»™ cÃ¡c táº§ng áº©n (layer-level) cung cáº¥p má»™t cÃ¡i nhÃ¬n tá»•ng quan vá» cÃ¡ch thÃ´ng tin Ä‘Æ°á»£c tá»• chá»©c vÃ  xá»­ lÃ½ theo tá»«ng khá»‘i cáº¥u trÃºc, cao hÆ¡n so vá»›i viá»‡c nghiÃªn cá»©u tá»«ng nÆ¡-ron (neuron) rá»i ráº¡c. 

Báº±ng viá»‡c tÃ¬m hiá»ƒu cÃ¡ch biá»ƒu diá»…n token (token embeddings) biáº¿n Ä‘á»•i vÃ  tÆ°Æ¡ng tÃ¡c qua cÃ¡c ma tráº­n Tá»± chÃº Ã½ (Self-Attention sublayers), ta cÃ³ thá»ƒ giáº£i mÃ£ dáº§n cÆ¡ cháº¿ náº¯m báº¯t ngá»¯ cáº£nh cá»§a mÃ´ hÃ¬nh. Trong bÃ i nghiÃªn cá»©u nÃ y, chÃºng tÃ´i Ä‘i sÃ¢u vÃ o viá»‡c Ä‘á»‘i chiáº¿u cÃ¡c Ä‘a táº¡p biá»ƒu diá»…n ná»™i táº¡i trong $Q$, $K$, $V$ khi má»™t token hoÃ n toÃ n giá»‘ng nhau Ä‘Æ°á»£c truyá»n qua cÃ¡c quy trÃ¬nh vÄƒn cáº£nh ngá»¯ phÃ¡p (context) khÃ¡c nhau.

---

## 2. PhÆ°Æ¡ng PhÃ¡p Thá»±c Nghiá»‡m & Äo LÆ°á»ng (Methodology)

### 2.1. Thiáº¿t Káº¿ Táº­p Dá»¯ Liá»‡u vÃ  Bá»‘i Cáº£nh
Thá»±c nghiá»‡m sá»­ dá»¥ng mÃ´ hÃ¬nh GPT-2 (small), tiáº¿n hÃ nh trÃ­ch xuáº¥t hÃ m kÃ­ch hoáº¡t (hooking activations) tháº³ng tá»« vÃ²ng Transformer. Má»™t há»‡ thá»‘ng bao gá»“m $54$ cÃ¢u vÄƒn ngáº¯n Ä‘Æ°á»£c Ä‘Æ°a vÃ o máº¡ng.
- Cáº¥u trÃºc chung: Má»i cÃ¢u Ä‘á»u chá»©a chung má»™t *token Ä‘Ã­ch* cá»‘ Ä‘á»‹nh (vÃ­ dá»¥: chuá»—i `[space] her`). Do Ä‘Ã³, báº£n sáº¯c cá»‘t lÃµi cá»§a token Ä‘Ã­ch lÃ  hoÃ n toÃ n giá»‘ng há»‡t nhau (identical) vá» Ä‘á»‹nh danh Ä‘áº§u vÃ o.
- TÃ­nh Ä‘á»™c láº­p: Äiá»u lÃ m nÃªn khá»‘i dá»¯ liá»‡u Ä‘á»‘i sÃ¡nh lÃ  token Ä‘á»©ng trÆ°á»›c/sau vÃ  tá»•ng chiá»u dÃ i má»—i chuá»—i chá»©a token thay Ä‘á»•i - buá»™c há»‡ thá»‘ng tá»± padding tá»± Ä‘á»™ng. 

### 2.2. Äo LÆ°á»ng Báº±ng Äá»™ TÆ°Æ¡ng Äá»“ng Cosine (Cosine Similarity)
Äá»ƒ kiá»ƒm chá»©ng ma tráº­n vector kÃ­ch hoáº¡t ná»™i táº¡i, ta Ã¡p dá»¥ng cÃ´ng thá»©c Äá»™ tÆ°Æ¡ng Ä‘á»“ng Cosine, Ä‘á»‹nh nghÄ©a sá»± trÃ¹ng láº·p gÃ³c Ä‘o Ä‘á»‹nh hÆ°á»›ng giá»¯a vector $x$ vÃ  vector $y$:
$$ \text{Cosine Similarity}(\mathbf{x}, \mathbf{y}) = \frac{\mathbf{x} \cdot \mathbf{y}}{\|\mathbf{x}\| \|\mathbf{y}\|} = \frac{\sum_{i=1}^{n} x_i y_i}{\sqrt{\sum_{i=1}^{n} x_i^2}\sqrt{\sum_{i=1}^{n} y_i^2}} $$
*Khai triá»ƒn tÃ­nh toÃ¡n vi mÃ´:* CÃ¡c ma tráº­n nÃ y Ä‘Æ°á»£c Ã¡nh xáº¡ Ä‘áº¡i sá»‘ báº±ng cáº¥u trÃºc phÃ©p nhÃ¢n vÃ´ hÆ°á»›ng cá»§a ma tráº­n dá»¯ liá»‡u chuyá»ƒn vá»‹ (transpose) lÃªn chÃ­nh nÃ³, vÃ  chia cho quy chuáº©n Ä‘á»™ dÃ i Ä‘Æ°á»ng chuáº©n $L_2$ (matrix norm) nháº±m táº¡o ra cÃ¡c táº­p há»£p phÃ¢n bá»• náº±m giá»›i háº¡n trong khung giÃ¡ trá»‹ lÃ½ tÆ°á»Ÿng $[-1, 1]$.

---

## 3. KhÃ¡m PhÃ¡ Khá»‘i Dá»¯ Liá»‡u Ná»™i Táº¡i (Results & Analysis)

Há»‡ thá»‘ng trÃ­ch xuáº¥t Tensor xuáº¥t báº£n ghi vá»›i dáº¡ng biáº¿n chiá»u $\mathbf{54 \times 8 \times 2304}$ (TÆ°Æ¡ng á»©ng: Khá»‘i 54 chuá»—i cÃ¢u $\times$ 8 tokens máº·c Ä‘á»‹nh tÃ­nh padding $\times$ tá»•ng concat cá»§a Q,K,V vÃ¬ GPT-2 small cÃ³ má»©c $n\_embed$ lÃ  $768$).

**PhÃ¢n TÃ­ch Cáº¥u Táº¡o:** HÃ¬nh Ä‘á»“ Histogram phÃ¢n bá»‘ cá»§a Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng Cosine á»Ÿ cÃ¡c chiá»u $Q-Q$ hoáº·c tÆ°Æ¡ng tÃ¡c cáº·p.
- Kháº£o sÃ¡t cÃ¡c kÃ­ch hoáº¡t á»Ÿ tá»« "her" dá»c theo 54 ngá»¯ cáº£nh cho má»™t káº¿t quáº£ kinh ngáº¡c: Äá»™ tÆ°Æ¡ng Ä‘á»“ng Cosine cá»§a cÃ¡c vector Ä‘Ã­ch biá»ƒu thá»‹ má»™t hÃ¬nh tráº¡ng há»™i tá»¥ hÆ°á»›ng hai cá»±c, thÆ°á»ng lÃ  **dÆ°Æ¡ng ráº¥t Ä‘áº­m** hoáº·c thá»‰nh thoáº£ng sáº½ mang xu hÆ°á»›ng **Ã¢m tÆ°Æ¡ng pháº£n rÃµ rá»‡t** (Strong Negative/Positive).
- Sá»± tá»“n táº¡i cá»§a token Ä‘Ã­ch giá»‘ng nhau Ã¡p Ä‘áº£o ngá»¯ cáº£nh khÃ¡c nhau lÃªn kÃ­ch hoáº¡t khÃ´ng gian, giá»¯ cÃ¡c Ä‘iá»ƒm scatter-plot gá»™p vÃ o má»™t há»‡ tÆ°Æ¡ng quan há»‡ sá»‘ cao (vÃ­ dá»¥: tÆ°Æ¡ng tÃ¡c $ > 0.9$ trÃªn há»‡ quy chiáº¿u chÃ©o cá»§a cÃ¡c cÃ¢u vÄƒn).

---

## 4. Káº¿t Luáº­n (Conclusion)
ThÃ´ng qua thá»§ phÃ¡p mÃ³c ná»‘i cÃ¡c táº§ng áº©n cá»§a mÃ´ hÃ¬nh táº¡i vÃ²ng láº·p thá»© $6$ (Layer-6), bÃ i thá»±c nghiá»‡m chá»©ng minh sá»± á»•n Ä‘á»‹nh cÆ¡ há»c Ä‘Ã¡ng lÆ°u tÃ¢m táº¡i $Q$, $K$, $V$ Ä‘á»‘i vá»›i nhÃ³m token Ä‘Ã­ch mang tÃ­nh nguyÃªn báº£n liÃªn káº¿t. Cáº£ quÃ¡ trÃ¬nh tÃ­nh Ä‘á»™ Ä‘o Cosinus tiáº¿t lá»™ sá»©c máº¡nh duy trÃ¬ Ã½ nghÄ©a Ä‘á»‹nh dang ban Ä‘áº§u, Ä‘i ngÆ°á»£c láº¡i má»™t sá»‘ giáº£ Ä‘á»‹nh vá» viá»‡c vÄƒn cáº£nh thay Ä‘á»•i sáº½ hoÃ n toÃ n thay Ä‘á»•i quá»¹ Ä‘áº¡o sá»‘ há»c áº©n tÃ ng.

Dá»¯ liá»‡u nÃ y cung cáº¥p tiá»n Ä‘á» Ä‘á»ƒ nghiÃªn cá»©u sÃ¢u thÃªm vá» nhÃ³m cá»¥m chá»©c nÄƒng há»c thuáº­t trÃªn máº¡ng ngÃ´n ngá»¯ nhiá»u Parameter hÆ¡n.

---

## TÃ i Liá»‡u Tham Kháº£o (Citations)
1. Dá»¯ liá»‡u trÃ­ch xuáº¥t tá»«: `aero_LLM_01_Token-related similarities within and across Q, K, V matrices (part 1).md`. (Kháº£o cá»©u cÃ¡ch tÃ­nh Cosinus, xÃ¢y dá»±ng ká»‹ch báº£n 54 cÃ¢u mÃ´ phá»ng token Ä‘Ã­ch vÃ  quy mÃ´ Tensor GPT-2 small PyTorch / Numpy).
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| [PhÃ¢n TÃ­ch Sá»± TÆ°Æ¡ng Äá»“ng Tokens Trong vÃ  Giá»¯a CÃ¡c Ma Tráº­n Q, K, V (Pháº§n 1)](aero_LLM_01_Token-related similarities within and across Q, K, V matrices (part 1).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_01_Token-related similarities within and across Q, K, V matrices (part 1).md) |
| [PhÃ¢n TÃ­ch Sá»± TÆ°Æ¡ng Äá»“ng Tokens Trong vÃ  Giá»¯a CÃ¡c Ma Tráº­n Q, K, V (Pháº§n 2)](aero_LLM_02_Token-related similarities within and across Q, K, V matrices (part 2).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_02_Token-related similarities within and across Q, K, V matrices (part 2).md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): PhÃ¢n TÃ­ch Äá»™ TÆ°Æ¡ng Äá»“ng Cá»§a Token XuyÃªn Suá»‘t CÃ¡c Táº§ng áº¨n](aero_LLM_03_CodeChallenge Token-related similarities across layers.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_03_CodeChallenge Token-related similarities across layers.md) |
| [PhÃ¢n TÃ­ch Sá»± PhÃ¢n Cá»¥m vÃ  TÆ°Æ¡ng Äá»“ng Biá»ƒu Diá»…n (RSA) Trong Ma Tráº­n Q vÃ  K](aero_LLM_04_Grouping and RSA in Q and K matrices.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_04_Grouping and RSA in Q and K matrices.md) |
| [Kháº£o SÃ¡t PhÃ¢n Táº§ng (Laminar Profile) Vá» RSA VÃ  Sá»± Chá»n Lá»c PhÃ¢n NhÃ³m](aero_LLM_05_CodeChallenge Laminar profile of RSA and category selectivity.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_05_CodeChallenge Laminar profile of RSA and category selectivity.md) |
| [PhÃ¢n TÃ­ch Sá»‘ Chiá»u Hiá»‡u Quáº£ (Effective Dimensionality) ThÃ´ng Qua PCA](aero_LLM_06_Effective dimensionality analysis with PCA.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_06_Effective dimensionality analysis with PCA.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): Kháº£o SÃ¡t Sá»‘ Chiá»u Hiá»‡u Quáº£ TrÃªn Pythia 2.8B](aero_LLM_07_CodeChallenge Dimensionalities in Pythia 2.3B.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_07_CodeChallenge Dimensionalities in Pythia 2.3B.md) |
| [LÃ½ Thuyáº¿t ThÃ´ng Tin: Äo LÆ°á»ng Entropy VÃ  Mutual Information](aero_LLM_08_Mutual information theory and code.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_08_Mutual information theory and code.md) |
| [PhÃ¢n TÃ­ch ThÃ´ng Tin TÆ°Æ¡ng Há»— Dá»c Theo CÃ¡c Táº§ng Cá»§a MÃ´ HÃ¬nh NgÃ´n Ngá»¯ (Pairwise Mutual Information Through LLMs)](aero_LLM_09_Pairwise mutual information through the LLM.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_09_Pairwise mutual information through the LLM.md) |
| [PhÃ¢n TÃ­ch Äá»‘i Chiáº¿u Äo LÆ°á»ng TÆ°Æ¡ng Quan: Mutual Information vÃ  Covariance](aero_LLM_10_Mutual information vs. covariance.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_10_Mutual information vs. covariance.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): MI VÃ  Khoáº£ng CÃ¡ch Token (Pháº§n 1)](aero_LLM_11_CodeChallenge Attention to coffee MI and token distances (part 1).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_11_CodeChallenge Attention to coffee MI and token distances (part 1).md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): MI VÃ  Khoáº£ng CÃ¡ch Token (Pháº§n 2)](aero_LLM_12_CodeChallenge Attention to coffee MI and token distances (part 2).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_12_CodeChallenge Attention to coffee MI and token distances (part 2).md) |
| [PhÃ¢n Kháº£o Cáº¥u TrÃºc Cá»¥m (Clusters): Dáº¥u CÃ¢u Ná»™i Bá»™ vs Dáº¥u CÃ¢u Káº¿t ThÃºc Táº­p 1](aero_LLM_13_CodeChallenge Clusters in internal vs. terminal punctuation (part 1).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_13_CodeChallenge Clusters in internal vs. terminal punctuation (part 1).md) |
| [PhÃ¢n Kháº£o Cáº¥u TrÃºc Cá»¥m (Clusters): Dáº¥u CÃ¢u Ná»™i Bá»™ vs Dáº¥u CÃ¢u Káº¿t ThÃºc Táº­p 2](aero_LLM_14_CodeChallenge Clusters in internal vs. terminal punctuation (part 2).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_14_CodeChallenge Clusters in internal vs. terminal punctuation (part 2).md) |
| [Tháº¥u KÃ­nh Logit (The Logit Lens): Soi SÃ¡ng TÆ° Duy Táº§ng Trung Gian Cá»§a MÃ´ HÃ¬nh NgÃ´n Ngá»¯](aero_LLM_15_The Logit Lens.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_15_The Logit Lens.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): á»¨ng Dá»¥ng Logit Lens Trong Máº¡ng BERT (Pháº§n 1)](aero_LLM_16_CodeChallenge Logit Lens in BERT (part 1).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_16_CodeChallenge Logit Lens in BERT (part 1).md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): á»¨ng Dá»¥ng Logit Lens Trong Máº¡ng BERT (Pháº§n 2)](aero_LLM_17_CodeChallenge Logit Lens in BERT (part 2).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_17_CodeChallenge Logit Lens in BERT (part 2).md) |
| ğŸ“Œ **[PhÃ¢n TÃ­ch Sá»± TÆ°Æ¡ng Äá»“ng Tokens Trong vÃ  Giá»¯a CÃ¡c Ma Tráº­n Q, K, V (Pháº§n 1)](article_aero_LLM_01_vn.md)** | [Xem bÃ i viáº¿t â†’](article_aero_LLM_01_vn.md) |
| [PhÃ¢n tÃ­ch ChuyÃªn SÃ¢u CÃ¡c Táº§ng áº¨n Trong MÃ´ HÃ¬nh NgÃ´n Ngá»¯ Lá»›n (LLMs): Äo LÆ°á»ng, Biá»ƒu Diá»…n vÃ  Giáº£i MÃ£ Ná»™i Táº¡i](scientific_article_vn.md) | [Xem bÃ i viáº¿t â†’](scientific_article_vn.md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
