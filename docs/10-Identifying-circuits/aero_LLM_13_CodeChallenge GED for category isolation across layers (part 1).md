
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../index.md) > [10 Identifying circuits](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../index.md)
- [ğŸ“š Module 01: LLM Course](../../01-LLM_Course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../02-Words-to-tokens-to-numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../04-buildGPT/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../07-Fine-tune-pretrained-models/index.md)
- [ğŸ” Module 19: AI Safety](../../19-AI-safety/index.md)
- [ğŸ Module 20: Python for AI](../../20-Python-Colab-notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): TÃ¡ch NhÃ³m GED Äa Táº§ng (Pháº§n 1)

## TÃ³m táº¯t (Abstract)
Thá»­ thÃ¡ch láº­p trÃ¬nh (Code Challenge) nÃ y lÃ  má»™t bÆ°á»›c tiáº¿n xa hÆ¡n trÃªn hÃ nh trÃ¬nh diá»…n giáº£i Máº¡ng tháº§n kinh, nÆ¡i Há»c viÃªn Ä‘Æ°á»£c hÆ°á»›ng dáº«n xÃ¢y dá»±ng Bá»™ mÃ¡y Kiá»ƒm Ä‘á»‹nh ChÃ©o (Cross-validation) trÃªn thuáº­t phÃ¢n tÃ­ch GED (Generalized Eigendecomposition). Ta tÃ¡ch biá»‡t "Data Huáº¥n luyá»‡n" (CÃ¢u Äiá»u kiá»‡n tá»± thiáº¿t káº¿) khá»i "Data ÄÃ¡nh giÃ¡" (FineWeb Dataset ngáº«u nhiÃªn) nháº±m phÃ²ng chá»‘ng Overfitting. Cáº¥u trÃºc gá»“m ba Module lÃµi: 1) Há»‡ thá»‘ng Khai thÃ¡c Ngá»¯ Cáº£nh cá»§a Tá»« khÃ³a Tá»« FineWeb. 2) Cá»— MÃ¡y Ã‰p Chiá»u Tá»©c Thá»i (Per-layer PCA) vÃ  3) HÃ m ÄÃ³ng gÃ³i PhÃ¢n ly GED, tÃ­nh toÃ¡n Pattern Vectors vÃ  Eigenvalues tá»‹nh tiáº¿n trÃªn cÃ¡c táº§ng.

---

## 1. Má»Ÿ Äáº§u (Introduction)
Vá»›i sá»©c máº¡nh kinh hoÃ ng cá»§a GED, tháº­t dá»… bá»‹ cuá»‘n vÃ o cáº¡m báº«y "MÃ¹ má» Overfit" - NÆ¡i Ma tráº­n Eigenvectors há»c quÃ¡ ká»¹ nhá»¯ng Ä‘áº·c thÃ¹ vÃ´ nghÄ©a tá»« má»™t File vÄƒn báº£n bÃ© xÃ­u rá»“i táº¡o áº£o giÃ¡c thÃ nh cÃ´ng. 
Trong bÃ i táº­p nÃ y, sinh viÃªn Ä‘Æ°á»£c rÃ¨n luyá»‡n quy trÃ¬nh thiáº¿t láº­p má»™t Ä‘Æ°á»ng á»‘ng Máº¡ch (Pipeline) Khoa Há»c Dá»¯ liá»‡u TiÃªu chuáº©n:
- Máº£nh ghÃ©p CÆ¡ báº£n $\mathbf{Train\_Set}$: Sá»­ dá»¥ng bá»™ dá»¯ liá»‡u kinh Ä‘iá»ƒn HIM/HER mÃ  ta thiáº¿t káº¿ trong lab trÆ°á»›c (54 Cáº·p TuyÃªn thá»‡ tÆ°Æ¡ng Ä‘á»“ng). Eigenvectors sáº½ Ä‘Æ°á»£c huáº¥n luyá»‡n Táº I ÄÃ‚Y.
- Thá»­ thÃ¡c Thá»±c Ä‘á»‹a $\mathbf{Test\_Set}$: Tá»± tay cÃ o 2000 VÄƒn báº£n Máº¡ng (`fineweb`), trÃ­ch chá»n 50 máº©u cÃ¢u chá»©a HIM, vÃ  50 máº©u chá»©a HER trong vÃ´ vÃ n bá»‘i cáº£nh (Contexts) há»—n loáº¡n. GED Filter Model pháº£i lá»c thÃ nh cÃ´ng dá»¯ liá»‡u chÆ°a há» Ä‘Æ°á»£c tháº¥y nÃ y.

---

## 2. Tiáº¿t Láº­p TrÃ¬nh Thá»­ ThÃ¡ch (Code Challenges)

### Giai Äoáº¡n 1: Tuyá»ƒn má»™ Táº­p ÄÃ¡nh GiÃ¡ Äá»™c láº­p (The Blind Test Set)
Äá»ƒ láº¥y Token Trá»ng tÃ¢m (Target Tokens) tá»« Fineweb, thuáº­t toÃ¡n quÃ©t lÃ¹ng Token `him` & `her`. Äá»ƒ Ä‘áº£m báº£o cáº¥u trÃºc Äá»“ng Ä‘á»u Input Model `[100, 10]`, ta cáº¯t Ä‘Ãºng Máº£nh ngá»¯ cáº£nh dÃ i 10 Token, vá»›i Keyword trá»ng tÃ¢m luÃ´n Ä‘áº­u á»Ÿ Vá»‹ trÃ­ Index $6$.
> **BÃ­ quyáº¿t Thiáº¿t Káº¿ TÃ¡ch Biá»‡t**: Äá»ƒ ngÄƒn mÃ´ hÃ¬nh Äƒn gian (VÃ­ dá»¥ 1 cÃ¢u chá»©a cáº£ "him and her" lá»t vÃ o cáº£ 2 list), máº£ng Token Her Ä‘Æ°á»£c cá»™ng thÃªm chá»‰ sá»‘ Lá»‡ch (Offset) $1/2$ quÃ£ng Ä‘Æ°á»ng, tá»‘ng chÃºng tháº³ng xuá»‘ng Ná»­a sau cá»§a Dataset. Sá»± phÃ¢n tÃ¡ch nÃ y lÃ  cÆ¡ cháº¿ báº£o vá»‡ Sinh há»c (Contamination Free).

### Giai Äoáº¡n 2: Tráº¡m Ã‰p Dá»¯ Liá»‡u ChuyÃªn SÃ¢u (Dimension Reduction Factory)
Táº¡o HÃ m `dim_red(layer)` tÃ¡i diá»…n quÃ¡ trÃ¬nh Ã‰p khÃ´ng gian $3072D\ \to 99\%\ Variance$ mÃ  ta tá»«ng lÃ m, nhÆ°ng pháº£i bá»c trong má»™t HÃ m Ä‘á»™c láº­p Ä‘á»ƒ láº·p tá»± Ä‘á»™ng n-Layers:
- Xá»­ lÃ½ NÃºt tháº¯t Cá»• Chai Hiá»‡u NÄƒng: á» bÃ i trÆ°á»›c ta Tá»± tay giáº£i Eigen PCA. Táº¡i bÃ i láº·p VÃ²ng Táº§ng nÃ y, ta Báº®T BUá»˜C gá»i máº£ng `sklearn.decomposition.PCA` Ä‘á»ƒ táº­n dá»¥ng há»‡ tÄƒng tá»‘c nhÃ¢n $C++$.
- Káº» thÃ¹ Cá»§a Äáº¡i sá»‘ Há»c (`sklearn Components`): ChÃº Ã½ cá»±c Ä‘iá»ƒm ráº±ng `scikit-learn` cá»‘ tÃ¬nh xoay ngang Eigenvector theo trá»¥c HÃ ng (Rows) thay vÃ¬ chuáº©n Má»±c Cá»™t (Columns). Khi tÃ­nh toÃ¡n, má»™t phÃ©p Chuyá»ƒn Vá»‹ Ma Tráº­n (`PCA.components_.T`) lÃ  bá»©c tÆ°á»ng phÃ²ng thá»§ cuá»‘i cÃ¹ng chá»‘ng láº¡i sá»¥p Ä‘á»• LÃµi Há»‡ thá»‘ng.

### Giai Äoáº¡n 3: Cáº¥u TrÃºc Khá»‘i Tá»•ng Há»£p GED (The GED Pipeline)
Táº¡o hÃ m tá»± Ä‘á»™ng giáº£i GED: `run_ged(train_data, pca_evecs)`
Má»™t Ä‘iá»ƒm tinh Ã½ trong viá»‡c LÃ½ giáº£i Há»‡ Trá»ng Sá»‘: Eigenvector (`W`) KHÃ”NG PHáº¢I lÃ  Máº«u KÃ­ch Hoáº¡t (Activation Pattern). Eigenvector lÃ  LÆ°á»›i Lá»c (Filter). 
Äá»ƒ tháº¥y rÃµ Dáº¥u áº¤n Váº­t LÃ½ cá»§a khÃ¡i niá»‡m "Giá»›i tÃ­nh" phá»§ lÃªn bá» máº·t $3072$ NÆ¡-ron (Má»i TÃ²a nhÃ  cá»§a Máº¡ng LÆ°á»›i), hÃ m toÃ¡n há»c Äá»‘c chiáº¿u Pháº£i lá»™i ngÆ°á»£c dÃ²ng: 
$$ Pattern = W_{GED} \cdot Covariance(S) \cdot PCA\_Evecs_{T} $$
Khá»‘i Cá»™t Pattern Cuá»‘i CÃ¹ng Ä‘Ã³ Ä‘Æ°á»£c Correlate chÃ©o giá»¯a phÃ¢n lá»›p HIM vÃ  lá»›p HER. GiÃ¡ trá»‹ Correlation ($R^{2}$) vÃ  Trá»‹ Sá»‘ TÃ¡ch Lá»›p ($Max\ Eigenvalue$) Ä‘Æ°á»£c tá»‘ng xuáº¥t phá»¥c vá»¥ cho biá»ƒu Ä‘á»“ Diá»…n tiáº¿n XuyÃªn Táº§ng á»Ÿ video Pháº§n 2.

---

## 3. Kháº£o SÃ¡t & Tráº£ Lá»i Váº¯n Táº¯t
- Táº¡i sao pháº£i `test_activations.copy()` nhÆ°ng Dictionary `train_activations` thÃ¬ khÃ´ng? 
$\to$ ÄÃ¡p Ã¡n: Khi ta cáº¯m Pipeline vÃ o Memory Pytorch. HÃ m GÃ¡n KhÃ´ng (Assignment) trá» tháº³ng 2 Data tá»›i 1 vÃ¹ng váº­t lÃ½. ChÃ¨n `.copy()` Ä‘á»ƒ báº» gÃ£y Con Trá», niÃªm phong Test_Set trá»Ÿ thÃ nh vÃ¹ng biá»ƒn ÄÃ³ng BÄƒng miá»…n nhiá»…m vá»›i má»i sá»­a Ä‘á»•i biáº¿n táº¥u diá»…n ra á»Ÿ khá»‘i Train_Set.

---

## TÃ i Liá»‡u Tham Kháº£o (Citations)
1. Thá»­ thÃ¡ch TÃ¡i Láº­p vÃ  Viáº¿t Code tá»± Ä‘á»™ng Äa Há»‡ (Automated Cross-validation Framework) táº¡i `aero_LLM_13_CodeChallenge GED for category isolation across layers (part 1).md`. Giá»›i thiá»‡u cÆ¡ cháº¿ Lá»c Cá»• chai báº±ng `sklearn` tá»‘c Ä‘á»™ cao.
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| [Máº¡ng Máº¡ch Thuáº­t ToÃ¡n (Circuits) Trong MÃ´ HÃ¬nh Há»c SÃ¢u](aero_LLM_01_What is a circuit in a DL model.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_01_What is a circuit in a DL model.md) |
| [CÃ´ Láº­p VÃ  ThÄƒm DÃ² Khá»‘i ChÃº Ã (Attention Heads)](aero_LLM_02_Isolating and investigating attention heads.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_02_Isolating and investigating attention heads.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh: Biá»ƒu Diá»…n PhÃ¢n Bá»‘ Nhiá»‡t Laminar Cá»§a Trá»ng Sá»‘ ChÃº Ã](aero_LLM_03_CodeChallenge Laminar profile of attention head weights.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_03_CodeChallenge Laminar profile of attention head weights.md) |
| [Kháº£o SÃ¡t TÆ°Æ¡ng Quan Cá»¥m (Clustering) Vi Máº¡ch (Circuits) Trong KhÃ´ng Gian Giáº£m Chiá»u](aero_LLM_04_Are circuits clustered in low-dimensional space.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_04_Are circuits clustered in low-dimensional space.md) |
| [LÃ½ Thuyáº¿t VÃ  á»¨ng Dá»¥ng Cá»§a Ká»¹ Thuáº­t DÃ² ThÆ°a (Sparse Probing)](aero_LLM_05_Sparse probing theory and code.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_05_Sparse probing theory and code.md) |
| [ThÃ¡ch Thá»©c Cá»§a TÃ­n Hiá»‡u ThÆ°a Trong Dá»¯ Liá»‡u Táº­p Lá»›n (Statistical Suppression)](aero_LLM_06_Challenges with sparse logistic regression in large datasets.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_06_Challenges with sparse logistic regression in large datasets.md) |
| [Biáº¿n Tiá»m áº¨n (Latent) VÃ  Biáº¿n Hiá»ƒn NgÃ´n (Manifest) Trong Giáº£i Diá»…n AI](aero_LLM_07_Latent vs. manifest variables.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_07_Latent vs. manifest variables.md) |
| [MÃ´ HÃ¬nh Sparse Autoencoders (SAEs): LÃ½ Thuyáº¿t VÃ  Kiáº¿n TrÃºc KhÃ´i Phá»¥c Vi Máº¡ch Tiá»m áº¨n](aero_LLM_08_Sparse autoencoders theory and code.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_08_Sparse autoencoders theory and code.md) |
| [Huáº¥n Luyá»‡n Sparse Autoencoder TrÃ­ch Xuáº¥t KhÃ¡i Niá»‡m Ngá»¯ Cáº£nh Palinka TrÃªn GPT-2](aero_LLM_09_SAE in GPT2 learns about Hungarian Palinka.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_09_SAE in GPT2 learns about Hungarian Palinka.md) |
| [Kháº£o SÃ¡t PhÃ¢n Táº§ng KÃ­ch Hoáº¡t (Laminar Profile) Qua Sparse Autoencoder](aero_LLM_10_CodeChallenge Laminar profile of autoencoder sparsity.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_10_CodeChallenge Laminar profile of autoencoder sparsity.md) |
| [Nháº­n Diá»‡n KhÃ¡i Niá»‡m XuyÃªn TÃ¢m Vá»›i PhÃ¢n RÃ£ GiÃ¡ Trá»‹ RiÃªng Suy Rá»™ng (Generalized Eigendecomposition - GED)](aero_LLM_11_Non-orthogonal latent components via eigendecomposition (theory and demo).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_11_Non-orthogonal latent components via eigendecomposition (theory and demo).md) |
| [Ráº¡ch RÃ²i Giá»›i TÃ­nh (Him vs Her) Báº±ng Generalized Eigendecomposition Trong MLP](aero_LLM_12_Generalized eigendecomposition separates him from her in MLP.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_12_Generalized eigendecomposition separates him from her in MLP.md) |
| ğŸ“Œ **[Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): TÃ¡ch NhÃ³m GED Äa Táº§ng (Pháº§n 1)](aero_LLM_13_CodeChallenge GED for category isolation across layers (part 1).md)** | [Xem bÃ i viáº¿t â†’](aero_LLM_13_CodeChallenge GED for category isolation across layers (part 1).md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): TÃ¡ch NhÃ³m GED Äa Táº§ng (Pháº§n 2) & Kiá»ƒm Chá»©ng ChÃ©o](aero_LLM_14_CodeChallenge GED for category isolation across layers (part 2).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_14_CodeChallenge GED for category isolation across layers (part 2).md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
