
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../index.md) > [14 modify activations](index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../index.md)
- [ğŸ“š Module 01: LLM Course](../01_llm_course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../02_words_to_tokens_to_numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../04_buildgpt/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../07_fine_tune_pretrained_models/index.md)
- [ğŸ” Module 19: AI Safety](../19_ai_safety/index.md)
- [ğŸ Module 20: Python for AI](../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Dáº«n Nháº­p Vá» Diá»…n Giáº£i CÆ¡ Há»c NhÃ¢n Quáº£ (Causal Mechanistic Interpretability)

## TÃ³m táº¯t (Abstract)
BÃ¡o cÃ¡o dáº«n nháº­p nÃ y má»Ÿ ra giai Ä‘oáº¡n cuá»‘i cá»§a quÃ¡ trÃ¬nh Diá»…n giáº£i MÃ´ hÃ¬nh (Interpretability) - Chuyá»ƒn dá»‹ch tá»« PhÆ°Æ¡ng phÃ¡p Quan sÃ¡t (Observational) thá»¥ Ä‘á»™ng sang cÃ¡c Biá»‡n phÃ¡p Can thiá»‡p NhÃ¢n quáº£ (Causal Manipulations). Viá»‡c thá»c sÃ¢u vÃ o bÃªn trong Ä‘á»ƒ thay Ä‘á»•i cÃ¡c Ä‘iá»ƒm KÃ­ch hoáº¡t (Activations) cho phÃ©p ta kiá»ƒm thá»­ cÃ¡c cáº¥u trÃºc vi máº¡ch (Circuits) má»™t cÃ¡ch triá»‡t Ä‘á»ƒ thÃ´ng qua CÃ¢u há»i Pháº£n thá»±c (Counterfactuals). Tuy nhiÃªn, cÃ´ng cuá»™c thao tÃºng thá»±c chá»©ng nÃ y Ä‘á»‘i máº·t vá»›i ba rÃ o cáº£n vÄ© mÃ´: 1) Sá»‘ lÆ°á»£ng bá»™ pháº­n chuyá»ƒn Ä‘á»™ng tiá»‡m cáº­n vÃ´ cá»±c; 2) TÃ­nh á»”n Ä‘á»‹nh Dá»¯ liá»‡u PhÃ¢n tÃ¡n (Distributed Robustness) vá»‘n Ä‘Æ°á»£c sinh ra tá»« cÃ¡c thá»§ thuáº­t khÃ¡ng lá»—i nhÆ° Dropout hay LayerNorm; 3) Thiáº¿u há»¥t GiÃ¡ trá»‹ ChÃ¢n lÃ½ (Ground Truth) Ä‘á»ƒ Ä‘á»‹nh chuáº©n. Láº¥y CÃ¢y cáº§u Ä‘á»©t Ä‘oáº¡n táº¡i Amsterdam lÃ m vÃ­ dá»¥, bÃ¡o cÃ¡o kháº³ng Ä‘á»‹nh Causal Interpretability lÃ  má»™t Lá»±c lÆ°á»£ng Bá»• trá»£ (Complementary), chá»© khÃ´ng pháº£i máº£nh ghÃ©p thay tháº¿ cho Observational Interpretability.

---

## 1. Má»Ÿ Äáº§u (Introduction)
Vá»›i Diá»…n giáº£i Quan sÃ¡t (Observational Interpretability), chÃºng ta Ä‘Ã³ng vai nhÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u: TrÃ­ch xuáº¥t Dá»¯ liá»‡u (Extract) qua cÃ¡c Hook rá»“i dÃ¹ng Sparse Autoencoders hoáº·c Generalized Eigendecomposition Ä‘á»ƒ xem mÃ´ hÃ¬nh nghÄ© gÃ¬. 
NhÆ°ng Ä‘á»ƒ chá»©ng minh má»™t Neuron thá»±c sá»± cÃ³ Há»“n (Tá»©c nÃ³ Cáº¥u thÃ nh nÃªn káº¿t quáº£ chá»© khÃ´ng chá»‰ ÄÃ³ng bÄƒng nhÆ° má»™t thá»© nhiá»…u Ä‘á»“ng phÃ¡t), ta pháº£i dÃ¹ng Diá»…n giáº£i NhÃ¢n Quáº£ (Causal Interpretability). 
Nhiá»‡m vá»¥ á»Ÿ Ä‘Ã¢y biáº¿n tá»« "Äá»c" sang "Viáº¿t": Ta sáº½ chá»§ Ä‘á»™ng Can thiá»‡p (Interfere), Chá»‰nh sá»­a KÃ­ch hoáº¡t, XÃ³a sá»• (Zero-out), hoáº·c Äáº£o chiá»u ToÃ¡n há»c toÃ n bá»™ TÃ­n hiá»‡u (Activations) á»Ÿ má»™t vá»‹ trÃ­ báº¥t ká»³ Ä‘ang cháº¡y trong quÃ¡ trÃ¬nh Forward-pass. Tá»« Ä‘Ã³, ta cÃ³ thá»ƒ Ä‘Ã¡nh giÃ¡ xem MÃ´ hÃ¬nh suy diá»…n sai lá»‡ch ra sao á»Ÿ Output Logits vÃ  KhÃ¢u Sinh tá»« (Token Generation).

---

## 2. Tiá»m NÄƒng Cá»§a PhÆ°Æ¡ng PhÃ¡p Thao TÃºng NhÃ¢n Quáº£ (The Power of Causal Manipulations)

### Quyá»n NÄƒng Pháº£n Thá»±c Táº¿ (Counterfactual Reasoning)
KhÃ¡c biá»‡t lá»›n nháº¥t cá»§a NghiÃªn cá»©u Causal so vá»›i Observational lÃ  nÃ³ giÃºp ta tráº£ lá»i cÃ¡c cÃ¢u há»i "Sáº½ tháº¿ nÃ o náº¿u..." (What-if questions). Trong cuá»™c sá»‘ng, báº¡n khÃ´ng thá»ƒ thay Ä‘á»•i quyáº¿t Ä‘á»‹nh quÃ¡ khá»© Ä‘á»ƒ xem káº¿t quáº£. NhÆ°ng trong há»‡ thá»‘ng LLMs, báº±ng cÃ¡ch dÃ¹ng Hooks, ta cÃ³ thá»ƒ cÃ´ láº­p má»™t biáº¿n $X$, giáº£ láº­p nÃ³ báº±ng $Y$ (Counterfactual Activation), vÃ  Ã©p Phá»• xÃ¡c suáº¥t $P(Token \mid  Context\_Mod)$ thay Ä‘á»•i. 

---

## 3. Ba KhÃ³ KhÄƒn Cá»‘t LÃµi Cá»§a Thao tÃ¡c NhÃ¢n Quáº£ (Three Main Challenges)

### 3.1. Nghá»‹ch LÃ½ Vá» Sá»‘ LÆ°á»£ng CÃ¡c Bá»™ Pháº­n Chuyá»ƒn Äá»™ng (Limitless Possibilities)
Há»‡ thá»‘ng Transformers chá»©a hÃ ng tá»· Tham sá»‘, hÃ ng chá»¥c ngÃ n Äiá»ƒm Äáº§u-Cuá»‘i, Multi-head Attentions, MLP Neurons tráº£i dá»c qua Ä‘á»™ sÃ¢u vÃ´ biÃªn.
Sá»± quÃ¡ táº£i á»Ÿ Ä‘Ã¢y lÃ  "Ta nÃªn sá»­a cÃ¡i gÃ¬?"
- XÃ³a sá»• kÃ­ch hoáº¡t (Zero-out activations)?
- Äá»•i nÃ³ thaÌ€nh GiÃ¡ trá»‹ Trung bÃ¬nh (Mean) hay GiÃ¡ trá»‹ Trung vá»‹ (Median)?
- BÆ¡m CÄƒn Nhiá»…u VÃ´ hÆ°á»›ng (Inject Noise)?
- Hay thÃ¡o GhÃ©p NhÃºng (Embeddings) cá»§a má»™t mÃ´ hÃ¬nh nÃ y Ä‘áº­p vÃ o má»™t há»‡ mÃ´ hÃ¬nh khÃ¡c?
Sá»‘ lÆ°á»£ng thao tÃ¡c thÃ­ nghiá»‡m (Combinatorics of experiments) lÃ  vÃ´ háº¡n, Ä‘Ã²i há»i sá»± tuyá»ƒn tráº¡ch lÃ½ thuyáº¿t vÃ´ cÃ¹ng sáº¯c bÃ©n.

### 3.2. TÃ­nh BÃ¹ Trá»« KhÃ¡ng Nhiá»…u Cá»§a Há»‡ Thá»‘ng Máº¡ng (System Robustness & Compensation)
Äiá»ƒm khÃ³ khÄƒn thá»© hai Ä‘áº¿n tá»« chÃ­nh Thiáº¿t káº¿ Máº¡ng nÆ¡-ron: NÃ³ Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»ƒ Tuyá»‡t Ä‘á»‘i KhÃ´ng Sá»¥p Äá»• trÆ°á»›c nhiá»…u.
- **Layer Normalization:** GiÃºp á»•n Ä‘á»‹nh PhÃ¢n phá»‘i ToÃ¡n há»c dáº«u KÃ­ch hoáº¡t (Activation magnitudes) bá»‹ Ä‘áº©y lá»‡ch má»™t cÃ¡ch cá»‘ Ã½.
- **Dropout Training:** Má»i LLM Ä‘Æ°á»£c há»c cÃ¡ch bá» qua hÃ ng pháº§n trÄƒm lÆ°á»£ng nÆ¡-ron ngáº«u nhiÃªn bá»‹ tá»‹t (Zeroed-out) ngá»£p trong quÃ¡ trÃ¬nh Ä‘áº¡o hÃ m Training.
Há»‡ quáº£ lÃ : Khi báº¡n cá»‘ Ã½ Cáº¯t cáº§u Causal (Zero-out 1 máº¡ch MLP), cÃ¡c lá»›p Phá»¥ cá»§a cáº¥u trÃºc sáº½ "GÃ¡nh táº¡" (Compensate) vÃ  tá»± Reroute Phá»• TÃ­n hiá»‡u, lÃ m cho Output cháº³ng thay Ä‘á»•i gÃ¬. 

*áº¨n dá»¥ CÃ¢y cáº§u Ä‘á»©t*: Giá»‘ng nhÆ° LÆ°á»›i Äiá»‡n á»Ÿ Amsterdam, khi cáº§u má»Ÿ ra cho TÃ u thuyá»n qua, há»‡ thá»‘ng dÃ¢y Ä‘iá»‡n bá»‹ ngáº¯t káº¿t ná»‘i váº­t lÃ½. Liá»‡u cáº£ thÃ nh phá»‘ cÃ³ máº¥t Ä‘iá»‡n? KhÃ´ng, vÃ¬ DÃ²ng Ä‘iá»‡n ngay láº­p tá»©c sáº½ Ä‘Æ°á»£c Ä‘á»‹nh tuyáº¿n (Reroutes) qua náº»o khÃ¡c cá»§a LÆ°á»›i Ä‘iá»‡n thÃ´ng minh. Language Models cÃ³ cÆ¡ cháº¿ sinh tá»“n y há»‡t váº­y.

### 3.3. Ãm áº¢nh Thiáº¿u Váº¯ng TiÃªu Chuáº©n Sá»± Tháº­t (Lack of Ground Truth)
ÄÃ¢y lÃ  cÃ¢u chuyá»‡n khÃ³ giáº£i: Náº¿u thao tÃ¡c thay Ä‘á»•i Tráº¡ng thÃ¡i Logits cá»§a mÃ´ hÃ¬nh, khÃ´ng cÃ³ báº¥t ká»³ TiÃªu chuáº©n Sá»± tháº­t nÃ o kiá»ƒm chá»©ng Ä‘Ã³ lÃ  do HÃ m Ná»™i Suy Máº¡ch (Circuit function) bá»‹ há»ng, hay lÃ  do Ta BÆ¡m Nháº§m Ma tráº­n Táº¡p má»¡ (Out-of-distribution noise) lÃ m phÃ¡ há»§y Tá»•ng quan MÃ´ hÃ¬nh TÃ­nh ToÃ¡n. Ta chá»‰ cÃ³ thá»ƒ xÃ¡c minh giáº£ thiáº¿t thÃ´ng qua Báº§u chá»n Sá»‘ Ä‘Ã´ng báº±ng cÃ¡c bÃ i Cháº¥m KÃ©p (Parametric Manipulations) cháº¡y xen káº½, Ä‘á»•i há»‡ sá»‘ Scale nhiá»u má»©c Ä‘á»™ rá»“i quan sÃ¡t Biáº¿n sá»‘ thay Ä‘á»•i.

---

## 4. Káº¿t Luáº­n
Viá»‡c thÃ² tay Thay Ä‘á»•i Tham sá»‘ Äiá»‡n tÃ­ch Há»‡ thá»‘ng lÃ  ChÃ©n ThÃ¡nh cá»§a chá»©ng minh Khoa há»c Diá»…n giáº£i Äáº§u-Cuá»‘i. DÃ¹ lÄ©nh vá»±c Causal Iterpretability Ä‘ang tiáº¿n bá»™ nhÆ° vÅ© bÃ£o, nÃ³ khÃ´ng pháº£i lÃ  "VÅ© khÃ­ diá»‡t vong" láº­t Ä‘á»• PhÆ°Æ¡ng phÃ¡p Observational. Thay vÃ o Ä‘Ã³, Causal vÃ  Observational Methods buá»™c pháº£i Ä‘i song hÃ nh (Complementary), soi chiáº¿u láº«n nhau nhÆ° hai máº·t cá»§a Tháº¥u kÃ­nh: Äáº§u tiÃªn ta TÃ¬m kiáº¿m Cáº¥u trÃºc KhÃ´ng Gian áº©n Báº±ng ToÃ¡n há»c Giáº£i tÃ­ch Quan sÃ¡t, rá»“i sau Ä‘Ã³ má»›i ÄÃ¢m Dao BÃ o Pháº«u thuáº­t NhÃ¢n quáº£ Ä‘á»ƒ xÃ¡c nháº­n lÃ½ thuyáº¿t Ä‘Ã³ lÃ  Sá»± tháº­t.

---

## TÃ i liÃªn tham kháº£o (Citations)
1. LÃ½ luáº­n KhÃ¡i Niá»‡m Pháº£n Thá»±c Táº¿ vÃ  PhÃ¢n bá»• Máº¡ng trÃªn thá»±c tiá»…n "Aero_LLM_01_Introduction to causal mech interp.md". ÄÆ°a ra vÃ­ dá»¥ vá» Dropout and LayerNorm nhÆ° nhá»¯ng Trá»Ÿ lá»±c NhÃ¢n quáº£.
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| ğŸ“Œ **[Dáº«n Nháº­p Vá» Diá»…n Giáº£i CÆ¡ Há»c NhÃ¢n Quáº£ (Causal Mechanistic Interpretability)](aero_llm_01_introduction_to_causal_mech_interp.md)** | [Xem bÃ i viáº¿t â†’](aero_llm_01_introduction_to_causal_mech_interp.md) |
| [CÃ¡c Cháº¿ Äá»™ Sá»­a Äá»•i Hoáº¡t HÃ³a CÆ¡ Há»c (Activation Editing Implementations)](aero_llm_02_activation_editing_code_implementations.md) | [Xem bÃ i viáº¿t â†’](aero_llm_02_activation_editing_code_implementations.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Thay tháº¿ Hoáº¡t hÃ³a Attention, MLP vÃ  Hidden States](aero_llm_03_codechallenge_replacing_attention_mlp_and_hidden_states.md) | [Xem bÃ i viáº¿t â†’](aero_llm_03_codechallenge_replacing_attention_mlp_and_hidden_states.md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
