WEBVTT

00:02.160 --> 00:09.040
Now that you have been introduced to the theory and implementation of mutual information, it's good

00:09.040 --> 00:13.240
to see it used with real life activation data.

00:13.880 --> 00:21.480
It turns out that mutual information is quite versatile and can be used in several different ways by

00:21.600 --> 00:28.480
organizing the data in different ways, and that will give different results and reveal different insights

00:28.640 --> 00:30.440
into model functioning.

00:31.040 --> 00:39.280
So in this video, I will show you one way of calculating mutual information across lots of tokens for

00:39.280 --> 00:42.120
each pair of hidden states dimensions.

00:42.400 --> 00:49.200
And then in the next video, you will implement mutual information across the hidden states dimensions

00:49.440 --> 00:51.680
for each pair of tokens.

00:51.680 --> 00:53.840
So it's a bit of a different strategy.

00:54.640 --> 00:58.850
You will also see in this video that scikit learn's learns.

00:58.850 --> 01:04.330
Implementation can be slow, prohibitively so for large data sets.

01:04.850 --> 01:09.650
Now, this is a nuanced discussion that we will continue into the next video.

01:09.970 --> 01:17.610
But the upshot is that although scikit learn's algorithm is more accurate, it doesn't really matter

01:17.610 --> 01:24.770
that much for comparing mutual information between different layers or token categories.

01:25.330 --> 01:31.210
Anyway, let me explain what we will do in the Python demo and then I'll switch to code.

01:32.410 --> 01:38.330
So to start with I will import GPT two and run some text through it.

01:38.650 --> 01:44.530
It's just a little sequence of text about Turkish coffee that I copied from Wikipedia.

01:45.210 --> 01:53.650
Then I will calculate mutual information across all the tokens for one pair of hidden state dimensions

01:53.650 --> 01:57.210
in one layer, and that you see visualized here.

01:57.780 --> 02:04.780
So the x and the y axes show two dimensions in one of the transformer blocks.

02:05.300 --> 02:10.620
Now remember that these are not the individual attention or MLP neurons.

02:10.980 --> 02:17.500
Instead, these are the final outputs of the transformer block and it has the same dimensionality as

02:17.500 --> 02:19.780
the token embeddings dimensionality.

02:20.540 --> 02:25.540
So in this scatter plot each dot is a token in the text.

02:25.820 --> 02:28.860
And I think there's like 94 tokens in total.

02:30.020 --> 02:34.180
So you can see that this cloud of dots is fairly isotropic.

02:34.220 --> 02:40.500
It doesn't really seem to be any clear linear or nonlinear relationship between the two variables,

02:40.500 --> 02:44.100
certainly not based on just initial visual inspection.

02:44.900 --> 02:50.340
And indeed, the mutual information between these two variables is zero.

02:51.060 --> 02:51.380
Okay.

02:51.420 --> 02:55.300
So that is for one pair of dimensions.

02:55.420 --> 03:01.710
But of course there are 768 dimensions, which is a lot of possible pairs.

03:02.230 --> 03:11.070
So the next part of the code demo I will run this same analysis, but over all of the possible pairs

03:11.390 --> 03:13.470
within one transformer block.

03:14.150 --> 03:20.110
So here you see a histogram of what those mutual information values look like.

03:20.550 --> 03:25.430
And you can see that over all of the pairs we do get some very small values.

03:25.630 --> 03:31.070
But there's most of the values are clustered around one or maybe a little bit greater than one.

03:31.750 --> 03:33.430
So here you see the histogram.

03:33.550 --> 03:35.270
So here you see the histogram.

03:35.270 --> 03:42.870
We can visualize all of these results in this matrix over here where the color corresponds to the strength

03:42.870 --> 03:48.470
of the mutual information between the corresponding pairs of dimensions.

03:49.270 --> 03:53.910
Now it looks like there's only around 370 ish dimensions.

03:54.200 --> 04:00.280
But that's because in the analysis code, I have skipped every other dimension.

04:00.720 --> 04:05.080
And I did that because this analysis takes a really long time to run.

04:05.600 --> 04:13.400
And when I use the scikit learn implementation, it takes a really, really long time to learn so long

04:13.560 --> 04:18.040
that it's not feasible even for this tiny little toy example.

04:18.840 --> 04:25.280
So I'll have more to say about that when I switch to code and continue the discussion into the next

04:25.280 --> 04:25.960
video.

04:26.480 --> 04:30.160
But anyway, this distribution is just for one layer.

04:30.160 --> 04:36.840
So then I will repeat this analysis that you see here for all of the hidden state layers.

04:37.040 --> 04:43.040
So that is the initial embeddings layer and all of the transformer blocks.

04:43.240 --> 04:45.640
And you can see those distributions here.

04:46.040 --> 04:52.660
Now they're almost entirely all overlapping except for the embeddings dimension or the embeddings layer

04:52.660 --> 04:53.060
here.

04:53.620 --> 05:01.580
So at least visually, doesn't really seem like mutual information is shifting on average as a function

05:01.580 --> 05:03.900
of depth into the model.

05:04.620 --> 05:08.540
Now in this video, in the code demo, I'll switch to in a moment.

05:08.540 --> 05:16.060
I calculated mutual information across all of the tokens within each pair of dimensions.

05:16.540 --> 05:22.220
As I mentioned in the beginning of this video, that's not the only way to calculate mutual information.

05:22.540 --> 05:29.420
And in fact, it's probably not the best way unless you're running an analysis like for different categories

05:29.420 --> 05:31.580
of tokens or token sequences.

05:31.940 --> 05:38.260
For example on different semantic topics, or maybe in different languages, you're going to see very

05:38.260 --> 05:39.980
different results from this.

05:40.020 --> 05:45.100
In the next video, when I apply the analysis in a slightly different way.

05:45.900 --> 05:49.020
Anyway, let's now switch to code and have a look.

05:50.020 --> 05:57.190
Here are the libraries that we will use in this video, and also this function which you have seen in

05:57.190 --> 05:58.550
the previous video.

05:58.630 --> 06:06.230
Here I'm importing GPT two small and its tokenizer and switching it to eval mode, which we will basically

06:06.230 --> 06:08.270
always do for the rest of the course.

06:08.710 --> 06:10.470
Okay, here is some text.

06:10.510 --> 06:13.190
Turkish coffee is very finely ground coffee.

06:13.230 --> 06:14.550
ET cetera, et cetera.

06:14.590 --> 06:22.550
There are a bit under 100 tokens in this text, and it's just one paragraph that I copied from Wikipedia.

06:22.790 --> 06:28.470
If you have never experienced the pleasure of drinking Turkish coffee, then I can recommend it.

06:28.470 --> 06:31.030
If you can find a real Turkish coffee shop.

06:31.510 --> 06:32.270
Okay, let's see.

06:32.270 --> 06:37.350
There are in fact 94 tokens and actually there is an error in here.

06:37.350 --> 06:39.390
This should say two list.

06:39.430 --> 06:40.870
This needs to be a list okay.

06:41.030 --> 06:43.230
There are 64 unique tokens.

06:43.350 --> 06:47.310
And why are there fewer unique tokens than there are total tokens.

06:47.590 --> 06:52.360
Because for example, the word coffee appears multiple times.

06:52.360 --> 06:58.160
In fact, I believe the word coffee appears seven times in this text.

06:58.360 --> 07:00.400
That is not relevant for this video.

07:00.600 --> 07:05.680
That is something we will investigate in the code challenge in the next video.

07:05.960 --> 07:07.520
So more on that anyway.

07:07.560 --> 07:09.280
Yeah, a bit under 100 tokens.

07:09.760 --> 07:10.080
Okay.

07:10.120 --> 07:13.360
Now I'm just pushing all of this text through the model.

07:13.360 --> 07:16.480
You can see I am running this on the CPU.

07:16.800 --> 07:20.920
I'm not using the GPU here because it's just a little bit of text.

07:20.920 --> 07:24.200
And this is the only time that I'm actually calling the model.

07:24.200 --> 07:29.880
So it's really not worth all the additional overhead for running the GPU here.

07:31.120 --> 07:38.520
So yeah, here I'm just confirming the size of the hidden layers for one particular layer, the hidden

07:38.520 --> 07:39.200
states.

07:39.200 --> 07:43.400
So we have one for one batch, one sequence 94 tokens.

07:43.400 --> 07:49.890
And of course 768 is the embeddings dimensionality of GPT two small.

07:50.570 --> 07:52.490
Here I'm creating a function.

07:52.490 --> 07:59.810
You will see this function we will use in the next several videos, all the code challenges in the next

07:59.810 --> 08:00.770
several videos.

08:01.010 --> 08:07.050
And there's no new code here compared to what you have seen in the previous video.

08:07.050 --> 08:14.170
All I'm doing is gathering up all of that information and putting it into a function so I can input

08:14.170 --> 08:20.050
the variables x and y and calculate the mutual information between them.

08:20.570 --> 08:26.290
Now this code here is a manual implementation of mutual information.

08:26.290 --> 08:32.290
It's a direct translation of the formulas from the previous video into code.

08:32.290 --> 08:37.410
This is not using uh, the method from scikit learn.

08:37.410 --> 08:38.930
We'll get back to that later okay.

08:38.970 --> 08:41.010
So I'll run that function.

08:41.130 --> 08:46.740
And here is just an example of one pair of dimensions across all the tokens.

08:46.780 --> 08:49.420
Okay, so I'm just picking hidden layer three.

08:49.460 --> 08:50.540
Just arbitrarily.

08:50.540 --> 08:51.940
You can change this if you like.

08:51.980 --> 08:59.900
And now I am going to calculate mutual information between these two dimensions again arbitrarily chosen.

09:00.060 --> 09:05.100
These can be any two numbers between 0 and 767.

09:05.460 --> 09:12.100
And now all of the data points for x and y are the 94 different tokens.

09:12.260 --> 09:15.740
So here I extract the data create a 2D histogram.

09:15.900 --> 09:18.580
And here I'm calculating mutual information.

09:18.620 --> 09:25.340
Actually in this case I'm using scikit learn's method because we know that this is more accurate compared

09:25.340 --> 09:27.620
to this code up here.

09:27.740 --> 09:28.020
Okay.

09:28.060 --> 09:30.460
So why do we ever want to use this code?

09:30.460 --> 09:32.780
I will get back to that in a few moments.

09:32.980 --> 09:33.260
Okay.

09:33.300 --> 09:38.780
And then the rest of this visualization here is just creating the demo.

09:39.100 --> 09:42.740
The figure that you saw in the slides a moment ago.

09:43.270 --> 09:47.870
Okay, so now I'm going to run some code that takes way too long.

09:48.030 --> 09:53.750
Okay, so here I am looping over all of the hidden layers.

09:54.710 --> 09:57.710
And then I'm looping over all of the dimensions.

09:57.710 --> 10:01.310
And you can see I'm skipping actually the dimensions by two.

10:01.550 --> 10:06.670
And then I'm calculating mutual information using the scikit learn function.

10:06.910 --> 10:07.150
Okay.

10:07.190 --> 10:11.710
Now it turns out this is just going to take an absurdly long amount of time.

10:11.750 --> 10:14.350
I'm actually going to let it run for like a minute.

10:14.350 --> 10:17.510
And then I'll come back and we'll see how far it got.

10:17.550 --> 10:19.430
In approximately one minute.

10:20.790 --> 10:21.070
Okay.

10:21.110 --> 10:29.790
So I just crashed this and basically it took uh, so after a minute it only got through 38 dimensions

10:29.790 --> 10:31.110
in the first layer.

10:31.150 --> 10:34.750
That means we I don't know, this would take hours or something like that.

10:34.750 --> 10:40.510
So therefore what I'm going to do is calculate pairwise mutual information using the function that I

10:40.550 --> 10:41.110
wrote.

10:41.150 --> 10:47.960
This is the direct implementation of the formula that I showed a moment ago.

10:48.000 --> 10:54.800
Now this takes around six minutes, which is still difficult to scale up to a really large data set

10:54.800 --> 10:59.960
and a larger model, more text, longer, more tokens in the text.

10:59.960 --> 11:06.040
But six minutes is certainly a lot better than the like six hours that it would take to run this analysis.

11:06.280 --> 11:12.400
Okay, so I am going to pause the recording and let this run for another 5.5 minutes or so.

11:13.440 --> 11:16.120
So actually that only took around four minutes.

11:16.160 --> 11:22.400
Not sure why that's faster than the six minutes that it took when I first wrote this code, but maybe

11:22.400 --> 11:25.400
it's connected to a better server computer anyway, it doesn't matter.

11:25.440 --> 11:27.840
Okay, so we got through all 13 layers.

11:27.840 --> 11:31.560
Remember that the first hidden states is the embeddings.

11:31.680 --> 11:34.720
And then we get the 12 transformer blocks.

11:35.080 --> 11:35.400
Okay.

11:35.440 --> 11:43.450
So now I'm going to create a histogram of all of the mutual information values and show the actual pairwise

11:43.450 --> 11:47.890
mutual information values in this matrix over here.

11:48.250 --> 11:55.970
Now remember that all of these values are zero because mutual information is a symmetric measure.

11:55.970 --> 12:03.210
So the mutual information between x and Y is the same as the mutual information between y and x.

12:03.490 --> 12:10.490
So therefore if I would loop over redundantly, if you know if this loop went like this starting at

12:10.490 --> 12:14.090
zero, then we would get a full matrix.

12:14.090 --> 12:15.810
But that would be completely redundant.

12:15.810 --> 12:21.770
Then it would take twice as long to calculate exactly the same values twice.

12:21.890 --> 12:27.290
So therefore this second loop I start from dim I plus one.

12:27.650 --> 12:31.930
Now if you actually want to have a full matrix, it's completely fine.

12:31.930 --> 12:37.210
What you can do is take this matrix and add to it its transpose.

12:37.330 --> 12:43.980
So that would just flip this lower triangle onto the upper triangle and you would get a full matrix.

12:44.140 --> 12:46.860
That's fine if you want to use that for some reason.

12:47.500 --> 12:53.860
But just keep in mind that all of the values here are perfectly mirrored for the values down here.

12:54.260 --> 12:54.700
Okay.

12:54.740 --> 12:55.780
Anyway, uh, yeah.

12:55.780 --> 12:59.660
And as I mentioned, let's see, you can see here I'm skipping by two.

12:59.700 --> 13:04.900
And that's just to increase the, uh, calculation or decrease the calculation time.

13:05.300 --> 13:05.620
Okay.

13:05.660 --> 13:11.060
Now what I am going to demonstrate in, I think in, in two videos for now.

13:11.060 --> 13:12.020
Or maybe it's the next video.

13:12.060 --> 13:18.740
Anyway, very soon in the future, what I will demonstrate is that the manual calculation of mutual

13:18.740 --> 13:25.260
information has a bias in it for, uh, that just shifts the entire distribution up.

13:25.540 --> 13:31.980
And that bias is basically due to, uh, undersampling the probability space because we have a lot of

13:32.020 --> 13:33.260
zeros in here.

13:33.740 --> 13:38.200
So what happens is that actually I can even show it in this example here.

13:38.400 --> 13:42.240
So the function that I wrote is called mutual Information Manual.

13:42.560 --> 13:51.280
So all I'm going to do now is change the scikit learn function into my manual function.

13:51.680 --> 13:56.520
And now we see that the uh wait let me get rid of this.

13:57.000 --> 14:00.560
And now we see that the mutual information is around one.

14:00.560 --> 14:05.760
So there is a constant shift increase in the mutual information.

14:05.800 --> 14:07.280
Let me set that back here.

14:08.640 --> 14:12.880
So that means that these values are the relative values are all accurate.

14:12.880 --> 14:17.240
So mutual information relatively calculated between different pairs.

14:17.440 --> 14:18.880
But there's a global shift.

14:18.880 --> 14:24.840
The entire distribution gets shifted to the right because of the uh yeah.

14:24.880 --> 14:30.400
Just some numerical issues with the direct implementation of mutual information.

14:30.400 --> 14:32.400
But all the relative values are the same.

14:32.440 --> 14:38.890
Again, that's something I'm going to discuss in more detail and demonstrate in a couple of videos from

14:38.890 --> 14:39.210
now.

14:39.690 --> 14:48.010
Okay, so what I do here is just extract all of the mutual information values, all the unique non-zero

14:48.010 --> 14:52.810
mutual information values from each layer, each of these hidden layers.

14:53.010 --> 14:56.730
And then I'm making a histogram of those and plotting those.

14:57.410 --> 14:57.970
Uh, oops.

14:57.970 --> 15:03.850
Okay, so I did not initially plan when I created this video, and I planned out this video.

15:04.010 --> 15:07.090
I did not plan to rerun this code from the beginning.

15:07.730 --> 15:15.250
Uh, so I actually overwrote this variable here, uh, which is why, um, yeah, that's why, uh,

15:15.370 --> 15:23.170
this is now crashing because mi is just one variable, whereas it's supposed to be a full tensor full

15:23.170 --> 15:23.810
of data.

15:24.010 --> 15:28.730
Anyway, all of this code just recreates this figure here.

15:28.730 --> 15:33.940
So I'm not going to spend 6 minutes or 4 minutes rerunning the code to generate all the data.

15:34.260 --> 15:40.340
The point here is that you see, for this particular analysis, the way I set up this analysis, the

15:40.340 --> 15:46.020
mutual information doesn't really shift as we go deeper into the model.

15:46.620 --> 15:53.140
And that is something that you can compare with the results from the next video, where we are going

15:53.140 --> 15:59.740
to set up the mutual information analysis in a slightly different way and get quite different results.

15:59.980 --> 16:03.740
Anyway, here are three take home points from this video.

16:04.020 --> 16:08.900
One is that mutual information is a fairly versatile technique.

16:08.940 --> 16:14.940
It can be used and adapted in several different ways, which you will see over the course of the next

16:14.940 --> 16:16.540
few videos.

16:16.860 --> 16:24.820
In general, it's better to interpret relative values of mutual information and not the absolute number.

16:24.940 --> 16:30.220
And that's for reasons that you have seen here, and we'll continue to see over the next few videos.

16:30.220 --> 16:37.430
Basically, that just has to do with the sensitivity of the mutual information analysis to parameters

16:37.430 --> 16:45.350
such as the number of bins in the histogram, and also possible numerical issues that can arise from

16:45.390 --> 16:48.350
undersampling the probability space.

16:48.670 --> 16:56.070
And finally, in this case, in this video, we calculated mutual information over all of the tokens

16:56.070 --> 16:57.910
for each pair of dimensions.

16:58.110 --> 17:03.510
That is not always necessarily going to be the most insightful application.

17:03.710 --> 17:11.510
In fact, calculating mutual information across the hidden state activations for each pair of tokens,

17:11.710 --> 17:17.910
and that is often going to be more interpretable and also more computationally feasible.

17:18.110 --> 17:24.070
And that is exactly what you are going to implement in the code challenge coming up after first learning

17:24.070 --> 17:28.790
about the relationship between mutual information and covariance.
