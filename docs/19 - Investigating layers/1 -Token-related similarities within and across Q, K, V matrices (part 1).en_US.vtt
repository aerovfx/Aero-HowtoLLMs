WEBVTT

00:02.440 --> 00:05.480
Welcome to this section of the course.

00:06.080 --> 00:14.640
The goal here is to learn methods of analyzing and thinking about llms at the level of layers.

00:15.120 --> 00:22.600
That is a level of granularity and organization that is higher than individual neurons and dimensions,

00:22.880 --> 00:25.640
which you studied in the previous section.

00:26.400 --> 00:32.440
Of course, layers are made up of dimensions and neurons, but you will see throughout this section

00:32.440 --> 00:40.120
that we will adopt a slightly different way of thinking and approaching the activations in networks.

00:40.920 --> 00:49.400
In this video, we will look at how activations in the Q, K and v vectors are related to each other

00:49.640 --> 00:56.480
in terms of cosine similarity and Pearson correlation coefficient for different tokens.

00:57.280 --> 01:04.100
In particular, we will use either identical tokens that are found in different sentences and thus have

01:04.100 --> 01:08.180
different contexts or other random tokens.

01:09.260 --> 01:13.660
And we will actually discover a few curious and strange looking patterns.

01:13.860 --> 01:20.780
Some of these I will dig into a little bit more, and others I will just leave as a curious observation.

01:21.380 --> 01:28.140
The code that I will show you in this video you will also use for the code challenge in the next video,

01:28.140 --> 01:33.420
where you will use a much bigger model and do more involved analyses.

01:33.780 --> 01:38.660
Anyway, let me now explain what I will do in the Python demo.

01:39.220 --> 01:48.220
For this demo, I'll use GPT two and implant hooks to get activations from the Q, K, and V vectors.

01:48.620 --> 01:50.100
Now this is nothing new.

01:50.140 --> 01:54.580
You've seen this kind of code at the end of the previous section.

01:55.340 --> 02:04.320
Then I will have 54 sentences that we will tokenize, batch and input into the model to get attention.

02:04.320 --> 02:05.400
Activations.

02:05.920 --> 02:10.640
Now when you look at these sentences, you can see that they all contain the word her.

02:11.280 --> 02:19.920
That word is going to be our target word, meaning that I'm going to extract the activations from everywhere.

02:19.920 --> 02:21.880
The word her appears.

02:22.400 --> 02:29.040
Now, that's quite an interesting experimental approach, because the token itself is literally exactly

02:29.040 --> 02:32.360
identical in every one of these sentences.

02:32.920 --> 02:36.320
But of course, the contexts vary somewhat.

02:36.800 --> 02:40.160
So you can also see that these sentences are different lengths.

02:40.320 --> 02:43.880
And so they are going to have a different number of tokens.

02:44.280 --> 02:50.280
And that will be a good reminder for how to tokenize into batches with padding.

02:51.320 --> 02:58.960
After pushing the data through the model, you can see that the activations tensor is 54 by eight by

02:59.000 --> 03:10.210
2304, that corresponds to 54 sentences Eight tokens per sentence, which includes the padding tokens

03:10.210 --> 03:19.850
for sentences with fewer than eight tokens and 2304, corresponds to three times the embedding dimensionality

03:19.850 --> 03:29.050
of GPT two small, which means that this wide matrix includes the Q, the V, and the k vectors all

03:29.050 --> 03:30.090
concatenated.

03:30.730 --> 03:34.210
Here you see a couple of plots of activations.

03:34.370 --> 03:40.770
This left plot here with the green dots shows the Q vectors for two different sentences.

03:41.330 --> 03:49.010
So each dot in this scatter plot corresponds to one of the dimensions in the Q matrix.

03:49.570 --> 03:57.170
Now these are activations to exactly the same token in both cases, but they're coming from different

03:57.170 --> 03:58.130
sentences.

03:58.650 --> 04:04.890
The middle plot here shows the same thing, but for k vectors instead of q vectors.

04:05.410 --> 04:08.150
And this plot on the right is slightly different.

04:08.150 --> 04:17.510
So here each dot corresponds to the token for her in the 54 different sentences, and the axes correspond

04:17.510 --> 04:22.150
to two dimensions of the q matrix, the q neurons.

04:22.270 --> 04:29.990
So of course there are 768 of these dimensions in Q and the same number in k.

04:30.790 --> 04:38.190
So it's a little arbitrary to show q dimension 123 here and dimension seven on the y axis.

04:38.510 --> 04:44.150
I just picked these two dimensions at random to show this relationship.

04:44.550 --> 04:52.150
So therefore I next calculated cosine similarity between all pairs of attention vectors.

04:52.630 --> 05:00.310
And that will allow me to examine the distribution of cosine similarities within each of the three attention

05:00.310 --> 05:04.150
matrices and across all of the pairs.

05:04.710 --> 05:08.010
And that is what you see in these results here.

05:08.450 --> 05:16.810
So these graphs show histograms of cosine similarity within and between attention matrices.

05:17.450 --> 05:22.410
And by the way this is all just for one layer of the GPT model.

05:22.650 --> 05:28.650
You will get to continue exploring different layers in the code challenge in the next video.

05:29.810 --> 05:36.330
Anyway, let me draw your attention just to this graph over here so I can explain what the lines mean.

05:37.010 --> 05:40.410
So let's just focus on this blue line for starters.

05:40.770 --> 05:47.450
That blue line is labeled QQ and the x axis corresponds to cosine similarity.

05:47.650 --> 05:50.770
And the y axis is density or count.

05:51.370 --> 06:01.010
So basically this line shows that the cosine similarity between pairs of qq dimensions tends to be very

06:01.010 --> 06:04.490
strong negative or very strongly positive.

06:04.970 --> 06:10.430
So the magnitudes of the similarities is fairly strong and the signs can differ.

06:11.030 --> 06:13.710
And this one scatter plot over here.

06:13.950 --> 06:17.270
This is a modest positive correlation.

06:17.270 --> 06:20.950
Maybe this is somewhere around 0.3 or something.

06:20.950 --> 06:25.510
So this would be going into the bin at somewhere around here.

06:26.150 --> 06:32.790
I will have more to say about creating and interpreting these plots when I switch to code, but this

06:32.790 --> 06:34.390
is just to give you a heads up.

06:34.830 --> 06:41.070
There's a few other curious observations that we will find here, including what these plots look like

06:41.070 --> 06:45.310
when we use correlation instead of cosine similarity.

06:45.870 --> 06:51.390
So I will explore a little bit to spark your interest and tickle your curiosity nerve.

06:51.670 --> 06:59.550
Although a really deep analysis would require a lot more time than what I'm going to spend in this video.

07:00.110 --> 07:02.910
Anyway, let's switch to Python and have a look.

07:04.030 --> 07:05.790
Here are some libraries here.

07:05.790 --> 07:11.720
I'm importing the GPT two small version and switching it to eval mode.

07:11.720 --> 07:13.560
Importing the tokenizer of course.

07:13.600 --> 07:20.200
And here I'm creating a variable that I will use quite a lot later in the code file called n embed.

07:20.240 --> 07:24.320
This is just shorthand for modelconfig n embed.

07:24.560 --> 07:31.000
As you are well aware, that number is 768 for GPT two small.

07:31.240 --> 07:35.720
And I'm just creating a variable so I don't need to write all of this out.

07:35.760 --> 07:43.880
And so I don't need to hard code it to 768 so that we can modify this code for larger versions of this

07:43.880 --> 07:44.560
model.

07:45.120 --> 07:45.640
Okay.

07:45.680 --> 07:46.560
Here is the hook.

07:46.600 --> 07:49.840
This is copied from the previous section.

07:49.840 --> 07:51.440
So you've seen this code before.

07:51.480 --> 07:55.720
Basically it's the attention sublayer of the transformer block.

07:55.880 --> 07:59.680
And then I'm looking at C attention and grabbing the output.

07:59.800 --> 08:09.680
So this is the q v and k vectors before the attention equation gets applied.

08:10.300 --> 08:18.540
So I take the output of this linear transformation, detach it from all of the gradients and other computational

08:18.540 --> 08:25.180
graph information, and then I transform it from a PyTorch tensor into a numpy array.

08:25.420 --> 08:31.100
That is not strictly necessary, but it's going to make the subsequent analyses a little bit easier

08:31.100 --> 08:34.540
because I prefer working with numpy than with PyTorch.

08:34.860 --> 08:36.540
A bit of a personal preference there.

08:37.620 --> 08:39.780
Okay, here are all the sentences.

08:40.220 --> 08:46.460
I came up with a couple of sentences, and then I gave them to Claude and said, give me 50 more of

08:46.460 --> 08:47.180
this type.

08:47.460 --> 08:53.020
So they all have her the word her somewhere in the short sentences.

08:53.460 --> 08:55.700
So pretty interesting experimental approach.

08:55.700 --> 09:04.700
We have exactly identical tokens, but the context will differ from one sentence or one sequence to

09:04.740 --> 09:05.420
the next.

09:05.980 --> 09:12.560
Okay, now for this case, because these sentences will have different numbers of Of tokens, and we

09:12.560 --> 09:18.120
want to create one batch for all of the token, all of the sentences.

09:18.320 --> 09:21.880
Then we need to specify padding equals true.

09:22.320 --> 09:25.200
And that gives us this as an output.

09:25.200 --> 09:28.080
So you can see these are all the tokens.

09:28.360 --> 09:36.880
And here at the end we have some padding tokens for all of the sentences that don't get up to eight

09:36.920 --> 09:38.240
tokens in total.

09:38.680 --> 09:47.480
And you can also see that the tokens 607 appears in various places in every one of these sequences.

09:47.920 --> 09:50.200
This is the token for her.

09:50.480 --> 09:56.440
It's technically space her because all of these sentences have space her in there.

09:56.960 --> 10:04.080
And yeah, so that makes an interesting challenge for the analysis because it means that we cannot simply

10:04.080 --> 10:08.960
grab, for example, like the fifth, uh, activation value in every sentence.

10:08.960 --> 10:15.220
We're actually going to need to loop through every sentence in the activation every row in the batch

10:15.460 --> 10:23.300
and find where we have the token corresponding to space here to get that specific activation.

10:23.700 --> 10:25.380
And here you see the attention mask.

10:25.380 --> 10:31.420
So it's all ones where there are valid tokens and zeros where we have pad tokens.

10:31.980 --> 10:32.300
Okay.

10:32.340 --> 10:38.620
And then here I am running all of those tokens all that that batch through the model.

10:38.660 --> 10:40.380
This takes not so long.

10:40.860 --> 10:42.700
And here I get an error message.

10:42.700 --> 10:46.940
I suspect that I forgot to run this code here.

10:46.980 --> 10:47.260
Okay.

10:47.300 --> 10:49.940
So I didn't actually run that code cell.

10:50.380 --> 10:52.740
So let's go back and do this again.

10:52.940 --> 10:54.660
And we have the tokens.

10:54.660 --> 10:57.860
And now we can actually do this okay.

10:57.900 --> 11:02.460
And then yeah here I'm just printing out all of the keys and the shape.

11:02.460 --> 11:07.740
So we see that there are 12 of the keys in this dictionary.

11:07.940 --> 11:09.660
And of course that makes sense.

11:09.660 --> 11:14.080
We start off with zero with the first transformer and GPT two.

11:14.160 --> 11:16.520
Small has 12 transformers.

11:16.800 --> 11:30.000
This size also makes sense 54 sentences, eight tokens including all of the Pad tokens, and 2304 activations,

11:30.360 --> 11:35.200
or neurons, which corresponds to three times 768.

11:35.760 --> 11:39.600
Okay, so for the rest of this script, we will just work with layer six.

11:39.880 --> 11:41.000
Why layer six?

11:41.160 --> 11:41.720
I don't know.

11:41.760 --> 11:44.440
You can pick any other layer totally fine.

11:44.440 --> 11:46.280
In the next video.

11:46.280 --> 11:50.560
In the code challenge we will actually loop through all of the layers.

11:51.200 --> 11:51.520
Okay.

11:51.560 --> 12:00.200
As I mentioned, the target token space her appears in a different location in every sentence.

12:00.360 --> 12:08.760
So therefore we need to loop through all of these sentences and find which index in that particular

12:08.760 --> 12:11.120
sentence has the target.

12:11.120 --> 12:12.400
And that's what I do here.

12:12.640 --> 12:19.210
So I'm taking all of the tokens for this sentence and I want to use this method.

12:19.370 --> 12:20.090
Index.

12:20.410 --> 12:20.850
Token.

12:20.850 --> 12:21.170
Target.

12:21.210 --> 12:24.370
Now this index method is really great.

12:24.410 --> 12:27.930
It's very convenient, but it only works on Python lists.

12:27.930 --> 12:32.210
It is not defined for Python PyTorch tensors.

12:32.570 --> 12:37.130
So therefore I have to convert the PyTorch tensor to a list.

12:37.610 --> 12:44.530
This is very similar to what I mentioned at the end of the previous section, where I asked you to use

12:44.530 --> 12:55.370
the method split to split up a wide matrix into the separate q, v and k vectors.

12:55.530 --> 13:02.090
So same concept here where I want to use a particular method, but I need to convert to the data type

13:02.490 --> 13:04.610
just to be able to use that method.

13:04.730 --> 13:12.970
Anyway, the upshot of all that is that this variable here, target id will be the index of the target

13:13.010 --> 13:21.590
token for space in each of the individual sentences, and from that I can grab the activations from

13:21.590 --> 13:26.350
this layer, from this sentence and this target index.

13:26.350 --> 13:31.870
Now this right here is always going to be the activation for the word her.

13:32.350 --> 13:40.030
But to have a reference set of activations, a non-target activations, I'm going to use the token immediately

13:40.030 --> 13:45.950
preceding that word, which is not any consistent word across sentences.

13:46.750 --> 13:53.750
So here it's going to be the word on here it's the here it's informed or whatever is the token before

13:53.750 --> 13:55.750
her married and so on.

13:55.750 --> 14:00.350
So every single non-target token will be random.

14:00.350 --> 14:05.350
And it's going to be different compared to the target token which will always be her.

14:05.670 --> 14:07.270
So that is the idea.

14:07.310 --> 14:13.630
So I'm getting all the activations for the target and for the non-target okay.

14:13.670 --> 14:14.150
There we go.

14:14.150 --> 14:22.770
Runs quite fast and we see that it's again 54 by 20 304 because we have 54 sentences.

14:22.770 --> 14:29.330
So now 54 words and activations across all of the attention matrices.

14:29.730 --> 14:32.330
And then this is the target matrix.

14:32.330 --> 14:37.050
So then we have exactly the same size for the non-target matrix.

14:37.690 --> 14:38.050
Okay.

14:38.090 --> 14:43.610
This code is just generating the figure that I showed in the slides.

14:43.810 --> 14:46.490
Pretty interesting to see that.

14:46.770 --> 14:51.130
Uh, in this case the word is exactly the same.

14:51.130 --> 14:55.450
It's the word her space her that token that doesn't change.

14:55.570 --> 14:59.770
What does change is the context in which that word appears.

14:59.890 --> 15:02.810
So the preceding tokens are different.

15:02.970 --> 15:08.930
And then we see that the, uh, the activations are slightly different.

15:08.970 --> 15:14.770
You know, I didn't actually calculate the correlation coefficient, but I would guess it would be above

15:14.810 --> 15:15.610
0.9.

15:16.290 --> 15:19.910
So yeah, in this plot, and these two plots.

15:19.950 --> 15:23.630
The two axes correspond to two different sentences.

15:23.950 --> 15:32.070
And every dot that you see here corresponds to a different dimension in the Q matrix or the V matrix.

15:32.470 --> 15:39.230
And that is plotting the other way from what I show here in this plot, where here I'm isolating two

15:39.270 --> 15:41.150
specific dimensions.

15:41.390 --> 15:45.390
So I just pick these two at random of the Q matrix.

15:45.390 --> 15:51.710
And now every square in this scatter plot corresponds to a different word.

15:51.710 --> 15:56.030
So a different sentence of the word activation for the word her.

15:56.590 --> 15:56.910
Okay.

15:56.950 --> 16:04.470
So now we are going to shift our focus to this plot and run this correlation or cosine similarity for

16:04.470 --> 16:10.750
all possible pairs within and across all of the attention matrices.

16:11.310 --> 16:21.440
So to calculate the cosine similarities across all pairs of neurons across all three matrices I implement

16:21.440 --> 16:28.720
cosine similarity using code that you've seen in multiple videos earlier in this course.

16:28.920 --> 16:33.600
I'm doing this in two lines of code using matrix multiplication.

16:33.800 --> 16:41.520
So essentially cosine similarity can be calculated as just the dot products of all of the pairs of vectors,

16:41.640 --> 16:48.960
which we can implement as the matrix multiplication of the data matrix transpose by itself.

16:49.280 --> 16:52.960
Now this alone is not cosine similarity.

16:53.200 --> 16:58.080
It becomes cosine similarity when the vectors are normalized.

16:58.200 --> 16:59.600
And so that's what I do here.

16:59.600 --> 17:02.880
So I divide by the matrix norm.

17:03.120 --> 17:05.960
And then that gives me normalized vectors.

17:05.960 --> 17:08.760
And then we get the cosine similarity.

17:08.800 --> 17:12.840
So this is for the target words and for the non-target words.

17:13.040 --> 17:17.560
And here you can see uh what those uh all those vectors look like.

17:17.880 --> 17:21.420
So again this is vectors by vectors.

17:21.420 --> 17:28.740
So the q vectors are in the beginning and then the so the query vectors, then the keys vectors and

17:28.740 --> 17:30.580
then the values vectors here.

17:30.980 --> 17:37.260
And what you see here is the distribution the histogram over all of the pairs.

17:37.260 --> 17:44.860
So every cosine similarity in this matrix you can see that they range from minus one to plus one.

17:44.860 --> 17:51.260
Those are the two absolute extremes of what we can possibly get with cosine similarity.

17:51.700 --> 17:57.620
Of course, the numbers are trivially equal to one for the the diagonal.

17:57.620 --> 17:59.540
So when the vectors equal themselves.

18:00.580 --> 18:05.900
But you do see a lot of really, really strong cosine similarity values.

18:05.940 --> 18:12.500
Now that's not really that surprising when we think about the fact that we are looking at the same token

18:12.660 --> 18:16.380
and dimensions within the same matrix.
