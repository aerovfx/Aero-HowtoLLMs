WEBVTT

00:01.520 --> 00:05.080
Now for the conclusion of this code challenge.

00:05.080 --> 00:12.280
There are two more exercises left, both involving new analyses and additional visualizations.

00:12.600 --> 00:22.000
So the goal here of exercise four is to take the analysis code from exercise three and put it in a for

00:22.000 --> 00:25.280
loop over all of the hidden states layers.

00:25.760 --> 00:31.760
Remember that there are 25 hidden states layers in Gpt2 medium.

00:32.000 --> 00:37.240
So you can create that scatterplot that we saw in the in exercise three.

00:37.400 --> 00:45.160
You can create that 25 times organized into a matrix of plots that is five by five.

00:45.680 --> 00:54.960
So plot both the internal and terminal punctuation marks for covariance on the x axis and mutual information

00:54.960 --> 00:56.600
on the y axis.

00:56.920 --> 00:59.830
So yeah, a five by five grid of subplots.

00:59.830 --> 01:06.990
You can label each of the plots, so title each of these plots according to the layer index.

01:07.270 --> 01:10.430
So the first few are obviously going to look something like this.

01:10.710 --> 01:16.190
And you already know what layer 20 looks like from the previous exercise.

01:16.670 --> 01:23.910
So the question is what does the transition look like in between layers one and layer 20.

01:24.630 --> 01:30.110
Now notice also that layer zero has only two dots in it.

01:30.510 --> 01:31.630
That is not a bug.

01:31.750 --> 01:35.270
It is a sensible and expected result.

01:35.470 --> 01:41.110
But it might not be so immediately obvious why that should be the case.

01:41.590 --> 01:47.950
So your goal here is to make sure you understand why you get this particular result.

01:49.110 --> 01:50.870
So that's for exercise four.

01:51.070 --> 01:53.670
Again one more exercise after this one.

01:53.670 --> 01:56.150
That's just some additional visualizations.

01:56.630 --> 02:00.940
But for now As usual, pause the video and get to work.

02:00.980 --> 02:02.700
And now I will switch to code.

02:03.620 --> 02:05.740
So here for this.

02:05.740 --> 02:06.500
Big for loop.

02:06.500 --> 02:07.980
Here triple for loop.

02:07.980 --> 02:13.460
Normally you would like to avoid triple for loops but it just happens sometimes.

02:13.780 --> 02:16.380
Anyway, this is all code you've seen before.

02:16.540 --> 02:19.100
Copy pasted from exercise three.

02:19.380 --> 02:25.460
And I'm just embedding it inside this loop over all of the layers.

02:25.620 --> 02:27.620
And then here I'm initializing this.

02:27.620 --> 02:31.620
So mutual information internal all for all the layers.

02:31.660 --> 02:37.100
Mutual information terminal and then covariance internal and covariance terminal.

02:37.660 --> 02:41.900
And then I have just a little bit of text here to print out the progress.

02:42.020 --> 02:44.900
And this will take I don't know ten minutes or something.

02:45.820 --> 02:49.460
So that actually took 15 minutes to calculate.

02:49.620 --> 02:58.530
And that was with using the manual implementation of the mutual information, which we know from a couple

02:58.570 --> 03:04.610
videos ago, is much faster than the scikit learn implementation.

03:04.730 --> 03:10.930
In fact, I don't think you could even do this analysis with the scikit learn implementation unless

03:10.930 --> 03:15.090
you did some fancy stuff and had access to a better processor.

03:15.530 --> 03:23.970
By the way, I did also try running this analysis completely on the GPU instead of on the CPU, and

03:23.970 --> 03:25.890
it actually didn't really save much time.

03:25.890 --> 03:32.370
There's just so much back and forth between the GPU and the CPU that yeah, it didn't really save all

03:32.410 --> 03:34.330
that much time anyway.

03:34.370 --> 03:36.570
So we got through all of the layers.

03:36.570 --> 03:39.570
So let's now make this big scatter plot.

03:39.610 --> 03:43.250
So here I'm looping through all 25 plots.

03:43.690 --> 03:48.250
I'm not actually plotting every single data point just because it's a lot.

03:48.290 --> 03:55.680
I'm skipping every seventh and it's just to make the plotting code look go a little bit faster without

03:55.680 --> 03:57.800
really losing much information.

03:58.200 --> 03:58.560
Okay.

03:58.600 --> 03:58.880
Yeah.

03:58.880 --> 04:04.200
So I have a five by five array of axes here.

04:04.200 --> 04:05.360
I'm flattening them.

04:05.360 --> 04:08.680
That's just to make the loop work a little bit easier.

04:08.680 --> 04:11.440
And then I'm plotting all of the dots.

04:11.760 --> 04:12.160
Okay.

04:12.200 --> 04:14.080
So a couple of things we see.

04:14.120 --> 04:18.840
First is that this really strong clustering does seem to shift.

04:18.840 --> 04:23.960
So we get clustering both for the internal and the terminal punctuations.

04:23.960 --> 04:31.600
And basically all of those clusters start to merge by around layer I don't know 789 something.

04:31.920 --> 04:36.880
So somewhere around one third of the way through the transformer.

04:37.160 --> 04:39.920
And then yeah there's really less and less clustering.

04:40.040 --> 04:42.600
Something different happens at the very end.

04:42.760 --> 04:49.720
The very last layer right before we get to the layernorm and the embeddings matrix all the way at the

04:49.720 --> 04:55.940
end that you see very often, you'll continue seeing throughout the rest of this course and your analyses

04:55.940 --> 05:02.180
that the very end, the very last last transformer block tends to look a little bit different, qualitatively

05:02.180 --> 05:05.420
different from the earlier transformer blocks.

05:06.500 --> 05:14.660
Now, why do we see only two dots here and not a, you know, sort of cloud of dots as we see for all

05:14.700 --> 05:16.380
the other layers?

05:16.820 --> 05:22.940
So the answer to this conundrum is that layer zero here is the embedding.

05:22.940 --> 05:27.220
So this is the token embeddings plus the position embeddings.

05:27.380 --> 05:34.900
Now the token embeddings are exactly identical in every sequence in these batches.

05:35.140 --> 05:42.500
And the reason is that at the level of embeddings token embeddings, the model hasn't yet started processing.

05:42.500 --> 05:47.620
So every token is treated as a unique token.

05:47.620 --> 05:54.210
And if you have two commas and those are treated as exactly the same, There's no context that is,

05:54.570 --> 05:57.090
uh, integrated across the different tokens.

05:57.090 --> 06:02.210
That only starts happening when you get into the first transformer block.

06:02.410 --> 06:06.450
And furthermore, the positions are exactly the same.

06:06.450 --> 06:13.650
So the way that we created these batches, the punctuation marks are always at position 21.

06:13.650 --> 06:15.450
So the punctuations are the same.

06:15.610 --> 06:19.610
The positions are the same in every sequence in these two batches.

06:19.770 --> 06:23.210
So therefore you only get two actual data points here.

06:23.330 --> 06:31.770
In fact there are you know underlying this looks like one dot, but it really is 250 divided by seven

06:31.770 --> 06:33.290
because I'm only plotting every seventh.

06:33.290 --> 06:37.970
But there's like many dozens of dots here that are all perfectly overlapping.

06:38.290 --> 06:44.370
By the way, when I create my slides, I normally take screenshots, but this figure was just too big

06:44.370 --> 06:50.250
to fit into one screenshot, so therefore I exported it as a PNG.

06:50.360 --> 06:56.920
So if you're curious how to export these figures and PNG format, then this is how you do it.

06:56.920 --> 07:01.440
Just make sure that this line is above the plt.show.

07:01.760 --> 07:07.160
Otherwise matplotlib will create a brand new empty plot and save that.

07:07.160 --> 07:10.520
So you want this before plt.show.

07:11.000 --> 07:16.480
Okay, now that you know, I haven't yet answered the question of what these clusters mean, why they

07:16.480 --> 07:18.800
are there, and why they merge together.

07:19.200 --> 07:27.240
To understand why that is, you would need to do some deeper investigations into these different clusters.

07:27.440 --> 07:35.720
So, for example, what you could do is perform a clustering analysis using DBscan or K-means.

07:35.760 --> 07:38.120
Actually, K-means would work quite well here.

07:38.840 --> 07:44.960
And then identify the sentences, the sequences that contain each of these.

07:45.000 --> 07:47.200
For example, I'm just looking at the red ones here.

07:47.320 --> 07:54.310
Each of these three clusters and then put those together, separate those, print them out and see if

07:54.310 --> 08:01.670
you can determine what is similar between these text snippets that is dissimilar from these, and what

08:01.670 --> 08:04.950
is similar for these that is dissimilar to these and so on.

08:04.950 --> 08:11.870
So it would take quite a bit more investigative work to determine what these what's really driving this

08:11.870 --> 08:12.550
clustering.

08:12.910 --> 08:20.710
If you do that you could actually follow you could track these clusters throughout the rest of the layers.

08:20.710 --> 08:27.470
So for example, you could give them different colors corresponding to each of these clusters and then

08:27.470 --> 08:32.910
continue coloring all of these dots here, uh, according to the three different clusters.

08:32.910 --> 08:35.310
And maybe you find that they all mix together.

08:35.430 --> 08:41.950
Maybe they still are separated, just not clearly clustered, like as if they are forming three different

08:41.950 --> 08:44.670
layers in these plots over here.

08:44.790 --> 08:46.790
I don't actually know what the answer is.

08:46.790 --> 08:48.860
I haven't tried that analysis.

08:49.100 --> 08:53.900
If you would like to do it and report to the Q&amp;A, then that would be fantastic.

08:53.900 --> 08:57.060
I'd be curious to know what that analysis looks like.

08:57.780 --> 09:00.620
And finally, exercise five.

09:01.100 --> 09:09.340
The goal of this exercise is to visualize all the data that you have already calculated, but in a slightly

09:09.340 --> 09:10.380
different way.

09:10.940 --> 09:17.020
Here I want you to create histograms for covariance and mutual information.

09:17.340 --> 09:21.740
I'm showing one plot here so you can see what it will look like.

09:22.180 --> 09:24.780
So this is for mutual information.

09:24.980 --> 09:31.140
Each line is a distribution that comes from a histogram for the different layers.

09:31.140 --> 09:34.500
And the color of course indicates the layer.

09:34.820 --> 09:40.580
Now in this case I'm only showing data for the internal punctuation marks.

09:40.580 --> 09:45.340
So the terminal punctuation marks are actually not shown in this figure at all.

09:45.730 --> 09:49.050
You can also recreate this figure for the terminal marks.

09:49.050 --> 09:49.690
That's great.

09:49.690 --> 09:54.050
I'm just using one punctuation type here for simplicity.

09:54.650 --> 10:01.930
Anyway, this top left plot is the same as the bottom one, but this shows covariance.

10:02.130 --> 10:04.450
This shows mutual information.

10:04.970 --> 10:13.930
Now these are the distributions over all of the mutual information or covariance values from within

10:13.930 --> 10:14.770
the layer.

10:15.130 --> 10:22.570
And here on the right column I've plotted the average of those metrics for each of the layers.

10:22.890 --> 10:27.010
So these are scatter plots hidden behind the red curtain here.

10:27.210 --> 10:33.450
So the one for mutual information, for example, you can already tell that the scatter plot here is

10:33.450 --> 10:35.010
going to go down.

10:35.650 --> 10:41.730
Average mutual information as a function of the layer because you already see that here.

10:41.730 --> 10:46.560
So these lines go these distributions go purple down to yellow.

10:46.800 --> 10:50.040
So as we increase the layer number.

10:50.040 --> 10:56.440
So as we go deeper into the model the average mutual information is getting lower.

10:56.480 --> 10:57.640
It's getting smaller.

10:58.360 --> 11:03.400
So we can already expect that this scatter plot will start somewhere higher.

11:03.560 --> 11:08.960
And then go down as we increase in depth into the model.

11:09.600 --> 11:15.760
And then the question is whether the covariance and mutual information look basically the same as each

11:15.760 --> 11:16.240
other.

11:16.960 --> 11:18.880
So that's it for this exercise.

11:18.880 --> 11:22.280
And that will actually finish off this code challenge.

11:23.200 --> 11:27.200
Here is the loop over all of the different layers.

11:27.440 --> 11:29.720
Here I'm getting the histogram.

11:29.720 --> 11:36.440
So the distribution of covariance here I'm getting the histogram for mutual information.

11:36.440 --> 11:40.200
And again I'm only using the internal punctuation marks here.

11:40.200 --> 11:44.350
That's really just to make the plot a little bit easier to look at.

11:44.710 --> 11:50.870
Okay, so then I get the histogram and I'm immediately plotting the histogram and also plotting the

11:50.870 --> 11:57.070
average over all of the non-zero values in the matrix.

11:57.230 --> 11:58.950
So we have the whole distribution.

11:58.950 --> 12:05.150
And then we have the mean of the distribution for covariance and for mutual information.

12:05.150 --> 12:10.230
And then the rest of this stuff is just making the plot look a little bit nicer.

12:10.670 --> 12:10.990
Okay.

12:11.030 --> 12:12.110
So what do we see here.

12:12.190 --> 12:19.350
Well, this plot I already showed and basically what we see is that mutual information goes down so

12:19.350 --> 12:24.870
we can see it going to the left as we go deeper into the model.

12:24.910 --> 12:33.510
Now, this is not the information that we can really gather from the figure for exercise four, because

12:33.990 --> 12:38.670
I removed all of the axis ticks and labels here.

12:38.670 --> 12:42.220
So you don't actually see the numerical values in here.

12:42.220 --> 12:47.460
You see the relationships, you see the lack of clustering in later layers and the clustering in the

12:47.460 --> 12:48.540
earlier layers.

12:48.540 --> 12:50.540
But this is all qualitative.

12:50.700 --> 12:57.060
So that's why now we can actually look at these distributions with these labeled axes.

12:58.020 --> 13:04.580
And here we see that as we go deeper into the model the mutual information goes gets lower.

13:04.860 --> 13:08.140
Now this one data point at hidden layer zero.

13:08.540 --> 13:10.420
This comes from the embedding.

13:10.420 --> 13:13.500
So we we should know not to trust this one.

13:13.500 --> 13:16.260
There's only really two unique values here.

13:16.260 --> 13:22.660
So we can just ignore this value here and really just focus on this pattern over here.

13:23.220 --> 13:25.940
So mutual information goes down.

13:26.420 --> 13:30.180
Uh on the other hand the covariances go up.

13:30.380 --> 13:32.860
And you see that here in this plot here.

13:32.860 --> 13:35.420
So, uh, the yellow lines.

13:35.460 --> 13:39.460
So in general, the lines are getting yellower as we go to the right.

13:39.560 --> 13:42.320
That's the opposite of mutual information.

13:42.520 --> 13:50.320
And here it's super clear the covariances are shooting up to the moon for, uh, as we go deeper into

13:50.320 --> 13:56.720
the model again, something different always happens at the very, very end of the model when we're

13:56.720 --> 14:00.280
right at the final unembedding matrix.

14:01.400 --> 14:04.120
Now the question is why does this happen?

14:04.120 --> 14:10.920
Why do we see increases in covariances but decreases in mutual information?

14:11.360 --> 14:18.400
Now, to gain some insight into this seeming discrepancy, we have to remember a couple of things.

14:18.520 --> 14:25.800
One is that we have to remember that covariance incorporates the scale of the data.

14:26.080 --> 14:30.200
So the data scale remain in the covariance.

14:30.240 --> 14:36.960
Now in this case, all of the the scale of every one of these data points is the same its activations

14:36.960 --> 14:40.990
squared because we have activations, times, activations.

14:40.990 --> 14:48.950
But importantly, we know from earlier exercises from earlier just investigating the model that the

14:48.950 --> 14:53.310
variance tends to increase as we go deeper in the model.

14:53.310 --> 14:59.110
So the covariances are increasing because the variances themselves are increasing.

14:59.550 --> 15:07.670
If you want a normalized measure of the linear relationships that is scale independent, so has the

15:07.670 --> 15:11.430
scale basically averaged out or normalized out.

15:11.630 --> 15:20.350
What you can do is divide the covariances by the product of the variances of the two separate variables.

15:20.390 --> 15:21.390
And what is that?

15:21.710 --> 15:24.990
That is literally just the Pearson correlation coefficient.

15:25.190 --> 15:28.070
So if you like this is not part of this code challenge.

15:28.070 --> 15:34.270
But if you are curious if you want to do a little bit more work here, you can try normalizing this

15:34.270 --> 15:39.660
covariance to see if you get a to transform this into a correlation.

15:39.660 --> 15:43.980
So you're plotting here the correlations instead of the covariances.

15:44.140 --> 15:52.060
And then you can see if those correlation values also decrease in a way that's more similar to the mutual

15:52.060 --> 15:56.380
information decreases with increasing depth into the model.

15:57.700 --> 16:00.540
I hope you found this code challenge intriguing.

16:01.060 --> 16:08.300
As I've mentioned many times before, a precise interpretation of these curious findings would require

16:08.380 --> 16:12.380
a lot more time and work than what we have just done here.

16:12.860 --> 16:20.300
That is often the case with scientific research, especially of complex systems, and I hope that this

16:20.300 --> 16:27.540
video, and really the rest of the course inspires you to continue investigating complex systems like

16:27.580 --> 16:28.340
LMS.

16:29.140 --> 16:35.050
One final point I want to stress here is something that I mentioned several videos ago and just, you

16:35.050 --> 16:43.050
know, said also in the code a moment ago, which is that mutual information has units of bits or nats,

16:43.250 --> 16:47.850
and that is a unit that is independent of the scale of the data.

16:48.370 --> 16:56.450
And covariance, on the other hand, has units of activations squared, which means that if the activations

16:56.450 --> 16:59.050
themselves are becoming more variable.

16:59.250 --> 17:06.570
So if the standard deviation of the data is increasing, then the numerical values of covariance will

17:06.570 --> 17:08.010
also increase.

17:08.490 --> 17:09.810
Now that's not a problem.

17:09.850 --> 17:11.530
It's not even a limitation.

17:11.810 --> 17:17.130
In fact, that is an important aspect of many applications of covariance.

17:17.370 --> 17:24.810
But it is something you need to keep in mind when you are comparing a statistical quantity that preserves

17:24.810 --> 17:32.370
the units of the data relative to a statistical quantity that does not preserve the units of the data.
