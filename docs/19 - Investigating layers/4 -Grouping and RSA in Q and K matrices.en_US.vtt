WEBVTT

00:01.800 --> 00:09.440
This video will be a nice combination of topics you learned a couple of sections ago, along with some

00:09.440 --> 00:12.040
new material from this section.

00:12.680 --> 00:22.080
I will give you a reminder of RSA representational similarity analysis, and also calculating a selectivity

00:22.120 --> 00:30.280
index that tells us about how much the coordinated activations across different neurons in the attention

00:30.280 --> 00:38.680
sublayer is similar with in a semantic category versus across different semantic categories.

00:39.280 --> 00:46.080
I will also introduce a slightly different experimental approach compared to what we've done before,

00:46.480 --> 00:50.880
in terms of matching different token sequences for activations.

00:51.400 --> 00:59.720
For example, in the previous couple of videos, we looked at activation for identical tokens that had

00:59.950 --> 01:02.110
different preceding contexts.

01:02.630 --> 01:05.750
Now here in this video we're going to flip that around.

01:05.790 --> 01:13.870
We will have identical context in terms of the recent history of tokens and different target tokens

01:13.870 --> 01:15.590
for the analyses.

01:16.070 --> 01:23.030
Here is a reminder of an overview of the representational similarity analysis.

01:23.510 --> 01:30.950
This is a slide that I showed several sections ago about comparing token embeddings from different tokenizers.

01:31.510 --> 01:38.190
Now in that example, the idea was that the embeddings dimensionalities might differ, for example,

01:38.190 --> 01:40.430
between GPT and Bert.

01:40.430 --> 01:47.790
So we cannot directly compare the vectors, but we can calculate cosine similarity or any other measure

01:47.790 --> 01:55.030
of similarity within each tokenizer, and then see if the ways that the different embeddings vectors

01:55.030 --> 01:59.900
relate to each other is similar across the different tokenizers.

02:00.340 --> 02:06.980
Now here in this video and also in the code challenge in the next video, the embeddings dimensionality

02:06.980 --> 02:09.180
will actually be exactly the same.

02:09.180 --> 02:16.100
But we're going to get the data matrices from different attention matrices for example Q versus k.

02:16.380 --> 02:17.980
So queries versus keys.

02:18.780 --> 02:25.340
Now the thing is that the embeddings dimensionalities are the same, but the vectors themselves don't

02:25.340 --> 02:27.300
really line up with each other.

02:27.900 --> 02:36.900
So that is to say vector 37 in the queries matrix does not correspond to vector 37 in the keys matrix.

02:37.620 --> 02:38.980
Now we could do other things.

02:38.980 --> 02:46.180
We can organize these by attention head, which we will get to later on in the course in the next section.

02:46.340 --> 02:52.660
But anyway, what we're going to do here in this video is calculate cosine similarity for lots of different

02:52.700 --> 02:55.860
tokens within the queries vectors.

02:55.980 --> 03:03.660
And then again within the keys vectors, and then see if the ways that the token embeddings are processed

03:03.700 --> 03:11.860
relative to each other is comparable between the the queries and the keys vectors, and that will be

03:11.860 --> 03:14.300
the basis for the RSA here.

03:14.820 --> 03:21.700
Now the tokens that we're going to be using here will come from three different semantic categories.

03:21.860 --> 03:26.220
And so that will also allow us to look for category selectivity.

03:26.780 --> 03:35.700
Now here in this video I'm only going to use the Q and the k matrices and only from one layer in a model.

03:36.260 --> 03:43.500
But the analyses and the code that I will show you in this video, you will get to extend and expand

03:43.500 --> 03:46.020
in the code challenge in the next video.

03:47.220 --> 03:50.380
So here's what I'm going to do in the Python demo.

03:51.100 --> 03:58.930
I'll work with GPT two medium and hook all of the Q and K activations.

03:59.290 --> 04:05.530
I have a bunch of target words that are organized into three categories, and you can already see the

04:05.530 --> 04:12.490
semantic categories are something about outer space, something about furniture and interior architecture,

04:12.650 --> 04:14.810
and different kinds of fruit.

04:15.370 --> 04:21.890
All of these words are single token words, and I will put them at the end of a short sentence, which

04:21.890 --> 04:25.650
I will then feed into the GPT language model.

04:26.170 --> 04:33.810
After extracting the activations from one layer, I will calculate the cosine similarities for each

04:33.810 --> 04:40.290
of the tokens across all of the Q vectors and across all of the k vectors.

04:40.730 --> 04:46.610
You can see that the cosine similarity is overall quite strong from the color bars here.

04:46.970 --> 04:55.400
And in this histogram of all the values, I didn't even plot any values below like 0.55 five or whatever.

04:55.960 --> 05:01.800
So the case similarities are considerably stronger than the similarities.

05:01.960 --> 05:08.680
Now, that might seem strange at first, but when you see that all of the tokens preceding the target

05:08.720 --> 05:15.880
tokens are identical for every target token and every sequence, then this actually does make sense,

05:15.880 --> 05:23.640
because the k vectors are representing the context to match with the q vectors, and the q is what's

05:23.640 --> 05:25.480
unique to each sentence.

05:26.240 --> 05:30.080
So it's also interesting to look at the similarity matrices.

05:30.080 --> 05:35.920
You can kind of see that there's three clusters forming for the three different semantic categories,

05:36.280 --> 05:40.920
although it's actually not so super obvious that there are three groups.

05:41.120 --> 05:45.320
And so the selectivity index is actually just a little bit above one.

05:45.560 --> 05:51.440
And it's a little bit higher for the Q matrix than for the k matrix, which you can kind of visually

05:52.000 --> 05:53.950
intuit from this plot.

05:54.830 --> 06:01.710
Now, to be honest, I was expecting the Q selectivity to be a little bit stronger, but the weak K

06:01.750 --> 06:08.510
selectivity is not so surprising to me, considering that all the tokens before the target word are

06:08.550 --> 06:09.510
identical.

06:10.630 --> 06:17.630
Anyway, the RSA in this case is really strong, so this indicates that the way the tokens are processed

06:17.630 --> 06:23.950
relative to each other is really, really similar in the Q and k matrices.

06:24.590 --> 06:30.670
Now this result here is the result of pooling over all three semantic categories.

06:30.870 --> 06:35.670
And I'll show you that the results are equally strong within each category.

06:35.990 --> 06:38.790
Although the sample sizes are smaller of course.

06:39.390 --> 06:46.670
Now all of these analyses in this video are just done in one layer, so you might wonder whether the

06:46.670 --> 06:50.430
findings are consistent across lots of different layers.

06:50.430 --> 06:52.420
So different transformer blocks.

06:52.700 --> 06:53.940
That's a great question.

06:53.940 --> 06:58.260
And it's something that you will get to evaluate in the next video.

06:58.540 --> 07:01.420
But for now let's switch to code and have a look.

07:01.940 --> 07:06.220
Import some libraries and the GPT two medium.

07:06.220 --> 07:07.900
So bigger than small.

07:08.500 --> 07:08.940
Uh let's see.

07:08.980 --> 07:11.660
Of course always switching into eval mode here.

07:12.020 --> 07:13.500
Here's where I define the hooks.

07:13.500 --> 07:17.540
So I get the output of attention dot c attention.

07:17.540 --> 07:22.740
So this is the linear transformation of the embeddings vectors.

07:22.740 --> 07:31.460
The token plus position embedding vectors through the wq, w, k and w weights matrices.

07:31.620 --> 07:36.340
But immediately before they go through the attention algorithm.

07:36.460 --> 07:38.060
And that's what I get here.

07:38.060 --> 07:39.180
So output.

07:39.180 --> 07:46.580
And then I'm detaching from the computational graph to ignore all of the gradient information which

07:46.580 --> 07:47.660
we don't want anyway.

07:48.020 --> 07:49.540
And then dot split.

07:49.580 --> 07:56.820
You've seen this method before splitting according to the embedding dimension on the final dimension

07:56.820 --> 07:57.900
of this tensor.

07:58.260 --> 08:07.860
Now that gives me the qq and V matrices, although for this video I'm only storing q and k, so v gets

08:07.860 --> 08:09.420
lost into the ether.

08:09.700 --> 08:14.780
Don't worry though, we will come back to it in the next in the code challenge in the next video.

08:15.180 --> 08:15.420
Okay.

08:15.460 --> 08:18.420
And then also I'm numpy ifying it.

08:18.460 --> 08:23.340
I'm pretty sure that I have decided that that is a valid English word.

08:23.780 --> 08:31.020
So, uh, transforming them from PyTorch to numpy just because later in the code I will find it easier

08:31.020 --> 08:32.140
to work with numpy.

08:32.500 --> 08:36.620
Okay, and now I'm only implanting one hook in layer five.

08:36.660 --> 08:42.340
Of course, you are welcome to explore other layers and in the next code challenge this is going to

08:42.340 --> 08:47.460
be um, a for loop where you'll, you'll get to implant these hooks into all the layers.

08:48.620 --> 08:48.900
Okay.

08:48.940 --> 08:51.930
So here you can see all of the target words.

08:52.090 --> 08:54.770
So I put them in three lines.

08:54.770 --> 08:55.930
It's all one list.

08:55.930 --> 09:02.250
But for visual clarification I have organized them into three rows of code here.

09:02.610 --> 09:02.890
Yeah.

09:02.890 --> 09:08.570
So things about outer space, things about interior design and things about fruits.

09:08.890 --> 09:15.570
And then yeah, this is just confirming that these are all single token words.

09:15.770 --> 09:19.130
Now the thing is there's no spaces before this, right?

09:19.170 --> 09:26.490
So it is possible that a lot of these words are actually represented by more than one token without

09:26.490 --> 09:27.370
a space.

09:27.490 --> 09:32.210
But when you put in a space, then they end up being single token words.

09:32.210 --> 09:33.930
So that's why I have this thing here.

09:33.930 --> 09:37.290
The next word is and then whatever is the target word.

09:37.450 --> 09:44.210
And in that case we get that this is you know, all of these words are represented by single tokens.

09:44.650 --> 09:44.970
Okay.

09:45.010 --> 09:50.480
Here I'm going to create a mask based on the word and the category.

09:50.480 --> 09:52.160
So these first words.

09:52.160 --> 09:57.040
So all of these words up here are in category space.

09:57.040 --> 10:02.280
But here I'm labeling it category one and then category two and category three.

10:02.520 --> 10:06.800
Now the uh sample sizes are not perfectly matched.

10:06.920 --> 10:08.560
You can already see that looking here.

10:08.560 --> 10:13.440
So there are more furniture words than there are, uh, fruit words.

10:13.440 --> 10:16.960
And there are more fruit words than there are outer space words.

10:17.080 --> 10:21.600
That's partly because I was a little bit lazy to find all of these words.

10:21.640 --> 10:28.840
And also partly, yeah, this kind of research, it is ideal to have, uh, equal sample sizes.

10:28.840 --> 10:32.040
And when possible, you should strive for equal sample sizes.

10:32.280 --> 10:37.960
But it's not strictly necessary as long as the sample sizes are roughly comparable.

10:38.120 --> 10:44.840
Uh, it's not a big deal if you would have, for example, uh, let's say like this one word in this

10:44.840 --> 10:53.030
category compared to, you know, 500 words in this other category that is really not statistically

10:53.030 --> 10:53.870
appropriate.

10:53.870 --> 10:58.550
But, you know, if the sample size is off by one or 2 or 3, that's not a big deal.

10:59.070 --> 10:59.390
Okay.

10:59.430 --> 11:01.590
Anyway, this kind of mask you have seen before.

11:01.630 --> 11:10.870
This is what will allow me to isolate and separate the different activations and the cosine similarities

11:10.870 --> 11:13.590
related to the words themselves.

11:13.590 --> 11:18.430
So the within category terms and the cross category terms.

11:19.510 --> 11:24.070
And I have also mentioned this before when I first introduced this.

11:24.070 --> 11:32.110
But just keep in mind that this is kind of a clever trick for identifying within versus cross category

11:32.350 --> 11:37.350
items, but it only works for a relatively small number of groups.

11:37.550 --> 11:44.590
This sort of approach does not arbitrarily scale to a much larger number of distinct groups.

11:44.590 --> 11:49.580
For example, Imagine we had 12 different semantic categories.

11:49.820 --> 11:58.260
Then you would be able to get to the number 12, as you know, one times 12 and three times four and

11:58.260 --> 11:59.380
two times six.

11:59.580 --> 12:04.380
So this approach only works for a relatively small number of categories.

12:04.380 --> 12:06.780
But when it does work, then it's great.

12:07.220 --> 12:10.060
Okay, so here I'm creating the batches.

12:10.220 --> 12:12.060
And the sentence.

12:12.060 --> 12:16.140
The sequence that I'm giving to the model is the following.

12:16.180 --> 12:19.220
The next word is and then it's the target word.

12:19.460 --> 12:24.140
So that is kind of boring in terms of what it actually means in language.

12:24.140 --> 12:31.380
But it is interesting from an experimental approach, because it means that literally every single sequence

12:31.540 --> 12:35.420
in this batch has identical context.

12:35.420 --> 12:38.860
So all of the tokens are exactly identical.

12:39.100 --> 12:47.530
So therefore any kind of causal processing in the model should be exactly identical up until the very

12:47.530 --> 12:55.330
last token, where we get all unique words organized into three different semantic categories.

12:55.330 --> 12:58.490
So it's a pretty nice experimental technique.

12:59.010 --> 13:03.090
Okay, here is where I'm pushing all of the data through the model.

13:03.090 --> 13:07.530
So this one batch through the model you can see I'm not using the GPU here.

13:07.530 --> 13:08.690
You could if you want to.

13:08.930 --> 13:10.170
I think it's not necessary.

13:10.170 --> 13:12.890
That took three seconds on the CPU.

13:13.450 --> 13:16.930
There are a lot of batches but are a lot of sequences.

13:16.930 --> 13:22.370
Excuse me, but each sequence is so short that it really just doesn't take the model a whole lot of

13:22.370 --> 13:23.650
time to run through this.

13:24.850 --> 13:33.210
So here I can just confirm that I get two keys in this dictionary for attention layer five and then

13:33.250 --> 13:35.490
matrix Q and matrix k.

13:35.810 --> 13:37.530
And then this is the size.

13:37.570 --> 13:47.090
There are 34 sequences corresponding to 34 target words, five tokens in each sequence, and the thousand

13:47.130 --> 13:52.130
24 is the embeddings dimensionality of GPT two medium.

13:52.490 --> 13:57.290
Now that we have all of the data, we can proceed with the analysis.

13:57.570 --> 14:01.850
So here I will calculate all of the cosine similarities.

14:01.850 --> 14:07.450
I'm extracting all of the activations from q here and k here.

14:07.730 --> 14:11.370
And you can see this is all of the sequences in the batch.

14:11.370 --> 14:16.850
So all batches the final token and all of the dimensions.

14:16.850 --> 14:20.530
So all of the neurons in Q and in k.

14:21.050 --> 14:28.130
Once I have those I can proceed with calculating the cosine similarity, as you've seen many times before.

14:28.370 --> 14:36.050
And also as I've stressed before, if you prefer to calculate this using scikit learn or PyTorch, that's

14:36.050 --> 14:36.570
great.

14:36.610 --> 14:44.560
You do not need to do everything manually, but it is a good idea to check the results and the sizes

14:44.560 --> 14:48.840
of the results because, for example, I could do it like this.

14:49.560 --> 14:55.320
And now this is also a perfectly valid cosine similarity matrix.

14:55.320 --> 15:00.560
But this is now calculating the cosine similarity along the other dimensions.

15:00.560 --> 15:08.360
So now we're going to get cosine similarity across the different q vectors and not across the different

15:08.520 --> 15:09.320
tokens.

15:09.600 --> 15:10.560
Both are fine.

15:10.560 --> 15:13.000
And you know we use both in this course.

15:13.360 --> 15:13.680
Okay.

15:13.720 --> 15:15.720
So then run all of that.

15:15.760 --> 15:20.200
And then we create these histograms which you saw in the slides.

15:21.200 --> 15:26.880
Now when you look at this you know a priori that there are three semantic categories.

15:27.080 --> 15:33.360
So what you want to look for here is whether you see three blocks in this matrix.

15:34.280 --> 15:35.920
So you do see the blocks.

15:35.920 --> 15:40.920
It looks like, you know, there's a couple of items that are even more strongly correlated with each

15:41.070 --> 15:47.790
other or have stronger cosine similarity compared to the other ones, and you also get a lot of interesting

15:47.910 --> 15:49.430
cross terms.

15:49.830 --> 15:54.670
For example, here, this is the word orange, and this is actually the word sun.

15:54.670 --> 16:00.510
It's labeled up here, but sun and orange have a strong cosine similarity.

16:00.510 --> 16:02.190
That's this data point over here.

16:02.510 --> 16:09.310
Not surprising, but it is kind of interesting because the word orange can indicate the fruit and also

16:09.350 --> 16:10.110
the color.

16:11.310 --> 16:11.670
Okay.

16:11.710 --> 16:18.030
So then I take all of the unique elements in this cosine similarity matrix.

16:18.030 --> 16:19.230
That's what I do here.

16:19.430 --> 16:23.030
So all of the unique elements are above the diagonal.

16:23.230 --> 16:26.550
And then I make histograms of those for q and k.

16:26.910 --> 16:30.070
And that is what you see plotted over here.

16:30.670 --> 16:38.990
As I mentioned in the slides the k cosine similarities are generally much higher than q, although q

16:38.990 --> 16:40.740
is also quite strong.

16:40.940 --> 16:46.940
And you see that in these numerical values over here in the, uh, the color bars.

16:47.380 --> 16:55.100
And again, that makes sense because k is all about the context, which is exactly the same in every

16:55.100 --> 16:56.140
single sentence.

16:56.700 --> 16:57.060
Okay.

16:57.100 --> 17:01.780
So now what I'm going to do is calculate the selectivity index.

17:01.780 --> 17:07.060
And the selectivity index as a reminder is the average of these.

17:07.060 --> 17:14.340
So within category cosine similarities plus the average of these plus the average of these.

17:14.500 --> 17:16.460
And then the average of those three.

17:16.860 --> 17:18.100
And that's the numerator.

17:18.140 --> 17:24.900
And the denominator is the average of all of the cross category cosine similarities which is all of

17:24.900 --> 17:26.740
these guys out here.

17:27.380 --> 17:27.580
Yeah.

17:27.580 --> 17:33.340
It's not really so obvious that it's going to be higher for Q compared to K.

17:33.580 --> 17:37.900
I was expecting it to be a little bit more visually differentiated.

17:37.900 --> 17:45.810
So a little bit less of the cross terms here, but perhaps that's because the sentences are quite short

17:45.970 --> 17:48.210
and they don't really have a lot of meaning.

17:48.250 --> 17:48.450
Right?

17:48.490 --> 17:53.890
These are not like deeply meaningful sentences that I'm giving to GPT to process.

17:54.330 --> 18:01.570
Anyway, uh, that ends up being just a hair above one for Q and also for K.

18:01.970 --> 18:05.410
Now is this significantly greater than one?

18:05.690 --> 18:07.930
That is something we cannot say here.

18:08.330 --> 18:14.690
Uh, you would have to do a full analysis with some, uh, shuffling to generate a null hypothesis distribution

18:14.690 --> 18:18.490
to see if this is statistically significantly greater than one.

18:18.690 --> 18:20.370
Uh, I'm not going to go into that here.

18:20.890 --> 18:27.130
Anyway, uh, what I am going to go into is the representational similarity analysis.

18:27.410 --> 18:33.090
Also, as you remember from earlier in the course, once you've done all the hard work to get to the

18:33.090 --> 18:37.930
RSA, the RSA itself is fairly straightforward.

18:37.930 --> 18:45.410
All you have to do is get the upper triangle so all of these unique elements and correlate them with

18:45.410 --> 18:47.170
these unique elements.

18:48.210 --> 18:49.770
And that's what I do here.

18:49.770 --> 18:52.530
So here I extract the unique elements.

18:52.530 --> 18:55.610
And here I correlate them and then plot them.

18:55.730 --> 19:01.690
And you see that those are not identical but really really really similar.

19:01.690 --> 19:03.330
And so what does this tell us.

19:03.330 --> 19:11.090
This tells us that although the q and the k so the query and the keys matrices are doing different things,

19:11.370 --> 19:12.810
they have different weights.

19:13.290 --> 19:19.010
They're calculating different results about the token embeddings vectors.

19:19.170 --> 19:26.490
But the way that they represent the relationships between the different words is really similar.

19:26.850 --> 19:27.130
Okay.

19:27.170 --> 19:30.490
And then this is collapsing across all of the words.

19:30.490 --> 19:34.450
What I do here is separate for the different categories.

19:34.450 --> 19:39.840
So I'm looping over the categories, and now I'm just getting the, uh, only those categories from

19:39.840 --> 19:40.920
the group mask.

19:41.240 --> 19:43.920
And then you see that it's still basically the same.

19:43.920 --> 19:46.960
The sample size is smaller, but that's fine.

19:47.000 --> 19:48.800
The relationships are really clear.

19:48.800 --> 19:51.520
The RSA correlations are super duper strong.

19:52.600 --> 19:58.000
A lot of the analyses that I'm teaching you in this course are quite versatile.

19:58.200 --> 20:04.200
They can be used in lots of different ways with different applications, and there are also lots of

20:04.200 --> 20:12.120
ways to adapt and tweak the analyses for particular hypotheses, experiment designs and investigations.

20:12.920 --> 20:18.280
And I have to say, that's one thing I really like about teaching analysis methods in statistics and

20:18.280 --> 20:25.080
data science and machine learning, because theories and interpretations change over time.

20:25.440 --> 20:32.720
But once a good method is introduced to the literature, it continues to be useful for a long time in

20:32.720 --> 20:34.480
many different use cases.
