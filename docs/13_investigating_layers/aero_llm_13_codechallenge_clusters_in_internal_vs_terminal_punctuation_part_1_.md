
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../index.md) > [13 investigating layers](index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../index.md)
- [ğŸ“š Module 01: LLM Course](../01_llm_course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../02_words_to_tokens_to_numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../04_buildgpt/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../07_fine_tune_pretrained_models/index.md)
- [ğŸ” Module 19: AI Safety](../19_ai_safety/index.md)
- [ğŸ Module 20: Python for AI](../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# PhÃ¢n Kháº£o Cáº¥u TrÃºc Cá»¥m (Clusters): Dáº¥u CÃ¢u Ná»™i Bá»™ vs Dáº¥u CÃ¢u Káº¿t ThÃºc Táº­p 1

## TÃ³m táº¯t (Abstract)
BÃ¡o cÃ¡o nÃ y táº­p há»£p cÃ¡c phÃ©p Ä‘o sá»± phá»¥ thuá»™c thá»‘ng kÃª (Statistical Dependencies) â€“ bao gá»“m Mutual Information (MI) vÃ  Covariance â€“ Ã¡p dá»¥ng trÃªn biá»ƒu diá»…n nhÃºng (embeddings) cá»§a cÃ¡c dáº¥u cÃ¢u. Báº±ng phÆ°Æ¡ng phÃ¡p chia tÃ¡ch rÃ nh máº¡ch Dáº¥u cÃ¢u ná»™i bá»™ (Internal Punctuation - nhÆ° dáº¥u pháº©y) vÃ  Dáº¥u cÃ¢u káº¿t thÃºc (Terminal Punctuation - nhÆ° dáº¥u cháº¥m), má»“i vÄƒn báº£n tá»« tiá»ƒu thuyáº¿t "Heart of Darkness" cháº¡y qua máº¡ng GPT-2 Medium chá»‰ ra ráº±ng Covariance cá»±c ká»³ nháº¡y bÃ©n trong viá»‡c báº¯t lá»—i cÃ¡c cá»¥m (clusters) dá»¯ liá»‡u ná»™i bá»™ á»Ÿ nhá»¯ng táº§ng Ä‘áº§u, trong khi M.I hÆ°á»›ng Ä‘áº¿n má»™t dáº£i tuyáº¿n tÃ­nh Ä‘á»“ng Ä‘á»u hÆ¡n. NghiÃªn cá»©u cÅ©ng bÃ n luáº­n vá» Nghá»‹ch lÃ½ Simpson trong Ä‘o lÆ°á»ng tÆ°Æ¡ng quan há»—n há»£p.

---

## 1. Má»Ÿ Äáº§u (Introduction)
Dáº¥u cÃ¢u Ä‘Ã³ng vai trÃ² nhÆ° nhá»¯ng "tráº¡m kiá»ƒm soÃ¡t luá»“ng" trong láº­p trÃ¬nh ngÃ´n ngá»¯ tá»± nhiÃªn:
- **Dáº¥u cÃ¢u ná»™i bá»™ (Internal Punctuation):** nhÆ° dáº¥u pháº©y (,), dáº¥u cháº¥m pháº©y (;). ChÃºng ráº½ nhÃ¡nh cá»¥c bá»™ nhÆ°ng giá»¯ nguyÃªn Ä‘áº¡i ngá»¯ cáº£nh cá»§a cÃ¢u.
- **Dáº¥u cÃ¢u káº¿t thÃºc (Terminal Punctuation):** nhÆ° dáº¥u cháº¥m (.), dáº¥u cháº¥m há»i (?), dáº¥u cháº¥m than (!). ChÃºng Ä‘Ã³ng gÃ³i toÃ n bá»™ luá»“ng thÃ´ng tin hiá»‡n táº¡i vÃ  dá»n sáº¡ch bá»™ Ä‘á»‡m (context window) Ä‘á»ƒ chÃ o Ä‘Ã³n má»™t tÆ° tÆ°á»Ÿng má»›i.
NghiÃªn cá»©u nÃ y ká»³ vá»ng tráº£ lá»i cÃ¢u há»i: *Vá»›i hÃ ng chá»¥c ngÃ n chiá»u kÃ­ch hoáº¡t (activations), LLM xá»­ lÃ½ sá»± khÃ¡c biá»‡t cáº¥u trÃºc phÃ¢n tÃ¡ch nÃ y nhÆ° tháº¿ nÃ o náº¿u ta dÃ¹ng hai lÄƒng kÃ­nh toÃ¡n há»c Mutual Information vÃ  Covariance Ä‘á»ƒ ná»™i soi?*

---

## 2. Tiá»n Xá»­ LÃ½ Dá»¯ Liá»‡u (Methodology)

### 2.1. PhÃ¢n Loáº¡i Dáº¥u CÃ¢u (Punctuation Extraction)
TÃ¡c pháº©m "Heart of Darkness" (vá»›i hÆ¡n 64.000 tokens) Ä‘Æ°á»£c dÃ¹ng lÃ m kho ngá»¯ liá»‡u. ThÃ´ng qua mÃ£ lá»‡nh dÃ² tÃ¬m, ta thiáº¿t láº­p 3 há»‡ cá» phÃ¢n loáº¡i (Flags):
- 0: KhÃ´ng pháº£i dáº¥u cÃ¢u.
- 1: Dáº¥u cÃ¢u ná»™i bá»™ (Chá»§ chá»‘t lÃ  Comma). (Lá»c ra $\approx$ 3000 máº«u).
- 2: Dáº¥u cÃ¢u káº¿t thÃºc (Chá»§ chá»‘t lÃ  Period). Äá»ƒ trÃ¡nh nháº§m láº«n vá»›i dáº¥u tháº­p phÃ¢n cá»§a chá»¯ sá»‘, cÃ¡c thuáº­t toÃ¡n kiá»ƒm tra chuá»—i token liá»n ká» Ä‘Æ°á»£c Ã¡p dá»¥ng. (Lá»c ra $\approx$ 2000 máº«u).

### 2.2. KÃ­ch Hoáº¡t Tensor VÃ  Äiá»u Chá»‰nh Context Window
Thay vÃ¬ náº¡p toÃ n bá»™ cÃ¢u, cÃ¡c tráº¡m Batch Ä‘Æ°á»£c cháº» nhá» theo cÃ´ng thá»©c: Láº¥y 20 tokens Ä‘áº±ng trÆ°á»›c dáº¥u cÃ¢u (Pre-context) vÃ  10 tokens Ä‘áº±ng sau (Post-context), tá»•ng 31 tokens. GPT-2 Medium Ä‘áº©y 250 Ä‘oáº¡n trÃ­ch ngáº«u nhiÃªn cho **Internal** vÃ  250 Ä‘oáº¡n trÃ­ch cho **Terminal** quy náº¡p vÃ o GPU, sau Ä‘Ã³ vector Hidden States (`250 x 31 x 1024`) Ä‘Æ°á»£c Ä‘Æ°a trá»Ÿ láº¡i CPU vÃ  chuyá»ƒn Ä‘á»•i thÃ nh Numpy Matrix Ä‘á»ƒ má»• xáº». 

---

## 3. Kháº£o SÃ¡t TÆ°Æ¡ng Quan (Analysis & Results)

### 3.1. Sá»± PhÃ¢n Cá»¥m Cá»§a Covariance á» CÃ¡c Táº§ng NÃ´ng (Shallow Layers)
Tiáº¿n hÃ nh tÃ­nh ma tráº­n Ä‘á»“ng biáº¿n (Pairs Matrix) cho lá»›p Ä‘áº§u tiÃªn (Layer 1 - ngay sau táº§ng nhÃºng Embeddings):
- **Vá»›i Mutual Information:** Quáº§n thá»ƒ cÃ¡c Ä‘iá»ƒm giao thoa Mutual Information táº¡o thÃ nh má»™t khá»‘i nhiá»…u phÃ¢n bá»• (Blob) duy nháº¥t.
- **Vá»›i Covariance:** Äá»“ hÃ¬nh scatter plot vá»¡ ra thÃ nh ba cá»¥m (Clusters) rÃµ rá»‡t Ä‘á»‘i vá»›i máº£ng *Internal Punctuation*. 
Hiá»‡n tÆ°á»£ng nÃ y phÃ¡t tÃ­n hiá»‡u: á» nhá»¯ng bÆ°á»›c Ä‘áº§u tiáº¿p xÃºc vá»›i ngÃ´n ngá»¯, LLM tÃ¡ch Ä‘á»‹nh nghÄ©a "dáº¥u cÃ¢u ná»‘i" thÃ nh 3 biá»ƒu diá»…n kÃ­ch hoáº¡t Ä‘iá»‡n toÃ¡n hoÃ n toÃ n tÃ¡ch biá»‡t, trong khi "dáº¥u káº¿t cÃ¢u" Ä‘Æ°á»£c co cá»¥m Ä‘á»“ng nháº¥t. 

### 3.2. Hiá»‡u á»¨ng Há»™i Tá»¥ á» Táº§ng SÃ¢u (Deep Layers)
Tuy nhiÃªn, cáº¥u trÃºc 3 cá»¥m (3-clusters) cá»§a Covariance khÃ´ng pháº£i lÃ  má»™t "hiá»‡n tÆ°á»£ng bá»n vá»¯ng vÄ©nh cá»­u". Khi tá»‹nh tiáº¿n thuáº­t toÃ¡n lÃªn Layer 20, ba vÃ¹ng Ä‘á»‘m phÃ¢n tÃ¡n nÃ y hoÃ  quyá»‡n láº¡i thÃ nh 1 cá»¥m thá»‘ng nháº¥t. TÃ­nh nÄƒng phÃ¢n tÃ¡ch chi ly cá»§a cá»¥m "dáº¥u cÃ¢u ráº½ nhÃ¡nh" khÃ´ng cÃ²n cáº§n thiáº¿t Ä‘á»‘i vá»›i táº§ng há»c sÃ¢u - nÆ¡i máº¡ng Neural Æ°u tiÃªn gá»™p má»i chá»‰ sá»‘ token láº¡i thÃ nh má»™t Ä‘á»‹nh dáº¡ng xÃ¡c suáº¥t tá»•ng quÃ¡t nháº±m tÃ¬m kiáº¿m cÃ¡c Word-Logits káº¿ tiáº¿p. 

### 3.3. Nghá»‹ch LÃ½ Simpson (Simpson's Paradox)
Äiá»u ká»³ láº¡ diá»…n ra khi lá»“ng ghÃ©p cáº£ 2 chá»‰ sá»‘ lÃªn 1 máº·t pháº³ng (Covariance trá»¥c X vÃ  M.I trá»¥c Y). á» Layer 1, thÃ´ng sá»‘ TÆ°Æ¡ng quan Pearson tá»•ng thá»ƒ bÃ¡o hiá»‡u $-0.13$ (TÆ°Æ¡ng quan nghá»‹ch yáº¿u). NhÆ°ng Ä‘i sÃ¢u vÃ o tá»«ng cá»¥m con má»™t cÃ¡ch Ä‘á»™c láº­p, Ä‘Æ°á»ng há»“i quy biÃªn Ä‘á»™ láº¡i cÃ³ xu hÆ°á»›ng TÆ°Æ¡ng quan Ä‘á»“ng biáº¿n (Ã‚m sinh Ã‚m, DÆ°Æ¡ng sinh DÆ°Æ¡ng).
Sá»± nháº§m láº«n chá»‰ sá»‘ sinh ra do sá»± phÃ¢n nhÃ¡nh ngáº§m (Subgroups confounder) Ä‘Æ°á»£c gá»i lÃ  **Nghá»‹ch lÃ½ Simpson**. 

---

## 4. Káº¿t Luáº­n
Covariance phÃ´ diá»…n lá»£i tháº¿ vÆ°á»£t trá»™i khi phÃ¡t hiá»‡n xu hÆ°á»›ng ráº½ nhÃ¡nh nhÃ³m máº§m trong táº§ng Ä‘Ã¡y mÃ´ hÃ¬nh. CÃ²n Mutual Information duy trÃ¬ Ä‘á»™ á»•n Ä‘á»‹nh Ä‘o lÆ°á»ng dáº£i thÃ´ng tin má»™t cÃ¡ch tá»•ng quÃ¡t. Sá»± mÃ¢u thuáº«n giá»¯a quy mÃ´ Cá»¥m nhá» (Subgroups) vÃ  Tá»•ng thá»ƒ (Global Data) nháº¯c nhá»Ÿ viá»‡c dÃ¡n nhÃ£n tÃ­nh cháº¥t biá»ƒu diá»…n (Representations) LLM pháº£i luÃ´n song hÃ nh vá»›i hiá»ƒu biáº¿t vá» hiá»‡n tÆ°á»£ng thá»‘ng kÃª Simpson.

---

## TÃ i Liá»‡u Tham Kháº£o (Citations)
1. Dá»¯ liá»‡u mÃ£ code thuá»™c `aero_LLM_13_CodeChallenge Clusters in internal vs. terminal punctuation (part 1).md` (HÆ°á»›ng dáº«n quy hoáº¡ch context arrays kÃ­ch thÆ°á»›c 31 tokens vÃ  xá»­ lÃ½ nghá»‹ch lÃ½ nhÃ³m Simpson).
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| [PhÃ¢n TÃ­ch Sá»± TÆ°Æ¡ng Äá»“ng Tokens Trong vÃ  Giá»¯a CÃ¡c Ma Tráº­n Q, K, V (Pháº§n 1)](aero_llm_01_token_related_similarities_within_and_across_q_k_v_matrices_part_1_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_01_token_related_similarities_within_and_across_q_k_v_matrices_part_1_.md) |
| [PhÃ¢n TÃ­ch Sá»± TÆ°Æ¡ng Äá»“ng Tokens Trong vÃ  Giá»¯a CÃ¡c Ma Tráº­n Q, K, V (Pháº§n 2)](aero_llm_02_token_related_similarities_within_and_across_q_k_v_matrices_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_02_token_related_similarities_within_and_across_q_k_v_matrices_part_2_.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): PhÃ¢n TÃ­ch Äá»™ TÆ°Æ¡ng Äá»“ng Cá»§a Token XuyÃªn Suá»‘t CÃ¡c Táº§ng áº¨n](aero_llm_03_codechallenge_token_related_similarities_across_layers.md) | [Xem bÃ i viáº¿t â†’](aero_llm_03_codechallenge_token_related_similarities_across_layers.md) |
| [PhÃ¢n TÃ­ch Sá»± PhÃ¢n Cá»¥m vÃ  TÆ°Æ¡ng Äá»“ng Biá»ƒu Diá»…n (RSA) Trong Ma Tráº­n Q vÃ  K](aero_llm_04_grouping_and_rsa_in_q_and_k_matrices.md) | [Xem bÃ i viáº¿t â†’](aero_llm_04_grouping_and_rsa_in_q_and_k_matrices.md) |
| [Kháº£o SÃ¡t PhÃ¢n Táº§ng (Laminar Profile) Vá» RSA VÃ  Sá»± Chá»n Lá»c PhÃ¢n NhÃ³m](aero_llm_05_codechallenge_laminar_profile_of_rsa_and_category_selectivity.md) | [Xem bÃ i viáº¿t â†’](aero_llm_05_codechallenge_laminar_profile_of_rsa_and_category_selectivity.md) |
| [PhÃ¢n TÃ­ch Sá»‘ Chiá»u Hiá»‡u Quáº£ (Effective Dimensionality) ThÃ´ng Qua PCA](aero_llm_06_effective_dimensionality_analysis_with_pca.md) | [Xem bÃ i viáº¿t â†’](aero_llm_06_effective_dimensionality_analysis_with_pca.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): Kháº£o SÃ¡t Sá»‘ Chiá»u Hiá»‡u Quáº£ TrÃªn Pythia 2.8B](aero_llm_07_codechallenge_dimensionalities_in_pythia_2_3b.md) | [Xem bÃ i viáº¿t â†’](aero_llm_07_codechallenge_dimensionalities_in_pythia_2_3b.md) |
| [LÃ½ Thuyáº¿t ThÃ´ng Tin: Äo LÆ°á»ng Entropy VÃ  Mutual Information](aero_llm_08_mutual_information_theory_and_code.md) | [Xem bÃ i viáº¿t â†’](aero_llm_08_mutual_information_theory_and_code.md) |
| [PhÃ¢n TÃ­ch ThÃ´ng Tin TÆ°Æ¡ng Há»— Dá»c Theo CÃ¡c Táº§ng Cá»§a MÃ´ HÃ¬nh NgÃ´n Ngá»¯ (Pairwise Mutual Information Through LLMs)](aero_llm_09_pairwise_mutual_information_through_the_llm.md) | [Xem bÃ i viáº¿t â†’](aero_llm_09_pairwise_mutual_information_through_the_llm.md) |
| [PhÃ¢n TÃ­ch Äá»‘i Chiáº¿u Äo LÆ°á»ng TÆ°Æ¡ng Quan: Mutual Information vÃ  Covariance](aero_llm_10_mutual_information_vs_covariance.md) | [Xem bÃ i viáº¿t â†’](aero_llm_10_mutual_information_vs_covariance.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): MI VÃ  Khoáº£ng CÃ¡ch Token (Pháº§n 1)](aero_llm_11_codechallenge_attention_to_coffee_mi_and_token_distances_part_1_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_11_codechallenge_attention_to_coffee_mi_and_token_distances_part_1_.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): MI VÃ  Khoáº£ng CÃ¡ch Token (Pháº§n 2)](aero_llm_12_codechallenge_attention_to_coffee_mi_and_token_distances_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_12_codechallenge_attention_to_coffee_mi_and_token_distances_part_2_.md) |
| ğŸ“Œ **[PhÃ¢n Kháº£o Cáº¥u TrÃºc Cá»¥m (Clusters): Dáº¥u CÃ¢u Ná»™i Bá»™ vs Dáº¥u CÃ¢u Káº¿t ThÃºc Táº­p 1](aero_llm_13_codechallenge_clusters_in_internal_vs_terminal_punctuation_part_1_.md)** | [Xem bÃ i viáº¿t â†’](aero_llm_13_codechallenge_clusters_in_internal_vs_terminal_punctuation_part_1_.md) |
| [PhÃ¢n Kháº£o Cáº¥u TrÃºc Cá»¥m (Clusters): Dáº¥u CÃ¢u Ná»™i Bá»™ vs Dáº¥u CÃ¢u Káº¿t ThÃºc Táº­p 2](aero_llm_14_codechallenge_clusters_in_internal_vs_terminal_punctuation_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_14_codechallenge_clusters_in_internal_vs_terminal_punctuation_part_2_.md) |
| [Tháº¥u KÃ­nh Logit (The Logit Lens): Soi SÃ¡ng TÆ° Duy Táº§ng Trung Gian Cá»§a MÃ´ HÃ¬nh NgÃ´n Ngá»¯](aero_llm_15_the_logit_lens.md) | [Xem bÃ i viáº¿t â†’](aero_llm_15_the_logit_lens.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): á»¨ng Dá»¥ng Logit Lens Trong Máº¡ng BERT (Pháº§n 1)](aero_llm_16_codechallenge_logit_lens_in_bert_part_1_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_16_codechallenge_logit_lens_in_bert_part_1_.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): á»¨ng Dá»¥ng Logit Lens Trong Máº¡ng BERT (Pháº§n 2)](aero_llm_17_codechallenge_logit_lens_in_bert_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_17_codechallenge_logit_lens_in_bert_part_2_.md) |
| [PhÃ¢n TÃ­ch Sá»± TÆ°Æ¡ng Äá»“ng Tokens Trong vÃ  Giá»¯a CÃ¡c Ma Tráº­n Q, K, V (Pháº§n 1)](article_aero_llm_01_vn.md) | [Xem bÃ i viáº¿t â†’](article_aero_llm_01_vn.md) |
| [PhÃ¢n tÃ­ch ChuyÃªn SÃ¢u CÃ¡c Táº§ng áº¨n Trong MÃ´ HÃ¬nh NgÃ´n Ngá»¯ Lá»›n (LLMs): Äo LÆ°á»ng, Biá»ƒu Diá»…n vÃ  Giáº£i MÃ£ Ná»™i Táº¡i](scientific_article_vn.md) | [Xem bÃ i viáº¿t â†’](scientific_article_vn.md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
