
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../index.md) > [13 investigating layers](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../index.md)
- [ğŸ“š Module 01: LLM Course](../../01_llm_course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../02_words_to_tokens_to_numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../04_buildgpt/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../07_fine_tune_pretrained_models/index.md)
- [ğŸ” Module 19: AI Safety](../../19_ai_safety/index.md)
- [ğŸ Module 20: Python for AI](../../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): PhÃ¢n TÃ­ch Äá»™ TÆ°Æ¡ng Äá»“ng Cá»§a Token XuyÃªn Suá»‘t CÃ¡c Táº§ng áº¨n

## TÃ³m táº¯t (Abstract)
Káº¿ thá»«a vÃ  má»Ÿ rá»™ng tá»« cÃ¡c ká»¹ thuáº­t tÃ­nh toÃ¡n trong pháº§n 1 vÃ  2, bÃ i viáº¿t nÃ y trÃ¬nh bÃ y phÆ°Æ¡ng phÃ¡p má»Ÿ rá»™ng thá»±c nghiá»‡m Ä‘á»ƒ phÃ¢n tÃ¡ch toÃ n bá»™ thÃ´ng lÆ°á»£ng kÃ­ch hoáº¡t (activations) xuyÃªn suá»‘t táº¥t cáº£ cÃ¡c táº§ng (all layers) cá»§a mÃ´ hÃ¬nh GPT-2 XL. Báº±ng cÃ¡ch thiáº¿t láº­p vÃ²ng láº·p phÃ¢n tÃ­ch qua tá»«ng `Transformer Block`, bÃ¡o cÃ¡o nÃ y hÆ°á»›ng dáº«n cÃ¡ch trÃ­ch xuáº¥t Ä‘á»™ phÃ¢n tÃ¡n (Variance), giÃ¡ trá»‹ trung bÃ¬nh (Means) vÃ  cáº¥u hÃ¬nh láº¡i ma tráº­n Äá»™ tÆ°Æ¡ng Ä‘á»“ng Cosine (Cosine Similarity) cho cÃ¡c Token Ä‘Ã­ch vÃ  Phi Ä‘Ã­ch. Nhá»¯ng káº¿t quáº£ thu Ä‘Æ°á»£c sáº½ Ä‘Æ°á»£c trá»±c quan hÃ³a káº¿t cáº¥u theo Ä‘á»™ sÃ¢u cá»§a kiáº¿n trÃºc máº¡ng lÆ°á»›i.

---

## 1. Má»Ÿ Äáº§u (Introduction)
PhÃ¢n tÃ­ch theo má»™t táº§ng cá»‘ Ä‘á»‹nh (nhÆ° layer-6 trÆ°á»›c Ä‘Ã³) cung cáº¥p cÃ¡i nhÃ¬n cá»¥c bá»™, nhÆ°ng khÃ´ng diá»…n giáº£i trá»n váº¹n "chu ká»³ sá»‘ng" cá»§a má»™t mÃ£ token há»c thuáº­t khi Ä‘i xuyÃªn qua Ä‘á»™ sÃ¢u cá»§a má»™t LLM khá»•ng lá»“.
ThÃ´ng qua thá»­ thÃ¡ch láº­p trÃ¬nh nÃ y, ta sáº½:
- Thay vÃ¬ nhá» láº», phÃ¢n rÃ£ máº¡ng `GPT-2 XL` (cÃ³ tá»›i 48 transformer blocks vÃ  sá»‘ chiá»u nhÃºng lÃ  1600).
- Cháº¡y há»‡ thá»‘ng trÃªn má»™t trá»¥c tÃ­nh toÃ¡n hÃ ng loáº¡t (batch compute level), tá»« Ä‘Ã³ Ä‘Ã¡nh giÃ¡ sá»± thay Ä‘á»•i biá»ƒu diá»…n theo thá»i gian khi tiáº¿n dáº§n vá» cÃ¡c táº§ng cáº­n cuá»•i.
- Äá»‘i sÃ¡nh má»©c Ä‘á»™ Ä‘a dáº¡ng theo vÄƒn cáº£nh cá»§a nhÃ³m tokens (Target vs. Non-target tokens) thÃ´ng qua phÆ°Æ¡ng sai (variance) trÃªn ma tráº­n attention Q, K, V.

---

## 2. PhÆ°Æ¡ng PhÃ¡p Luáº­n VÃ  Giáº£i PhÃ¡p Ká»¹ Thuáº­t (Methodology)

### 2.1. MÃ£ HÃ³a HÃ m Kháº£o SÃ¡t Lá»›p Äá»™ng (Dynamic Layer Scanning)
Sá»­ dá»¥ng bá»™ cÃ´ng cá»¥ PyTorch, ta xÃ¢y dá»±ng má»™t hÃ m láº·p Ä‘á»ƒ quÃ©t vÃ  trÃ­ch xuáº¥t Ä‘iá»ƒm káº¿t ná»‘i:
1. XÃ¡c Ä‘á»‹nh vá»‹ trÃ­ Index cá»§a Token má»¥c tiÃªu linh hoáº¡t á»©ng vá»›i cÃ¡c cÃ¢u cÃ³ Ä‘á»™ dÃ i ngáº¯n khÃ¡c nhau.
2. Táº¡i má»—i táº§ng `l` $(1 \le l \le 48)$, vector hÃ m kÃ­ch hoáº¡t tÆ°Æ¡ng á»©ng cho "Target" vÃ  má»™t token ngáº«u nhiÃªn "Non-target" káº¿ trÆ°á»›c nÃ³ sáº½ Ä‘Æ°á»£c tÃ¡ch báº¡ch.
3. KÃ­ch thÆ°á»›c mong Ä‘á»£i trong GPT-2 XL sau khi tÃ¡ch $Q, K, V$ sáº½ lÃ  $\sim \text{Seq} \times 1600 \times 3$.

### 2.2. Äo LÆ°á»ng PhÆ°Æ¡ng Sai NhÃ³m (Variance Calculation)
Äá»ƒ Ä‘Ã¡nh giÃ¡ tÃ¡c Ä‘á»™ng cá»§a "context" lÃªn cÃ¡ch thá»©c máº¡ng nÆ¡-ron nháº­n thá»©c chung má»™t cá»¥m tá»« ("her") trong 54 tÃ¬nh huá»‘ng cÃ¢u vÄƒn khÃ¡c nhau:
- **NguyÃªn lÃ½:** Náº¿u mÃ´ hÃ¬nh Ä‘á»‘i xá»­ vá»›i tá»« "her" y há»‡t nhau dÃ¹ nÃ³ Ä‘á»©ng á»Ÿ Ä‘Ã¢u, PhÆ°Æ¡ng sai sáº½ $\approx 0$. NgÆ°á»£c láº¡i, PhÆ°Æ¡ng sai má»Ÿ rá»™ng Ã¡m chá»‰ táº§m áº£nh hÆ°á»Ÿng ráº¥t lá»›n tá»« cÃ¡c chuá»—i ngá»¯ cáº£nh má»“i.
- **TÃ­nh toÃ¡n:** $V_{target} = \text{Var}(X_{layer=l, \space \text{token}="her"})\ \text{trÃªn}\ 54 \text{ máº«u cÃ¢u}$.

### 2.3. Táº¡o Ma Tráº­n Khá»‘i LiÃªn Hiá»‡p (Cosine Matrix Block & Histogram Masking)
Tiáº¿p tá»¥c á»©ng dá»¥ng Matrix Mask $(\text{size} = 4800 \times 4800)$ Ä‘á»ƒ bá»‘c tÃ¡ch pháº§n giao tuyáº¿n $Q-Q$, $K-K$ vÃ  ráº½ nhÃ¡nh cá»§a $Q-K, K-V$. TrÃ­ch xuáº¥t biá»ƒu Ä‘á»“ phÃ¢n phá»‘i Histogram tá»«ng táº§ng riÃªng ráº½ rá»“i tá»•ng há»£p (Stack).

---

## 3. KhÃ¡m PhÃ¡ CÃ¡c Táº§ng Máº¡ng áº¨n (Analysis & Visualizations)

Viá»‡c ghim Plotting cÃ¡c phÃ¢n phá»‘i Cosine xuyÃªn khÃ´ng gian Ä‘a lá»›p mang vá» má»™t gÃ³c nhÃ¬n thá»‹ giÃ¡c giá»‘ng quang phá»•:

1. **Hiá»‡u á»©ng thu háº¹p phÃ¢n cá»±c (Convergence to Zero):**
   - Ráº¥t áº¥n tÆ°á»£ng, á»Ÿ cÃ¡c táº§ng nÃ´ng (early layers), Cosine Similarity giá»¯a cÃ¡c block cÃ³ tÃ­nh tá»¥ táº­p ráº¥t máº¡nh bÃ¡m sÃ¡t miá»n há»™i tá»¥ cao $(\approx 1.0/-1.0)$.
   - CÃ ng trÆ°á»£t sÃ¢u xuá»‘ng nhá»¯ng block cuá»‘i (deeper into the model), phÃ¢n bá»‘ bá»‹ lÃ  pháº³ng Ä‘i vÃ  thu trá»ng tÃ¢m dáº§n vá» má»©c $0$.

2. **LÃ½ giáº£i vá» máº·t CÆ¡ Há»c (Mechanistic Reason):** 
   - Hiá»‡n tÆ°á»£ng nÃ y pháº£n chiáº¿u báº£n cháº¥t cá»§a ngÃ´n ngá»¯: á» cÃ¡c táº§ng dÆ°á»›i, há»‡ thá»‘ng má»›i chá»‰ "Ä‘á»c vÃ  ghim" biá»ƒu diá»…n tÄ©nh ban Ä‘áº§u theo tá»± vá»±ng cá»§a "her" (nÃªn tÆ°Æ¡ng Ä‘á»“ng cao). 
   - Äáº¿n cÃ¡c táº§ng trong cÃ¹ng, mÃ´ hÃ¬nh dá»“n dáº­p tÃ­ch luá»¹ sá»± táº­p trung vÃ o chá»©c nÄƒng dá»± Ä‘oÃ¡n tá»« ngá»¯ Ä‘á»©ng theo sau (subsequent prediction context). VÃ¬ cÃ¡c cÃ¢u Ä‘a dáº¡ng Ä‘á»u cÃ³ luá»“ng vÄƒn cáº£nh cÃ¡ biá»‡t, cÃ¡c Vector mang "trÃ¡ch nhiá»‡m tiáº¿p theo" nÃ y sáº½ phÃ¢n huá»· dáº§n sá»± giá»‘ng nhau nguyÃªn báº£n ban Ä‘áº§u. 

---

## 4. Káº¿t Luáº­n (Conclusion)
ThÃ´ng qua thá»§ phÃ¡p quan sÃ¡t toÃ n cá»¥c quy mÃ´ kiáº¿n trÃºc (across layers) trÃªn siÃªu vi mÃ´ mÃ´ hÃ¬nh GPT-2 XL, chÃºng ta tháº¥u thá»‹ Ä‘Æ°á»£c cháº·ng hÃ nh trÃ¬nh sinh há»c cá»§a Attention. Táº¡i Ä‘Ã³, LLMs cÃ³ vÃ²ng Ä‘á»i tá»± Ä‘á»™ng chuyá»ƒn hÆ°á»›ng quy trÃ¬nh há»c: Ä‘i tá»« Ä‘á»‹nh hÃ¬nh Ä‘áº·c trÆ°ng ngá»¯ nghÄ©a cÆ¡ sá»Ÿ (hiá»‡u á»©ng liÃªn cá»±c lá»›n), dáº§n hoÃ  quyá»‡n theo phÃ¢n hoÃ¡ sá»± kiáº¿n giáº£i ngá»¯ cáº£nh Ä‘á»ƒ káº¿t ná»‘i cáº¥u trÃºc cho nhá»¯ng token vÃ´ Ä‘á»‹nh á»Ÿ tÆ°Æ¡ng lai (hiá»‡u á»©ng suy tÃ n há»™i tá»¥). KhÃ¡m phÃ¡ nÃ y cá»§ng cá»‘ ná»n táº£ng diá»…n giáº£i cÆ¡ há»c má»™t cÃ¡ch sÃ¢u sáº¯c vÃ  thá»±c chá»©ng.

---

## TÃ i Liá»‡u Tham Kháº£o (Citations)
1. Dá»¯ liá»‡u trÃ­ch xuáº¥t tá»« pháº§n phá»¥ Ä‘á» vÃ  mÃ£ lá»‡nh bÃ i toÃ¡n: `aero_LLM_03_CodeChallenge Token-related similarities across layers.md` (Giá»›i thiá»‡u cÃ¡c hÃ m tÃ­nh Variance, Mean, Cosine Similarity vÃ  ká»¹ nÄƒng Stack Histogram cho GPT-2 XL).
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| [PhÃ¢n TÃ­ch Sá»± TÆ°Æ¡ng Äá»“ng Tokens Trong vÃ  Giá»¯a CÃ¡c Ma Tráº­n Q, K, V (Pháº§n 1)](aero_llm_01_token_related_similarities_within_and_across_q_k_v_matrices_part_1_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_01_token_related_similarities_within_and_across_q_k_v_matrices_part_1_.md) |
| [PhÃ¢n TÃ­ch Sá»± TÆ°Æ¡ng Äá»“ng Tokens Trong vÃ  Giá»¯a CÃ¡c Ma Tráº­n Q, K, V (Pháº§n 2)](aero_llm_02_token_related_similarities_within_and_across_q_k_v_matrices_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_02_token_related_similarities_within_and_across_q_k_v_matrices_part_2_.md) |
| ğŸ“Œ **[Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): PhÃ¢n TÃ­ch Äá»™ TÆ°Æ¡ng Äá»“ng Cá»§a Token XuyÃªn Suá»‘t CÃ¡c Táº§ng áº¨n](aero_llm_03_codechallenge_token_related_similarities_across_layers.md)** | [Xem bÃ i viáº¿t â†’](aero_llm_03_codechallenge_token_related_similarities_across_layers.md) |
| [PhÃ¢n TÃ­ch Sá»± PhÃ¢n Cá»¥m vÃ  TÆ°Æ¡ng Äá»“ng Biá»ƒu Diá»…n (RSA) Trong Ma Tráº­n Q vÃ  K](aero_llm_04_grouping_and_rsa_in_q_and_k_matrices.md) | [Xem bÃ i viáº¿t â†’](aero_llm_04_grouping_and_rsa_in_q_and_k_matrices.md) |
| [Kháº£o SÃ¡t PhÃ¢n Táº§ng (Laminar Profile) Vá» RSA VÃ  Sá»± Chá»n Lá»c PhÃ¢n NhÃ³m](aero_llm_05_codechallenge_laminar_profile_of_rsa_and_category_selectivity.md) | [Xem bÃ i viáº¿t â†’](aero_llm_05_codechallenge_laminar_profile_of_rsa_and_category_selectivity.md) |
| [PhÃ¢n TÃ­ch Sá»‘ Chiá»u Hiá»‡u Quáº£ (Effective Dimensionality) ThÃ´ng Qua PCA](aero_llm_06_effective_dimensionality_analysis_with_pca.md) | [Xem bÃ i viáº¿t â†’](aero_llm_06_effective_dimensionality_analysis_with_pca.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): Kháº£o SÃ¡t Sá»‘ Chiá»u Hiá»‡u Quáº£ TrÃªn Pythia 2.8B](aero_llm_07_codechallenge_dimensionalities_in_pythia_2_3b.md) | [Xem bÃ i viáº¿t â†’](aero_llm_07_codechallenge_dimensionalities_in_pythia_2_3b.md) |
| [LÃ½ Thuyáº¿t ThÃ´ng Tin: Äo LÆ°á»ng Entropy VÃ  Mutual Information](aero_llm_08_mutual_information_theory_and_code.md) | [Xem bÃ i viáº¿t â†’](aero_llm_08_mutual_information_theory_and_code.md) |
| [PhÃ¢n TÃ­ch ThÃ´ng Tin TÆ°Æ¡ng Há»— Dá»c Theo CÃ¡c Táº§ng Cá»§a MÃ´ HÃ¬nh NgÃ´n Ngá»¯ (Pairwise Mutual Information Through LLMs)](aero_llm_09_pairwise_mutual_information_through_the_llm.md) | [Xem bÃ i viáº¿t â†’](aero_llm_09_pairwise_mutual_information_through_the_llm.md) |
| [PhÃ¢n TÃ­ch Äá»‘i Chiáº¿u Äo LÆ°á»ng TÆ°Æ¡ng Quan: Mutual Information vÃ  Covariance](aero_llm_10_mutual_information_vs_covariance.md) | [Xem bÃ i viáº¿t â†’](aero_llm_10_mutual_information_vs_covariance.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): MI VÃ  Khoáº£ng CÃ¡ch Token (Pháº§n 1)](aero_llm_11_codechallenge_attention_to_coffee_mi_and_token_distances_part_1_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_11_codechallenge_attention_to_coffee_mi_and_token_distances_part_1_.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): MI VÃ  Khoáº£ng CÃ¡ch Token (Pháº§n 2)](aero_llm_12_codechallenge_attention_to_coffee_mi_and_token_distances_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_12_codechallenge_attention_to_coffee_mi_and_token_distances_part_2_.md) |
| [PhÃ¢n Kháº£o Cáº¥u TrÃºc Cá»¥m (Clusters): Dáº¥u CÃ¢u Ná»™i Bá»™ vs Dáº¥u CÃ¢u Káº¿t ThÃºc Táº­p 1](aero_llm_13_codechallenge_clusters_in_internal_vs_terminal_punctuation_part_1_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_13_codechallenge_clusters_in_internal_vs_terminal_punctuation_part_1_.md) |
| [PhÃ¢n Kháº£o Cáº¥u TrÃºc Cá»¥m (Clusters): Dáº¥u CÃ¢u Ná»™i Bá»™ vs Dáº¥u CÃ¢u Káº¿t ThÃºc Táº­p 2](aero_llm_14_codechallenge_clusters_in_internal_vs_terminal_punctuation_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_14_codechallenge_clusters_in_internal_vs_terminal_punctuation_part_2_.md) |
| [Tháº¥u KÃ­nh Logit (The Logit Lens): Soi SÃ¡ng TÆ° Duy Táº§ng Trung Gian Cá»§a MÃ´ HÃ¬nh NgÃ´n Ngá»¯](aero_llm_15_the_logit_lens.md) | [Xem bÃ i viáº¿t â†’](aero_llm_15_the_logit_lens.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): á»¨ng Dá»¥ng Logit Lens Trong Máº¡ng BERT (Pháº§n 1)](aero_llm_16_codechallenge_logit_lens_in_bert_part_1_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_16_codechallenge_logit_lens_in_bert_part_1_.md) |
| [Thá»­ ThÃ¡ch Láº­p TrÃ¬nh (Code Challenge): á»¨ng Dá»¥ng Logit Lens Trong Máº¡ng BERT (Pháº§n 2)](aero_llm_17_codechallenge_logit_lens_in_bert_part_2_.md) | [Xem bÃ i viáº¿t â†’](aero_llm_17_codechallenge_logit_lens_in_bert_part_2_.md) |
| [PhÃ¢n TÃ­ch Sá»± TÆ°Æ¡ng Äá»“ng Tokens Trong vÃ  Giá»¯a CÃ¡c Ma Tráº­n Q, K, V (Pháº§n 1)](article_aero_llm_01_vn.md) | [Xem bÃ i viáº¿t â†’](article_aero_llm_01_vn.md) |
| [PhÃ¢n tÃ­ch ChuyÃªn SÃ¢u CÃ¡c Táº§ng áº¨n Trong MÃ´ HÃ¬nh NgÃ´n Ngá»¯ Lá»›n (LLMs): Äo LÆ°á»ng, Biá»ƒu Diá»…n vÃ  Giáº£i MÃ£ Ná»™i Táº¡i](scientific_article_vn.md) | [Xem bÃ i viáº¿t â†’](scientific_article_vn.md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
