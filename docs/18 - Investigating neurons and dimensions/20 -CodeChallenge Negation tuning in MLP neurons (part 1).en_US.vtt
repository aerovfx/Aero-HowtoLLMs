WEBVTT

00:02.200 --> 00:08.000
In this code challenge, you will look for tuning in MLP neurons.

00:08.480 --> 00:15.240
I think this code challenge is a nice balance between using and adapting code you've already learned

00:15.240 --> 00:21.320
about in the past, several videos, with new concepts and new material.

00:21.920 --> 00:29.240
This will be a fairly long code challenge, but a lot of the code in these exercises will also be used

00:29.240 --> 00:31.560
for the next code challenge.

00:32.000 --> 00:33.520
Anyway, let's begin.

00:34.000 --> 00:43.080
The goal here in exercise one is to import GPT two large and implant hooks to get all the activations

00:43.080 --> 00:46.320
from all the MLP expansion layers.

00:47.040 --> 00:54.000
Now, in previous videos, we implanted hooks using code that looked something like this where we actually

00:54.040 --> 01:02.920
hooked into the main MLP layer and then pushed the input through the fully connected layer that does

01:02.920 --> 01:10.680
the matrix multiplication on the input into the MLP layer, which is technically a little redundant

01:10.680 --> 01:18.320
because that means the multiplication happens twice, once here in the hook, and then once again in

01:18.320 --> 01:19.960
the model forward pass.

01:20.600 --> 01:27.000
Now, I wanted to have the code set up this way to show you how to work with the inputs into a hook

01:27.000 --> 01:31.920
function, and how much flexibility you have inside these hooks.

01:32.400 --> 01:39.000
But here in this code challenge, I want you to create the hook in a slightly different way.

01:39.640 --> 01:46.600
Instead of hooking into the main MLP layer and then pushing the inputs through the expansion layer,

01:46.960 --> 01:54.080
you can hook directly into the expansion layer and then just grab the output of that expansion layer.

01:55.240 --> 02:00.610
If you are curious, you can even implant two hooks, one as in the previous video.

02:00.610 --> 02:07.490
Like what you see in this screenshot here, and then a second time hooking into the output of the fully

02:07.490 --> 02:08.610
connected layer.

02:09.050 --> 02:16.130
If you do that, that will demonstrate that those two hooks are identical, although I don't actually

02:16.130 --> 02:19.250
show that in the code in my solution file.

02:19.770 --> 02:23.690
Anyway, a final general point about this code challenge.

02:23.690 --> 02:31.450
If you are using a CPU and not connecting to the GPU, you might consider using a smaller version of

02:31.610 --> 02:32.650
GPT two.

02:33.730 --> 02:36.730
Okay, so that's it for this exercise.

02:36.850 --> 02:39.930
Now you can pause the video and code that up.

02:40.210 --> 02:44.370
And of course, copying as much as you like from the previous video.

02:44.930 --> 02:48.010
And now I will switch to code and show my solution.

02:48.730 --> 02:52.930
Here are lots of libraries that I'm importing here.

02:53.050 --> 02:56.050
Some of these we need for exercise one.

02:56.610 --> 03:01.850
Some of them we will use in later exercises in this code challenge.

03:02.210 --> 03:03.770
Okay, so anyway, here we are.

03:03.810 --> 03:06.490
I'm importing GPT two large.

03:07.130 --> 03:09.690
In this case I am using the GPU.

03:09.890 --> 03:14.770
You actually can run this code challenge on the CPU if you like.

03:14.770 --> 03:20.690
It will just take a little bit longer to do the forward pass calculations, but overall it's not so

03:20.690 --> 03:21.090
bad.

03:21.610 --> 03:23.210
Okay, so here you see the hooks.

03:23.210 --> 03:28.130
This is probably the main difference from the code in the previous video.

03:28.530 --> 03:35.650
Remember in the previous video, the code in that hook we were hooking directly into the MLP layer.

03:35.930 --> 03:42.610
And then what we were storing, the activations we were storing in the dictionary was something like

03:43.010 --> 03:48.610
a module module dot C fully connected.

03:48.770 --> 03:51.210
And then the input like this.

03:51.210 --> 03:52.770
So that looked like this.

03:53.090 --> 03:53.930
And that's fine.

03:53.930 --> 03:54.530
That's great.

03:54.530 --> 04:00.170
But this means that we are running through this calculation twice, once here in the hook, and then

04:00.170 --> 04:03.050
again as the model does the forward pass.

04:03.250 --> 04:10.330
So here I'm just getting the output of that fully connected layer that I'm hooking directly into here.

04:10.730 --> 04:13.770
So there's no real right or wrong way to do this.

04:13.770 --> 04:15.210
Hooks are very versatile.

04:15.210 --> 04:17.330
You can do it any way that you like.

04:17.450 --> 04:17.850
Okay.

04:17.890 --> 04:20.050
So now you know multiple ways.

04:20.050 --> 04:27.250
And throughout the rest of this course, I will try to show a variety of techniques for hooking into

04:27.250 --> 04:29.490
models and grabbing activations.

04:30.170 --> 04:32.090
Okay, so imported the model run.

04:32.090 --> 04:41.650
This here is just a variable that I use to count the number of neurons, and that is 5128.

04:42.010 --> 04:49.090
That corresponds to a embeddings dimensionality of 1280 in GPT two large.

04:49.250 --> 04:52.500
And then we have an expansion factor of four For.

04:53.620 --> 05:03.580
The goal of exercise two is to import text and find words in two categories negations and affirmations.

05:04.220 --> 05:11.660
The goal in later exercises will be to use logistic regression to identify neurons that show stronger

05:11.780 --> 05:16.340
activation for the negation words compared to the affirmation words.

05:16.700 --> 05:20.140
So what we will get to the analyses in later exercises.

05:20.620 --> 05:23.140
Negation words here include or.

05:23.500 --> 05:24.700
This list over here.

05:24.700 --> 05:28.420
So cannot can't don't won't never.

05:28.420 --> 05:30.100
Wasn't these kinds of words.

05:30.740 --> 05:37.660
Now some of these words are easy to find in sequences of tokens, because you can just search for that

05:37.700 --> 05:46.660
word like uh, for example, uh isn't is going to appear definitely is one token in the GPT two tokenizer.

05:46.660 --> 05:52.940
So it's easy to just look through all of the tokens to find, the word that matches.

05:52.940 --> 05:53.700
Definitely.

05:54.140 --> 06:00.060
But some of these words are a little bit trickier to find, and you might need to come up with some

06:00.060 --> 06:04.340
little algorithms for making sure that you're getting the correct word.

06:04.780 --> 06:12.540
For example, the character sequence can see here also appears in cannot.

06:12.700 --> 06:15.860
So you need to make sure that you account for that.

06:15.940 --> 06:23.420
So looking for can as an affirmation word and not as just the first part of a negation word.

06:24.180 --> 06:28.500
Now for the data set we will use this book by Philip K Dick.

06:28.940 --> 06:30.900
You might recognize his name.

06:31.060 --> 06:36.980
He wrote lots of sci fi stories, including one called Do Androids Dream of Electric Sheep?

06:37.020 --> 06:40.740
That book was the basis for the movie The Blade Runner.

06:41.780 --> 06:46.740
Anyway, you can import this book from the Gutenberg website.

06:46.860 --> 06:52.660
You can look this up on your own or just copy the code from these solutions or helpers files.

06:53.220 --> 07:00.780
Now, when you're looking through this text to identify the tokens, make sure that you ignore any target

07:00.780 --> 07:08.020
words that appear in the first 90 tokens or the last ten tokens before the end of the book.

07:08.500 --> 07:16.700
The reason for ignoring any target tokens in the first 90 or the last 90 is that these will be a context

07:16.700 --> 07:25.020
window that we will use for creating batches in later exercises that will make more sense in the next

07:25.300 --> 07:32.340
exercise, but for now, just suffice it to say that any negation or affirmation words that you find

07:32.340 --> 07:36.180
in the first 90 tokens do not include them in your list.

07:36.180 --> 07:38.620
And same for the final ten tokens.

07:39.380 --> 07:43.180
Okay, you can also confirm the tokenization of this book.

07:43.220 --> 07:51.380
You should get 46,971 tokens in total and 5649 unique tokens.

07:51.540 --> 07:59.460
And then the final step for exercise two is to print out a couple of examples of negation and affirmation

07:59.460 --> 08:05.580
tokens, and also printing out their context of 15 tokens on either side.

08:06.060 --> 08:15.660
So using my code for finding negation words, I got 217 negation tokens in this book according to the

08:15.700 --> 08:17.220
little algorithm that I wrote.

08:17.460 --> 08:19.460
And here you see some examples.

08:19.460 --> 08:25.460
So we have not and not and not and also not over here.

08:25.700 --> 08:31.380
So it looks like in this first couple of examples that I printed out, all of the negation words were

08:31.380 --> 08:31.980
not.

08:32.620 --> 08:40.620
And then I found 178 affirmation tokens again using the code that I wrote for identifying these.

08:41.100 --> 08:42.100
So here you see.

08:42.140 --> 08:42.740
Let's see.

08:42.900 --> 08:44.100
Uh, here is neither.

08:44.100 --> 08:50.830
So this is actually a negation token that also ended up in the affirmation token list, but the actual

08:50.830 --> 08:52.990
activation token, the target token is.

08:52.990 --> 08:54.110
This one can.

08:54.710 --> 08:57.670
And here we get also can this one.

08:57.950 --> 08:58.510
Let me see.

08:58.550 --> 09:00.310
This one is could down here.

09:00.470 --> 09:02.590
This one is an interesting case here.

09:02.590 --> 09:11.430
This is a mistake in my simple algorithm because I was looking for the word may as in you may proceed

09:11.430 --> 09:12.310
with your plan.

09:12.670 --> 09:15.910
But this also tagged the month of May.

09:16.430 --> 09:23.910
Now, I decided to leave this in as an illustration of how tricky it can be to search for specific word

09:23.910 --> 09:26.470
categories in a large text.

09:27.270 --> 09:29.430
Anyway, that's exercise two.

09:29.470 --> 09:33.230
So now please pause the video and work your way through that exercise.

09:33.470 --> 09:36.710
And now I will switch to code and show my solution.

09:37.430 --> 09:45.990
Here is the URL for the text file of that book and import that and tokenize it.

09:45.990 --> 09:46.990
That's pretty fast.

09:46.990 --> 09:53.390
And here you see 47,000 tokens, 5000 and a half of which are unique.

09:53.830 --> 09:56.030
Here I define the context windows.

09:56.030 --> 10:03.870
So I'm looking for 90 tokens before each target token and ten tokens afterwards.

10:03.990 --> 10:09.310
Now we're not building up batches for the model forward pass just yet.

10:09.310 --> 10:11.070
That comes in a later exercise.

10:11.430 --> 10:17.510
But I do need to define these parameters here so that I can exclude them from the list.

10:17.510 --> 10:21.110
So we don't cause we don't get any errors later okay.

10:21.150 --> 10:26.270
So first in this cell I'm going to identify all the negation tokens.

10:26.430 --> 10:31.590
And then in the next couple of cells I will get the affirmation tokens.

10:32.030 --> 10:38.150
So to find the negation tokens I had to do this in a multi step process.

10:38.350 --> 10:46.950
So here I'm looping over most of the tokens I'm starting this looping count from 90, and I'm going

10:46.950 --> 10:51.270
up to the total number of tokens in the book minus ten.

10:52.470 --> 10:52.750
Okay.

10:52.790 --> 10:56.550
And then I have some words over here and some conditions.

10:56.630 --> 11:04.110
So the way I thought about setting up this algorithm is to loop through and then basically decode the

11:04.110 --> 11:05.190
current token.

11:05.390 --> 11:12.310
And I'm stripping it so that we don't get the space in the beginning of the word and making it lowercase.

11:12.550 --> 11:18.630
Uh, because I'm, I want to also have tokens that start, for example, in the beginning of a sentence.

11:18.750 --> 11:25.950
But as you saw in the slides, this also means that we get the month of May included in this list,

11:25.950 --> 11:27.950
which is actually a bit of a mistake.

11:27.950 --> 11:29.270
That's a type two error.

11:29.830 --> 11:30.110
Okay.

11:30.150 --> 11:39.070
So here I say, um, if this token contains a contraction which indicates a negation term in English.

11:39.070 --> 11:43.960
So can't won't Shouldn't don't these kinds of words.

11:44.480 --> 11:52.360
So if that condition is met or if this condition is met, which means the current token matches one

11:52.360 --> 11:57.280
of these words, then that passes this part of the test.

11:57.280 --> 12:01.280
And also the next token starts with a space.

12:01.440 --> 12:04.240
And why do I want the next token to start with a space?

12:04.560 --> 12:12.440
That's because I want to avoid a situation like this where the letter sequence not appears, but it's

12:12.480 --> 12:14.400
actually part of a longer word.

12:14.400 --> 12:16.040
And this is just one example.

12:16.360 --> 12:25.000
So if this these three letters not is the current token, but it's actually part of a longer word like

12:25.000 --> 12:30.080
connotative then the next token will not begin with a space.

12:30.240 --> 12:32.280
So that is condition C.

12:32.760 --> 12:42.000
So if one of these two is met and this condition is met, then I change the value of this index in this

12:42.000 --> 12:43.960
vector is negation to one.

12:44.440 --> 12:47.360
So all of that together gives me.

12:48.440 --> 12:49.640
So that takes two seconds.

12:49.640 --> 12:49.840
Yeah.

12:49.880 --> 12:53.800
And that that gives us 217 negation tokens.

12:53.800 --> 12:59.600
And these are the examples I copied some of these into the slides.

12:59.600 --> 13:09.160
So for example here you see not this is showing 15 tokens before the target token and 15 tokens after

13:09.160 --> 13:11.280
the target token okay.

13:11.320 --> 13:13.600
So that is for the negation tokens.

13:13.600 --> 13:19.400
If you have a different algorithm that gives you a different number then that's very interesting.

13:19.440 --> 13:22.600
I'd be curious to hear about what you have done.

13:22.600 --> 13:25.480
You can feel free to post the description in the Q&amp;A.

13:26.040 --> 13:26.400
Okay.

13:26.440 --> 13:32.440
Oh yeah, here I am just printing out all of the negation tokens, uh, just so you can see what they

13:32.440 --> 13:32.960
look like.

13:32.960 --> 13:37.520
So not, uh, and the apostrophe t come out really often.

13:37.960 --> 13:40.320
Okay, so that was the negation tokens.

13:40.320 --> 13:43.440
Here I have the affirmation tokens.

13:43.560 --> 13:46.160
And here I'm looking for all of these words.

13:46.200 --> 13:53.200
Now this algorithm here for identifying the affirmation words, I had to come up with a slightly different

13:53.200 --> 14:00.680
algorithm because yeah, confirmatory or affirmation words just aren't exactly like the negation words.

14:01.080 --> 14:06.600
So here what I looked for is that the next token cannot contain the word not.

14:06.840 --> 14:12.080
And this would exclude something like cannot and do not and does not.

14:12.640 --> 14:19.560
And then here I have the condition similar to with the negations that the current token needs to match

14:19.560 --> 14:21.880
one of these target affirmation words.

14:21.880 --> 14:22.720
Exactly.

14:23.240 --> 14:28.720
And then also similarly the next token must be must begin with a space.

14:28.720 --> 14:34.960
And that would mean that the current token is an entire word, and not just part of a longer word.

14:35.360 --> 14:42.690
So then I say, if all of these conditions are satisfied, then I consider this token index to be an

14:42.690 --> 14:43.810
affirmation word.

14:44.290 --> 14:47.650
Again, that takes a couple of seconds to run through for this book.

14:47.850 --> 14:54.490
And that is how I got seven 178 target tokens.

14:54.490 --> 14:57.450
And here you just see a couple of those examples.

14:58.210 --> 15:03.610
So that's it for this part of the code challenge I'm going to cut the video here.

15:03.610 --> 15:08.570
I encourage you to get out of your chair, stretch your legs, have some coffee or whatever.

15:08.570 --> 15:14.530
When you feel refreshed, come back to the next video where we will continue with this code challenge.

22:11.430 --> 22:20.430
The goal of exercise three is to get the MLP activations for all of our target tokens, so that we can

22:20.430 --> 22:28.590
set up a logistic regression Classifier, you will implement the actual classifier in the next exercise.

22:28.830 --> 22:37.150
The goal here in exercise three is to create batches and push the tokens through the model to hook the

22:37.150 --> 22:38.910
MLP activations.

22:39.430 --> 22:47.270
So you want to create two batches of data, one for the negation words and one for the affirmation words.

22:47.830 --> 22:50.790
You can check the sizes of the batches.

22:51.310 --> 22:56.390
These are, however, many tokens you identified and then 101.

22:56.430 --> 23:04.470
And the idea here is that the first 90 of these tokens are the 90 tokens before each target word.

23:04.670 --> 23:06.670
And then we have the target token.

23:06.670 --> 23:10.070
And then there are ten more target tokens after that.

23:10.510 --> 23:18.990
And the reason why I set up, set it up this way is so that in every sequence here, the 91st token

23:19.190 --> 23:26.350
of every sequence will be the target word, and that is going to make things easier for grabbing the

23:26.350 --> 23:29.670
activations from those target tokens.

23:29.870 --> 23:36.830
Later on, when we start running analyses, once you have these batches, you can run forward passes

23:36.830 --> 23:45.310
through the model for each of the two batches, you want to check the sizes of the activations matrix.

23:45.470 --> 23:46.910
Here you see an example.

23:46.910 --> 23:52.750
This one is 178 by 101 by 5120.

23:53.150 --> 23:59.910
Of course, that corresponds to the number of sequences, the number of tokens, and the number of neurons

23:59.910 --> 24:02.550
in each MLP expansion layer.

24:03.390 --> 24:10.310
Now also remember that the way that I coded the hook, which might also be the way that you coded the

24:10.310 --> 24:17.510
hook, the activations dictionary, that variable gets overwritten every time there's a forward pass.

24:17.790 --> 24:19.430
So you have two options here.

24:19.550 --> 24:26.800
You can either recreate the hook so you can define the hook in a different way so that it doesn't overwrite,

24:27.000 --> 24:31.120
and instead it just appends another set of matrices.

24:31.680 --> 24:36.120
Or you can copy the activations into a different variable.

24:36.880 --> 24:41.200
Between running the two forward passes for the two different batches.

24:41.800 --> 24:44.920
Now in my opinion that was the easier solution.

24:44.920 --> 24:46.040
So that's what I did.

24:46.040 --> 24:51.840
Here you can see this variable is the activations for the affirmations word.

24:52.240 --> 24:55.680
And I have a different variable for the negations word.

24:55.880 --> 24:57.360
Again that is my solution.

24:57.360 --> 25:00.720
You can do that if you also like that approach.

25:00.720 --> 25:03.320
But you can also do it differently if you prefer.

25:04.400 --> 25:11.920
Anyway, once you have these activations matrices, you will be ready to do some analyses and visualizations,

25:12.040 --> 25:15.280
but that will come in the next exercise.

25:15.640 --> 25:21.240
For now, you should pause the video and create those batches and push them through the model.

25:21.600 --> 25:24.960
And now I will switch to code and show my solution.

25:25.760 --> 25:29.600
Here I am initializing the two batch variables.

25:29.600 --> 25:33.040
They are sequences by tokens.

25:33.080 --> 25:39.600
Now this actually says number of tokens here, but that it will correspond to the number of sequences.

25:39.600 --> 25:47.440
And the length of each sequence is the 90 tokens before the target token, the target token itself,

25:47.600 --> 25:50.360
and then the ten tokens afterwards.

25:50.800 --> 25:57.840
And because we are using these as integers, that we will input into the model that are used to select

25:58.040 --> 26:05.080
each corresponding row in the embeddings matrix, you need to make sure that these are integers or torched

26:05.080 --> 26:05.480
long.

26:06.080 --> 26:12.560
So here for the negation sequences, I'm looping over the number of negation tokens.

26:12.840 --> 26:15.240
And then I'm just grabbing one index out of here.

26:15.240 --> 26:20.120
I didn't explain this variable in a lot of detail in the previous exercise.

26:20.120 --> 26:22.160
So let me just show this to you really quickly.

26:22.560 --> 26:30.160
So this is the index into the book token sequence where we have all of the negation terms.

26:30.280 --> 26:31.280
So that's simple.

26:31.480 --> 26:34.760
So here I'm grabbing each one of those in the loop.

26:35.040 --> 26:42.720
And then I'm populating this batch for this row and all of the tokens to be the tokens from this target

26:42.760 --> 26:49.000
token minus the preceding token context to the post seeding context.

26:49.400 --> 26:53.760
So for the negation sequences and the affirmation sequences.

26:53.960 --> 26:55.320
And there we have it.

26:55.720 --> 26:55.960
Okay.

26:56.000 --> 26:56.560
Very nice.

26:56.680 --> 27:01.560
Now I am pushing the tokens through the model of course with torch.

27:01.800 --> 27:02.360
Nograd.

27:02.360 --> 27:05.480
We don't want to do any gradient related computations.

27:05.480 --> 27:09.000
We also want to make sure the model is in eval mode.

27:09.000 --> 27:14.000
So we switch off all of the regularizations and dropout and so on.

27:15.120 --> 27:15.440
Okay.

27:15.440 --> 27:19.160
Now this activations variable, that's what gets replaced.

27:19.160 --> 27:22.600
It gets overwritten when I run this line of code.

27:22.600 --> 27:29.280
So that's why I save a copy of the activations into this variable over here.

27:29.960 --> 27:36.600
So if you're running this on the CPU, this code cell will take, I don't know, a minute, two minutes,

27:36.600 --> 27:37.400
five minutes.

27:37.440 --> 27:39.840
It shouldn't be too bad on the GPU.

27:39.880 --> 27:41.400
It's several seconds.

27:41.840 --> 27:45.200
And then here I'm just printing out the keys here.

27:45.200 --> 27:53.200
So we confirm that we get the MLP activations for all of the layers in the model, and then just picking

27:53.200 --> 27:59.160
one at random just to show the shape of the shape is the same for every layer.

28:00.080 --> 28:02.720
Now for the logistic regression.

28:03.080 --> 28:10.080
The goal here is to test for negation word tuning in all of the neurons from one layer.

28:10.640 --> 28:12.560
I picked layer 13.

28:12.600 --> 28:14.250
You can pick any other layer.

28:14.250 --> 28:15.250
It doesn't matter.

28:15.290 --> 28:22.450
Actually, in the next exercise, you will expand your analysis to look for neurons in all of the layers.

28:22.650 --> 28:30.370
So this exercise is really just about developing and inspecting the results for one layer for simplicity.

28:31.170 --> 28:37.610
Now you can create the same two visualizations as we did in the previous videos.

28:38.010 --> 28:44.050
And I recommend finding and copying that code and then modifying it as necessary.

28:44.250 --> 28:50.770
This is a really interesting example neuron where the classification is really, really high.

28:51.330 --> 28:58.890
So there are these are the probabilities coming from the logistic regression model for all of the affirmation

28:58.890 --> 29:02.730
words over here, and the negation words up here.

29:03.050 --> 29:10.250
By the way, this neuron that I'm showing here, this was the neuron that had the maximum positive beta

29:10.250 --> 29:10.850
value.

29:10.890 --> 29:12.330
You can actually see it here.

29:12.330 --> 29:13.850
It's this one over here.

29:14.090 --> 29:21.050
So that means to create this plot, you just need to find the neuron that had the largest beta value

29:21.050 --> 29:28.450
and then grab its data again and rerun the logistic regression to generate the predictions for each

29:28.450 --> 29:30.290
of the target tokens.

29:30.970 --> 29:33.010
Now for this exercise here.

29:33.050 --> 29:39.690
Exercise four you can just focus on coding the analysis and generating these two plots.

29:39.730 --> 29:46.810
We're going to do some additional visualizations including text heatmaps in the next exercise.

29:47.410 --> 29:47.770
Okay.

29:47.810 --> 29:51.610
So pause the video and enjoy working through this exercise.

29:51.730 --> 29:56.450
And now I will switch to code for the logistic regression.

29:56.450 --> 30:00.450
We need a vector of category labels.

30:00.450 --> 30:03.010
So a bunch of zeros and a bunch of ones.

30:03.050 --> 30:09.890
And we're going to use that vector of category labels multiple times throughout the rest of this code

30:10.050 --> 30:11.930
challenge, so I'm creating it here.

30:11.970 --> 30:19.490
Call it category labels and it is zeros for the number of affirmation tokens and ones for the number

30:19.490 --> 30:21.250
of negation tokens.

30:21.850 --> 30:25.570
As I have discussed in I think it was the previous video.

30:26.090 --> 30:33.370
It doesn't really matter which order you do it in, so you could have the negation tokens be zeros and

30:33.370 --> 30:35.730
the affirmation tokens be ones.

30:35.930 --> 30:38.290
That doesn't change any of the statistics.

30:38.290 --> 30:40.330
It doesn't change the significance.

30:40.450 --> 30:47.650
The only thing it changes is the sign of the beta values, the sign of the of the model parameters.

30:48.050 --> 30:53.850
So if it's a positive beta, that means more activation for negation tokens.

30:54.090 --> 30:59.210
If it's a negative beta it means more activation for affirmation tokens.

30:59.850 --> 31:02.170
Okay, so uh, run that.

31:02.170 --> 31:08.130
And yeah, as I mentioned for this exercise, we just want to focus on one layer just to keep things

31:08.260 --> 31:08.740
simple.

31:09.780 --> 31:17.340
Okay, this is just some confirmation to make sure that I was really getting the correct token.

31:17.340 --> 31:25.580
So looking at token index from these batches token index context pre that basically just get, you know,

31:25.620 --> 31:30.900
skips past all of the preceding contextual tokens.

31:31.060 --> 31:40.140
And this just confirms that I'm getting the word not from the negations and the word uh from the affirmations.

31:40.780 --> 31:48.100
So that means when I use this variable context pre as an index into the activations, I can be confident

31:48.100 --> 31:51.180
that I am getting the correct target tokens.

31:51.700 --> 31:58.660
Okay, here I am gathering up all of the data and running the logistic model.

31:58.820 --> 32:01.900
Okay, so I have a loop over all of the neurons.

32:01.900 --> 32:03.380
All 5000 neurons.

32:03.700 --> 32:06.820
Here is where I'm gathering up all of the data.

32:06.940 --> 32:12.660
So you can see it's from I call this variable targets for targets and comps for comparison.

32:13.380 --> 32:18.500
So this is the negations activations from this particular layer.

32:18.500 --> 32:24.860
And we have all the batches this token index and this particular neuron index.

32:24.980 --> 32:27.860
So that's for the negations and the affirmations.

32:28.300 --> 32:30.340
This code you have seen before.

32:30.380 --> 32:38.100
I'm running statsmodels logit for the logistic regression I input the dependent variable here which

32:38.100 --> 32:39.700
is the category labels.

32:39.700 --> 32:45.660
And then I have the data here which is the comparison and the targets.

32:45.660 --> 32:49.380
So that would correspond to labels zero and one.

32:49.860 --> 32:53.700
And this is kind of new here I think I had disp equals zero before.

32:53.700 --> 33:01.100
This just suppresses the output of the function basically because we're running 5000 of these things.

33:01.100 --> 33:04.740
So I don't need to just have this printed out multiple times.

33:05.620 --> 33:14.700
this max Iter basically increases the maximum number of iterations for this iterative, nonlinear,

33:14.700 --> 33:20.100
model fitting approach to fit the data up to 3000 iterations.

33:20.460 --> 33:23.900
The default, I believe, is 30 or 40, something like that.

33:24.260 --> 33:31.260
So in case the parameters can be estimated, but the model just needs a couple of more iterations.

33:31.260 --> 33:33.100
And that's what this is for.

33:33.420 --> 33:39.980
And then I have this whole thing encased in a try except command statement.

33:39.980 --> 33:46.820
And basically that's because sometimes the model fit just really doesn't work at all because the data

33:46.820 --> 33:49.940
are just there's outliers or it's perfect separability.

33:50.500 --> 33:51.900
And this can crash.

33:52.060 --> 33:59.100
So if this crashes then I just want to leave the matrices the values as Nans.

33:59.420 --> 34:04.750
And if it doesn't crash which happens nearly all the time, it only crashes every once in a while.

34:05.190 --> 34:09.750
So if it does crash, then the results will be Nan.

34:09.790 --> 34:10.230
That's good.

34:10.230 --> 34:11.550
We can ignore them later.

34:11.910 --> 34:13.750
If it doesn't crash.

34:13.750 --> 34:21.550
If everything goes well, then these nans get replaced with the p value here and the beta value over

34:21.550 --> 34:21.990
here.

34:22.510 --> 34:24.790
This is a single parameter model.

34:24.790 --> 34:31.630
It just has a one parameter for the category label and then one parameter for the constant.

34:31.870 --> 34:36.470
The constant or the intercept is the first variable in the model.

34:36.470 --> 34:40.910
So that would be with index zero as I mentioned before.

34:40.950 --> 34:42.430
So just a quick reminder.

34:42.550 --> 34:47.030
We generally do not care about the constant or the intercept term.

34:47.310 --> 34:53.790
All that does is tell us whether the average activation is different from zero.

34:54.390 --> 35:01.110
So really what we want is the slope which is the second term, the second beta term.

35:01.470 --> 35:01.710
Okay.

35:01.750 --> 35:03.190
So I can run all that.

35:03.190 --> 35:06.550
And then here this is all code you have seen.

35:06.990 --> 35:13.190
So basically we see that there's a lot of statistically significant neurons here.

35:13.470 --> 35:14.790
Now what does this mean.

35:14.950 --> 35:20.670
This tells us that the model was statistically significant for all of these neurons.

35:20.670 --> 35:22.150
All of these neurons up here.

35:22.430 --> 35:27.350
Remember that we have a comparison between two categories.

35:27.510 --> 35:36.550
So red or positive beta means that the neuron had more activation for negation tokens compared to affirmation

35:36.550 --> 35:37.350
tokens.

35:37.510 --> 35:39.630
And green indicates the opposite.

35:39.630 --> 35:46.950
So there were more there were stronger activation, more positive activations for negation of affirmation

35:46.950 --> 35:49.510
tokens compared to negation tokens.

35:49.910 --> 35:54.470
And I'm not actually counting these, but it looks like it's roughly balanced.

35:54.470 --> 36:01.870
So it kind of looks like there's approximately as many negation tuned neurons as there are affirmation

36:01.870 --> 36:02.950
tuned neurons.

36:03.350 --> 36:05.350
Now this is a direct comparison.

36:05.350 --> 36:07.110
So what we do not know.

36:07.150 --> 36:14.830
What we cannot say about these neurons is that they only care about negation or affirmation and nothing

36:14.830 --> 36:15.270
else.

36:15.430 --> 36:22.830
For all we know, these neurons respond a lot to like football and bottled water, or like any other

36:22.870 --> 36:24.710
random categories of tokens.

36:24.710 --> 36:33.470
The only thing we know for sure is that there is a significant difference in activation values across

36:33.470 --> 36:40.830
the 400 tokens that we are using here for negation versus affirmation target tokens.

36:41.310 --> 36:41.590
Okay.

36:41.630 --> 36:47.310
And then here what I'm doing is just grabbing the the maximum beta.

36:47.310 --> 36:49.750
So it's index 2022.

36:49.790 --> 36:51.310
So it's this one up here.

36:51.470 --> 36:54.630
This one had the largest beta value.

36:54.790 --> 36:57.030
And that looks like this one over here.

36:57.430 --> 37:03.710
Interestingly this is not the most significant one in terms of the smallest p value, but it is the

37:03.710 --> 37:05.990
one with the largest beta coefficient.

37:06.990 --> 37:08.350
And why is that the case?

37:08.430 --> 37:15.950
Well, the p value is based on a number of factors, including the sample size and the variability and

37:15.950 --> 37:16.470
so on.

37:16.590 --> 37:23.830
So simply having a larger parameter does not necessarily mean that the p value will be smaller.

37:24.310 --> 37:26.110
That is often the case.

37:26.110 --> 37:31.190
This is a much deeper discussion into inferential statistics.

37:31.190 --> 37:39.830
But uh, it often can be the case that larger uh magnitude effects have smaller p values, but it is

37:39.830 --> 37:41.670
not trivially the case.

37:42.150 --> 37:42.390
Okay.

37:42.430 --> 37:47.030
Anyway, we are going to continue working with this one, uh, with this neuron later.

37:47.310 --> 37:54.070
The last thing that I'm going to do is generate the predictions and calculate accuracy.

37:54.670 --> 38:01.840
So now I've already extracted all of these activations here inside the for loop, but at each.

38:01.880 --> 38:02.640
Iteration.

38:02.640 --> 38:07.240
Inside the for loop, these variables get replaced, they get overwritten.

38:07.240 --> 38:14.320
So if I want to do a detailed analysis for one particular neuron, I need to go back to this for loop,

38:14.360 --> 38:17.280
basically to this code and rerun this.

38:17.280 --> 38:23.120
But not for each individual neuron, but only the one that I'm specifically interested in.

38:23.560 --> 38:25.400
And that is what I do here.

38:25.560 --> 38:33.040
So here I get the targets, the comparison activations, and I rerun the logistic regression model exactly

38:33.040 --> 38:35.200
as I did earlier in that for loop.

38:35.200 --> 38:41.360
But this is just for this one neuron that shows the maximum response okay.

38:41.720 --> 38:43.400
And then I use results.

38:43.600 --> 38:48.000
So result is the output of SM dot logit dot fit.

38:48.360 --> 38:50.320
And then I get the predictions.

38:50.520 --> 38:59.480
And remember that this is the probabilities of each token being an affirmation token if the probability

38:59.480 --> 39:05.120
is close to zero, or a negation token if the probability is close to one.

39:05.480 --> 39:14.760
So I use 0.5 as the threshold, and I say if those match the actual category label, then that is the

39:14.760 --> 39:15.680
accuracy.

39:15.800 --> 39:18.200
So this would be the per token accuracy.

39:18.320 --> 39:25.280
And then to get the overall accuracy you would average across all of these elements here okay.

39:25.320 --> 39:27.320
And then finally the visualization.

39:27.320 --> 39:32.080
This is all code you have seen before in the previous video.

39:32.880 --> 39:38.480
Exercise five is not so difficult in terms of writing new code.

39:38.760 --> 39:44.720
So you can spend your time thinking about what the results mean, how we set up the analysis, what

39:44.720 --> 39:47.800
might be other ways to implement this analysis?

39:48.280 --> 39:49.960
The goal here is simple.

39:49.960 --> 39:56.800
Just find that best predicting neuron that you identified in the previous exercise and create a heat

39:56.840 --> 39:59.120
map with its activations.

39:59.760 --> 40:08.040
Now for this visualization, I used a smaller context window just so we don't have to see all 90 tokens

40:08.040 --> 40:10.200
preceding each target token.

40:10.720 --> 40:18.240
So here in each line you see for example, not not not not not there's a lot of knots nor here.

40:18.240 --> 40:21.600
These are all the target tokens wouldn't uh and so on.

40:21.840 --> 40:28.800
And as you know from other videos, I just arbitrarily set the color here to be 0.1 for all of these

40:28.800 --> 40:35.600
tokens so that you can experience the joy of discovering what the actual results look like when you

40:35.640 --> 40:37.000
code this up yourself.

40:37.520 --> 40:44.400
And as you are considering the results, I would like you to think about how we set up the analysis,

40:44.560 --> 40:51.840
what the logistic regression really identifies, and if you have any ideas for how you might change

40:51.840 --> 40:54.810
the analysis or do something differently.

40:54.810 --> 41:01.170
If you were doing this code challenge, for example, as like a four month long research project.

41:02.290 --> 41:05.170
Okay, so now you can pause the video and get to work.

41:05.330 --> 41:09.130
And now I will discuss my solution and my thoughts.

41:10.690 --> 41:17.250
Here I am grabbing the negation activations from the maximum beta neuron.

41:17.370 --> 41:20.130
In fact, I already calculated this variable above.

41:20.170 --> 41:21.490
But here it is again anyway.

41:21.850 --> 41:29.810
Okay, and here I'm just min max scaling this neurons activation so that we can use it as an index into

41:29.810 --> 41:30.850
the Colormap.

41:31.250 --> 41:32.850
This code here you've seen before.

41:32.890 --> 41:37.930
This is just identifying the width of a letter in Monospace.

41:38.370 --> 41:42.250
And yeah there's not much I can show here that's new.

41:42.610 --> 41:47.850
The main thing that's different that you haven't seen before is just this for loop here.

41:47.850 --> 41:52.570
So instead of looping over all of the tokens in each batch.

41:52.610 --> 41:55.930
I'm just looping over from the preceding five.

41:55.930 --> 41:58.730
So this was 90.

41:58.770 --> 42:02.890
We have the preceding context of 90 and then we have the target token.

42:03.010 --> 42:07.970
So now I'm just going to show a handful of tokens before instead of showing all of them.

42:07.970 --> 42:10.210
That would just make a really long line.

42:10.570 --> 42:15.450
And then I'm also just showing the first 20 batches in the sequence.

42:15.890 --> 42:16.210
Okay.

42:16.250 --> 42:18.290
So here we see what this looks like.

42:18.370 --> 42:20.010
So this looks pretty nice.

42:20.010 --> 42:26.130
What we are looking for here again is uh, the words uh not and contractions.

42:26.130 --> 42:34.170
So we do see that there are more active or relatively strong activations for not not not not neither

42:34.210 --> 42:42.530
not this one also shows pretty similar level of activation for enough compared to neither and not pretty

42:42.530 --> 42:43.250
interesting.

42:43.450 --> 42:50.850
This one is also interesting because we see strong activations for the apostrophe t compared to the

42:50.850 --> 42:53.690
couldn't or without the apostrophe t.

42:55.090 --> 42:55.410
Yeah.

42:55.410 --> 42:58.930
So overall I think this looks fairly compelling.

42:59.250 --> 43:06.930
But we do also see very strong activations for tokens that are not really related to negation, like

43:06.930 --> 43:10.690
rusty and dead at the end of corroded.

43:10.690 --> 43:14.450
Although I suppose corroded does have kind of a negative connotation.

43:15.090 --> 43:22.610
Out is not really a negation term, although again, you know, pass out maybe does have some negative

43:22.610 --> 43:23.650
connotation.

43:23.890 --> 43:32.050
So it looks like we do get some specificity for the tokens that we are looking for, but we also get

43:32.050 --> 43:35.450
some activations for other tokens as well.

43:35.810 --> 43:43.450
One thing to keep in mind is that we did not select for neurons that show strong activations to negation

43:43.450 --> 43:47.290
words, and low activations to all the other tokens.

43:47.340 --> 43:54.900
In fact, the analysis has nothing to do with the tokens like evidence and Commissioner, these tokens

43:54.900 --> 43:57.540
never entered the analysis.

43:57.540 --> 43:58.900
The logistic regression.

43:59.140 --> 44:06.900
The logistic regression only had two sets of tokens the negation tokens and the affirmation tokens.

44:07.060 --> 44:11.060
Now, I'm not plotting here all or any of the affirmation tokens.

44:11.180 --> 44:12.900
If you would like, you can do that.

44:12.900 --> 44:20.700
That could be interesting to look through the affirmation tokens for this same neuron, and maybe you

44:20.700 --> 44:25.900
would want to print those out using blue color map instead of red color map.

44:27.220 --> 44:35.780
Now for the final exercise in this code challenge, take the code that you wrote for exercise five and

44:35.780 --> 44:37.060
embed it in a for.

44:37.060 --> 44:39.140
Loop over all the layers.

44:39.780 --> 44:46.700
As you're going through each layer, there are several statistical quantities that you want to extract

44:47.060 --> 44:54.460
first is the percent of neurons that have a statistically significant beta coefficient.

44:55.100 --> 45:00.900
So you'll need to get and store the p value from each test on each neuron.

45:01.500 --> 45:09.820
And as I've discussed in previous videos, you should also use a corrected p value threshold by correcting

45:09.820 --> 45:12.620
for the number of neurons in each layer.

45:13.060 --> 45:19.460
You can do it simply through Bonferroni correction if you that is, dividing by the number of neurons.

45:19.620 --> 45:21.340
That's what I do in my solution.

45:21.660 --> 45:27.780
If you are more comfortable with statistics, you can also do something like FDR correction.

45:29.260 --> 45:35.940
Next, you also want to calculate the prediction accuracy from all of the neurons.

45:36.380 --> 45:41.660
And when you're finished your for loop you can generate two scatter plots that will look like this.

45:42.060 --> 45:47.500
In both cases, the x axis, is the layer or the transformer block.

45:47.820 --> 45:56.140
And remember that zero is the first layer after the embeddings, and 36 is the final transformer block

45:56.260 --> 45:58.260
before the embeddings.

45:58.780 --> 46:06.300
And what I'm plotting over here on the left is the percent of significant logistic regressions in each

46:06.300 --> 46:06.900
layer.

46:07.460 --> 46:14.380
So this is the number of neurons that had a beta coefficient with a corresponding p value below the

46:14.380 --> 46:16.020
significance threshold.

46:16.500 --> 46:22.260
You can see from the y axis that this is going to range from around 25 to 70.

46:22.740 --> 46:29.540
And the question is whether it's just kind of randomly scattered or whether the significance count goes

46:29.700 --> 46:35.580
up or down, or maybe some other kind of non-linear pattern as a function of the layer.

46:36.220 --> 46:43.100
So this plot on the left is just about how many neurons have any beta coefficient that is statistically

46:43.100 --> 46:43.900
significant.

46:44.340 --> 46:50.380
And then over here on the right, I have actually two scatter plots in the same axis.

46:50.860 --> 46:54.060
Both of them show the prediction accuracy.

46:54.500 --> 46:58.900
And there are red dots to show the results for all of the neurons.

46:59.060 --> 47:04.060
So the prediction accuracy averaged over 5000 neurons in each layer.

47:04.380 --> 47:11.860
And the green squares show only the neurons that had a significant positive beta coefficient.

47:12.100 --> 47:18.780
So that means that this is averaging over the neurons if the beta coefficient was positive.

47:19.020 --> 47:25.060
And also if the p value was less than the threshold.

47:25.300 --> 47:32.060
And again, it will be interesting to see what kinds of patterns there are across the layers, if there

47:32.060 --> 47:33.460
are any patterns at all.

47:33.860 --> 47:35.140
Now here's a little tip.

47:35.140 --> 47:43.350
When averaging the accuracies for only a subset of neurons where the beta values were positive and significant.

47:43.790 --> 47:52.790
You can use the numpy function numpy dot dot where the ma here is for masked array.

47:53.350 --> 47:58.830
I'm sure this is not the only way to do this selection, but I found this function pretty useful and

47:58.830 --> 48:00.070
perhaps you will too.

48:01.070 --> 48:06.550
Okay, so please now pause the video and enjoy wrapping up this code challenge.

48:06.750 --> 48:10.350
And now I will show my solution and discuss my results.

48:11.230 --> 48:18.750
A lot of the code here, at least in this first code cell, is code you've seen before in exercise five.

48:19.110 --> 48:26.030
Here I'm initializing three matrices of p values, beta values and accuracies.

48:26.070 --> 48:27.310
Average accuracies.

48:27.830 --> 48:33.430
These two I'm initializing to be zeros, and the p values I'm initializing to be ones.

48:33.870 --> 48:42.270
And the reason for this is that if the logistic regression model doesn't work well if it crashes or

48:42.430 --> 48:44.190
yeah, it just doesn't give a good solution.

48:44.430 --> 48:51.270
Then I actually want the p value to be initialized as a one, so that I can ignore it in the selection

48:51.270 --> 48:55.550
procedure in the in the visualization after this loop.

48:56.510 --> 48:56.790
Right.

48:56.830 --> 49:00.270
So here I'm looping over all of the layers in the model.

49:01.110 --> 49:07.990
And then within each layer I loop over all of the neurons, grab their activations, build the model.

49:07.990 --> 49:10.910
And all of this code you have seen before.

49:11.310 --> 49:12.630
This code is new.

49:12.670 --> 49:15.190
This line of code is kind of new.

49:15.230 --> 49:17.550
I mean, you've seen this code before.

49:17.550 --> 49:20.790
This just wasn't inside the loop over neurons.

49:20.790 --> 49:24.110
So now I'm calculating the accuracy for each neuron.

49:24.110 --> 49:27.910
This gets the accuracy for each neuron and each token.

49:28.230 --> 49:30.550
And then I average those together.

49:30.750 --> 49:33.950
This gives me a proportion with the mean.

49:33.950 --> 49:38.030
And then I'm multiplying it by 100 just to scale up to percent.

49:38.590 --> 49:45.790
This code takes several minutes, and so I'm printing out just some update information here as it goes

49:45.790 --> 49:52.030
through each layer here in this cell is where I do the visualization.

49:52.150 --> 50:00.030
So here I'm creating masks to identify, uh, the beta values that have significant p values.

50:00.150 --> 50:02.030
So that is here the p value mask.

50:02.030 --> 50:08.110
Where are the p values less than 0.05 divided by the number of neurons.

50:08.110 --> 50:11.470
So this is Bonferroni correcting within each layer.

50:11.790 --> 50:18.150
It's an extremely strict p value threshold by the way because this is 5120.

50:18.190 --> 50:20.950
So the p value needs to be really really small.

50:20.990 --> 50:25.350
The effect needs to be really significant for it to show up here.

50:25.710 --> 50:28.390
And then here is for the positive betas.

50:28.390 --> 50:29.710
That one's a little bit simpler.

50:30.110 --> 50:39.400
Now uh, I find this somewhat confusing that uh, in this numpy function for masked array, the mask

50:39.440 --> 50:45.560
actually gets flipped, so it masks out where something is true and it preserves where something is

50:45.560 --> 50:46.120
false.

50:46.560 --> 50:52.760
I don't know what you think, but in my opinion, that is totally opposite of the way that I think about

50:52.760 --> 50:53.440
masks.

50:53.760 --> 51:00.360
So if you define the masks to be the thing that you're looking for, the qualities that you are looking

51:00.360 --> 51:08.280
for in a matrix or vector, then you actually need to invert that mask in order for it to apply in such

51:08.280 --> 51:14.560
a way that you actually get the values that you are looking for that fit into this mask.

51:15.640 --> 51:15.960
Okay.

51:16.000 --> 51:18.080
So that is that's for that.

51:18.120 --> 51:27.400
And then here I'm plotting here is the average of the p value mask over axis one which is the layer

51:27.600 --> 51:28.080
axis.

51:28.120 --> 51:28.720
I don't know sorry.

51:28.760 --> 51:30.600
This is the neuron axis.

51:30.600 --> 51:34.880
So we're averaging over all the neurons within each layer.

51:34.880 --> 51:37.480
And that's how I get the average accuracy.

51:37.800 --> 51:43.000
And then or the average number of neurons that showed a significant result.

51:43.000 --> 51:45.640
And then I multiply that by 100.

51:45.680 --> 51:48.400
Again that's just to scale up to percent.

51:48.800 --> 51:56.120
And then over here I'm averaging accuracy and masked accuracy, which is just the accuracy where the

51:56.160 --> 52:01.040
p value was significant and the beta value was positive.

52:01.920 --> 52:05.480
So here is what that result looks like.

52:05.760 --> 52:13.320
And we see in all of these cases, the number or the percent of significant neurons that showed a significant

52:13.840 --> 52:21.320
logistic regression decreased pretty steeply by a factor of two from 70 or even over two from almost

52:21.320 --> 52:22.480
70%.

52:22.480 --> 52:31.080
So in the early layers of this transformer, almost 70% like two thirds of the neurons showed a significant

52:31.120 --> 52:39.720
difference in Activation between negation and affirmation token words, and then by the end it drops

52:39.720 --> 52:44.400
down to less than a third, maybe a little bit over a quarter of the neurons.

52:44.440 --> 52:47.040
Now that's still a pretty significant percentage.

52:47.040 --> 52:50.560
That's around 1000 neurons out of 5000.

52:50.720 --> 52:57.560
That still shows some kind of statistically significant difference in activation between the category

52:57.560 --> 53:02.800
of negation words and the category of affirmation words, at least in this book.

53:03.280 --> 53:05.720
But it is certainly quite a bit lower.

53:06.160 --> 53:10.640
As for the prediction accuracy, we see that on average.

53:10.640 --> 53:13.200
So this is not the best performing neuron.

53:13.200 --> 53:15.520
It's also not the worst performing neuron.

53:15.880 --> 53:21.440
This is the average of all of the neurons and also all the significant positive neurons.

53:21.720 --> 53:32.930
The prediction accuracy was fairly high again going up to almost 80% close to 75% in the early layers

53:32.930 --> 53:36.730
and going down to 65% around two thirds.

53:36.930 --> 53:39.250
Prediction accuracy later on.

53:39.410 --> 53:44.330
Now the chance level performance here would be 50%.

53:44.450 --> 53:53.250
So numbers above around 50 or maybe a little bit over 50 are indicating some pretty decent predictability.

53:53.530 --> 53:58.130
Now the reason why the all of the tests here the red dots is lower.

53:58.170 --> 54:04.490
That's pretty trivial because here I'm also including into the average these neurons where there was

54:04.490 --> 54:10.690
significant prediction, and also neurons that were not statistically significant.

54:10.810 --> 54:16.050
And so their prediction accuracy, we would expect to be somewhere around 50%.

54:16.290 --> 54:20.170
So in fact, this is not really a terribly useful thing to show.

54:20.170 --> 54:21.930
But I think it's nice.

54:21.930 --> 54:30.410
Anyway, just as a way to practice your coding skills and, uh, working with masked matrices.

54:31.650 --> 54:32.770
Now, why is this the case?

54:32.770 --> 54:36.490
I just want to say one quick word about interpreting this effect.

54:36.810 --> 54:43.810
Remember that as these token embeddings vectors pass through the model, they go from one transformer

54:43.810 --> 54:45.010
block to the next.

54:45.410 --> 54:48.570
What's happening inside each transformer block?

54:48.610 --> 54:57.010
As we get a little bit of a modification to the vector from the attention and from the MLP sublayers,

54:57.370 --> 55:04.450
is that the model shifts from transforming the current token to making a prediction about the next token.

55:04.850 --> 55:11.170
So in the beginning of the model, the transformer is really like thinking a lot about this token.

55:11.210 --> 55:15.050
The token not and can't and isn't and shouldn't.

55:15.450 --> 55:22.730
And the later you get into the model, the more the model is not processing that token in particular,

55:22.730 --> 55:30.890
but thinking about what the next token should be based on this token and all the tokens that preceded

55:30.890 --> 55:31.210
it.

55:31.970 --> 55:39.810
Just as a meta comment here, we're not even finished the first mech Interp section, and I think you're

55:39.810 --> 55:47.330
already starting to see that this kind of research is challenging for many reasons, including the complexity

55:47.330 --> 55:52.010
of the models and the complexity of language human written language.

55:52.410 --> 55:58.530
On the other hand, I actually enjoy that challenge, that difficulty, and I hope that you are also

55:58.530 --> 55:59.490
enjoying it.

55:59.850 --> 56:07.610
This complexity also means that it's difficult to blindly trust the outcome of any random statistical

56:07.610 --> 56:13.850
analysis, in terms of just looking at how many parameter estimates have a small p value.

56:14.210 --> 56:21.170
You really need to check the results carefully to make sure that any interpretation you make is valid,

56:21.170 --> 56:24.970
correct, and consistent with what the data are really showing.

56:25.610 --> 56:32.290
And just to be clear, as long as you don't have any coding bugs, the statistics themselves are never

56:32.290 --> 56:32.850
wrong.

56:33.210 --> 56:38.010
Statistics is just math, and the math doesn't do things right or wrong.

56:38.250 --> 56:47.130
But the way that someone uses a particular statistical analysis may not reveal exactly the results that

56:47.130 --> 56:48.530
they are looking for.

56:48.970 --> 56:50.850
And that is the tricky part.

56:51.410 --> 56:57.930
Anyway, I'm sure that you put in a lot of work and effort into this code challenge, and the good news

56:57.930 --> 57:04.730
is that all of that work will pay off in the next code challenge, where we will basically just adapt

57:04.770 --> 57:07.890
this code to look at the attention sublayer.

58:18.100 --> 58:23.460
This is the continuation of the code challenge we started in the previous video.
