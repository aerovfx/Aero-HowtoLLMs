WEBVTT

00:02.680 --> 00:08.200
This code challenge is a direct follow up to the previous code challenge.

00:08.440 --> 00:15.480
You definitely need to have solved the previous code challenge before doing this one, or at least be

00:15.480 --> 00:17.880
familiar with my code solution.

00:18.360 --> 00:26.840
In fact, this code challenge here is almost the same thing, except that you will analyze the neurons

00:26.960 --> 00:29.240
instead of the MLP neurons.

00:30.000 --> 00:38.400
So exercise one is actually just copying exercises one through three from the previous code challenge.

00:38.880 --> 00:46.520
In fact, what I recommend doing is making a copy of the previous code challenge notebook file and then

00:46.520 --> 00:49.320
modifying and deleting things from that notebook.

00:49.720 --> 00:56.920
For one thing, you don't need any of the visualizations from exercises one through three, so you can

00:56.920 --> 00:58.240
get rid of all of those.

00:58.720 --> 01:06.780
Of course, the main change here is to modify the hook functions so that you get the qkv activations

01:06.780 --> 01:14.980
instead of the MLP expansion layer activations, and make sure you get the pre attention activations.

01:15.700 --> 01:18.780
I don't think you'll have difficulties with this code challenge.

01:18.900 --> 01:26.180
I will now switch to code, but only briefly just to discuss the changes that I made to hook the Qkv

01:26.220 --> 01:27.300
activations.

01:28.260 --> 01:29.780
Here I import here.

01:29.780 --> 01:32.260
I call this exercise one A.

01:32.460 --> 01:39.540
So that was exercise one from the previous code challenge getting GPT two large, putting it on the

01:39.540 --> 01:40.180
GPU.

01:40.220 --> 01:45.460
Although as I mentioned for the previous code challenge, you don't really need the GPU here.

01:45.460 --> 01:47.500
It's fine also to use the CPU.

01:48.100 --> 01:52.060
So here is where I define the function to create the hooks.

01:52.140 --> 01:59.620
You can see that instead of grabbing the MLP layer, I'm grabbing the attention layer and then C attention.

01:59.760 --> 02:08.080
These are the variables immediately before they get pushed through the attention equation.

02:08.440 --> 02:15.080
So if you want the post attention numbers, then you will need to explicitly run through the attention

02:15.440 --> 02:16.400
equation.

02:16.400 --> 02:21.000
So this output here is the output of this multiplication.

02:21.000 --> 02:29.560
Here this linear layer which is the q, v and k vectors for the tokens that you push through the model

02:29.600 --> 02:31.120
pre attention.

02:31.320 --> 02:31.560
Okay.

02:31.600 --> 02:32.520
So that's that.

02:32.800 --> 02:37.360
And then yeah here is uh here I call this exercise one b.

02:37.400 --> 02:40.480
This was exercise two in the previous video.

02:40.520 --> 02:42.200
I changed nothing here.

02:42.240 --> 02:43.840
This is all exactly the same.

02:44.360 --> 02:49.400
Uh all I did was delete the printing out, uh, of the examples.

02:49.840 --> 02:55.400
And then exercise one c here was exercise three from the previous video.

02:55.440 --> 03:02.860
Again, I didn't change anything except to just preserve the conformation of the shapes.

03:02.900 --> 03:10.860
Now, of course, the sizes here are different because the MLP layers have that four x expansion, whereas

03:10.860 --> 03:20.580
here we only have A3X expansion corresponding to the q, the k and the v vectors all being concatenated

03:20.580 --> 03:22.900
into one wide matrix.

03:24.100 --> 03:26.380
Now for exercise two.

03:26.780 --> 03:32.220
This is very similar to exercise six from the previous code challenge.

03:32.660 --> 03:37.820
Of course, we're working with the Qvq matrix instead of the MLP matrix.

03:38.340 --> 03:45.540
You can run the analyses on the concatenated matrix that contains all of the qvq neurons.

03:45.980 --> 03:53.220
And then for visualization, you want to separate the neurons into their three different matrices.

03:54.060 --> 04:00.880
Now remember that in the previous code challenge that you showed the accuracy for all the neurons,

04:00.880 --> 04:07.480
and separately for only the neurons with the positive betas here, because we're already plotting three

04:07.480 --> 04:14.400
different things for the three different matrices, you can just focus on the accuracy from the neurons

04:14.400 --> 04:19.200
that have a statistically significant positive beta value.

04:20.040 --> 04:27.440
Another thing that I would like you to do here is to use the PyTorch method split to separate the results

04:27.440 --> 04:29.400
into the three matrices.

04:29.960 --> 04:36.720
So just to make sure that this part is really clear, remember that the open AI models have the queries,

04:36.720 --> 04:43.240
the keys, and the values matrices all concatenated into one wide matrix.

04:43.480 --> 04:51.640
But for this visualization, you want to split that concatenated matrix into three separate matrices.

04:52.800 --> 04:57.680
There are several ways that you can do this, including just simple indexing and slicing.

04:57.680 --> 04:57.820
Thing.

04:58.180 --> 05:03.740
However, there is a method on PyTorch tensors called dot split.

05:04.180 --> 05:08.580
It's a pretty handy function to know about and to be comfortable using.

05:08.580 --> 05:14.020
So I would like you to use this method to split these matrices for this exercise.

05:14.900 --> 05:18.180
Okay, so I hope you enjoy working through this exercise.

05:18.340 --> 05:23.620
Of course, you should not just run the code and look at the plots, but think about the differences

05:23.620 --> 05:28.780
between what you saw here and what you saw in the previous code challenge.

05:29.220 --> 05:36.460
In fact, it's probably a good idea to leave the notebook file from the previous video open so that

05:36.460 --> 05:42.460
you can easily compare the two sets of results for the two different populations of neurons.

05:43.100 --> 05:45.220
Okay, and now I will switch to code.

05:46.260 --> 05:52.180
These first two code cells here are literally copy pasted up, not literally copy pasted.

05:52.180 --> 06:00.760
I did change the MLP to attention, but otherwise it's it's basically the same as in the previous code

06:00.760 --> 06:01.560
challenge.

06:01.960 --> 06:05.440
And then over here most of this code is the same.

06:05.640 --> 06:07.520
This code is new here.

06:07.760 --> 06:14.160
Now the method split is a method that operates on PyTorch tensors.

06:14.400 --> 06:21.800
It does not operate on numpy arrays or Python lists or dictionaries or any other kind of variable.

06:21.920 --> 06:24.480
It's really just on PyTorch tensors.

06:24.600 --> 06:33.440
So to get this to work, you actually need to first convert this masked array matrix into a PyTorch

06:33.440 --> 06:40.240
tensor, and only then can you use the split method on that tensor.

06:40.480 --> 06:48.200
So that was actually one of my goals for this exercise was to get you to, uh, know about this method,

06:48.200 --> 06:54.000
but also appreciate that there are times when there are certain methods or functions that are really

06:54.000 --> 07:00.100
handy to use, but you need to do a data type conversion in order to be able to use them.

07:00.660 --> 07:08.540
Okay, so the way that you use this split method is to provide at least one input and possibly two.

07:09.100 --> 07:15.780
And the first input is the number of rows or the number of elements that you want to split by.

07:16.060 --> 07:25.020
In this case, it's n dimension, because this matrix here is embeddings times three for the q, k and

07:25.020 --> 07:26.500
v matrices.

07:26.740 --> 07:35.220
And then you need to specify the dimension along which you want to split the one input into however

07:35.220 --> 07:36.700
many it ends up being.

07:37.220 --> 07:44.980
So this matrix is has the number of columns corresponding to n embed times three.

07:45.180 --> 07:48.380
So that's why the first input is n embed.

07:48.380 --> 07:54.700
And then because we're separating by columns which are the second dimension I write dim equals one.

07:54.700 --> 07:57.320
And that gives me the three matrices.

07:57.360 --> 07:59.800
Pretty handy function to be familiar with.

08:00.280 --> 08:02.280
Okay, so now we see the results.

08:02.440 --> 08:10.560
And they look overall quite similar to the results that we saw in the previous video with the MLP neurons.

08:10.920 --> 08:17.560
In particular, the percent of significant neurons that had significant beta values.

08:17.560 --> 08:25.640
So significantly different activation values for negation terms versus affirmation terms that generally

08:25.640 --> 08:31.640
decrease from somewhere around 70% to somewhere a little around under 30%.

08:31.800 --> 08:38.160
As we go deeper into the layer, so that looks qualitatively very similar to the MLP.

08:38.680 --> 08:45.560
And here we see also very similar to what we saw with the MLP neurons, that the prediction accuracy

08:45.720 --> 08:55.000
for these significant neurons starts from around 7,075% down to around 60%, maybe a little bit lower.

08:56.260 --> 09:03.300
Now, by the way, the fact that these include only the significant positive betas neurons with significant

09:03.300 --> 09:12.180
positive betas tells you that even amongst the neurons where the prediction is significant, the prediction

09:12.180 --> 09:13.900
accuracy is lower.

09:14.020 --> 09:18.420
So even though there still we're only plotting these significant neurons.

09:18.420 --> 09:20.900
So we're just selecting these significant neurons.

09:21.300 --> 09:26.340
The magnitude of the effect the effect size is generally pretty low.

09:26.740 --> 09:33.060
Also remember that 50% corresponds to chance level literally purely guessing.

09:33.380 --> 09:38.100
And so this is technically significantly better than chance.

09:38.100 --> 09:39.900
But it's not that much better.

09:41.060 --> 09:44.740
This first point here is very general about coding.

09:45.180 --> 09:53.300
Taking the time to understand and write out code is always time well spent and wisely invested.

09:53.740 --> 09:57.400
This is particularly true when you're learning a new field.

09:57.840 --> 10:05.200
I know it's very tempting to like vibe code and have ChatGPT or some other LLM write a lot of code for

10:05.200 --> 10:05.560
you.

10:06.040 --> 10:12.560
Now, I do sometimes get llms to code for me, but my honest opinion is that it's usually not worth

10:12.560 --> 10:13.000
it.

10:13.040 --> 10:20.720
Partly because still, after all this time, I find that ChatGPT makes a lot of coding errors, but

10:20.720 --> 10:27.640
also because if you do not take the time to really understand the code that you're using, then it's

10:27.640 --> 10:29.320
hard to know what the code is doing.

10:29.320 --> 10:34.920
It's even harder to trust that you're doing it correctly in different applications.

10:35.480 --> 10:41.920
Now, that said, I do find ChatGPT very useful for helping me debug my own code.

10:42.320 --> 10:49.400
But anyway, this is just a bit of a meta comment about using Llms in a course about understanding Llms.

10:49.960 --> 10:56.820
The main thing I wanted to say here is that although you will find differences across different transformer

10:56.820 --> 11:00.500
layers and different populations of artificial neurons.

11:00.860 --> 11:06.540
The population level differences are generally more quantitative than qualitative.

11:07.620 --> 11:14.060
That is to say, the characteristics and the features that you will find in one part of the model,

11:14.340 --> 11:17.380
you'll probably find everywhere else in the model.

11:17.780 --> 11:22.620
Now, maybe more of those characteristics you'll find in one part or a different part.

11:22.820 --> 11:30.620
But it does seem like the representations and the calculations in Llms are really distributed within

11:30.620 --> 11:32.060
and across layers.

11:32.420 --> 11:39.140
They're not really modularly different the way that, for example, your liver and your lung are qualitatively

11:39.140 --> 11:41.340
doing completely different things.

11:42.180 --> 11:48.980
And that's probably a good final statement for this section and a good segue into the next section where

11:48.980 --> 11:54.140
we will focus on a higher level of organization in Llms.
