WEBVTT

00:02.120 --> 00:03.360
Before moving on.

00:03.360 --> 00:08.680
I want to have one more video about activation maximization.

00:09.360 --> 00:17.520
The concept that I will introduce you to in this video is the same as in the previous few videos, in

00:17.520 --> 00:25.360
the sense that the idea is to try to discover the language features that are represented by a single

00:25.400 --> 00:28.440
dimension or single neuron in an LM.

00:29.440 --> 00:36.200
However, the approach here in this video will be a bit different and actually much simpler than in

00:36.200 --> 00:38.760
the previous several videos.

00:39.320 --> 00:45.920
So we're not going to do any training or shaping noise or gradient ascent or anything like that.

00:46.320 --> 00:53.720
Instead, I'm just going to push through tens of thousands of tokens through the model, pick one dimension

00:53.720 --> 01:00.260
from one transformer block, and just see which tokens maximally activate that one dimension.

01:00.820 --> 01:05.620
And when I show you the code, you will see how simple this method really is.

01:06.500 --> 01:09.660
So here's what I will do in the Python demo.

01:09.980 --> 01:15.380
I'll start by importing the GPT neo model from eleuther.

01:15.700 --> 01:18.940
And also the text for the book Through the Looking Glass.

01:19.460 --> 01:23.820
Then I'll pick one layer, one hidden layer, and one dimension.

01:23.820 --> 01:32.460
Basically arbitrarily randomly chosen, process one batch of tokens and literally just search through

01:32.780 --> 01:40.100
all of the activations for all the tokens and find the token that gets the most activation, the strongest

01:40.100 --> 01:44.780
activation from that one dimension, from one layer.

01:45.820 --> 01:49.060
And that is the basics of how this analysis works.

01:49.300 --> 01:56.740
Then I will repeat that a thousand times and collect the token that generates the maximum activation

01:56.740 --> 02:05.070
from each of those 1000 batches, and then I'll just list them out and we'll see if there are any consistencies

02:05.070 --> 02:06.750
that we can identify.

02:07.470 --> 02:08.070
Great.

02:08.110 --> 02:09.390
Let's switch to code.

02:10.310 --> 02:15.150
We don't actually need too many libraries for this code demo.

02:15.390 --> 02:18.870
Here I'm importing the model from Eleuther.

02:18.910 --> 02:22.910
This is GPT neo 125 million parameters.

02:23.070 --> 02:28.710
I will run this on the GPU and switch model into eval mode.

02:29.270 --> 02:29.550
Okay.

02:29.590 --> 02:33.830
And then here I'm importing the text for through the looking glass.

02:34.030 --> 02:35.430
Tokenizing the text.

02:35.710 --> 02:39.430
Printing out the number of tokens is actually just copy.

02:39.430 --> 02:46.070
The whole reason why this line is there is because I just keep copying this code from other code files.

02:46.550 --> 02:46.990
Okay.

02:47.030 --> 02:50.670
So here I'm going to process a batch.

02:50.870 --> 02:54.510
This is going to be a batch of 32 sequences.

02:54.630 --> 02:58.890
And each sequence will be 256 tokens long.

02:59.210 --> 03:09.050
Now I will discuss in a few moments why some reasons why we might want this to be larger versus smaller.

03:09.250 --> 03:12.250
But anyway, these are the parameters that I will use for now.

03:12.690 --> 03:15.090
So here's one example.

03:15.090 --> 03:22.410
So here I get a batch of tokens, push those through the model and get the hidden states.

03:22.410 --> 03:24.730
And then just printing out some of these.

03:25.250 --> 03:27.970
Yeah one of these shapes of these tensors.

03:28.370 --> 03:31.530
So we have 13 hidden states altogether.

03:31.770 --> 03:38.330
Of course you know that that's the embeddings plus the 12 transformer blocks.

03:38.690 --> 03:48.890
And then each one of those hidden states is of size 32 batches, 256 tokens and 768 dimensions.

03:49.090 --> 03:51.090
Now here is the idea.

03:51.250 --> 03:58.580
What we are going to do is pick one of these layers and one of these dimensions.

03:58.580 --> 04:04.060
And that's going to give us a matrix of size 32 by 256.

04:04.180 --> 04:12.940
And that corresponds to the activation for each of these tokens in each of these sequences for one specific

04:12.940 --> 04:13.740
dimension.

04:13.740 --> 04:20.620
So dimension 345 and from one specific layer I'm picking layer two.

04:20.660 --> 04:24.100
So transformer block two okay.

04:24.140 --> 04:26.260
So why do I pick these numbers.

04:26.500 --> 04:28.380
No really no particular reason.

04:28.380 --> 04:32.540
I just kind of randomly assembled this collection of four numbers here.

04:32.980 --> 04:33.380
Okay.

04:33.420 --> 04:36.340
So here I just get the activations.

04:36.780 --> 04:41.660
I'm detaching them and bringing them back from the GPU to the CPU.

04:42.140 --> 04:47.500
And basically the point of this line of code is just for convenience.

04:47.500 --> 04:53.200
So I can have this one matrix instead of worrying about all of this business here.

04:53.640 --> 04:54.080
Okay.

04:54.120 --> 04:59.480
And then I want to find the maximum value in this matrix.

04:59.480 --> 05:02.440
So actually let me just to make sure this is really clear.

05:02.640 --> 05:05.160
So layer x dot shape.

05:05.600 --> 05:09.040
So here we have 32 by 256.

05:09.360 --> 05:19.880
And yeah this is 32 batches or one batch of 32 sequences and each of 256 tokens.

05:20.680 --> 05:22.360
And now from here.

05:22.360 --> 05:24.760
So these are not the tokens anymore.

05:24.800 --> 05:30.680
These are the activations for these tokens from this one dimension and this one layer.

05:30.840 --> 05:33.960
So then I want to know what is the index.

05:33.960 --> 05:34.960
So let me do this.

05:34.960 --> 05:38.320
Now numpy dot arg max.

05:38.800 --> 05:43.840
What is the index at which this reaches a maximum.

05:44.000 --> 05:49.760
So this has a maximum activation value at index 4024.

05:50.000 --> 05:52.570
Now this is a linear index.

05:52.570 --> 05:56.210
So it's wrapping around the rows and the columns.

05:56.370 --> 06:00.930
So therefore just to make this convenient I flatten out x as well.

06:00.930 --> 06:04.010
This is the matrix of tokens.

06:04.090 --> 06:07.810
And then I can use this as a linear index.

06:07.810 --> 06:13.490
And this gives me the token index at which the activation was the maximum.

06:13.610 --> 06:15.690
And then we can decode that.

06:15.690 --> 06:21.850
So then we find that the token with the maximum activation is the word space before.

06:22.050 --> 06:24.130
So the token space before.

06:24.690 --> 06:25.010
Okay.

06:25.050 --> 06:26.370
So that's pretty interesting.

06:26.370 --> 06:27.890
This is for one batch.

06:28.170 --> 06:32.970
Now that doesn't tell us that this is the before dimension in the model.

06:33.090 --> 06:41.370
All it tells us is that in this particular batch, this specific batch, that one token got the largest

06:41.410 --> 06:44.210
activation from this dimension and so on.

06:44.570 --> 06:44.890
Okay.

06:44.930 --> 06:48.530
So now what I'm going to do is repeat all of that code.

06:48.730 --> 06:52.670
All of this stuff is exactly the same that I just showed you.

06:53.230 --> 06:55.950
Except here I'm storing the result.

06:55.990 --> 06:58.110
Actually, I'm just storing the index here.

06:58.110 --> 07:02.750
Just because it's easier to store in a matrix and not the token itself.

07:02.910 --> 07:07.790
But anyway, then I'm repeating that analysis 1000 times.

07:07.790 --> 07:09.030
So I'm going to run this now.

07:09.030 --> 07:12.310
It takes somewhere around two minutes on the GPU.

07:12.670 --> 07:18.750
I did not time this on the CPU, but I guess it would take quite a bit longer than the GPU.

07:19.750 --> 07:23.030
So now I've run this 1000 times.

07:23.230 --> 07:30.470
And now what I do here is find all of the unique values in this tokens matrix.

07:30.710 --> 07:34.110
So now we can imagine two different possibilities.

07:34.110 --> 07:36.830
How many unique elements will there be?

07:37.310 --> 07:41.910
We can imagine the one extreme where this analysis works super duper well.

07:42.030 --> 07:45.870
And then every single token will be exactly the same.

07:46.470 --> 07:49.690
I will get back to that in a moment, whether that's even possible.

07:50.370 --> 07:56.810
But, you know, imagine out of this 1000 tokens, maybe there's only like five unique tokens that would

07:56.810 --> 08:03.570
indicate that the model, every time the model sees the word or this dimension from this layer sees

08:03.570 --> 08:07.450
the word the, then it always just responds a lot.

08:07.490 --> 08:10.090
So then we're always going to get the out here.

08:10.370 --> 08:17.170
On the other hand, if it's completely random, the this dimension for this model, for this layer has

08:17.170 --> 08:23.330
no preference whatsoever for any particular word or category or set of words.

08:23.490 --> 08:30.810
Then we would expect this to be basically a thousand the unique elements to be 1000, because each time

08:30.810 --> 08:36.290
we present new tokens, it's going to be a completely random selection of tokens.

08:37.210 --> 08:38.370
So let's see what we get.

08:38.730 --> 08:42.530
Uh, the answer is somewhere in between 5 and 1000.

08:42.570 --> 08:44.450
Actually, these are very, very small.

08:44.770 --> 08:50.460
So it turns out that This dimension for this layer really likes the word before.

08:50.700 --> 08:52.980
So we get a space before.

08:53.180 --> 09:02.300
And that elicits that token elicits the maximum activation in for this dimension for this layer.

09:02.500 --> 09:04.340
Almost half of the time.

09:04.340 --> 09:05.860
So almost half of the batches.

09:06.180 --> 09:09.140
And then when we look at some of the other ones I'm not sure yet.

09:09.180 --> 09:10.700
This is a subword here.

09:10.700 --> 09:16.780
So I'm not sure what parts of the word this would correspond to in principle, that something you could

09:16.780 --> 09:19.780
check by adding to the code, but it's not.

09:20.260 --> 09:21.540
The code doesn't do that here.

09:21.780 --> 09:26.540
And then we also see before with capital and before here.

09:26.540 --> 09:32.460
So this is a different token from this one because this has a space in front and this one doesn't.

09:32.940 --> 09:41.060
And even when we look at the other tokens we see we get first faster head you know similar words to

09:41.100 --> 09:41.620
before.

09:41.620 --> 09:43.940
Here's also first quicker I don't know.

09:43.980 --> 09:44.220
Yeah.

09:44.220 --> 09:50.160
This maybe is related to temporal precedence, which is a similar concept as before.

09:50.520 --> 09:54.680
So overall we seem to get something, you know, we seem to be hitting on something here.

09:54.920 --> 09:56.960
Now you can run this code lots of times.

09:56.960 --> 10:01.200
It's always going to generate new random batches.

10:01.400 --> 10:08.760
But it will always kind of like this word before first quicker faster things words like that.

10:09.040 --> 10:11.520
But that is not just something trivial.

10:11.560 --> 10:14.200
Because now what I'll do is change this.

10:14.200 --> 10:17.400
Let's say I don't know six and I'll just make that a five.

10:18.200 --> 10:23.240
So again, I have no a priori motivation for picking these numbers.

10:23.240 --> 10:24.240
It's pretty random.

10:24.400 --> 10:24.640
Okay.

10:24.680 --> 10:26.400
So now I'm going to run this again.

10:27.400 --> 10:30.240
So let's see what these results look like.

10:30.280 --> 10:32.680
This is still from the previous run.

10:32.680 --> 10:36.200
We get lots of befores first quicker faster and so on.

10:36.520 --> 10:39.120
Here we see the list is a little bit longer.

10:39.320 --> 10:43.690
Uh, and yeah we get some I don't know, some formatting, uh, thing.

10:43.730 --> 10:46.810
Hope course gun family afraid states.

10:46.810 --> 10:53.570
Wish I will let you decide whether you think that there is any meaningful relationship across some of

10:53.570 --> 10:58.370
these top activated tokens, but it's certainly nothing really obvious.

10:58.370 --> 11:02.650
It's not like the same word is appearing multiple times.

11:03.170 --> 11:11.410
Okay, the last thing I want to discuss is the question of this trade off between, uh, where is it

11:11.450 --> 11:18.850
this, uh, the, the batch size in terms of the number of sequences and the number of tokens per sequence

11:19.090 --> 11:22.570
versus the number of samples.

11:22.930 --> 11:24.010
Now, here's the thing.

11:24.010 --> 11:27.410
You can imagine making this as big as possible.

11:27.410 --> 11:30.010
So maybe this is 1024.

11:30.210 --> 11:36.570
And I don't know maybe you make this 128 debatable whether this matrix and all of the activations would

11:36.610 --> 11:43.550
actually fit on the GPU, but even if they would, then, you know, that would be great because then

11:43.790 --> 11:50.230
each individual batch has a huge number of tokens, over 100,000 tokens.

11:50.230 --> 11:56.950
So we're highly likely to get a sufficient amount of variability of tokens.

11:57.150 --> 12:04.070
But on the other hand, if you do that, you might want to reduce the number of samples just to get

12:04.070 --> 12:07.190
it to run in a reasonable time frame.

12:07.550 --> 12:13.710
And that means that you're going to have a smaller number here for collecting these statistics.

12:13.830 --> 12:19.750
On the other hand, you can imagine setting the number of samples to be really high, but setting the

12:19.750 --> 12:21.950
number of batches to be really small.

12:21.950 --> 12:25.510
Maybe you do it something like, uh, how about that?

12:25.550 --> 12:28.030
So now the batches are really small.

12:28.070 --> 12:35.070
The risk here is that you just don't have a lot of variability in the tokens because you're just randomly

12:35.070 --> 12:36.310
selecting tokens.

12:36.750 --> 12:43.490
Also, you know, other typical limitations Imitations of this as a kind of research investigation.

12:43.490 --> 12:49.250
As I've discussed repeatedly in this course, for example, I'm only using exactly one text.

12:49.890 --> 12:56.730
Of course, if you were doing this in a real research, you would want to basically find a nice balance

12:56.730 --> 13:01.730
to increase these numbers and also keep this number pretty high.

13:01.890 --> 13:07.970
And of course, if you're doing this for a, you know, let's say a three month research project, then

13:08.010 --> 13:10.410
you can let this code run for a week.

13:10.570 --> 13:11.570
And it's fine.

13:11.570 --> 13:14.450
You get an enormous amount of data from that.

13:14.850 --> 13:23.290
And then of course, we have the issue of scaling and feasibility, where searching through all 768

13:23.290 --> 13:29.610
dimensions times 12 layers is just not feasible for a human being to do.

13:30.730 --> 13:35.290
Here are some advantages and limitations of this approach.

13:35.690 --> 13:40.820
Let's start with the advantages, Because I like starting with things that are positive.

13:41.340 --> 13:48.700
So unlike the gradient ascent approach that I showed in the previous several videos, this approach

13:48.700 --> 13:55.820
here uses real words from real human written text, and that means that the results are likely to be

13:55.980 --> 13:58.580
more interpretable to us humans.

13:59.140 --> 14:06.620
Of course, human interpretability is not guaranteed by the method, but using real texts instead of

14:06.620 --> 14:12.820
random noise that we try to shape into a meaningful token sequence does make this approach at least

14:12.820 --> 14:15.100
more likely to be interpretable.

14:15.860 --> 14:20.220
As you saw, it takes very little code to run this analysis.

14:20.500 --> 14:24.180
And again, I want to be clear with the phrasing here.

14:24.180 --> 14:32.060
I'm not claiming that the results will always be understandable and reproducible, but the method itself

14:32.180 --> 14:33.900
is easy to understand.

14:33.900 --> 14:35.540
It's easy to explain.

14:35.540 --> 14:39.000
It's easy for anyone else to code up in a different model.

14:39.480 --> 14:45.520
And because it's so simple, it's also easy to adapt to other features of the model.

14:45.880 --> 14:50.880
For example, here I used an output dimension from a transformer block.

14:51.080 --> 14:58.800
But actually this kind of a method is more commonly done with individual neurons, for example inside

14:58.800 --> 15:00.680
an MLP sub block.

15:01.320 --> 15:08.040
Now, the reason why I focused on the output dimension from a transformer block is really just because

15:08.040 --> 15:16.240
I haven't yet introduced you to extracting activations from individual neurons within the transformer

15:16.240 --> 15:16.920
blocks.

15:17.400 --> 15:23.360
But it doesn't matter because the code, the approach, the parameters, everything is the same if you're

15:23.360 --> 15:26.520
looking at different components of the model.

15:27.880 --> 15:32.680
Okay, all of these points aside, obviously this method is not super fantastic.

15:32.680 --> 15:35.650
Otherwise this video would be the end of the course.

15:36.170 --> 15:38.610
So there are some limitations.

15:38.610 --> 15:44.490
I think the main disadvantage of this method is with the scalability.

15:45.010 --> 15:53.490
So even if we are just thinking about GPT two small, we already have over 9000 dimensions to search

15:53.490 --> 15:53.930
through.

15:54.330 --> 16:01.810
And that is not even including all of the neurons in the MLP and the attention layers.

16:02.330 --> 16:10.450
So it's just a massive problem to try to figure out how to understand so many tens of thousands of results,

16:10.610 --> 16:14.410
like what we did, uh, a moment ago in the Python demo.

16:15.210 --> 16:22.290
Furthermore, it might be difficult to identify some higher level concepts that a model dimension is

16:22.290 --> 16:23.650
actually coding for.

16:24.130 --> 16:30.690
So maybe it's just difficult for us humans trying to interpret the results to figure out what is really

16:30.690 --> 16:34.190
connecting all of the highly activated words.

16:34.630 --> 16:40.750
Now, that is especially true if we aren't using a diverse enough data set.

16:41.230 --> 16:48.550
And that leads me to this third limitation here, which is that some representations of concepts like

16:48.590 --> 16:56.150
temporal precedence might not exist only in one dimension, in only one layer, just because we happen

16:56.150 --> 16:59.150
to be searching in that particular dimension.

16:59.710 --> 17:07.550
So these representations, this coding might be distributed over some or many dimensions, many neurons

17:07.550 --> 17:10.230
in one or more transformer blocks.

17:10.870 --> 17:18.790
And then the final limitation that I list here is that this method actually ignores all of the contextual

17:18.790 --> 17:26.230
information, because we're only looking for individual tokens that give maximum activation.

17:26.590 --> 17:34.480
We're not searching for token sequences that provide a context for interpreting each current token.

17:35.600 --> 17:44.920
So overall, I and many other people really like the idea of activation maximization via data sampling.

17:45.400 --> 17:52.920
Now, if you have a relatively small model or if you have a really specific targeted hypothesis whereby

17:53.160 --> 18:00.440
you have a very specific layer or neuron or set of neurons to investigate, then this approach can be

18:00.440 --> 18:04.240
really great, easy to implement and easy to interpret.

18:04.720 --> 18:11.480
But unfortunately, it's just not really scalable to large models, especially where you don't really

18:11.480 --> 18:13.400
know exactly what you're looking for.

18:13.440 --> 18:18.200
You're just kind of poking around and searching through lots and lots of data.

18:19.280 --> 18:26.800
Still, it's a great analysis to know about, and I hope that you now feel a tiny bit smarter compared

18:26.800 --> 18:29.120
to at the beginning of this video.
