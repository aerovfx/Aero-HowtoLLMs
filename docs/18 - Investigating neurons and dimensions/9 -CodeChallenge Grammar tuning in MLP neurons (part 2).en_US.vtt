WEBVTT

00:02.720 --> 00:11.960
The result of exercise three is a set of activations for each neuron and 100 samples from two categories

00:12.520 --> 00:14.080
in exercise four.

00:14.240 --> 00:21.640
You will now perform a statistical analysis on those activations to see whether we can find neurons

00:21.880 --> 00:28.160
that are statistically significantly more active for nouns versus verbs.

00:28.720 --> 00:32.440
So we can do a couple of statistical tests here.

00:32.440 --> 00:40.080
The one that I will focus on here for simplicity is a paired samples t test, because we have individual

00:40.080 --> 00:43.600
neurons that have measurements in two categories.

00:44.080 --> 00:51.120
So if you've studied statistics before, then you will remember that a paired samples t test is the

00:51.120 --> 00:58.560
same thing as a one sample t test on the difference values with a null hypothesis value of zero.

00:59.200 --> 01:04.990
In other words, you can calculate the difference between the activations for the verbs and the nouns,

01:05.310 --> 01:11.870
and then use the one sample t test function from the Scipy.stats library.

01:12.390 --> 01:17.390
Now the outputs of this function are t values and p values.

01:17.710 --> 01:25.990
And because we are comparing so many neurons, you can use a significance threshold of p equals 0.05

01:26.030 --> 01:28.990
divided by the number of neurons.

01:29.110 --> 01:33.750
This corresponds to a Bonferroni correction for multiple comparisons.

01:34.390 --> 01:40.910
When you finish this test, you can visualize all of the t values in a scatter plot like this, where

01:40.910 --> 01:47.790
we see the MLP neurons on the x axis and the t value on the y axis.

01:48.310 --> 01:55.550
Now, I have colored all of these significant results as blue circles and the non-significant t tests

01:56.230 --> 01:58.590
using smaller red squares.

01:59.390 --> 02:02.540
Now, because these are difference scores.

02:02.540 --> 02:09.780
The positive T values correspond to neurons that have significantly stronger activations for nouns compared

02:09.780 --> 02:17.540
to verbs, and the negative t values correspond to neurons that have stronger activations for verbs

02:17.540 --> 02:19.020
compared to nouns.

02:19.700 --> 02:27.620
So the final step in this exercise is to identify the two neurons that have the most extreme t values,

02:27.620 --> 02:28.900
positive and negative.

02:29.980 --> 02:30.420
All right.

02:30.420 --> 02:33.900
So pause the video and good luck working through this one.

02:33.900 --> 02:40.460
If you are not so comfortable with statistics and t tests, then feel free to check my code solution

02:40.460 --> 02:44.700
and keep watching for my explanation when I switch to code.

02:45.780 --> 02:52.140
Let me begin by reminding you of the shape of this all activations matrix.

02:52.140 --> 03:02.100
So it's two by 100 by 3000, corresponding to two categories by 100 samples from each category and 3000

03:02.290 --> 03:03.090
neurons.

03:03.090 --> 03:06.930
So if we would calculate the difference using numpy dot diff.

03:07.490 --> 03:14.610
Along axis zero, that is going to give us a matrix of one by 100 by 3000.

03:14.610 --> 03:19.410
And this is one because yeah it's the difference between the two categories.

03:19.410 --> 03:24.530
So then here we can implement the t test as a one sample t test.

03:24.810 --> 03:31.530
If you are a statistics aficionado then you might think it's maybe a little bit questionable whether

03:31.530 --> 03:37.970
we can really do a paired test, because the words across the two categories are not actually paired.

03:38.250 --> 03:43.410
It is the same neurons, but the measurements for the two categories aren't paired.

03:43.730 --> 03:48.490
However, the variances are the same and the sample sizes are the same.

03:48.730 --> 03:51.410
So I think this is actually fine.

03:51.850 --> 03:54.770
Okay, here I calculate the p value threshold.

03:54.770 --> 04:00.170
That's what I called Greek letter alpha lowercase alpha in the slides.

04:00.170 --> 04:07.720
So 0.05 corresponding to the standard statistical significance threshold divided by the Bonferroni correction

04:07.720 --> 04:13.440
value or the number of tests we are performing, which is 3072.

04:13.920 --> 04:14.280
Okay.

04:14.320 --> 04:15.240
And then yeah.

04:15.280 --> 04:23.320
So here I'm plotting the, uh, the t values by the p values and coloring them according to their significance

04:23.320 --> 04:26.040
relative to this threshold that I have here.

04:26.560 --> 04:33.720
And then here, I'm just finding the, uh, neuron associated with the largest t value and the smallest

04:33.760 --> 04:34.560
t value.

04:34.680 --> 04:37.520
And that happens to be these two indices here.

04:38.680 --> 04:43.120
The final exercise is to test for generalizability.

04:43.720 --> 04:50.200
So the idea is that we used all of these individual tokens to identify these neurons.

04:50.520 --> 04:56.920
But it's possible that the results just reflect sampling variability and overfitting to the test the

04:56.920 --> 04:57.600
train set.

04:58.120 --> 05:05.830
So what we really want to do is test whether these neurons are also significantly differentiating nouns

05:05.830 --> 05:10.270
from verbs in a completely new text that we did not use before.

05:10.310 --> 05:11.910
In exercise four.

05:12.630 --> 05:14.870
And that's what you are going to do here.

05:14.870 --> 05:22.110
In this exercise, you can use really any text you want, but to reproduce my results, I recommend

05:22.150 --> 05:29.830
copying the text from the randomness Wikipedia page that I have pasted into the solutions and helper

05:29.830 --> 05:30.550
files.

05:31.110 --> 05:35.070
So you should tokenize that text and push it through the model.

05:35.270 --> 05:42.270
Get the activations from the two extreme neurons that you identified in the previous exercise, and

05:42.270 --> 05:45.830
then create a heat map that will look something like this.

05:46.510 --> 05:53.550
So this is the text from Wikipedia, and the color behind the text will correspond to the strength of

05:53.550 --> 06:01.310
the activation of the largest t value neuron and the smallest t value, or the most negative t value

06:01.310 --> 06:01.870
neuron.

06:02.510 --> 06:07.300
And don't forget to min max normalize for the color scaling.

06:07.900 --> 06:11.020
Now you can see that I have the text repeated here.

06:11.260 --> 06:18.460
And that's because the upper text in red corresponds to the maximum t value neuron, which was the neuron

06:18.460 --> 06:22.660
that most significantly differentiated nouns from verbs.

06:23.180 --> 06:29.380
And the lower text here is the neuron that best differentiated verbs from nouns.

06:29.940 --> 06:34.420
Now in this plot that you are looking at right now, these are not the real colors.

06:34.420 --> 06:39.380
I set all of the color values to 0.1 just for this slide.

06:39.660 --> 06:44.260
Of course, when you use the actual activation values, it will look different.

06:44.260 --> 06:47.940
The text is the same of course, but the color will be different.

06:48.860 --> 06:56.180
So then the question is whether the part of speech categorization that we identified in the previous

06:56.380 --> 07:00.140
exercise generalizes to this new text.

07:00.700 --> 07:08.370
In particular, you want to see if the bright red colours here correspond to nouns, and the dark blue

07:08.370 --> 07:12.050
colours here correspond to verbs in this text.

07:12.810 --> 07:16.570
Now you don't have to worry about doing any quantitative analyses.

07:16.570 --> 07:20.850
This is purely qualitative here, just visual inspection.

07:22.010 --> 07:22.330
Okay.

07:22.370 --> 07:25.410
I hope you enjoy working through this exercise.

07:25.410 --> 07:31.490
And I would also like you to think about what limitations or maybe problems or other issues with how

07:31.490 --> 07:37.370
we set up this code challenge that you can think of and what you might do differently if you were to

07:37.410 --> 07:39.050
do a follow up study.

07:39.650 --> 07:45.210
I will discuss some of my ideas when I switch back to the slides after going through the code.

07:45.930 --> 07:47.650
So here is the text.

07:48.010 --> 07:54.690
The story behind this text is I wanted to just grab some text from a random Wikipedia page, and the

07:54.690 --> 08:01.050
first thing that came to mind was look for the Wikipedia page on randomness instead of picking a randomly

08:01.050 --> 08:03.170
selected Wikipedia page.

08:03.570 --> 08:04.760
Anyway, Uh, yeah.

08:04.800 --> 08:10.800
Here again, you can see I have no output from the model because I do not care about the final stage

08:10.800 --> 08:11.400
of the model.

08:11.400 --> 08:16.480
We just want the activations from these specific MLP neurons.

08:16.680 --> 08:17.720
And that's what I do here.

08:17.720 --> 08:19.680
So I grab the activations.

08:20.000 --> 08:27.320
Uh, this corresponds to the batch dimension, all the tokens and the neuron index that had the largest

08:27.360 --> 08:28.200
T value.

08:28.200 --> 08:30.920
So that was one of these guys probably this one.

08:30.920 --> 08:36.400
And then from the most extreme negative value probably corresponding to this one.

08:36.440 --> 08:37.840
Yeah I guess that's that one there.

08:38.440 --> 08:38.720
Okay.

08:38.760 --> 08:41.720
And then here I, uh, modify those.

08:41.720 --> 08:48.960
I transform those into, uh, min max scale so that they have the smallest activation value would be

08:48.960 --> 08:52.760
zero, and the largest activation value would be one.

08:53.480 --> 08:57.040
This is like boilerplate code which you've now seen before.

08:57.160 --> 09:03.160
This just calculates the width of one particular letter using Monospace font.

09:03.520 --> 09:09.710
And then here is where I have the code that runs through and actually generates that heat map.

09:09.910 --> 09:18.150
So here I plot the text and then here is where I color it according to the activation of the max neuron

09:18.150 --> 09:19.950
and the min neuron.

09:20.390 --> 09:26.150
So all of this code you have seen several times earlier in this course, the only thing I really added

09:26.390 --> 09:33.550
here for this exercise was a separate line, with some extra adjustments here, so that there are actually

09:33.550 --> 09:38.070
two axes instead of just one axis in this figure.

09:38.710 --> 09:40.670
Okay, so let's see what this looks like.

09:40.750 --> 09:48.390
So what we are looking for here in the red text is that the nouns should have deeper red colors corresponding

09:48.430 --> 09:56.870
to larger activations of this neuron, and the verbs should have more like faint colors closer to white.

09:57.070 --> 10:02.510
So you know, we do see is that is a verb and it's colored very light.

10:02.990 --> 10:03.630
Example.

10:03.630 --> 10:04.470
That's a noun.

10:04.470 --> 10:06.020
now outcomes.

10:06.020 --> 10:08.740
That's a noun entropy uncertainty information.

10:08.740 --> 10:12.300
Chance concepts applies as a verb.

10:12.300 --> 10:13.380
Is is a verb.

10:13.620 --> 10:14.580
Uh, yeah.

10:14.860 --> 10:15.340
Let's see.

10:15.340 --> 10:19.380
So it does seem like, you know, I'm not doing any quantification.

10:19.380 --> 10:24.420
All I'm doing is some visual inspection of a little bit of text.

10:24.420 --> 10:32.300
But these results visually do seem to be consistent with the statistical results, which is that this

10:32.300 --> 10:38.060
neuron does seem to give stronger activation for nouns compared to verbs.

10:38.500 --> 10:39.660
And now let's look over here.

10:39.660 --> 10:45.900
So what we would really like to see here is basically the opposite that words like information theory,

10:45.940 --> 10:51.980
uncertainty, probability, symbols, combination these should all have lighter colors and all of the

10:51.980 --> 11:00.300
verbs like is applies, follow and so on that these are words that the verbs should have the deepest

11:00.300 --> 11:04.580
blue colors indicating strongest activations.

11:05.010 --> 11:08.570
So to some extent that does seem like it is the case.

11:08.570 --> 11:12.410
However, it's certainly not the case that there's real selectivity.

11:12.570 --> 11:16.650
For example, but is not a verb, neither is ha.

11:16.690 --> 11:18.370
This is actually part of half hazard.

11:18.970 --> 11:21.090
A semicolon is not a verb.

11:21.330 --> 11:22.530
Actual apparent.

11:22.570 --> 11:29.530
You know, a lot of these, uh, the comma and, uh, a lot of these words that are getting strong activations

11:29.530 --> 11:32.130
from this neuron are not verbs.

11:32.490 --> 11:40.050
So I think we can say that these results are somewhat qualitatively consistent with the identification

11:40.050 --> 11:46.170
of the neurons in the previous exercise, but it's not really so compelling that we have identified

11:46.170 --> 11:49.570
a noun neuron and a verb neuron.

11:50.010 --> 11:51.930
Now, why might that be the case?

11:51.930 --> 11:57.330
What are some things that you could think about to improve the quality of this experiment?

11:57.610 --> 12:02.490
Uh, in a way that would make this analysis be more rigorous and more compelling.

12:03.410 --> 12:07.240
So here are some limitations for this code challenge.

12:07.640 --> 12:13.400
For one thing, we only looked at one transformer block, although there are 11 more that we could look

12:13.400 --> 12:13.720
at.

12:14.000 --> 12:17.160
And that's just in the small version of GPT two.

12:17.520 --> 12:22.480
The larger models have even more neurons and even more transformer blocks.

12:23.520 --> 12:30.240
Secondly, the sample size was also fairly small, so we just used 100 words per category.

12:30.360 --> 12:35.320
That's a pretty small sample size considering the complexity of language.

12:35.440 --> 12:41.160
So that means that the signal to noise ratio is likely to be fairly low.

12:41.160 --> 12:44.200
So that's going to give us unreliable results.

12:44.680 --> 12:52.360
And also Llms are really not designed to process individual tokens with no context.

12:52.840 --> 12:59.600
In fact, you've already seen several times in this course that the first token in a sequence gives

12:59.640 --> 13:04.240
kind of weird and sometimes extreme outlier activation values.

13:04.920 --> 13:12.230
In fact, in several videos, I've even completely ignored or removed the activations from the first

13:12.230 --> 13:19.070
token in the sequence, just because its values are so much different from the values of the other tokens.

13:19.230 --> 13:24.550
Where the model can leverage some preceding context to process those words.

13:25.350 --> 13:33.150
So that means that we might not really be doing a fair approach to identify actual category selectivity.

13:33.870 --> 13:41.630
But on the other hand, having no context does mean that we get kind of like a pure processing without

13:41.630 --> 13:43.670
any context modulations.

13:44.270 --> 13:48.190
That is the theme of the next code challenge.

13:48.190 --> 13:51.470
So we're going to get back to this discussion in the next video.

13:52.350 --> 13:59.670
The generalization test was fairly, you know, qualitative and really just based on a tiny amount of

13:59.670 --> 14:00.430
text.

14:00.430 --> 14:06.350
So that's probably not really a fair judgment to say that the procedure did or didn't work.

14:06.940 --> 14:13.700
Finally, we only tested for two parts of speech categories, which doesn't really provide much evidence

14:13.700 --> 14:15.380
for selectivity.

14:15.820 --> 14:21.820
If you really want to argue that a neuron is selective for a particular category, you would want to

14:21.860 --> 14:29.340
identify neurons that have more activations for nouns compared to all the other parts of speech, including

14:29.500 --> 14:37.740
verbs, but also adjectives, adverbs, punctuations, numbers, non-linguistic tokens like HTML tags

14:37.740 --> 14:39.780
or Python code, and so on.

14:41.100 --> 14:49.540
Nevertheless, my primary goal with this code challenge was to show you how to code for extracting activations

14:49.540 --> 14:52.660
and setting up these kinds of analyses.

14:53.340 --> 15:00.740
Doing this kind of research rigorously and carefully in practice is going to be like weeks or months

15:00.740 --> 15:06.140
of full time work to make sure everything is really done correctly and rigorously.
