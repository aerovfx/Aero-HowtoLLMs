
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../index.md) > [05 Embeddings spaces](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../index.md)
- [ğŸ“š Module 01: LLM Course](../../01-LLM_Course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../02-Words-to-tokens-to-numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../04-buildGPT/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../07-Fine-tune-pretrained-models/index.md)
- [ğŸ” Module 19: AI Safety](../../19-AI-safety/index.md)
- [ğŸ Module 20: Python for AI](../../20-Python-Colab-notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Huáº¥n luyá»‡n vÃ  ÄÃ¡nh giÃ¡ MÃ´ hÃ¬nh Há»c MÃ¡y: CÆ¡ sá»Ÿ LÃ½ thuyáº¿t vÃ  Thá»±c tiá»…n

TÃ³m táº¯t

Huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh lÃ  hai giai Ä‘oáº¡n cá»‘t lÃµi trong quy trÃ¬nh phÃ¡t triá»ƒn há»‡ thá»‘ng há»c mÃ¡y (Machine Learning â€“ ML). BÃ i viáº¿t nÃ y trÃ¬nh bÃ y cÆ¡ sá»Ÿ toÃ¡n há»c cá»§a quÃ¡ trÃ¬nh huáº¥n luyá»‡n, cÃ¡c phÆ°Æ¡ng phÃ¡p tá»‘i Æ°u hÃ³a, chiáº¿n lÆ°á»£c chia dá»¯ liá»‡u, vÃ  cÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ phá»• biáº¿n. Äá»“ng thá»i, bÃ i viáº¿t bá»• sung cÃ¡c cÃ´ng thá»©c toÃ¡n há»c ná»n táº£ng nhÆ° hÃ m máº¥t mÃ¡t, gradient descent, entropy chÃ©o vÃ  cÃ¡c thÆ°á»›c Ä‘o hiá»‡u suáº¥t. Ná»™i dung Ä‘Æ°á»£c xÃ¢y dá»±ng theo chuáº©n khoa há»c, káº¿t há»£p lÃ½ thuyáº¿t tá»« cÃ¡c tÃ i liá»‡u kinh Ä‘iá»ƒn trong lÄ©nh vá»±c ML.

â¸»

1. Giá»›i thiá»‡u

Trong há»c mÃ¡y, má»¥c tiÃªu cá»§a mÃ´ hÃ¬nh lÃ  xáº¥p xá»‰ má»™t hÃ m Ã¡nh xáº¡:

f_\theta: X \rightarrow Y

Trong Ä‘Ã³:
	â€¢	X lÃ  khÃ´ng gian Ä‘áº§u vÃ o
	â€¢	Y lÃ  khÃ´ng gian Ä‘áº§u ra
	â€¢	\theta lÃ  táº­p tham sá»‘ cá»§a mÃ´ hÃ¬nh

QuÃ¡ trÃ¬nh huáº¥n luyá»‡n nháº±m tÃ¬m ra bá»™ tham sá»‘ \theta^* sao cho hÃ m máº¥t mÃ¡t Ä‘Æ°á»£c tá»‘i thiá»ƒu hÃ³a:

\theta^* = \arg\min_\theta \mathcal{L}(\theta)

â¸»

2. CÆ¡ sá»Ÿ ToÃ¡n há»c cá»§a Huáº¥n luyá»‡n MÃ´ hÃ¬nh

2.1 HÃ m máº¥t mÃ¡t (Loss Function)

TÃ¹y theo loáº¡i bÃ i toÃ¡n, hÃ m máº¥t mÃ¡t Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh khÃ¡c nhau.

(a) Há»“i quy â€“ Mean Squared Error (MSE)

\mathcal{L}_{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2

Trong Ä‘Ã³:
	â€¢	y_i lÃ  giÃ¡ trá»‹ thá»±c
	â€¢	\hat{y}_i lÃ  giÃ¡ trá»‹ dá»± Ä‘oÃ¡n

â¸»

(b) PhÃ¢n loáº¡i â€“ Cross Entropy Loss

\mathcal{L}_{CE} = - \sum_{i=1}^{n} y_i \log(\hat{y}_i)

Cross-entropy cÃ³ nguá»“n gá»‘c tá»« lÃ½ thuyáº¿t thÃ´ng tin cá»§a Shannon (1948).

â¸»

2.2 Tá»‘i Æ°u hÃ³a báº±ng Gradient Descent

Thuáº­t toÃ¡n cáº­p nháº­t tham sá»‘:

\theta_{t+1} = \theta_t - \eta \nabla_\theta \mathcal{L}(\theta_t)

Trong Ä‘Ã³:
	â€¢	\eta lÃ  learning rate
	â€¢	\nabla_\theta \mathcal{L} lÃ  gradient

CÃ¡c biáº¿n thá»ƒ:
	â€¢	Batch Gradient Descent
	â€¢	Stochastic Gradient Descent (SGD)
	â€¢	Adam Optimizer:

m_t = \beta_1 m_{t-1} + (1-\beta_1)g_t
v_t = \beta_2 v_{t-1} + (1-\beta_2)g_t^2

Adam Ä‘Æ°á»£c Ä‘á» xuáº¥t bá»Ÿi Kingma & Ba (2015).

â¸»

3. Quy trÃ¬nh Huáº¥n luyá»‡n

3.1 Chia táº­p dá»¯ liá»‡u

ThÃ´ng thÆ°á»ng:
	â€¢	Training set: 70â€“80%
	â€¢	Validation set: 10â€“15%
	â€¢	Test set: 10â€“15%

MÃ´ hÃ¬nh Ä‘Æ°á»£c tá»‘i Æ°u trÃªn training set, Ä‘iá»u chá»‰nh siÃªu tham sá»‘ trÃªn validation set vÃ  Ä‘Ã¡nh giÃ¡ cuá»‘i cÃ¹ng trÃªn test set.

â¸»

3.2 Overfitting vÃ  Underfitting

Overfitting

MÃ´ hÃ¬nh há»c quÃ¡ sÃ¡t dá»¯ liá»‡u huáº¥n luyá»‡n:

\mathcal{L}_{train} \ll \mathcal{L}_{test}

Giáº£i phÃ¡p:
	â€¢	Regularization:
\mathcal{L}_{reg} = \mathcal{L} + \lambda ||\theta||^2
	â€¢	Dropout
	â€¢	Early stopping

â¸»

4. ÄÃ¡nh giÃ¡ MÃ´ hÃ¬nh

4.1 BÃ i toÃ¡n PhÃ¢n loáº¡i

(a) Accuracy

Accuracy = \frac{TP + TN}{TP + TN + FP + FN}

â¸»

(b) Precision & Recall

Precision = \frac{TP}{TP + FP}

Recall = \frac{TP}{TP + FN}

â¸»

(c) F1-score

F1 = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall}

â¸»

(d) ROC-AUC

Diá»‡n tÃ­ch dÆ°á»›i Ä‘Æ°á»ng cong ROC Ä‘o kháº£ nÄƒng phÃ¢n biá»‡t hai lá»›p.

â¸»

4.2 BÃ i toÃ¡n Há»“i quy

(a) Mean Absolute Error (MAE)

MAE = \frac{1}{n} \sum |y_i - \hat{y}_i|

(b) RÂ² Score

R^2 = 1 - \frac{\sum (y_i - \hat{y}_i)^2}{\sum (y_i - \bar{y})^2}

â¸»

5. ÄÃ¡nh giÃ¡ Thá»±c nghiá»‡m

Trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n:
	â€¢	Theo dÃµi loss curve
	â€¢	So sÃ¡nh train vs validation
	â€¢	Sá»­ dá»¥ng confusion matrix
	â€¢	Cross-validation:

CV = \frac{1}{k} \sum_{i=1}^{k} \mathcal{L}_i

â¸»

6. Tháº£o luáº­n

Huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh khÃ´ng chá»‰ lÃ  quÃ¡ trÃ¬nh ká»¹ thuáº­t mÃ  cÃ²n lÃ  bÃ i toÃ¡n tá»‘i Æ°u hÃ³a thá»‘ng kÃª. Sai lá»‡ch (bias) vÃ  phÆ°Æ¡ng sai (variance) Ä‘Ã³ng vai trÃ² quan trá»ng:

\mathbb{E}[(y - \hat{f}(x))^2] = Bias^2 + Variance + \sigma^2

CÃ¢n báº±ng bias-variance lÃ  chÃ¬a khÃ³a xÃ¢y dá»±ng mÃ´ hÃ¬nh tá»•ng quÃ¡t hÃ³a tá»‘t.

â¸»

7. Káº¿t luáº­n

QuÃ¡ trÃ¬nh huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh dá»±a trÃªn ná»n táº£ng toÃ¡n há»c vá»¯ng cháº¯c cá»§a:
	â€¢	Tá»‘i Æ°u hÃ³a
	â€¢	XÃ¡c suáº¥t thá»‘ng kÃª
	â€¢	LÃ½ thuyáº¿t thÃ´ng tin

Viá»‡c lá»±a chá»n hÃ m máº¥t mÃ¡t, thuáº­t toÃ¡n tá»‘i Æ°u vÃ  chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ phÃ¹ há»£p quyáº¿t Ä‘á»‹nh trá»±c tiáº¿p Ä‘áº¿n hiá»‡u nÄƒng há»‡ thá»‘ng. Trong bá»‘i cáº£nh AI hiá»‡n Ä‘áº¡i, Ä‘áº·c biá»‡t vá»›i cÃ¡c mÃ´ hÃ¬nh lá»›n (Large Language Models), quy trÃ¬nh huáº¥n luyá»‡n cÃ²n má»Ÿ rá»™ng sang:
	â€¢	Fine-tuning
	â€¢	Transfer learning
	â€¢	Reinforcement Learning from Human Feedback (RLHF)

â¸»

TÃ i liá»‡u tham kháº£o
	1.	Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.
	2.	Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.
	3.	Kingma, D. P., & Ba, J. (2015). Adam: A Method for Stochastic Optimization.
	4.	Vapnik, V. (1998). Statistical Learning Theory. Wiley.
	5.	Shannon, C. E. (1948). A Mathematical Theory of Communication.
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| [aero_LLM_01_Word2Vec vs. GloVe vs. GPT vs. BERT... oh my!.md](aero_LLM_01_Word2Vec vs. GloVe vs. GPT vs. BERT... oh my!.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_01_Word2Vec vs. GloVe vs. GPT vs. BERT... oh my!.md) |
| [aero_LLM_02_Exploring GloVe pretrained embeddings.md](aero_LLM_02_Exploring GloVe pretrained embeddings.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_02_Exploring GloVe pretrained embeddings.md) |
| [aero_LLM_03_CodeChallenge Wikipedia vs. Twitter embeddings (part 1).md](aero_LLM_03_CodeChallenge Wikipedia vs. Twitter embeddings (part 1).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_03_CodeChallenge Wikipedia vs. Twitter embeddings (part 1).md) |
| [So sÃ¡nh Biá»ƒu Diá»…n Tá»« Vá»±ng giá»¯a Wikipedia vÃ  Twitter báº±ng PhÃ¢n TÃ­ch TÆ°Æ¡ng Äá»“ng Biá»ƒu Diá»…n (RSA)](aero_LLM_04_CodeChallenge Wikipedia vs. Twitter embeddings (part 2).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_04_CodeChallenge Wikipedia vs. Twitter embeddings (part 2).md) |
| [So sÃ¡nh Biá»ƒu Diá»…n Ngá»¯ NghÄ©a cá»§a GPT-2 vÃ  BERT thÃ´ng qua PhÃ¢n TÃ­ch Embedding](aero_LLM_05_Exploring GPT2 and BERT embeddings.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_05_Exploring GPT2 and BERT embeddings.md) |
| [ToÃ¡n há»c cá»§a Token vÃ  Embedding trong MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n](aero_LLM_06_CodeChallenge Math with tokens and embeddings.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_06_CodeChallenge Math with tokens and embeddings.md) |
| [Cosine Similarity vÃ  Má»‘i Quan Há»‡ vá»›i Há»‡ Sá»‘ TÆ°Æ¡ng Quan: CÆ¡ Sá»Ÿ ToÃ¡n Há»c vÃ  á»¨ng Dá»¥ng trong NLP](aero_LLM_07_Cosine similarity (and relation to correlation).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_07_Cosine similarity (and relation to correlation).md) |
| [PhÃ¢n TÃ­ch Cosine Similarity trong KhÃ´ng Gian Embedding cá»§a GPT-2](aero_LLM_08_CodeChallenge GPT2 cosine similarities.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_08_CodeChallenge GPT2 cosine similarities.md) |
| [Unembedding trong MÃ´ HÃ¬nh NgÃ´n Ngá»¯ Lá»›n: Tá»« Vector áº¨n Äáº¿n Token](aero_LLM_09_CodeChallenge Unembeddings (vectors to tokens).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_09_CodeChallenge Unembeddings (vectors to tokens).md) |
| [Position Embeddings trong Transformer: CÆ¡ Sá»Ÿ ToÃ¡n Há»c vÃ  á»¨ng Dá»¥ng trong MÃ´ HÃ¬nh NgÃ´n Ngá»¯ Lá»›n](aero_LLM_10_Position embeddings.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_10_Position embeddings.md) |
| [PhÃ¢n TÃ­ch Thá»±c Nghiá»‡m Embedding Vá»‹ TrÃ­ Trong Transformer: Tá»« Cáº¥u TrÃºc Tuyáº¿n TÃ­nh Äáº¿n KhÃ´ng Gian HÃ¬nh Há»c](aero_LLM_11_CodeChallenge Exploring position embeddings.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_11_CodeChallenge Exploring position embeddings.md) |
| [Huáº¥n Luyá»‡n Embedding Tá»« Äáº§u: CÆ¡ Sá»Ÿ ToÃ¡n Há»c, CÆ¡ Cháº¿ Tá»‘i Æ¯u vÃ  á»¨ng Dá»¥ng Trong MÃ´ HÃ¬nh NgÃ´n Ngá»¯](aero_LLM_12_Training embeddings from scratch.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_12_Training embeddings from scratch.md) |
| [Thiáº¿t Káº¿ Data Loader Cho Huáº¥n Luyá»‡n MÃ´ HÃ¬nh NgÃ´n Ngá»¯: CÆ¡ Sá»Ÿ ToÃ¡n Há»c, Kiáº¿n TrÃºc vÃ  Tá»‘i Æ¯u HoÃ¡](aero_LLM_13_Create a data loader to train a model.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_13_Create a data loader to train a model.md) |
| [XÃ¢y Dá»±ng MÃ´ HÃ¬nh Há»c Embedding Tá»« Äáº§u: Kiáº¿n TrÃºc, Tá»‘i Æ¯u HoÃ¡ vÃ  PhÃ¢n TÃ­ch ToÃ¡n Há»c](aero_LLM_14_Build a model to learn the embeddings.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_14_Build a model to learn the embeddings.md) |
| [HÃ m Máº¥t MÃ¡t Trong Huáº¥n Luyá»‡n Embedding: CÆ¡ Sá»Ÿ LÃ½ Thuyáº¿t, PhÃ¢n TÃ­ch Gradient vÃ  á»¨ng Dá»¥ng Trong MÃ´ HÃ¬nh NgÃ´n Ngá»¯](aero_LLM_15_Loss function to train the embeddings.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_15_Loss function to train the embeddings.md) |
| ğŸ“Œ **[Huáº¥n luyá»‡n vÃ  ÄÃ¡nh giÃ¡ MÃ´ hÃ¬nh Há»c MÃ¡y: CÆ¡ sá»Ÿ LÃ½ thuyáº¿t vÃ  Thá»±c tiá»…n](aero_LLM_16_Train and evaluate the model.md)** | [Xem bÃ i viáº¿t â†’](aero_LLM_16_Train and evaluate the model.md) |
| [Sá»± Thay Äá»•i cá»§a Embeddings Trong QuÃ¡ TrÃ¬nh Huáº¥n Luyá»‡n: PhÃ¢n TÃ­ch ToÃ¡n Há»c vÃ  Thá»±c Nghiá»‡m](aero_LLM_17_CodeChallenge How the embeddings change.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_17_CodeChallenge How the embeddings change.md) |
| [Äá»™ á»”n Äá»‹nh cá»§a Embeddings trong MÃ´ HÃ¬nh NgÃ´n Ngá»¯: PhÃ¢n TÃ­ch ToÃ¡n Há»c vÃ  Thá»±c Nghiá»‡m](aero_LLM_18_CodeChallenge How stable are embeddings.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_18_CodeChallenge How stable are embeddings.md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
