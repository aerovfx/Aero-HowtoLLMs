
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../index.md) > [11 Investigating token embeddings](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../index.md)
- [ğŸ“š Module 01: LLM Course](../../01-LLM_Course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../02-Words-to-tokens-to-numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../04-buildGPT/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../07-Fine-tune-pretrained-models/index.md)
- [ğŸ” Module 19: AI Safety](../../19-AI-safety/index.md)
- [ğŸ Module 20: Python for AI](../../20-Python-Colab-notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# PhÃ¢n TÃ­ch RSA (Representational Similarity Analysis) Giá»¯a CÃ¡c MÃ´ HÃ¬nh NgÃ´n Ngá»¯

## TÃ³m táº¯t

Representational Similarity Analysis (RSA) lÃ  má»™t phÆ°Æ¡ng phÃ¡p luáº­n ban Ä‘áº§u Ä‘Æ°á»£c phÃ¡t triá»ƒn trong Khoa há»c Tháº§n kinh (Neuroscience) nháº±m so sÃ¡nh phá»• Ä‘iá»‡n nÃ£o Ä‘á»“ vá»›i mÃ´ hÃ¬nh tÃ­nh toÃ¡n. NgÃ y nay, thuáº­t toÃ¡n nÃ y trá»Ÿ thÃ nh má»™t trong nhá»¯ng mÅ©i nhá»n cá»§a lÄ©nh vá»±c PhÃ¢n tÃ­ch Biá»ƒu diá»…n NgÃ´n ngá»¯ (Representational Analysis) giÃºp chÃºng ta Ä‘á»‘i chiáº¿u, so sÃ¡nh vÃ  Ä‘á»‹nh lÆ°á»£ng sá»± tÆ°Æ¡ng Ä‘á»“ng giá»¯a cÃ¡c ma tráº­n nhÃºng (Embeddings matrices) vá»‘n cÃ³ khÃ´ng gian chiá»u (dimensionality) hoÃ n toÃ n lá»‡ch nhau (VÃ­ dá»¥: So sÃ¡nh Word2Vec 300 chiá»u vá»›i GPT-2 768 chiá»u). BÃ i viáº¿t dÆ°á»›i Ä‘Ã¢y trÃ¬nh bÃ y nguyÃªn lÃ½ toÃ¡n há»c vÃ  quy trÃ¬nh thá»±c hiá»‡n cáº¥u trÃºc RSA trong ngá»¯ cáº£nh xá»­ lÃ½ ngÃ´n ngá»¯ há»c mÃ¡y.

---

## 1. Giá»›i thiá»‡u

Vá»›i sá»± bÃ¹ng ná»• cá»§a cÃ¡c mÃ´ hÃ¬nh nhÃºng (Embeddings) nhÆ° GloVe, Word2Vec, BERT hay GPT, má»™t cÃ¢u há»i lá»›n Ä‘Æ°á»£c Ä‘áº·t ra: *LÃ m sao Ä‘á»ƒ biáº¿t liá»‡u hai mÃ´ hÃ¬nh nÃ y cÃ³ chung má»™t cÃ¡ch hiá»ƒu vá» máº·t váº­t lÃ½ khÃ´ng gian cho má»™t bá»™ tá»« vá»±ng hay khÃ´ng?* 

Sá»± lá»‡ch pha vá» chiá»u khÃ´ng gian vector cá»§a cÃ¡c ma tráº­n khiáº¿n cho chÃºng ta khÃ´ng thá»ƒ sá»­ dá»¥ng cÃ¡c phÃ©p trá»« trá»±c tiáº¿p (direct subtraction) hay khoáº£ng cÃ¡ch Euclidean giá»¯a hai máº¡ng mÃ´ hÃ¬nh. RSA giáº£i quyáº¿t váº¥n Ä‘á» nÃ y báº±ng cÃ¡ch cháº¯t lá»c cÃ¡c Ä‘áº·c trÆ°ng tÆ°Æ¡ng quan khoáº£ng cÃ¡ch *bÃªn trong* vÃ¹ng dá»¯ liá»‡u cá»§a má»—i mÃ´ hÃ¬nh trÆ°á»›c, sau Ä‘Ã³ má»›i so sÃ¡nh khá»‘i Ä‘áº·c trÆ°ng tÆ°Æ¡ng quan (Similarity structures) *giá»¯a* hai mÃ´ hÃ¬nh.

---

## 2. NguyÃªn LÃ½ ToÃ¡n Há»c Cá»§a RSA

Khung toÃ¡n há»c cá»§a RSA tráº£i qua 3 bÆ°á»›c cá»‘t lÃµi: 

### 2.1 Ma tráº­n Khoáº£ng CÃ¡ch / TÆ°Æ¡ng Quan Cá»¥c Bá»™ (Similarity Matrices)

Cho ma tráº­n nhÃºng $E_1 \in \mathbb{R}^{N \times D_1}$ tá»« mÃ´ hÃ¬nh 1 (VÃ­ dá»¥ Word2Vec kÃ­ch thÆ°á»›c $D_1 = 300$) vÃ  $E_2 \in \mathbb{R}^{N \times D_2}$ tá»« mÃ´ hÃ¬nh 2 (GPT, kÃ­ch thÆ°á»›c $D_2 = 768$), vá»›i $N$ lÃ  sá»‘ lÆ°á»£ng token ngÃ´n ngá»¯ chung giá»¯a hai mÃ´ hÃ¬nh (pháº£i Ä‘á»“ng nháº¥t thá»© tá»± token).

BÆ°á»›c Ä‘áº§u tiÃªn, RSA tÃ­nh toÃ¡n cÃ¡c Ma tráº­n TÆ°Æ¡ng quan ná»™i bá»™ (viáº¿t táº¯t lÃ  Representational Similarity Matrix - RSM) cho tá»«ng khÃ´ng gian chiá»u:
$$ S_1 = \text{CosineSimilarity}(E_1) $$
$$ S_2 = \text{CosineSimilarity}(E_2) $$

Trong Ä‘Ã³, má»—i pháº§n tá»­ $S(i, j)$ Ä‘Æ°á»£c cho báº±ng cÃ´ng thá»©c ná»™i tÃ­ch ma tráº­n Gram Ä‘Ã£ chuáº©n hÃ³a:
$$
S(i,j) = \frac{e_i \cdot e_j}{\|e_i\| \|e_j\|}
$$
Káº¿t quáº£ thu Ä‘Æ°á»£c lÃ  2 ma tráº­n vuÃ´ng Ä‘á»‘i xá»©ng kÃ­ch thÆ°á»›c $N \times N$, Ä‘á»™c láº­p hoÃ n toÃ n vá»›i chiá»u khÃ´ng gian ban Ä‘áº§u $D_1$ hay $D_2$.

### 2.2 TrÃ­ch Xuáº¥t Vector Tam GiÃ¡c ThÆ°á»£ng (Upper Triangular Unrolling)

VÃ¬ cÃ¡c ma tráº­n $S_1$ vÃ  $S_2$ lÃ  Ä‘á»‘i xá»©ng qua Ä‘Æ°á»ng chÃ©o $S(i,j) = S(j,i)$, vÃ  cÃ¡c giÃ¡ trá»‹ trÃªn Ä‘Æ°á»ng chÃ©o luÃ´n báº±ng 1 ($S(i,i) = 1$), viá»‡c tÃ­nh toÃ¡n trÃªn toÃ n bá»™ ma tráº­n sáº½ dáº«n Ä‘áº¿n hiá»‡n tÆ°á»£ng bÆ¡m phá»“ng tÆ°Æ¡ng quan (inflation artifact). Do Ä‘Ã³, ta chá»‰ trÃ­ch xuáº¥t cÃ¡c thÃ nh pháº§n khÃ´ng bá»‹ trÃ¹ng láº·p á»Ÿ ná»­a trÃªn tam giÃ¡c (upper triangular part):
$$ 
\vec{v}_1 = \{ S_1(i, j) \mid i < j \}
$$
$$ 
\vec{v}_2 = \{ S_2(i, j) \mid i < j \}
$$
Sá»‘ lÆ°á»£ng cÃ¡c pháº§n tá»­ duy nháº¥t sau khi bung ra lÃ  $\frac{N(N-1)}{2}$.

### 2.3 PhÃ¢n TÃ­ch Pearson Correlation Giá»¯a RSA

BÆ°á»›c cuá»‘i cÃ¹ng lÃ  Ã¡p dá»¥ng há»‡ sá»‘ TÆ°Æ¡ng quan bÃ¬nh phÆ°Æ¡ng Pearson (hoáº·c Spearman rank correlation) giá»¯a hai vector $\vec{v}_1$ vÃ  $\vec{v}_2$:

$$
\rho = \frac{\sum (\vec{v}_1 - \mu_{\vec{v}_1})(\vec{v}_2 - \mu_{\vec{v}_2})}{\sigma_{\vec{v}_1} \sigma_{\vec{v}_2}}
$$

Náº¿u $\rho$ tiáº¿n sÃ¡t tá»›i 1, ta káº¿t luáº­n ráº±ng báº¥t cháº¥p viá»‡c Ä‘Æ°á»£c huáº¥n luyá»‡n á»Ÿ nhá»¯ng nguá»“n dá»¯ liá»‡u khÃ¡c nhau vá»›i sá»‘ lÆ°á»£ng lá»›p nÆ¡-ron khÃ¡c nhau, hai mÃ´ hÃ¬nh nÃ y sá»­ dá»¥ng cÃ¹ng má»™t cáº¥u trÃºc hÃ¬nh há»c tÆ°Æ¡ng quan Ä‘á»ƒ báº£o toÃ n ngá»¯ nghÄ©a tá»« vá»±ng.

---

## 3. á»¨ng Dá»¥ng Khai ThÃ¡c Äá»™ DÆ° Thá»«a Cá»§a Neural Network

Trong tÃ i liá»‡u Ä‘Ã­nh kÃ¨m, RSA Ä‘Æ°á»£c khai thÃ¡c á»Ÿ má»™t biáº¿n thá»ƒ thÃº vá»‹: thay vÃ¬ so sÃ¡nh hai mÃ´ hÃ¬nh Ä‘á»™c láº­p, ta so sÃ¡nh ná»™i bá»™ hai ma tráº­n chia cáº¯t tá»« má»™t cá»¥m nhÃºng Ä‘Æ¡n Ä‘iá»‡u. Báº±ng cÃ¡ch tÃ¡ch má»™t ma tráº­n 300 chiá»u thÃ nh hai khá»‘i 150 chiá»u D-cháºµn (Even dimensions) vÃ  D-láº» (Odd dimensions), chÃºng ta thu Ä‘Æ°á»£c sá»± tÆ°Æ¡ng Ä‘á»“ng mÃ£ hÃ³a $\rho \approx 0.8$. Sá»± lá»‡ch pha cÃ²n láº¡i ($\sim 20\%$) táº¡o nÃªn má»™t lÆ°á»£ng thÃ´ng tin khÃ´ng Ä‘á»‘i xá»©ng (Unique internal coding) bÃªn cáº¡nh pháº§n dÆ° thá»«a Ä‘áº·c trÆ°ng.

Viá»‡c Ä‘Ã¡nh giÃ¡ sá»± tÆ°Æ¡ng quan dÆ° thá»«a (representational redundancy) giÃºp tá»‘i Æ°u bÃ i toÃ¡n nÃ©n vÃ  cáº¯t bá»›t mÃ´ hÃ¬nh (Model Pruning) nháº±m tÄƒng tá»‘c quÃ¡ trÃ¬nh suy luáº­n mÃ  khÃ´ng giáº£m hiá»‡u suáº¥t diá»…n giáº£i cá»§a há»‡ thá»‘ng trÃ­ tuá»‡.

---

## 4. Káº¿t luáº­n

Representational Similarity Analysis (RSA) Ä‘Æ°á»£c coi lÃ  má»™t á»‘ng kÃ­nh trung gian hoÃ n háº£o Ä‘á»ƒ thu phÃ³ng vÃ  Ä‘á»‘i chiáº¿u hai há»™p Ä‘en AI Ä‘á»™c láº­p báº±ng cÃ¡ch so sÃ¡nh cÃ¡c Ä‘áº·c tÃ­nh má»‘i quan há»‡ thay vÃ¬ giÃ¡ trá»‹ vector thÃ´. Kháº£ nÄƒng loáº¡i bá» tÃ­nh khÃ´ng biá»ƒu diá»…n (Dimension elimination constraint) lÃ  ná»n táº£ng giÃºp phÆ°Æ¡ng phÃ¡p nÃ y trá»Ÿ thÃ nh má»™t phÃ©p tÃ­nh chuáº©n trong lÄ©nh vá»±c Alignment vÃ  Äá»‹nh lÆ°á»£ng Kháº£ nÄƒng Diá»…n giáº£i (Interpretability).

---

## TÃ i liá»‡u tham kháº£o

1. **Kriegeskorte, N., et al. (2008).** *Representational similarity analysis - connecting the branches of systems neuroscience.* Frontiers in Systems Neuroscience, 2. (Khoa há»c há»‡ tháº§n kinh gá»‘c cá»§a RSA).
2. **Abnar, S., et al. (2019).** *Blackbox meets blackbox: Representational Similarity and Stability Analysis of Neural Language Models.* Proceedings of the 2019 ACL Workshop BlackboxNLP.
3. **ChrupaÅ‚a, G., & Alishahi, A. (2019).** *Correlating neural and symbolic representations of language.* ACL.
4. TÃ i liá»‡u bÃ i giáº£ng *Investigating token embeddings - RSA*.
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| [aero_LLM_01_CodeChallenge Cosine similarity (advanced) (part 1).md](aero_LLM_01_CodeChallenge Cosine similarity (advanced) (part 1).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_01_CodeChallenge Cosine similarity (advanced) (part 1).md) |
| [aero_LLM_02_CodeChallenge Cosine similarity (advanced) (part 2).md](aero_LLM_02_CodeChallenge Cosine similarity (advanced) (part 2).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_02_CodeChallenge Cosine similarity (advanced) (part 2).md) |
| [Theo DÃµi DÃ²ng Cháº£y Cosine Similarity TrÃªn Trá»¥c VÄƒn Báº£n ChuyÃªn Tuáº§n Tá»± (Word Sequences)](aero_LLM_03_CodeChallenge Cosine similarity in word sequences.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_03_CodeChallenge Cosine similarity in word sequences.md) |
| [Nghá»‡ Thuáº­t Váº½ Báº£n Äá»“ Nhiá»‡t Ma Tráº­n NhÃºng Báº±ng CÆ°á»ng Äá»™ Tá»« (Coloring Cosine Similarity)](aero_LLM_04_CodeChallenge Coloring cosine similarity.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_04_CodeChallenge Coloring cosine similarity.md) |
| [áº¢o áº¢nh Cá»§a TrÃ­ Tuá»‡ ToÃ¡n Há»c Trong NgÃ´n Ngá»¯: Sá»©c Máº¡nh Cá»§a Random Embeddings](aero_LLM_05_CodeChallenge Can random embeddings be interpreted.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_05_CodeChallenge Can random embeddings be interpreted.md) |
| [PhÆ°Æ¡ng PhÃ¡p T-SNE VÃ  Thuáº­t ToÃ¡n PhÃ¢n Cá»¥m DBSCAN: Chiáº¿u KhÃ´ng Gian Äa Chiá»u Cho LLMs](aero_LLM_06_T-SNE projection and DBSCAN clustering (theory).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_06_T-SNE projection and DBSCAN clustering (theory).md) |
| [PhÃ¢n Cá»¥m Ngá»¯ NghÄ©a Qua PhÃ©p Chiáº¿u t-SNE & Máº­t Äá»™ DBSCAN (Python)](aero_LLM_07_T-SNE projection and DBSCAN clustering (Python).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_07_T-SNE projection and DBSCAN clustering (Python).md) |
| [ThÃ¡ch Thá»©c Code: TÃ¬m Lá»— Há»•ng PhÃ¢n Cá»¥m Báº±ng Bá»™ Lá»c Báº£ng Chá»¯ CÃ¡i Chá»¯ X](aero_LLM_08_CodeChallenge cluster the x terms.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_08_CodeChallenge cluster the x terms.md) |
| [PhÃ¢n RÃ£ Token, NhÃºng VÃ  PhÃ¢n Cá»¥m Biá»ƒu TÆ°á»£ng Emojis Báº±ng Äá»“ Thá»‹ Máº­t Äá»™](aero_LLM_09_CodeChallenge Tokenize, embed, and cluster happy emojis.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_09_CodeChallenge Tokenize, embed, and cluster happy emojis.md) |
| ğŸ“Œ **[PhÃ¢n TÃ­ch RSA (Representational Similarity Analysis) Giá»¯a CÃ¡c MÃ´ HÃ¬nh NgÃ´n Ngá»¯](aero_LLM_10_RSA (representational similarity analysis).md)** | [Xem bÃ i viáº¿t â†’](aero_LLM_10_RSA (representational similarity analysis).md) |
| [PhÃ¢n TÃ­ch Äá»™ Lá»‡ch RSA (Part 1): So SÃ¡nh Sá»± Báº¥t Äá»“ng Giá»¯a KhÃ´ng Gian GloVe 50D vÃ  300D](aero_LLM_11_CodeChallenge Compare embeddings with RSA (part 1).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_11_CodeChallenge Compare embeddings with RSA (part 1).md) |
| [PhÃ¢n TÃ­ch Äá»™ Lá»‡ch RSA (Part 2): Äá»‘i Chiáº¿u TÆ°Æ¡ng Quan Pearson Cho Khoáº£ng CÃ¡ch Cosine](aero_LLM_12_CodeChallenge Compare embeddings with RSA (part 2).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_12_CodeChallenge Compare embeddings with RSA (part 2).md) |
| [So SÃ¡nh KhÃ´ng Gian NhÃºng: Word2Vec VÃ  GPT-2 Qua PhÃ¢n TÃ­ch RSA](aero_LLM_13_CodeChallenge Word2vec vs. GPT2.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_13_CodeChallenge Word2vec vs. GPT2.md) |
| [Bá»‘ Cá»¥c Äá»“ Thá»‹ Máº¡ng (Network Graph) ThÃ´ng Qua Ma Tráº­n Cosine Similarity](aero_LLM_14_CodeChallenge Graph representation of cosine similarities.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_14_CodeChallenge Graph representation of cosine similarities.md) |
| [Sá»‘ Há»c Tuyáº¿n TÃ­nh vÃ  RÃºt TrÃ­ch TÆ°Æ¡ng Äá»“ng Giá»¯a CÃ¡c Tá»« NhÃºng (Word Embeddings Analogies)](aero_LLM_15_Embeddings arithmetic and analogies.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_15_Embeddings arithmetic and analogies.md) |
| [Vá»¡ Má»™ng Vá» Sá»‘ Há»c Vector TÆ°Æ¡ng ÄÆ°Æ¡ng (Soft-Coded Analogies) TrÃªn Word2Vec](aero_LLM_16_CodeChallenge soft-coded analogies in word2vec.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_16_CodeChallenge soft-coded analogies in word2vec.md) |
| [Thiáº¿t Láº­p VÃ  Diá»…n Giáº£i Trá»¥c Ngá»¯ NghÄ©a Tuyáº¿n TÃ­nh (Linear Semantic Axes)](aero_LLM_17_Creating and interpreting linear semantic axes.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_17_Creating and interpreting linear semantic axes.md) |
| [Khai ThÃ¡c Thuáº­t ToÃ¡n k-NN Cho TÃ¬m Kiáº¿m Tá»« Äá»“ng NghÄ©a TrÃªn BERT](aero_LLM_18_kNN for synonym-searching in BERT.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_18_kNN for synonym-searching in BERT.md) |
| [Cáº¡nh Tranh TÃ¬m Tá»« Äá»“ng NghÄ©a BERT vs GPT: CÆ¡ Cháº¿ Tokenization Äa KÃ½ Tá»±](aero_LLM_19_CodeChallenge BERT v GPT kNN kompetition.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_19_CodeChallenge BERT v GPT kNN kompetition.md) |
| [Sá»± Dá»‹ch Chuyá»ƒn VÃ  Äá»“ng Tá»“n Biá»ƒu Diá»…n Giá»¯a CÃ¡c KhÃ´ng Gian NhÃºng](aero_LLM_20_Research on translating embeddings spaces.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_20_Research on translating embeddings spaces.md) |
| [PhÃ¢n TÃ­ch ChÃ¹m Quang Phá»• Suy Biáº¿n (Singular Value Spectrum) Cá»§a KhÃ´ng Gian NhÃºng](aero_LLM_21_Singular value spectrum of embeddings submatrices.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_21_Singular value spectrum of embeddings submatrices.md) |
| [Ãnh Xáº¡ SVD CÃ¡c Dáº£i Äiá»ƒm NhÃºng CÃ³ Quan Há»‡ ChÃ©o](aero_LLM_22_CodeChallenge SVD projections of related embeddings.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_22_CodeChallenge SVD projections of related embeddings.md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
