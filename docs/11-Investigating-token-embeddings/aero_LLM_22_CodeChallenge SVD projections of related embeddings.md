
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../index.md) > [11 Investigating token embeddings](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../index.md)
- [ğŸ“š Module 01: LLM Course](../../01-LLM_Course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../02-Words-to-tokens-to-numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../04-buildGPT/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../07-Fine-tune-pretrained-models/index.md)
- [ğŸ” Module 19: AI Safety](../../19-AI-safety/index.md)
- [ğŸ Module 20: Python for AI](../../20-Python-Colab-notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Ãnh Xáº¡ SVD CÃ¡c Dáº£i Äiá»ƒm NhÃºng CÃ³ Quan Há»‡ ChÃ©o

## TÃ³m táº¯t

Má»™t trong nhá»¯ng giá»›i háº¡n khi phÃ¢n tÃ­ch toÃ n bá»™ KhÃ´ng gian Embeddings báº±ng SVD (Singular Value Decomposition) lÃ  sá»± bÃ£o hÃ²a nhiá»…u - nhá»¯ng thÃ nh pháº§n chÃ­nh (Principal Components) thÆ°á»ng Ä‘Ã¡nh máº¥t Ä‘á»™ chi tiáº¿t do pháº£i gÃ¡nh Ä‘á»¡ má»™t tá»· lá»‡ phÆ°Æ¡ng sai khá»•ng lá»“ cá»§a cáº£ trÄƒm ngÃ n cá»¥m tá»« dá»‹ biá»‡t. Giáº£i phÃ¡p Ä‘á»‘i trá»ng lÃ  khoanh vÃ¹ng tá»a Ä‘á»™ vi mÃ´: Thay vÃ¬ nÃ©n toÃ n thá»ƒ máº£ng BERT, ta táº¡o ra cÃ¡c "Ma tráº­n Con" (Submatrices) chá»©a duy nháº¥t tá»• há»£p token mang Ä‘áº·c trÆ°ng nhÃ³m (VD: TÃªn quá»‘c gia, chá»¯ sá»‘). BÃ i phÃ¢n tÃ­ch dÆ°á»›i Ä‘Ã¢y minh chá»©ng nÄƒng lá»±c cá»§a SVD trong viá»‡c tÃ¬m ra nhá»¯ng trá»¥c liÃªn káº¿t Ä‘á»“ng dáº¡ng áº©n dáº­t dÆ°á»›i cÃ¡c nhÃ³m tá»« vá»±ng cá»¥ thá»ƒ.

---

## 1. Kiáº¿n Táº¡o Ma Tráº­n Con (Submatrices Embeddings)

Cáº¥u hÃ¬nh thá»­ nghiá»‡m Ä‘Æ°á»£c thiáº¿t káº¿ dá»±a trÃªn 2 táº­p dá»¯ liá»‡u máº«u trÃ­ch tá»« mÃ´ hÃ¬nh BERT:
1. **Táº­p 10 Chá»¯ sá»‘ Ä‘Æ¡n:** `["0", "1", "2", ..., "9"]`
2. **Táº­p 10 Quá»‘c gia LiÃªn Minh ChÃ¢u Ã‚u (EU):** `["France", "Germany", "Italy", "Spain", ...]` (Chá»n lá»c Æ°u tiÃªn cÃ¡c quá»‘c gia khÃ´ng bá»‹ bÄƒm ngang bá»Ÿi tokenizer Ä‘á»ƒ Ä‘áº£m báº£o luáº­t *1 word = 1 token*).

Hai ma tráº­n con nháº­n Ä‘Æ°á»£c (Matrix $M_{\text{digits}}$ vÃ  $M_{\text{EU}}$) cÃ³ chung kÃ­ch thÆ°á»›c $10 \times 768$.
TÃ­nh Ä‘á»™c láº­p phÃ¢n phá»‘i (Orthogonality mapping) Ä‘Æ°á»£c kháº³ng Ä‘á»‹nh ngay tá»« bÆ°á»›c thá»­ nghiá»‡m khi Ma tráº­n VectÆ¡ Trung BÃ¬nh (Mean vectors) cá»§a táº­p Chá»¯ sá»‘ vÃ  táº­p EU tráº£ vá» má»©c tÆ°Æ¡ng quan cá»±c tháº¥p ($r \approx 0.01$). Äiá»u nÃ y chá»©ng minh 2 Ä‘Ã¡m mÃ¢y tá»a Ä‘á»™ nÃ y bay xa nhau hoÃ n toÃ n trong cáº¥u trÃºc dáº£i ngÃ¢n hÃ  768 chiá»u.

---

## 2. Loáº¡i Bá» ÄÆ°á»ng Tiá»‡m Cáº­n Báº±ng Ká»¹ Thuáº­t Dá»‹ch TÃ¢m (Mean-Centering)

TrÆ°á»›c khi tiáº¿n hÃ nh phÃ¢n rÃ£ nhÃ¢n ma tráº­n $M$, má»i cáº¥u trÃºc dá»¯ liá»‡u hÃ¬nh há»c tuyáº¿n tÃ­nh Ä‘á»u pháº£i tiáº¿n hÃ nh lÃ¹i tÃ¢m (Mean Centering).
TÃ­nh tá»‹nh tiáº¿n nÃ y cÆ°a bá» khoáº£ng cÃ¡ch dÆ° thá»«a tá»« Ä‘iá»ƒm $0$ Ä‘áº¿n lÃµi Ä‘Ã¡m mÃ¢y dá»¯ liá»‡u:
$$ 
\hat{M}_{i} = M_{i} - \mu 
$$
*(Vá»›i $\mu$ lÃ  vector trung bÃ¬nh cá»±c Ä‘áº¡i cÃ³ Ä‘á»™ dÃ i báº±ng sá»‘ cá»™t kÃ­ch thÆ°á»›c D=768).*

Khi Mean-centering Ä‘Æ°á»£c thá»±c thi cháº·t cháº½, Ä‘Æ°á»ng quang phá»• giÃ¡ trá»‹ suy biáº¿n (Singular value spectrum / Scree plot) tá»« SVD sáº½ cÃ³ Ä‘áº·c tÃ­nh rá»—ng dÆ° táº¡i giÃ¡ trá»‹ cuá»‘i cÃ¹ng. NÃ³i cÃ¡ch khÃ¡c, thuáº­t toÃ¡n cÆ°a Ä‘i má»™t *báº­c tá»± do* (Rank minus 1), biá»ƒu diá»…n báº±ng viá»‡c singular value cuá»‘i cÃ¹ng sáº½ Ä‘Ã¢m tháº³ng vá» $0$. Náº¿u khÃ´ng lÃ¹i tÃ¢m, trá»¥c phÃ¢n phá»‘i SVD sáº½ dá»“n toÃ n bá»™ sá»± khÃ¡c biá»‡t vÃ o Component-1 (Trá»¥c thá»© 1), lÃ m sai lá»‡ch kháº£ nÄƒng Ä‘á»c hiá»ƒu Component-2.

---

## 3. KhÃ¡m PhÃ¡ Ã NghÄ©a SVD Báº±ng PhÃ©p Chiáº¿u Nghá»‹ch Táº­p Há»£p (Over-Projections)

### KhÃ¡i Niá»‡m PhÃ©p Chiáº¿u Rá»™ng RÃ£i:
Sau khi SVD thÃ nh cÃ´ng $\hat{M}_{\text{EU}} = U \Sigma V^T$, chÃºng ta thu Ä‘Æ°á»£c chÃ¹m Vector riÃªng biá»‡t Ä‘áº·c táº£ tÃ­nh "*ChÃ¢u Ã‚u*" náº¯m giá»¯ táº¡i hÃ ng thá»© tá»± Ä‘áº§u tiÃªn cá»§a Ä‘a giÃ¡c $V^T$ (KÃ­ hiá»‡u $V_{\text{top}}$).

PhÃ©p mÃ u giáº£i thÃ­ch náº±m á»Ÿ bÆ°á»›c sau: Thay vÃ¬ giá»›i háº¡n kháº£o sÃ¡t trÃªn 10 nÆ°á»›c ChÃ¢u Ã‚u, ta láº¥y **toÃ n bá»™ 30.000 tokenizer cÃ²n láº¡i cá»§a há»‡ BERT**, trá»« Ä‘i $\mu_{\text{EU}}$, rá»“i nhÃ¢n tÃ­ch vÃ´ hÆ°á»›ng Ä‘á»• bÃ³ng toÃ n bá»™ 30.000 tá»« nÃ y lÃªn trá»¥c $V_{\text{top}}$:
$$ 
\text{Projections} = (E_{\text{all\_tokens}} - \mu_{\text{EU}}) \cdot V_{\text{top}} 
$$

### Diá»…n Dá»‹ch ChÃ³p Äá»“ Thá»‹ (Extremes Projections):
Thá»‘ng kÃª 30 token cÃ³ tÃ­ch vÃ´ hÆ°á»›ng vÄƒng ra xa nháº¥t trÃªn Trá»¥c $V_{\text{top}}$ (Top positive / Top negative Projections) má»Ÿ ra chÃ¢n trá»i cÆ¡ cháº¿ mÃ¡y há»c:
- á» dáº£i cá»±c Ã¢m cá»§a Trá»¥c ChÃ¢u Ã‚u, chÃºng ta báº¯t gáº·p nhá»¯ng tá»« vá»±ng khÃ´ng há» náº±m trong nhÃ³m gá»‘c Ä‘Ã o táº¡o nhÆ°ng cÃ¹ng má»™t há»‡ trá»¥c Ä‘á»‹a lÃ½ ngÃ´n ngá»¯ nhÆ°: *Latvian, Tallinn, Vilnius, Estonian*.
- á» dáº£i cá»§a ma tráº­n Chá»¯ Sá»‘, cÃ¡c cá»±c Ä‘oan dá»± Ä‘oÃ¡n kÃ©o theo sá»± xuáº¥t hiá»‡n cá»§a cÃ¡c chuá»—i text format sá»‘ (VD: *Seven, Null, Zero, Divided*), chá»©ng tá» trá»¥c khÃ´ng gian toÃ¡n há»c cÃ³ kháº£ nÄƒng ná»‘i káº¿t hÃ¬nh dÃ¡ng sá»‘ ("7") vá»›i kÃ½ hiá»‡u vÄƒn báº£n ("Seven").

---

## 4. Káº¿t luáº­n

Sá»± phÃ¢n máº£ng Ma tráº­n con (Submatrices Extracting) cung cáº¥p má»™t khung kÃ­nh lÃºp máº¡nh máº½ giáº£m bá»›t nhiá»…u loáº¡n ngáº«u nhiÃªn cá»§a toÃ n bá»™ thÆ° viá»‡n ngÃ´n ngá»¯ tá»± nhiÃªn. PhÆ°Æ¡ng phÃ¡p láº¥y SVD táº¡o ra ma tráº­n V, rá»“i Ä‘em toÃ n bá»™ Ä‘áº¡i dÆ°Æ¡ng Embeddings pháº£n kÃ­ch dá»™i ngÆ°á»£c chiáº¿u rá»i lÃªn $V$ chÃ­nh lÃ  má»™t chiáº¿c kÃ­nh rá»i Ä‘Ã¨n soi sÃ¡ng cáº¥u trÃºc ná»™i máº¡c (Mech Interpretability) cho tháº¥y cÃ¡ch hÃ ng tá»· ma tráº­n thÃ´ng sá»‘ Neural Network mÃ³c ná»‘i khÃ¡i niá»‡m cá»§a con ngÆ°á»i thÃ nh máº¡ng nhá»‡n tÃ­nh toÃ¡n.

---

## TÃ i liá»‡u tham kháº£o

1. **Turian, J., et al. (2010).** *Word representations: A simple and general method for semi-supervised learning.* ACL.
2. **Deerwester, S., et al. (1990).** *Indexing by latent semantic analysis.* JASIS.
3. TÃ i liá»‡u thá»±c hÃ nh Ä‘á»‹nh lÆ°á»£ng *SVD projections of related embeddings*.
<!-- Aero-Footer-Start -->
---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
