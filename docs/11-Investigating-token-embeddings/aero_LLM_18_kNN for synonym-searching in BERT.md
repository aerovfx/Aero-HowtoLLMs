
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../index.md) > [11 Investigating token embeddings](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../index.md)
- [ğŸ“š Module 01: LLM Course](../../01-LLM_Course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../02-Words-to-tokens-to-numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../04-buildGPT/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../07-Fine-tune-pretrained-models/index.md)
- [ğŸ” Module 19: AI Safety](../../19-AI-safety/index.md)
- [ğŸ Module 20: Python for AI](../../20-Python-Colab-notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Khai ThÃ¡c Thuáº­t ToÃ¡n k-NN Cho TÃ¬m Kiáº¿m Tá»« Äá»“ng NghÄ©a TrÃªn BERT

## TÃ³m táº¯t

K-Nearest Neighbors (k-NN - k LÃ¡ng giá»ng gáº§n nháº¥t) lÃ  má»™t thuáº­t toÃ¡n cá»‘t lÃµi trong phÃ¢n loáº¡i cá»¥m há»c mÃ¡y cá»• Ä‘iá»ƒn (Machine Learning Classification). Tuy nhiÃªn, khi káº¿t há»£p cÃ¹ng Vector nhÃºng (Embeddings) cá»§a há» mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLMs) nhÆ° BERT, thuáº­t toÃ¡n nÃ y thá»ƒ hiá»‡n kháº£ nÄƒng tra cá»©u chÃ©o tá»« Ä‘á»“ng nghÄ©a (synonym search) á»Ÿ má»©c Ä‘á»™ Ä‘Ã¡ng kinh ngáº¡c. BÃ i viáº¿t dÆ°á»›i Ä‘Ã¢y trÃ¬nh bÃ y nguyÃªn lÃ½ khÃ´ng gian cá»§a k-NN, phÃ¢n biá»‡t hai Ä‘á»‹nh chuáº©n tÃ­nh Ä‘iá»ƒm Euclidean vÃ  Cosine Similarity, cÅ©ng nhÆ° cÃ¡ch triá»ƒn khai cho cÃ¡c chiá»u áº©n trong tá»« Ä‘iá»ƒn sá»‘ hÃ³a tá»± nhiÃªn.

---

## 1. NguyÃªn LÃ½ Cá»§a k-Nearest Neighbors (k-NN)

Trong mÃ´ hÃ¬nh k-NN, dá»¯ liá»‡u má»›i khÃ´ng há» Ä‘Æ°á»£c gáº¯n nhÃ£n trÆ°á»›c theo má»™t há»‡ sá»‘ cháº·n hÃ m (Linear threshold). CÃ¡ch tiáº¿p cáº­n nÃ y tuÃ¢n theo má»™t cÆ¡ cháº¿ Ä‘á»‹nh vá»‹ hÃ¬nh há»c Ä‘Æ¡n giáº£n: **Dá»¯ liá»‡u thuá»™c vá» cá»™ng Ä‘á»“ng nÃ o Ä‘ang Ã¡p Ä‘áº£o xung quanh nÃ³.**

1. Äáº§u vÃ o lÃ  má»™t Vector truy váº¥n vÃ´ danh (Unlabeled data point) $x$.
2. Há»‡ thá»‘ng quÃ©t Ä‘áº¿m khoáº£ng cÃ¡ch tá»« $x$ Ä‘áº¿n toÃ n bá»™ nhá»¯ng Vector $\vec{v}_i$ Ä‘ang mang nhÃ£n dá»¯ liá»‡u cÃ³ sáºµn trong bá»™ nhá»›.
3. Tham sá»‘ $k$ quy Ä‘á»‹nh sáº½ láº¥y $k$ Ä‘iá»ƒm cÃ³ khoáº£ng cÃ¡ch khÃ´ng gian sÃ¡t vá»›i $x$ nháº¥t (Nearest Neighbors). Lá»i khuyÃªn lÃ  thiáº¿t láº­p $k$ thÃ nh sá»‘ láº» (VD: $k=3, 5, 7$) Ä‘á»ƒ cháº·n trÆ°á»ng há»£p hÃ²a/cÃ¢n báº±ng.
4. Lá»±a chá»n Æ°u tiÃªn theo nguyÃªn lÃ½ Báº§u chá»n theo khuynh hÆ°á»›ng (Majority Voting): nhÃ£n hiá»‡u chiáº¿m Ä‘a sá»‘ trong $k$ pháº§n tá»­ cáº­n ká» sáº½ Ä‘Æ°á»£c gÃ¡n cho $x$.

TrÆ°á»ng há»£p sá»­ dá»¥ng Ä‘á»ƒ khÃ¡m phÃ¡ tá»« loáº¡i trong BERT, viá»‡c dá»± Ä‘oÃ¡n theo lá»›p sáº½ Ä‘Æ°á»£c thay tháº¿ báº±ng liá»‡t kÃª $k$-vector gáº§n nháº¥t vá»›i tá»« gá»‘c nháº±m tÃ¬m ra cÃ¡c tá»« Ä‘á»“ng nghÄ©a (vd: "Beauty" sáº½ gá»i ra "Gorgeous", "Elegance"). 

---

## 2. Sá»‘ Há»c Khoáº£ng CÃ¡ch: Euclidean vÃ  Cosine Similarity

KhÃ´ng gian tá»a Ä‘á»™ cá»§a máº£ng Embeddings ma tráº­n BERT sá»Ÿ há»¯u $D=768$ chiá»u. BÃ i toÃ¡n tÃ¬m LÃ¡ng giá»ng (Distance calculations) yÃªu cáº§u má»™t thÆ°á»›c Ä‘o chuáº©n. Hai thÆ°á»›c Ä‘o thÃ´ng dá»¥ng Ä‘em láº¡i hai gÃ³c nhÃ¬n dá»‹ biá»‡t:

### 2.1. Chuáº©n Khoáº£ng CÃ¡ch HÃ¬nh Há»c (Euclidean Distance)
Láº¥y gá»‘c tá»« Ä‘á»‹nh lÃ½ tam giÃ¡c vuÃ´ng trong khÃ´ng gian $N$-chiá»u, Euclidean Ä‘o Ä‘áº¡c chiá»u dÃ i tháº­t sá»± cá»§a sá»£i dÃ¢y ná»‘i giá»¯a mÅ©i tÃªn vector token $\vec{v}$ vÃ  token má»¥c tiÃªu $\vec{w}$:
$$ 
\delta(\vec{v}, \vec{w}) = \sqrt{\sum_{i=1}^{D} (v_i - w_i)^2} 
$$
Chuáº©n Euclidean thá»ƒ hiá»‡n tÃ­nh tÃ¡ch biá»‡t tuyá»‡t Ä‘á»‘i (absolute spatial magnitude) cá»§a thÃ´ng tin.

### 2.2. Chuáº©n TÆ°Æ¡ng Quan GÃ³c (Cosine Similarity)
Trá»ng tÃ¢m Ä‘o lÆ°á»ng sá»± Ä‘á»“ng dáº¡ng khÃ´ng náº±m á»Ÿ lá»±c Ä‘á»™ dÃ i, mÃ  vá»©t bá» táº¥t cáº£ giá»›i háº¡n vÃ©c-tÆ¡ Ä‘á»ƒ tÃ¬m Ä‘á»™ chÃªnh gÃ³c giá»¯a hai ngá»n vector:
$$ 
\text{CosineSim}(\vec{v}, \vec{w}) = \frac{\vec{v} \cdot \vec{w}}{\|\vec{v}\| \|\vec{w}\|} \in [-1, 1] 
$$

**Sá»± Lá»‡ch Pha ÄÃ¡ng LÆ°u Ã:** CÃ¡c vector cÃ³ chung hÆ°á»›ng ná»™i hÃ m (Cosine Similarity hÆ°á»›ng vá» 1) nhÆ°ng hoÃ n toÃ n cÃ³ thá»ƒ sá»Ÿ há»¯u Khoáº£ng cÃ¡ch Euclidean kÃ©o dÃ£n ra khá»•ng lá»“ náº¿u Ä‘á»™ phá»§ vector (Norm of vector) bá»‹ Ä‘áº©y cá»±c xa gá»‘c tá»a Ä‘á»™. Do Ä‘Ã³, viá»‡c tÃ¬m LÃ¡ng giá»ng gáº§n nháº¥t k-NN trong cáº¥u trÃºc BERT Ä‘Ã²i há»i nhÃ  nghiÃªn cá»©u pháº£i xÃ¡c Ä‘á»‹nh thuá»™c tÃ­nh Ä‘ang sÄƒn tÃ¬m lÃ  khoáº£ng cÃ¡ch hay gÃ³c lá»‡ch nháº¡y cáº£m biá»ƒu diá»…n song song.

---

## 3. Khai ThÃ¡c Tiá»n Xá»­ LÃ½ Giáº£m Chiá»u Báº±ng PCA/t-SNE

Khi á»©ng dá»¥ng tá»‡p $k=5$ cho cá»¥m tá»« "Beauty" xuyÃªn tháº¥u toÃ n bá»™ $30.000$ tá»« Ä‘iá»ƒn cá»§a BERT, gÃ¡nh náº·ng toÃ¡n há»c (TÃ­nh $30.000$ phÃ©p tÃ­nh hÃ m mÅ© $L2-Norm$) cÃ³ thá»ƒ sáº½ lÃ m Ä‘Ã¬nh trá»‡ bá»™ vi xá»­ lÃ½ náº¿u há»‡ vector lá»›n nhÆ° Ä‘á»‹nh dáº¡ng GPT hiá»‡n Ä‘áº¡i (vá»›i sá»‘ token trÃªn 1 triá»‡u). 
Theo lÃ½ thuyáº¿t thÃ´ng luáº­t cá»§a Há»c MÃ¡y (Machine Learning), Ä‘á»ƒ trÃ¡nh "Lá»i nguyá»n Ä‘a chiá»u" (Curse of Dimensionality), ma tráº­n nÃªn Ä‘Æ°á»£c phÃ¢n rÃ£ báº±ng Principal Component Analysis (PCA) triá»‡t tiÃªu quang phá»• yáº¿u (SVD variance noise) sinh ra má»™t ma tráº­n giáº£m chiá»u $D = 100$ trÆ°á»›c khi hÃ m k-NN khá»Ÿi cháº¡y, Ä‘áº£m báº£o chi phÃ­ tháº¥p mÃ  khÃ´ng Ä‘Ã¡nh tá»¥t Ä‘á»™ nháº¡y tÆ°Æ¡ng quan ngá»¯ nghÄ©a.

---

## 4. Káº¿t luáº­n

MÃ´ hÃ¬nh k-Nearest Neighbors lÃ  khá»‘i háº¡t nhÃ¢n trong má»i bá»™ truy váº¥n tÃ¬m Ä‘iá»ƒm dá»¯ liá»‡u (Search Engines) á»©ng dá»¥ng vÃ o Máº¡ng NÆ¡-ron. Viá»‡c láº¡m dá»¥ng tÃ­nh cháº¥t khoáº£ng cÃ¡ch á»Ÿ vÃ¹ng Embeddings cá»§a BERT cho phÃ©p k-NN bá»©t phÃ¡ khá»i cÆ¡ cháº¿ nhÃ£n mÃ¡c nhá»‹ phÃ¢n, trá»Ÿ thÃ nh cÃ´ng cá»¥ Ä‘áº¯c lá»±c giáº£i pháº«u hiá»‡n tÆ°á»£ng Ä‘a nghÄ©a tá»« vá»±ng cÅ©ng nhÆ° khai thÃ¡c vÃ¹ng giao thoa khÃ¡i niá»‡m (Concept boundary overlapping).

---

## TÃ i liá»‡u tham kháº£o

1. **Cover, T., & Hart, P. (1967).** *Nearest neighbor pattern classification*. IEEE Transactions on Information Theory.
2. **Devlin, J., et al. (2018).** *BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding*. NAACL.
3. TÃ i liá»‡u Ä‘Ã o táº¡o *Investigating token embeddings - kNN for synonym-searching in BERT*.
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| [aero_LLM_01_CodeChallenge Cosine similarity (advanced) (part 1).md](aero_LLM_01_CodeChallenge Cosine similarity (advanced) (part 1).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_01_CodeChallenge Cosine similarity (advanced) (part 1).md) |
| [aero_LLM_02_CodeChallenge Cosine similarity (advanced) (part 2).md](aero_LLM_02_CodeChallenge Cosine similarity (advanced) (part 2).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_02_CodeChallenge Cosine similarity (advanced) (part 2).md) |
| [Theo DÃµi DÃ²ng Cháº£y Cosine Similarity TrÃªn Trá»¥c VÄƒn Báº£n ChuyÃªn Tuáº§n Tá»± (Word Sequences)](aero_LLM_03_CodeChallenge Cosine similarity in word sequences.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_03_CodeChallenge Cosine similarity in word sequences.md) |
| [Nghá»‡ Thuáº­t Váº½ Báº£n Äá»“ Nhiá»‡t Ma Tráº­n NhÃºng Báº±ng CÆ°á»ng Äá»™ Tá»« (Coloring Cosine Similarity)](aero_LLM_04_CodeChallenge Coloring cosine similarity.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_04_CodeChallenge Coloring cosine similarity.md) |
| [áº¢o áº¢nh Cá»§a TrÃ­ Tuá»‡ ToÃ¡n Há»c Trong NgÃ´n Ngá»¯: Sá»©c Máº¡nh Cá»§a Random Embeddings](aero_LLM_05_CodeChallenge Can random embeddings be interpreted.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_05_CodeChallenge Can random embeddings be interpreted.md) |
| [PhÆ°Æ¡ng PhÃ¡p T-SNE VÃ  Thuáº­t ToÃ¡n PhÃ¢n Cá»¥m DBSCAN: Chiáº¿u KhÃ´ng Gian Äa Chiá»u Cho LLMs](aero_LLM_06_T-SNE projection and DBSCAN clustering (theory).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_06_T-SNE projection and DBSCAN clustering (theory).md) |
| [PhÃ¢n Cá»¥m Ngá»¯ NghÄ©a Qua PhÃ©p Chiáº¿u t-SNE & Máº­t Äá»™ DBSCAN (Python)](aero_LLM_07_T-SNE projection and DBSCAN clustering (Python).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_07_T-SNE projection and DBSCAN clustering (Python).md) |
| [ThÃ¡ch Thá»©c Code: TÃ¬m Lá»— Há»•ng PhÃ¢n Cá»¥m Báº±ng Bá»™ Lá»c Báº£ng Chá»¯ CÃ¡i Chá»¯ X](aero_LLM_08_CodeChallenge cluster the x terms.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_08_CodeChallenge cluster the x terms.md) |
| [PhÃ¢n RÃ£ Token, NhÃºng VÃ  PhÃ¢n Cá»¥m Biá»ƒu TÆ°á»£ng Emojis Báº±ng Äá»“ Thá»‹ Máº­t Äá»™](aero_LLM_09_CodeChallenge Tokenize, embed, and cluster happy emojis.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_09_CodeChallenge Tokenize, embed, and cluster happy emojis.md) |
| [PhÃ¢n TÃ­ch RSA (Representational Similarity Analysis) Giá»¯a CÃ¡c MÃ´ HÃ¬nh NgÃ´n Ngá»¯](aero_LLM_10_RSA (representational similarity analysis).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_10_RSA (representational similarity analysis).md) |
| [PhÃ¢n TÃ­ch Äá»™ Lá»‡ch RSA (Part 1): So SÃ¡nh Sá»± Báº¥t Äá»“ng Giá»¯a KhÃ´ng Gian GloVe 50D vÃ  300D](aero_LLM_11_CodeChallenge Compare embeddings with RSA (part 1).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_11_CodeChallenge Compare embeddings with RSA (part 1).md) |
| [PhÃ¢n TÃ­ch Äá»™ Lá»‡ch RSA (Part 2): Äá»‘i Chiáº¿u TÆ°Æ¡ng Quan Pearson Cho Khoáº£ng CÃ¡ch Cosine](aero_LLM_12_CodeChallenge Compare embeddings with RSA (part 2).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_12_CodeChallenge Compare embeddings with RSA (part 2).md) |
| [So SÃ¡nh KhÃ´ng Gian NhÃºng: Word2Vec VÃ  GPT-2 Qua PhÃ¢n TÃ­ch RSA](aero_LLM_13_CodeChallenge Word2vec vs. GPT2.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_13_CodeChallenge Word2vec vs. GPT2.md) |
| [Bá»‘ Cá»¥c Äá»“ Thá»‹ Máº¡ng (Network Graph) ThÃ´ng Qua Ma Tráº­n Cosine Similarity](aero_LLM_14_CodeChallenge Graph representation of cosine similarities.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_14_CodeChallenge Graph representation of cosine similarities.md) |
| [Sá»‘ Há»c Tuyáº¿n TÃ­nh vÃ  RÃºt TrÃ­ch TÆ°Æ¡ng Äá»“ng Giá»¯a CÃ¡c Tá»« NhÃºng (Word Embeddings Analogies)](aero_LLM_15_Embeddings arithmetic and analogies.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_15_Embeddings arithmetic and analogies.md) |
| [Vá»¡ Má»™ng Vá» Sá»‘ Há»c Vector TÆ°Æ¡ng ÄÆ°Æ¡ng (Soft-Coded Analogies) TrÃªn Word2Vec](aero_LLM_16_CodeChallenge soft-coded analogies in word2vec.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_16_CodeChallenge soft-coded analogies in word2vec.md) |
| [Thiáº¿t Láº­p VÃ  Diá»…n Giáº£i Trá»¥c Ngá»¯ NghÄ©a Tuyáº¿n TÃ­nh (Linear Semantic Axes)](aero_LLM_17_Creating and interpreting linear semantic axes.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_17_Creating and interpreting linear semantic axes.md) |
| ğŸ“Œ **[Khai ThÃ¡c Thuáº­t ToÃ¡n k-NN Cho TÃ¬m Kiáº¿m Tá»« Äá»“ng NghÄ©a TrÃªn BERT](aero_LLM_18_kNN for synonym-searching in BERT.md)** | [Xem bÃ i viáº¿t â†’](aero_LLM_18_kNN for synonym-searching in BERT.md) |
| [Cáº¡nh Tranh TÃ¬m Tá»« Äá»“ng NghÄ©a BERT vs GPT: CÆ¡ Cháº¿ Tokenization Äa KÃ½ Tá»±](aero_LLM_19_CodeChallenge BERT v GPT kNN kompetition.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_19_CodeChallenge BERT v GPT kNN kompetition.md) |
| [Sá»± Dá»‹ch Chuyá»ƒn VÃ  Äá»“ng Tá»“n Biá»ƒu Diá»…n Giá»¯a CÃ¡c KhÃ´ng Gian NhÃºng](aero_LLM_20_Research on translating embeddings spaces.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_20_Research on translating embeddings spaces.md) |
| [PhÃ¢n TÃ­ch ChÃ¹m Quang Phá»• Suy Biáº¿n (Singular Value Spectrum) Cá»§a KhÃ´ng Gian NhÃºng](aero_LLM_21_Singular value spectrum of embeddings submatrices.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_21_Singular value spectrum of embeddings submatrices.md) |
| [Ãnh Xáº¡ SVD CÃ¡c Dáº£i Äiá»ƒm NhÃºng CÃ³ Quan Há»‡ ChÃ©o](aero_LLM_22_CodeChallenge SVD projections of related embeddings.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_22_CodeChallenge SVD projections of related embeddings.md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
