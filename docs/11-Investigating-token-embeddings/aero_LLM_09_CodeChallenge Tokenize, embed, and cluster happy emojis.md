
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../index.md) > [11 Investigating token embeddings](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../index.md)
- [ğŸ“š Module 01: LLM Course](../../01-LLM_Course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../02-Words-to-tokens-to-numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../04-buildGPT/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../07-Fine-tune-pretrained-models/index.md)
- [ğŸ” Module 19: AI Safety](../../19-AI-safety/index.md)
- [ğŸ Module 20: Python for AI](../../20-Python-Colab-notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# PhÃ¢n RÃ£ Token, NhÃºng VÃ  PhÃ¢n Cá»¥m Biá»ƒu TÆ°á»£ng Emojis Báº±ng Äá»“ Thá»‹ Máº­t Äá»™

## TÃ³m táº¯t

CÃ¡c MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n (LLMs) nhÆ° ChatGPT thÆ°á»ng xuyÃªn láº¡m dá»¥ng vÃ  thá»ƒ hiá»‡n má»©c biá»ƒu cáº£m cao thÃ´ng qua cÃ¡c biá»ƒu tÆ°á»£ng cáº£m xÃºc (Emojis). Tá»« gÃ³c nhÃ¬n Ä‘iá»‡n toÃ¡n, chÃºng ta xem má»™t Emoji nhÆ° má»™t hÃ¬nh váº½ duy nháº¥t, nhÆ°ng cáº¥u trÃºc Tokenizer cá»§a GPT láº¡i "Ä‘á»c" chÃºng thÃ´ng qua lÄƒng kÃ­nh cá»±c ká»³ phá»©c táº¡p dá»±a trÃªn quy chuáº©n mÃ£ hÃ³a Unicode Ä‘a kÃ­ tá»±. BÃ i viáº¿t nÃ y trÃ¬nh bÃ y phÃ¢n tÃ­ch khoa há»c vá» sá»± hÃ¬nh thÃ nh cÃ¡c Vector nhÃºng (Embeddings) cá»§a Emoji, vÃ  á»©ng dá»¥ng káº¿t há»£p **t-SNE** cÃ¹ng **DBSCAN** Ä‘á»ƒ phÃ¢n cá»¥m tháº¿ giá»›i cáº£m xÃºc cá»§a AI.

---

## 1. Cáº¥u TrÃºc Khá»‘i Báº¥t Äá»‘i Xá»©ng Giá»¯a KÃ½ Tá»± vÃ  Tokenizer

Há»‡ quy chuáº©n mÃ¡y tÃ­nh nháº­n diá»‡n má»i kÃ½ tá»± thÃ´ng qua tá»a Ä‘á»™ Tháº­p lá»¥c phÃ¢n (Hexadecimal Unicode). VÃ­ dá»¥ chá»¯ cÃ¡i 'A' lÃ  `U+0041` (hay máº£ng sá»‘ nguyÃªn Tháº­p phÃ¢n lÃ  $65$). á» há»‡ tiÃªu chuáº©n nÃ y, Emojis khÃ´ng cÃ³ báº¥t ká»³ Ä‘áº·c quyá»n nÃ o, chÃºng lÃ  nhá»¯ng tá»• há»£p chuá»—i giÃ¡ trá»‹ Unicode cÃ³ chá»‰ má»¥c ráº¥t cao trÃªn há»‡ 150.000 kÃ½ tá»±.

Váº¥n Ä‘á» nghiÃªm trá»ng náº£y sinh á»Ÿ bá»™ cáº¯t tá»« ngá»¯ (Tokenizer) cá»§a GPT: *Háº§u nhÆ° khÃ´ng má»™t Emoji nÃ o Ä‘Æ°á»£c nÃ©n thÃ nh má»™t Token duy nháº¥t.*
Nhá»¯ng biá»ƒu tÆ°á»£ng trÃ´ng ráº¥t bÃ¬nh thÆ°á»ng thÆ°á»ng bá»‹ cáº¥u thÃ nh bá»Ÿi 2 Ä‘áº¿n 4 tokens ná»‘i tiáº¿p nhau. Láº½ ra, quy luáº­t 1-token-1-Ä‘á»‘i-tÆ°á»£ng Ä‘áº£m báº£o vector $\vec{v}$ gÃ¡nh trá»n váº¹n ngá»¯ nghÄ©a khá»‘i. TÃ­nh phi tuyáº¿n tÃ­nh nÃ y yÃªu cáº§u Máº¡ng NÆ¡-ron (Neural Network) pháº£i káº¿t há»£p (Attention mechanism) chÃ¹m token liÃªn hoÃ n thÃ nh má»™t há»‡ quy chiáº¿u cáº£m xÃºc logic duy nháº¥t. TrÃ¡i vá»›i linh cáº£m, vector cá»§a token Ä‘áº§u tiÃªn thuá»™c Emoji hoÃ n toÃ n khÃ´ng bao quÃ¡t Ä‘á»§ hÃ m Ã½ cá»§a Emoji gá»‘c (Cosine Similarity giá»¯a first-token vÃ  last-token cá»§a má»™t Emoji chá»‰ rÆ¡i vÃ o khoáº£ng $\approx 0.3$).

---

## 2. TÃ­nh ToÃ¡n NhÃºng Emojis VÃ  QuÃ¡ TrÃ¬nh Há»£p Nháº¥t (Mean Pooling)

VÃ¬ má»™t Emoji (giáº£ sá»­ CÆ°á»i) bá»‹ cáº¯t rÃ¡ch thÃ nh tá»• há»£p $K$ tokens $\left[ t_1, t_2, ..., t_K \right]$, chÃºng ta sáº½ thu vá» má»™t táº­p há»£p cÃ¡c ma tráº­n nhÃºng $\vec{e}_1, \vec{e}_2, ..., \vec{e}_K$.
Äá»ƒ cÃ³ Ä‘Æ°á»£c má»™t Ä‘áº¡i lÆ°á»£ng Embeddings duy nháº¥t $\vec{E}_{\text{emoji}}$ nháº±m tÃ­nh toÃ¡n khoáº£ng cÃ¡ch vector tá»« hoáº·c tÆ°Æ¡ng quan gÃ³c (Cosine Similarity), phÆ°Æ¡ng Ã¡n ná»n mÃ³ng lÃ  tÃ­nh Trung bÃ¬nh cá»™ng vector (Vector Ave18-RAGe / Mean Pooling):

$$
\vec{E}_{\text{emoji}} = \frac{1}{K} \sum_{i=1}^{K} \vec{e}_i
$$

Báº±ng cÃ¡ch táº¡o má»™t ma tráº­n há»—n há»£p $N \times 768$ chiá»u (giáº£ sá»­ chá»n táº­p $N=32$ Emojis), toÃ n bá»™ Ä‘Ã¡m mÃ¢y cáº£m xÃºc Ä‘Ã£ Ä‘Æ°á»£c Ä‘á»‹nh chuáº©n hÃ³a lÃªn khÃ´ng gian nÆ¡-ron báº­c cao cá»§a khá»‘i lÆ°á»£ng Transformers.

*(LÆ°u Ã½: Trung bÃ¬nh cá»™ng token vector trong Word Embeddings chá»‰ lÃ  ká»¹ thuáº­t Ä‘Æ¡n giáº£n. Äá»‘i vá»›i mÃ´ hÃ¬nh sÃ¢u (Deep layers), ta nÃªn trÃ­ch vector tá»a Ä‘á»™ cá»§a token cuá»‘i cÃ¹ng á»Ÿ lá»›p attention thá»© 12 Ä‘á»ƒ gom háº¿t dá»¯ kiá»‡n contextual tá»« cÃ¡c token trÆ°á»›c).*

---

## 3. PhÃ¢n Cá»¥m Ã Niá»‡m Emojis Báº±ng Äá»“ Thá»‹ t-SNE vÃ  DBSCAN

Nháº±m cháº©n Ä‘oÃ¡n xem AI cÃ³ tháº­t sá»± phÃ¢n biá»‡t Ä‘Æ°á»£c "NhÃ³m Tim", "NhÃ³m CÆ°á»i", "NhÃ³m ChÃ³ MÃ¨o" vá»›i nhau á»Ÿ cáº¥p vector, ta tráº£i máº¡ng t-SNE vÃ  DBSCAN:

### 3.1 NÃ©n t-SNE xuá»‘ng há»‡ máº·t pháº³ng Euclidean 2D
Giáº£n Ä‘á»“ t-SNE sá»­ dá»¥ng phÃ¢n phá»‘i Gaussian chuáº©n Ä‘á»ƒ kÃ©o sáº­p khá»‘i tá»a Ä‘á»™ 768 chiá»u xuá»‘ng má»™t sÃ n pháº³ng 2 tá»a Ä‘á»™ (2D Coordinates). Káº¿t quáº£ trÃªn 32 máº·t emoji sáº½ táº¡o nÃªn cÃ¡c dáº£i ngÃ¢n hÃ  liÃªn Ä‘á»›i cháº·t cháº½.

### 3.2 Chuáº©n HÃ³a Z-Score (Standardization)
TrÆ°á»›c khi cháº¡y DBSCAN, káº¿t quáº£ Ä‘á»“ thá»‹ t-SNE buá»™c pháº£i Ä‘Æ°á»£c quy Ä‘á»•i sang má»™t trung tÃ¢m chuáº©n hÃ³a khoáº£ng cÃ¡ch Ä‘á»™ lá»‡ch (Standard Deviation Units):
$$
Z = \frac{X - \mu}{\sigma}
$$
PhÃ©p dá»‹ch tÃ¢m $Z-score$ nÃ y báº£o toÃ n nguyÃªn váº¹n tÃ­nh cháº¥t hÃ¬nh há»c tÆ°Æ¡ng Ä‘á»‘i nhÆ°ng Ä‘em toÃ n bá»™ trá»¥c tung vÃ  trá»¥c hoÃ nh thu gá»n vÃ o khoáº£ng tá»« $-2$ Ä‘áº¿n $2$. Viá»‡c nÃ y cung cáº¥p sá»©c máº¡nh Ä‘á»‹nh dáº¡ng bÃ¡n kÃ­nh cá»±c Ä‘á»™ cho DBSCAN.

### 3.3 PhÃ¢n cá»¥m Epsilon ($\epsilon$) qua DBSCAN
Trong hÃ m DBSCAN, tham sá»‘ cá»‘t tá»­ lÃ  $\epsilon$ (khoáº£ng cÃ¡ch tá»‘i Ä‘a Ä‘á»ƒ káº¿t ná»‘i hai Ä‘iá»ƒm háº¡t nhÃ¢n liÃªn hoÃ n thÃ nh 1 cá»¥m). Do tá»a Ä‘á»™ Ä‘Ã£ bá»‹ chuáº©n hÃ³a $Z-Score$, viá»‡c chá»n $\epsilon = 0.3$ mang Ã½ nghÄ©a "Káº¿t ná»‘i má»i Ä‘iá»ƒm lÃ¢n cáº­n trong vÃ²ng bÃ¡n kÃ­nh 0.3 Äá»™ lá»‡ch chuáº©n phÆ°Æ¡ng sai".

Káº¿t quáº£ nháº­n Ä‘Æ°á»£c ráº¥t xuáº¥t sáº¯c: Ma tráº­n nhÃºng GPT-2 tá»¥ há»£p cÃ¡c nhÃ³m CÆ°á»i, nhÃ³m TÃ¬nh YÃªu (Tim), vÃ  NhÃ³m Äá»™ng váº­t vÃ o nhá»¯ng khá»‘i liá»n ká» biá»‡t láº­p. GPT thá»±c sá»± hiá»ƒu phÆ°Æ¡ng sai ngá»¯ nghÄ©a cá»§a Ä‘á»“ há»a Unicode há»‡t nhÆ° tá»« vá»±ng cá»§a tiáº¿ng ngÆ°á»i.

---

## TÃ i liá»‡u tham kháº£o

1. **Eisner, B., et al. (2016).** *emoji2vec: Learning Emoji Representations from their Description.* EMNLP.
2. **Barbieri, F., et al. (2016).** *Does Multiword Expression help Word Representation?* EACL (PhÃ¢n tÃ­ch sá»± áº£nh hÆ°á»Ÿng cá»§a token phÃ¢n máº£nh).
3. TÃ i liá»‡u Ä‘Ã o táº¡o *Investigating token embeddings - Tokenize, embed, and cluster emojis*.
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| [aero_LLM_01_CodeChallenge Cosine similarity (advanced) (part 1).md](aero_LLM_01_CodeChallenge Cosine similarity (advanced) (part 1).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_01_CodeChallenge Cosine similarity (advanced) (part 1).md) |
| [aero_LLM_02_CodeChallenge Cosine similarity (advanced) (part 2).md](aero_LLM_02_CodeChallenge Cosine similarity (advanced) (part 2).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_02_CodeChallenge Cosine similarity (advanced) (part 2).md) |
| [Theo DÃµi DÃ²ng Cháº£y Cosine Similarity TrÃªn Trá»¥c VÄƒn Báº£n ChuyÃªn Tuáº§n Tá»± (Word Sequences)](aero_LLM_03_CodeChallenge Cosine similarity in word sequences.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_03_CodeChallenge Cosine similarity in word sequences.md) |
| [Nghá»‡ Thuáº­t Váº½ Báº£n Äá»“ Nhiá»‡t Ma Tráº­n NhÃºng Báº±ng CÆ°á»ng Äá»™ Tá»« (Coloring Cosine Similarity)](aero_LLM_04_CodeChallenge Coloring cosine similarity.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_04_CodeChallenge Coloring cosine similarity.md) |
| [áº¢o áº¢nh Cá»§a TrÃ­ Tuá»‡ ToÃ¡n Há»c Trong NgÃ´n Ngá»¯: Sá»©c Máº¡nh Cá»§a Random Embeddings](aero_LLM_05_CodeChallenge Can random embeddings be interpreted.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_05_CodeChallenge Can random embeddings be interpreted.md) |
| [PhÆ°Æ¡ng PhÃ¡p T-SNE VÃ  Thuáº­t ToÃ¡n PhÃ¢n Cá»¥m DBSCAN: Chiáº¿u KhÃ´ng Gian Äa Chiá»u Cho LLMs](aero_LLM_06_T-SNE projection and DBSCAN clustering (theory).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_06_T-SNE projection and DBSCAN clustering (theory).md) |
| [PhÃ¢n Cá»¥m Ngá»¯ NghÄ©a Qua PhÃ©p Chiáº¿u t-SNE & Máº­t Äá»™ DBSCAN (Python)](aero_LLM_07_T-SNE projection and DBSCAN clustering (Python).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_07_T-SNE projection and DBSCAN clustering (Python).md) |
| [ThÃ¡ch Thá»©c Code: TÃ¬m Lá»— Há»•ng PhÃ¢n Cá»¥m Báº±ng Bá»™ Lá»c Báº£ng Chá»¯ CÃ¡i Chá»¯ X](aero_LLM_08_CodeChallenge cluster the x terms.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_08_CodeChallenge cluster the x terms.md) |
| ğŸ“Œ **[PhÃ¢n RÃ£ Token, NhÃºng VÃ  PhÃ¢n Cá»¥m Biá»ƒu TÆ°á»£ng Emojis Báº±ng Äá»“ Thá»‹ Máº­t Äá»™](aero_LLM_09_CodeChallenge Tokenize, embed, and cluster happy emojis.md)** | [Xem bÃ i viáº¿t â†’](aero_LLM_09_CodeChallenge Tokenize, embed, and cluster happy emojis.md) |
| [PhÃ¢n TÃ­ch RSA (Representational Similarity Analysis) Giá»¯a CÃ¡c MÃ´ HÃ¬nh NgÃ´n Ngá»¯](aero_LLM_10_RSA (representational similarity analysis).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_10_RSA (representational similarity analysis).md) |
| [PhÃ¢n TÃ­ch Äá»™ Lá»‡ch RSA (Part 1): So SÃ¡nh Sá»± Báº¥t Äá»“ng Giá»¯a KhÃ´ng Gian GloVe 50D vÃ  300D](aero_LLM_11_CodeChallenge Compare embeddings with RSA (part 1).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_11_CodeChallenge Compare embeddings with RSA (part 1).md) |
| [PhÃ¢n TÃ­ch Äá»™ Lá»‡ch RSA (Part 2): Äá»‘i Chiáº¿u TÆ°Æ¡ng Quan Pearson Cho Khoáº£ng CÃ¡ch Cosine](aero_LLM_12_CodeChallenge Compare embeddings with RSA (part 2).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_12_CodeChallenge Compare embeddings with RSA (part 2).md) |
| [So SÃ¡nh KhÃ´ng Gian NhÃºng: Word2Vec VÃ  GPT-2 Qua PhÃ¢n TÃ­ch RSA](aero_LLM_13_CodeChallenge Word2vec vs. GPT2.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_13_CodeChallenge Word2vec vs. GPT2.md) |
| [Bá»‘ Cá»¥c Äá»“ Thá»‹ Máº¡ng (Network Graph) ThÃ´ng Qua Ma Tráº­n Cosine Similarity](aero_LLM_14_CodeChallenge Graph representation of cosine similarities.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_14_CodeChallenge Graph representation of cosine similarities.md) |
| [Sá»‘ Há»c Tuyáº¿n TÃ­nh vÃ  RÃºt TrÃ­ch TÆ°Æ¡ng Äá»“ng Giá»¯a CÃ¡c Tá»« NhÃºng (Word Embeddings Analogies)](aero_LLM_15_Embeddings arithmetic and analogies.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_15_Embeddings arithmetic and analogies.md) |
| [Vá»¡ Má»™ng Vá» Sá»‘ Há»c Vector TÆ°Æ¡ng ÄÆ°Æ¡ng (Soft-Coded Analogies) TrÃªn Word2Vec](aero_LLM_16_CodeChallenge soft-coded analogies in word2vec.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_16_CodeChallenge soft-coded analogies in word2vec.md) |
| [Thiáº¿t Láº­p VÃ  Diá»…n Giáº£i Trá»¥c Ngá»¯ NghÄ©a Tuyáº¿n TÃ­nh (Linear Semantic Axes)](aero_LLM_17_Creating and interpreting linear semantic axes.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_17_Creating and interpreting linear semantic axes.md) |
| [Khai ThÃ¡c Thuáº­t ToÃ¡n k-NN Cho TÃ¬m Kiáº¿m Tá»« Äá»“ng NghÄ©a TrÃªn BERT](aero_LLM_18_kNN for synonym-searching in BERT.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_18_kNN for synonym-searching in BERT.md) |
| [Cáº¡nh Tranh TÃ¬m Tá»« Äá»“ng NghÄ©a BERT vs GPT: CÆ¡ Cháº¿ Tokenization Äa KÃ½ Tá»±](aero_LLM_19_CodeChallenge BERT v GPT kNN kompetition.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_19_CodeChallenge BERT v GPT kNN kompetition.md) |
| [Sá»± Dá»‹ch Chuyá»ƒn VÃ  Äá»“ng Tá»“n Biá»ƒu Diá»…n Giá»¯a CÃ¡c KhÃ´ng Gian NhÃºng](aero_LLM_20_Research on translating embeddings spaces.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_20_Research on translating embeddings spaces.md) |
| [PhÃ¢n TÃ­ch ChÃ¹m Quang Phá»• Suy Biáº¿n (Singular Value Spectrum) Cá»§a KhÃ´ng Gian NhÃºng](aero_LLM_21_Singular value spectrum of embeddings submatrices.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_21_Singular value spectrum of embeddings submatrices.md) |
| [Ãnh Xáº¡ SVD CÃ¡c Dáº£i Äiá»ƒm NhÃºng CÃ³ Quan Há»‡ ChÃ©o](aero_LLM_22_CodeChallenge SVD projections of related embeddings.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_22_CodeChallenge SVD projections of related embeddings.md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
