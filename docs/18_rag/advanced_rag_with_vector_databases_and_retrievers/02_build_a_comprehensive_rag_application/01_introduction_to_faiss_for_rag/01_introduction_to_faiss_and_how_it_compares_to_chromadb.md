
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../../../index.md) > [18 rag](../../../index.md) > [advanced rag with vector databases and retrievers](../../index.md) > [02 build a comprehensive rag application](../index.md) > [01 introduction to faiss for rag](index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../../../index.md)
- [ğŸ“š Module 01: LLM Course](../../../../01_llm_course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../../../02_words_to_tokens_to_numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../../../04_buildgpt/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../../../07_fine_tune_pretrained_models/index.md)
- [ğŸ” Module 19: AI Safety](../../../../19_ai_safety/index.md)
- [ğŸ Module 20: Python for AI](../../../../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Giá»›i Thiá»‡u FAISS Cho RAG vÃ  So SÃ¡nh vá»›i ChromaDB

## Tá»•ng Quan

ChÆ°Æ¡ng nÃ y giá»›i thiá»‡u vá» **FAISS (Facebook AI Similarity Search)** - thÆ° viá»‡n tÃ¬m kiáº¿m sá»± tÆ°Æ¡ng Ä‘á»“ng vector Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi Meta, vÃ  so sÃ¡nh vá»›i **ChromaDB** - má»™t vector database phá»• biáº¿n khÃ¡c.

## 1. Giá»›i Thiá»‡u FAISS

### 1.1 FAISS lÃ  gÃ¬?

FAISS (Facebook AI Similarity Search) lÃ  thÆ° viá»‡n mÃ£ nguá»“n má»Ÿ Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi Meta (trÆ°á»›c Ä‘Ã¢y lÃ  Facebook) cho viá»‡c tÃ¬m kiáº¿m sá»± tÆ°Æ¡ng Ä‘á»“ng trong cÃ¡c táº­p há»£p vector dense:

- **NgÃ´n ngá»¯**: C++ vá»›i Python bindings
- **Hiá»‡u suáº¥t**: Tá»‘i Æ°u cho tÃ¬m kiáº¿m nhanh
- **Pháº§n cá»©ng**: Há»— trá»£ CPU vÃ  GPU
- **Quy mÃ´**: Single-machine operations

### 1.2 á»¨ng Dá»¥ng

FAISS Ä‘Æ°á»£c sá»­ dá»¥ng trong:
- TÃ¬m kiáº¿m hÃ¬nh áº£nh/video
- Recommendation systems
- NLP vÃ  semantic search
- Clustering

## 2. CÃ¡c Loáº¡i Index Trong FAISS

### 2.1 Index Types Overview

| Index | MÃ´ táº£ | Use Case |
|-------|--------|----------|
| Flat | Brute-force exact search | Small datasets |
| IVF | Inverted File Index | Medium datasets |
| HNSW | Graph-based approximate | Large datasets |
| LSH | Locality-Sensitive Hashing | Approximate search |
| PQ | Product Quantization | Memory constrained |

### 2.2 Flat Index (Exact Search)

```python
import faiss
import numpy as np

# Táº¡o index vá»›i exact search
dimension = 128
index = faiss.IndexFlatL2(dimension)  # L2 distance
# Hoáº·c
index = faiss.IndexFlatIP(dimension)   # Inner product (cosine)

# ThÃªm vectors
vectors = np.random.random((10000, dimension)).astype('float32')
index.add(vectors)

# TÃ¬m kiáº¿m
query = np.random.random((5, dimension)).astype('float32')
distances, indices = index.search(query, k=10)

**Äáº·c Ä‘iá»ƒm:**
- Äá»™ chÃ­nh xÃ¡c tuyá»‡t Ä‘á»‘i
- Time: $O(N \cdot D)$ vá»›i N = sá»‘ vectors, D = dimension
- Memory: $O(N \cdot D)$

### 2.3 IVF Index (Inverted File)

```python
# Táº¡o IVF index
nlist = 100  # Sá»‘ clusters

quantizer = faiss.IndexFlatL2(dimension)
index = faiss.IndexIVFFlat(quantizer, dimension, nlist)

# Train trÆ°á»›c khi add
index.train(vectors)

# Add vectors
index.add(vectors)

# TÃ¬m kiáº¿m
index.nprobe = 10  # Sá»‘ clusters cáº§n tÃ¬m
distances, indices = index.search(query, k=10)

**Äáº·c Ä‘iá»ƒm:**
- Nhanh hÆ¡n Flat vá»›i large datasets
- Accuracy phá»¥ thuá»™c vÃ o nprobe
- Time: $O(N/D \cdot nlist + nprobe \cdot k)$

### 2.4 HNSW Index (Hierarchical Navigable Small World)

```python
# Táº¡o HNSW index
dimension = 128
index = faiss.IndexHNSWFlat(dimension, 32)  # 32 = M parameter

# Cáº¥u hÃ¬nh
index.hnsw.efConstruction = 200  # XÃ¢y dá»±ng
index.hnsw.efSearch = 50        # TÃ¬m kiáº¿m

# Add vÃ  search
index.add(vectors)
distances, indices = index.search(query, k=10)

**Äáº·c Ä‘iá»ƒm:**
- Graph-based navigation
- Time: $O(\log N)$
- Memory: $O(N \cdot M)$

### 2.5 LSH (Locality-Sensitive Hashing)

```python
# Táº¡o LSH index
dimension = 128
nbits = 32  # Sá»‘ bits cho má»—i hash

index = faiss.IndexLSH(dimension, nbits)
index.add(vectors)
distances, indices = index.search(query, k=10)

**Äáº·c Ä‘iá»ƒm:**
- Hash-based approximate search
- Good for high-dimensional data
- Memory efficient

### 2.6 PQ (Product Quantization)

```python
# Táº¡o PQ index
m = 8           # Sá»‘ sub-vectors
nbits = 8        # Bits per sub-vector

quantizer = faiss.IndexFlatL2(dimension)
index = faiss.IndexIVFPQ(quantizer, dimension, nlist, m, nbits)

index.train(vectors)
index.add(vectors)
distances, indices = index.search(query, k=10)

**Äáº·c Ä‘iá»ƒm:**
- Compression cao
- Memory efficient
- Good for large-scale search

## 3. So SÃ¡nh FAISS vs ChromaDB

### 3.1 Tá»•ng Quan So SÃ¡nh

| TiÃªu chÃ­ | FAISS | ChromaDB |
|----------|-------|----------|
| **Loáº¡i** | Library | Database |
| **Architecture** | Single-node | Single + Distributed |
| **Index Types** | Multiple | HNSW only |
| **Metadata** | KhÃ´ng cÃ³ | CÃ³ |
| **Persistence** | Memory-only | Persistent |
| **Query Language** | Python API | SQL-like |
| **Scalability** | Medium | High |
| **Integrations** | LangChain, LlamaIndex | LangChain, LlamaIndex |

### 3.2 FAISS - Æ¯u vÃ  NhÆ°á»£c Äiá»ƒm

**Æ¯u Ä‘iá»ƒm:**
- Hiá»‡u suáº¥t cao vá»›i single machine
- Nhiá»u thuáº­t toÃ¡n index
- Há»— trá»£ GPU
- Kiá»ƒm soÃ¡t full parameters
- Lightweight

**NhÆ°á»£c Ä‘iá»ƒm:**
- KhÃ´ng cÃ³ native metadata
- Single-node only
- Cáº§n tá»± quáº£n lÃ½ persistence
- KhÃ´ng cÃ³ built-in server

### 3.3 ChromaDB - Æ¯u vÃ  NhÆ°á»£c Äiá»ƒm

**Æ¯u Ä‘iá»ƒm:**
- Full database vá»›i persistence
- Native metadata support
- Filtering
- Dá»… sá»­ dá»¥ng
- Distributed scaling
- Good LangChain integration

**NhÆ°á»£c Ä‘iá»ƒm:**
- Ãt index options (chá»‰ HNSW)
- Performance tháº¥p hÆ¡n FAISS cho má»™t sá»‘ cases
- Younger project

## 4. Milvus Extension

### 4.1 Giá»›i Thiá»‡u Milvus

Milvus lÃ  distributed vector database cÃ³ thá»ƒ má»Ÿ rá»™ng FAISS:

```python
from pymilvus import connections, Collection

# Káº¿t ná»‘i Milvus
connections.connect("default", host="localhost", port="19530")

# Táº¡o collection
collection = Collection("FAISS_Collection")
collection.create_schema(
    fields=[
        {"name": "id", "type": "INT"},
        {"name": "embedding", "type": "FLOAT_VECTOR", "dim": 128}
    ]
)

### 4.2 Sá»­ Dá»¥ng FAISS vá»›i Milvus

```python
# Milvus há»— trá»£ nhiá»u FAISS indexes
index_params = {
    "index_type": "IVF_FLAT",
    "metric_type": "L2",
    "params": {"nlist": 128}
}

collection.create_index(
    field_name="embedding",
    index_params=index_params
)

## 5. Khi NÃ o Sá»­ Dá»¥ng

### 5.1 Chá»n FAISS Khi:

- Cáº§n hiá»‡u suáº¥t cao nháº¥t
- Single-machine deployment
- Kiá»ƒm soÃ¡t full parameters
- Research/prototyping
- Memory constraints (vá»›i PQ)

```python
# Use case: Production vá»›i hiá»‡u suáº¥t cao
index = faiss.IndexHNSWFlat(dimension, 32)
index.hnsw.efSearch = 100

### 5.2 Chá»n ChromaDB Khi:

- Cáº§n persistence
- Metadata filtering
- Distributed deployment
- Rapid development
- LangChain/LlamaIndex integration

```python
# Use case: Development vá»›i LangChain
vectorstore = Chroma.from_documents(
    documents=texts,
    embedding=OpenAIEmbeddings()
)

### 5.3 Decision Tree

Start
  â”‚
  â”œâ”€> Need metadata filtering?
  â”‚     â”œâ”€ Yes â†’ ChromaDB
  â”‚     â””â”€ No
  â”‚           â”‚
  â”‚     â”œâ”€> Single machine?
  â”‚     â”‚     â”œâ”€ Yes
  â”‚     â”‚     â”‚     â”‚
  â”‚     â”‚     â”‚     â”œâ”€> Need full control?
  â”‚     â”‚     â”‚     â”‚     â”œâ”€ Yes â†’ FAISS
  â”‚     â”‚     â”‚     â”‚     â””â”€ No â†’ ChromaDB
  â”‚     â”‚     â””â”€ No â†’ Milvus/Pinecone
  â”‚     â””â”€ No

## 6. Code Examples

### 6.1 FAISS vá»›i GPU

```python
import faiss

# Chuyá»ƒn sang GPU
gpu_index = faiss.index_cpu_to_gpu(
    faiss.StandardGpuResources(),
    0,  # GPU ID
    index  # CPU index
)

# Search trÃªn GPU
distances, indices = gpu_index.search(query, k=10)

### 6.2 ChromaDB vá»›i Metadata Filtering

```python
import chromadb

client = chromadb.Client()
collection = client.create_collection("documents")

# Add vá»›i metadata
collection.add(
    documents=["Doc 1", "Doc 2"],
    metadatas=[{"source": "blog", "year": 2024}, 
               {"source": "news", "year": 2023}],
    ids=["id1", "id2"]
)

# Query vá»›i filter
results = collection.query(
    query_texts=["search query"],
    n_results=2,
    where={"source": "blog"}
)

## 7. Káº¿t Luáº­n

Viá»‡c lá»±a chá»n giá»¯a FAISS vÃ  ChromaDB phá»¥ thuá»™c vÃ o:
- YÃªu cáº§u vá» hiá»‡u suáº¥t
- Nhu cáº§u metadata
- Quy mÃ´ triá»ƒn khai
- Äá»™ phá»©c táº¡p cá»§a infrastructure

FAISS phÃ¹ há»£p cho á»©ng dá»¥ng cáº§n hiá»‡u suáº¥t cao vÃ  kiá»ƒm soÃ¡t full, trong khi ChromaDB phÃ¹ há»£p cho rapid development vÃ  production vá»›i metadata requirements.

## TÃ i Liá»‡u Tham Kháº£o

1. Johnson, J., Douze, M., & JÃ©gou, H. (2017). "Billion-scale similarity search with GPUs". *IEEE BigData 2017*.

2. Malkov, Y.A., & Yashunin, D. (2018). "Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs". *IEEE TPAMI 2018*.

3. ChromaDB Documentation. (2024). "Chroma: The AI-native embedding database". https://docs.trychroma.com/

4. Milvus Documentation. (2024). "Milvus: A Purpose-Built Vector Database". https://milvus.io/docs

5. Gæ·¡æ°´. (2023). "FAISS: Efficient Similarity Search and Clustering of Dense Vectors". *GitHub Repository*.
<!-- Aero-Footer-Start -->
---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
