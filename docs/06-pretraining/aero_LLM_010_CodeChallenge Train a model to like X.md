DÆ°á»›i Ä‘Ã¢y lÃ  **bÃ i viáº¿t khoa há»c** Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn tÃ i liá»‡u **â€œCodeChallenge: Train a Model to Like Xâ€**, cÃ³ bá»• sung phÃ¢n tÃ­ch há»c thuáº­t vÃ  trÃ­ch dáº«n nguá»“n, trÃ¬nh bÃ y theo Ä‘á»‹nh dáº¡ng **Markdown**.

---

# ğŸ“˜ Huáº¥n Luyá»‡n MÃ´ HÃ¬nh NgÃ´n Ngá»¯ Vá»›i ThiÃªn Lá»‡ch CÃ³ Chá»§ ÄÃ­ch Báº±ng KL-Divergence: Má»™t NghiÃªn Cá»©u Thá»±c Nghiá»‡m

---

## **Abstract**

Trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (Large Language Models â€“ LLMs), hÃ m máº¥t mÃ¡t Ä‘Ã³ng vai trÃ² quyáº¿t Ä‘á»‹nh trong viá»‡c Ä‘á»‹nh hÆ°á»›ng hÃ nh vi há»c cá»§a mÃ´ hÃ¬nh. BÃ i viáº¿t nÃ y phÃ¢n tÃ­ch phÆ°Æ¡ng phÃ¡p huáº¥n luyá»‡n má»™t biáº¿n thá»ƒ cá»§a GPT-2 nháº±m táº¡o ra thiÃªn lá»‡ch cÃ³ chá»§ Ä‘Ã­ch: Æ°u tiÃªn sinh ra cÃ¡c token chá»©a kÃ½ tá»± â€œXâ€. NghiÃªn cá»©u sá»­ dá»¥ng hÃ m máº¥t mÃ¡t Kullbackâ€“Leibler Divergence (KL-divergence) Ä‘á»ƒ Ã©p phÃ¢n phá»‘i xÃ¡c suáº¥t Ä‘áº§u ra cá»§a mÃ´ hÃ¬nh tiá»‡m cáº­n má»™t phÃ¢n phá»‘i má»¥c tiÃªu Ä‘Æ°á»£c thiáº¿t káº¿ trÆ°á»›c. Káº¿t quáº£ cho tháº¥y mÃ´ hÃ¬nh cÃ³ thá»ƒ bá»‹ â€œláº­p trÃ¬nh thiÃªn lá»‡châ€ vá»›i hiá»‡u quáº£ ráº¥t cao chá»‰ sau sá»‘ lÆ°á»£ng nhá» epoch huáº¥n luyá»‡n, qua Ä‘Ã³ Ä‘áº·t ra nhá»¯ng váº¥n Ä‘á» nghiÃªm trá»ng liÃªn quan Ä‘áº¿n Ä‘áº¡o Ä‘á»©c vÃ  an toÃ n AI. 

---

## **1. Introduction**

CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ hiá»‡n Ä‘áº¡i nhÆ° GPT-2 vÃ  GPT-3 há»c cÃ¡ch sinh vÄƒn báº£n thÃ´ng qua viá»‡c tá»‘i Æ°u hÃ³a hÃ m máº¥t mÃ¡t dá»±a trÃªn dá»¯ liá»‡u huáº¥n luyá»‡n. Trong pháº§n lá»›n nghiÃªn cá»©u, má»¥c tiÃªu lÃ  cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c vÃ  kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a.

Tuy nhiÃªn, tÃ i liá»‡u *Train a Model to Like X* Ä‘á» xuáº¥t má»™t thÃ­ nghiá»‡m mang tÃ­nh minh há»a: huáº¥n luyá»‡n mÃ´ hÃ¬nh Ä‘á»ƒ Æ°u tiÃªn cÃ¡c token chá»©a chá»¯ cÃ¡i â€œXâ€, báº¥t ká»ƒ ngá»¯ nghÄ©a. ThÃ­ nghiá»‡m nÃ y vá»«a mang tÃ­nh giÃ¡o dá»¥c, vá»«a cho tháº¥y má»©c Ä‘á»™ dá»… dÃ ng trong viá»‡c â€œbáº» lÃ¡iâ€ hÃ nh vi cá»§a mÃ´ hÃ¬nh ngÃ´n ngá»¯. 

Má»¥c tiÃªu cá»§a bÃ i viáº¿t lÃ :

* PhÃ¢n tÃ­ch phÆ°Æ¡ng phÃ¡p táº¡o thiÃªn lá»‡ch báº±ng KL-divergence,
* ÄÃ¡nh giÃ¡ káº¿t quáº£ thá»±c nghiá»‡m,
* Tháº£o luáº­n cÃ¡c há»‡ quáº£ vá» AI safety.

---

## **2. Theoretical Background**

### **2.1. Language Modeling vÃ  PhÃ¢n Phá»‘i XÃ¡c Suáº¥t**

MÃ´ hÃ¬nh GPT-2 há»c phÃ¢n phá»‘i:

[
P(x_t \mid x_1, \dots, x_{t-1})
]

Trong Ä‘Ã³, má»—i token Ä‘Æ°á»£c sinh dá»±a trÃªn ngá»¯ cáº£nh trÆ°á»›c Ä‘Ã³.

Äáº§u ra cá»§a mÃ´ hÃ¬nh lÃ  má»™t vector xÃ¡c suáº¥t trÃªn toÃ n bá»™ tá»« vá»±ng:

[
P = (p_1, p_2, \dots, p_V)
]

vá»›i (V) lÃ  kÃ­ch thÆ°á»›c vocab.

---

### **2.2. Kullbackâ€“Leibler Divergence**

KL-divergence Ä‘o Ä‘á»™ khÃ¡c biá»‡t giá»¯a hai phÃ¢n phá»‘i xÃ¡c suáº¥t (P) vÃ  (Q):

[
D_{KL}(Q||P) = \sum_i Q(i)\log\frac{Q(i)}{P(i)}
]

Trong Ä‘Ã³:

* (Q): phÃ¢n phá»‘i má»¥c tiÃªu,
* (P): phÃ¢n phá»‘i dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh.

Tá»‘i thiá»ƒu hÃ³a KL-divergence tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i viá»‡c Ã©p (P) tiá»‡m cáº­n (Q). 

---

### **2.3. Bias Trong MÃ´ HÃ¬nh NgÃ´n Ngá»¯**

ThiÃªn lá»‡ch (bias) trong LLMs cÃ³ thá»ƒ xuáº¥t hiá»‡n do:

* Dá»¯ liá»‡u huáº¥n luyá»‡n,
* HÃ m máº¥t mÃ¡t,
* Má»¥c tiÃªu tá»‘i Æ°u hÃ³a.

Trong nghiÃªn cá»©u nÃ y, bias Ä‘Æ°á»£c táº¡o ra má»™t cÃ¡ch cÃ³ chá»§ Ä‘Ã­ch thÃ´ng qua phÃ¢n phá»‘i má»¥c tiÃªu nhÃ¢n táº¡o.

---

## **3. Methodology**

### **3.1. Thiáº¿t Láº­p MÃ´ HÃ¬nh**

MÃ´ hÃ¬nh sá»­ dá»¥ng lÃ  Model 5, má»™t biáº¿n thá»ƒ rÃºt gá»n cá»§a GPT-2:

* Kiáº¿n trÃºc Transformer,
* Tokenizer GPT-2,
* Cháº¡y trÃªn GPU.

Viá»‡c huáº¥n luyá»‡n trÃªn CPU bá»‹ háº¡n cháº¿ nghiÃªm trá»ng vá» thá»i gian. 

---

### **3.2. Sinh Chuá»—i Ban Äáº§u**

Dá»¯ liá»‡u Ä‘áº§u vÃ o ban Ä‘áº§u gá»“m:

* Token ngáº«u nhiÃªn,
* Äá»™ dÃ i chuá»—i: 256,
* Sinh thÃªm 200 token má»›i.

TrÆ°á»›c huáº¥n luyá»‡n, khÃ´ng cÃ³ token nÃ o chá»©a â€œXâ€ trong 200 token sinh ra. 

---

### **3.3. Táº¡o Mask Cho Token Má»¥c TiÃªu**

Má»™t vector mask Ä‘Æ°á»£c xÃ¢y dá»±ng:

[
M_i =
\begin{cases}
1, & \text{náº¿u token } i \text{ chá»©a X}\
0, & \text{ngÆ°á»£c láº¡i}
\end{cases}
]

Sau Ä‘Ã³ Ä‘Æ°á»£c chuáº©n hÃ³a thÃ nh phÃ¢n phá»‘i xÃ¡c suáº¥t:

[
Q_i = \frac{M_i}{\sum_j M_j}
]

Theo thá»‘ng kÃª, chá»‰ khoáº£ng 2% token chá»©a kÃ½ tá»± â€œXâ€. 

---

### **3.4. XÃ¢y Dá»±ng Custom Loss Function**

HÃ m loss Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng `torch.nn.Module` vÃ  sá»­ dá»¥ng `F.kl_div`:

[
\mathcal{L} = D_{KL}(Q||P)
]

LÆ°u Ã½:

* Äáº§u vÃ o thá»© nháº¥t: log-probability,
* Äáº§u vÃ o thá»© hai: probability.

Sai khÃ¡c nÃ y lÃ  Ä‘iá»ƒm ká»¹ thuáº­t quan trá»ng trong triá»ƒn khai. 

---

### **3.5. Quy TrÃ¬nh Huáº¥n Luyá»‡n**

Quy trÃ¬nh huáº¥n luyá»‡n gá»“m:

* 200 epoch,
* Dá»¯ liá»‡u Ä‘áº§u vÃ o: token ngáº«u nhiÃªn,
* Chá»‰ dÃ¹ng token cuá»‘i Ä‘á»ƒ tÃ­nh loss,
* Optimizer: SGD/Adam.

KhÃ´ng sá»­ dá»¥ng dá»¯ liá»‡u vÄƒn báº£n thá»±c táº¿. 

---

## **4. Experimental Results**

### **4.1. Diá»…n Biáº¿n Loss**

Loss ban Ä‘áº§u xáº¥p xá»‰:

[
\log(V) \approx 11
]

Sau huáº¥n luyá»‡n, loss giáº£m máº¡nh vá» gáº§n 0, cho tháº¥y mÃ´ hÃ¬nh Ä‘Ã£ há»c gáº§n nhÆ° hoÃ n háº£o phÃ¢n phá»‘i má»¥c tiÃªu. 

---

### **4.2. Káº¿t Quáº£ Sinh VÄƒn Báº£n**

Sau huáº¥n luyá»‡n:

* 188/200 token chá»©a â€œXâ€,
* Tá»· lá»‡ â‰ˆ 95%.

So vá»›i 0% ban Ä‘áº§u, má»©c tÄƒng nÃ y lÃ  ráº¥t Ä‘Ã¡ng ká»ƒ. 

---

### **4.3. Äáº·c TÃ­nh VÄƒn Báº£n Sinh Ra**

VÄƒn báº£n sau huáº¥n luyá»‡n:

* Xuáº¥t hiá»‡n dÃ y Ä‘áº·c kÃ½ tá»± â€œXâ€,
* Máº¥t ngá»¯ nghÄ©a tá»± nhiÃªn,
* Bá»‹ chi phá»‘i máº¡nh bá»Ÿi má»¥c tiÃªu tá»‘i Æ°u.

Äiá»u nÃ y cho tháº¥y loss function cÃ³ thá»ƒ â€œbáº» congâ€ hÃ nh vi mÃ´ hÃ¬nh.

---

## **5. Discussion**

### **5.1. Hiá»‡u Quáº£ Cá»§a KL-Divergence**

KL-divergence cho phÃ©p:

* Äiá»u khiá»ƒn toÃ n bá»™ phÃ¢n phá»‘i output,
* KhÃ´ng chá»‰ tÃ¡c Ä‘á»™ng lÃªn má»™t token Ä‘Æ¡n láº»,
* Táº¡o bias máº¡nh vÃ  nhanh.

ÄÃ¢y lÃ  cÃ´ng cá»¥ ráº¥t máº¡nh trong huáº¥n luyá»‡n cÃ³ Ä‘iá»u kiá»‡n.

---

### **5.2. Kháº£ NÄƒng Thao TÃºng MÃ´ HÃ¬nh**

ThÃ­ nghiá»‡m cho tháº¥y:

* Viá»‡c táº¡o thiÃªn lá»‡ch lÃ  ráº¥t dá»…,
* KhÃ´ng cáº§n dá»¯ liá»‡u tháº­t,
* Chá»‰ cáº§n thiáº¿t káº¿ loss phÃ¹ há»£p.

Äiá»u nÃ y Ä‘áº·t ra nguy cÆ¡ thao tÃºng hÃ nh vi LLMs trong thá»±c táº¿.

---

### **5.3. LiÃªn Há»‡ Äáº¿n AI Safety**

Theo tÃ i liá»‡u, cÃ¹ng má»™t ká»¹ thuáº­t cÃ³ thá»ƒ Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ:

* ThÃºc Ä‘áº©y quan Ä‘iá»ƒm chÃ­nh trá»‹,
* Gá»£i Ã½ hÃ nh vi tiÃªu dÃ¹ng,
* Táº¡o thiÃªn lá»‡ch xÃ£ há»™i,
* áº¢nh hÆ°á»Ÿng quyáº¿t Ä‘á»‹nh cÃ¡ nhÃ¢n.

CÃ¡c bias tinh vi khÃ³ phÃ¡t hiá»‡n hÆ¡n nhiá»u so vá»›i vÃ­ dá»¥ â€œXâ€. 

---

## **6. Limitations**

NghiÃªn cá»©u cÃ²n má»™t sá»‘ háº¡n cháº¿:

* KhÃ´ng dÃ¹ng dá»¯ liá»‡u thá»±c,
* KhÃ´ng Ä‘Ã¡nh giÃ¡ long-term generalization,
* Chá»‰ thá»­ nghiá»‡m má»™t dáº¡ng bias,
* KhÃ´ng Ä‘o áº£nh hÆ°á»Ÿng tá»›i downstream tasks.

Do Ä‘Ã³, káº¿t quáº£ mang tÃ­nh minh há»a nhiá»u hÆ¡n thá»±c nghiá»‡m á»©ng dá»¥ng.

---

## **7. Conclusion**

BÃ i viáº¿t Ä‘Ã£ phÃ¢n tÃ­ch phÆ°Æ¡ng phÃ¡p huáº¥n luyá»‡n mÃ´ hÃ¬nh GPT-2 vá»›i thiÃªn lá»‡ch cÃ³ chá»§ Ä‘Ã­ch thÃ´ng qua KL-divergence. CÃ¡c káº¿t luáº­n chÃ­nh gá»“m:

1. KL-divergence cho phÃ©p Ä‘iá»u khiá»ƒn phÃ¢n phá»‘i Ä‘áº§u ra hiá»‡u quáº£.
2. MÃ´ hÃ¬nh cÃ³ thá»ƒ há»c bias ráº¥t nhanh.
3. Custom loss cÃ³ sá»©c áº£nh hÆ°á»Ÿng máº¡nh Ä‘áº¿n hÃ nh vi LLM.
4. Viá»‡c táº¡o thiÃªn lá»‡ch ká»¹ thuáº­t lÃ  tÆ°Æ¡ng Ä‘á»‘i dá»… dÃ ng.
5. Váº¥n Ä‘á» AI safety cáº§n Ä‘Æ°á»£c xem xÃ©t nghiÃªm tÃºc.

NghiÃªn cá»©u nháº¥n máº¡nh ráº±ng thiáº¿t káº¿ hÃ m máº¥t mÃ¡t khÃ´ng chá»‰ lÃ  váº¥n Ä‘á» ká»¹ thuáº­t, mÃ  cÃ²n lÃ  váº¥n Ä‘á» Ä‘áº¡o Ä‘á»©c vÃ  xÃ£ há»™i.

---

## **References**

1. CodeChallenge: Train a Model to Like X. Lecture Transcript.

2. Goodfellow, I., Bengio, Y., Courville, A. (2016). *Deep Learning*. MIT Press.
3. Sutton, R., Barto, A. (2018). *Reinforcement Learning: An Introduction*. MIT Press.
4. Amodei et al. (2016). Concrete Problems in AI Safety. *arXiv*.

---
