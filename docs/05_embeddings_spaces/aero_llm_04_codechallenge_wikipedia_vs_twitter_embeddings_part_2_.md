
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../index.md) > [05 embeddings spaces](index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../index.md)
- [ğŸ“š Module 01: LLM Course](../01_llm_course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../02_words_to_tokens_to_numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../04_buildgpt/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../07_fine_tune_pretrained_models/index.md)
- [ğŸ” Module 19: AI Safety](../19_ai_safety/index.md)
- [ğŸ Module 20: Python for AI](../20_python_colab_notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# So sÃ¡nh Biá»ƒu Diá»…n Tá»« Vá»±ng giá»¯a Wikipedia vÃ  Twitter báº±ng PhÃ¢n TÃ­ch TÆ°Æ¡ng Äá»“ng Biá»ƒu Diá»…n (RSA)

## TÃ³m táº¯t

Trong nghiÃªn cá»©u xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn (NLP), cÃ¡c mÃ´ hÃ¬nh embedding há»c Ä‘Æ°á»£c biá»ƒu diá»…n vector cá»§a tá»« dá»±a trÃªn ngá»¯ cáº£nh. Tuy nhiÃªn, khi hai mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn cÃ¡c miá»n dá»¯ liá»‡u khÃ¡c nhau â€” vÃ­ dá»¥ nhÆ° tá»« Ä‘iá»ƒn bÃ¡ch khoa toÃ n thÆ° cá»§a [Wikipedia](chatgpt://generic-entity?number=0) vÃ  dá»¯ liá»‡u máº¡ng xÃ£ há»™i tá»« [Twitter](chatgpt://generic-entity?number=1) â€” thÃ¬ khÃ´ng gian vector thu Ä‘Æ°á»£c cÃ³ thá»ƒ khÃ¡c biá»‡t Ä‘Ã¡ng ká»ƒ. BÃ i viáº¿t nÃ y trÃ¬nh bÃ y phÆ°Æ¡ng phÃ¡p so sÃ¡nh hai khÃ´ng gian embedding thÃ´ng qua **Cosine Similarity** vÃ  **Representational Similarity Analysis (RSA)**, minh há»a báº±ng cÃ¢u máº«u â€œThe quick brown fox jumps over the lazy dogâ€. CÃ¡c cÃ´ng thá»©c toÃ¡n há»c Ä‘Æ°á»£c bá»• sung nháº±m lÃ m rÃµ ná»n táº£ng lÃ½ thuyáº¿t.

---

## 1. Giá»›i thiá»‡u

$$
Word embedding Ã¡nh xáº¡ má»—i tá»« w vÃ o má»™t vector \mathbf{v}_w \in \mathbb{R}^d, trong Ä‘Ã³:
$$

$$
f: w \rightarrow \mathbf{v}_w
$$

vá»›i $d$ lÃ  sá»‘ chiá»u cá»§a khÃ´ng gian nhÃºng.

Khi hai mÃ´ hÃ¬nh embedding Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn hai táº­p dá»¯ liá»‡u khÃ¡c nhau (vÃ­ dá»¥: vÄƒn báº£n bÃ¡ch khoa vÃ  tweet ngáº¯n), ta cÃ³:

$$

$$

f_{wiki}(w) = \mathbf{v}_w^{(wiki)}

$$

$$

$$
f_{twitter}(w) = \mathbf{v}_w^{(twitter)}
$$

$$
Do khÃ¡c biá»‡t vá» miá»n dá»¯ liá»‡u vÃ  phÃ¢n bá»‘ ngÃ´n ngá»¯, cÃ¡c vector thu Ä‘Æ°á»£c khÃ´ng thá»ƒ so sÃ¡nh trá»±c tiáº¿p tá»«ng chiá»u. --- ## 2. Äá»™ tÆ°Æ¡ng Ä‘á»“ng Cosine Äá»ƒ Ä‘o má»©c Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng giá»¯a hai tá»« w_i vÃ  w_j trong cÃ¹ng má»™t mÃ´ hÃ¬nh, ta sá»­ dá»¥ng **cosine similarity**:
$$

$$
\text{cosine}(\mathbf{v}_i, \mathbf{v}_j) = \frac{\mathbf{v}_i \cdot \mathbf{v}_j} {\|\mathbf{v}_i\| \|\mathbf{v}_j\|}
$$

$$
Trong Ä‘Ã³: - \mathbf{v}_i \cdot \mathbf{v}_j lÃ  tÃ­ch vÃ´ hÆ°á»›ng. - \\mid\mathbf{v}_i\\mid lÃ  chuáº©n Euclid:
$$

$$
\|\mathbf{v}_i\| = \sqrt{\sum_{k=1}^{d} v_{ik}^2}
$$

$$
Cosine similarity náº±m trong khoáº£ng:
$$

-1 $\le$q \text{cosine} $\le$q 1

$$
Quan sÃ¡t thá»±c nghiá»‡m cho tháº¥y trong má»™t sá»‘ cáº·p tá»«, embedding tá»« Twitter cho giÃ¡ trá»‹ cosine cao hÆ¡n so vá»›i embedding tá»« Wikipedia, pháº£n Ã¡nh tÃ­nh ngá»¯ cáº£nh gáº§n gÅ©i hÆ¡n trong vÄƒn báº£n máº¡ng xÃ£ há»™i. --- ## 3. Váº¥n Ä‘á»: KhÃ´ng gian embedding khÃ¡c nhau Máº·c dÃ¹ cÃ³ thá»ƒ so sÃ¡nh cosine similarity trong *cÃ¹ng má»™t mÃ´ hÃ¬nh*, ta khÃ´ng thá»ƒ so sÃ¡nh trá»±c tiáº¿p:
$$

\mathbf{v}_w^{(wiki)} \neq \mathbf{v}_w^{(twitter)}

$$
LÃ½ do: 1. CÃ¡c khÃ´ng gian Ä‘Æ°á»£c há»c Ä‘á»™c láº­p. 2. Trá»¥c tá»a Ä‘á»™ khÃ´ng Ä‘á»“ng nháº¥t. 3. PhÃ©p quay (rotation) cá»§a khÃ´ng gian khÃ´ng lÃ m thay Ä‘á»•i khoáº£ng cÃ¡ch ná»™i táº¡i nhÆ°ng lÃ m thay Ä‘á»•i tá»a Ä‘á»™ tuyá»‡t Ä‘á»‘i. Giáº£ sá»­ tá»“n táº¡i má»™t ma tráº­n quay trá»±c giao \mathbf{R}:
$$

$$
\mathbf{v}_w^{(twitter)} \approx \mathbf{R} \mathbf{v}_w^{(wiki)}
$$

$$
Khi Ä‘Ã³, tá»a Ä‘á»™ khÃ¡c nhau nhÆ°ng cáº¥u trÃºc tÆ°Æ¡ng Ä‘á»‘i cÃ³ thá»ƒ váº«n Ä‘Æ°á»£c báº£o toÃ n. --- ## 4. Representational Similarity Analysis (RSA) ### 4.1 Ã tÆ°á»Ÿng RSA khÃ´ng so sÃ¡nh vector trá»±c tiáº¿p, mÃ  so sÃ¡nh **ma tráº­n tÆ°Æ¡ng Ä‘á»“ng ná»™i bá»™** giá»¯a cÃ¡c tá»« trong tá»«ng mÃ´ hÃ¬nh. Giáº£ sá»­ ta cÃ³ táº­p n tá»« trong cÃ¢u: > â€œThe quick brown fox jumps over the lazy dogâ€
$$

Ta xÃ¢y dá»±ng ma tráº­n tÆ°Æ¡ng Ä‘á»“ng S \in \mathbb{R}^{n \times n}:

$$

$$

S_{ij} = \text{cosine}(\mathbf{v}_i, \mathbf{v}_j)

$$

$$

Ta cÃ³:

$$
S^{(wiki)} \quad \text{vÃ } \quad S^{(twitter)}
$$

---

### 4.2 So sÃ¡nh hai ma tráº­n

Ta vector hÃ³a pháº§n tam giÃ¡c trÃªn (khÃ´ng tÃ­nh Ä‘Æ°á»ng chÃ©o):

$$
\mathbf{s}^{(wiki)}, \quad \mathbf{s}^{(twitter)}
$$

Sau Ä‘Ã³ tÃ­nh há»‡ sá»‘ tÆ°Æ¡ng quan Pearson:

$$

$$

r = \frac{\sum (x_i - \bar{x})(y_i - \bar{y})} {\sqrt{\sum (x_i - \bar{x})^2} \sqrt{\sum (y_i - \bar{y})^2}}

$$

$$

Náº¿u:

- $r $\approx$ 1$: Hai khÃ´ng gian cÃ³ cáº¥u trÃºc quan há»‡ tÆ°Æ¡ng Ä‘á»“ng cao.
- $r $\approx$ 0$: Cáº¥u trÃºc khÃ¡c biá»‡t.
- $r < 0$: Quan há»‡ nghá»‹ch Ä‘áº£o.

---

## 5. Minh há»a quy trÃ¬nh thá»±c nghiá»‡m

### BÆ°á»›c 1: Láº¥y chá»‰ sá»‘ tá»« (word indices)

Vá»›i má»—i tá»« $w$ trong cÃ¢u:

$$
\text{index}_{wiki}(w)
$$

$$
\text{index}_{twitter}(w)
$$

LÆ°u Ã½: Má»™t sá»‘ tá»« cÃ³ thá»ƒ khÃ´ng xuáº¥t hiá»‡n (vÃ­ dá»¥: chá»¯ hoa â€œTheâ€).

---

### BÆ°á»›c 2: TrÃ­ch xuáº¥t embedding

$$

$$

\mathbf{v}_w^{(wiki)} = E^{(wiki)}[\text{index}(w)]

$$

$$

$$
\mathbf{v}_w^{(twitter)} = E^{(twitter)}[\text{index}(w)]
$$

$$
--- ### BÆ°á»›c 3: TÃ­nh ma tráº­n tÆ°Æ¡ng Ä‘á»“ng
$$

$$
S^{(model)}_{ij} = \frac{\mathbf{v}_i \cdot \mathbf{v}_j} {\|\mathbf{v}_i\| \|\mathbf{v}_j\|}
$$

$$
--- ### BÆ°á»›c 4: TÃ­nh tÆ°Æ¡ng quan giá»¯a hai ma tráº­n
$$

$$
\text{RSA score} = \text{corr}(\mathbf{s}^{(wiki)}, \mathbf{s}^{(twitter)})
$$

$$
--- ## 6. PhÃ¢n tÃ­ch káº¿t quáº£ Náº¿u embedding tá»« Twitter cho giÃ¡ trá»‹ cosine cao hÆ¡n trong nhiá»u cáº·p tá»«, Ä‘iá»u nÃ y cÃ³ thá»ƒ pháº£n Ã¡nh: - NgÃ´n ngá»¯ trÃªn máº¡ng xÃ£ há»™i mang tÃ­nh ngá»¯ cáº£nh cháº·t cháº½. - CÃ¡c tá»« xuáº¥t hiá»‡n trong cáº¥u trÃºc há»™i thoáº¡i ngáº¯n, lÃ m tÄƒng máº­t Ä‘á»™ Ä‘á»“ng xuáº¥t hiá»‡n. Trong khi Ä‘Ã³, Wikipedia cÃ³ phong cÃ¡ch há»c thuáº­t, phÃ¢n bá»‘ tá»« rá»™ng hÆ¡n, dáº«n Ä‘áº¿n cáº¥u trÃºc embedding phÃ¢n tÃ¡n hÆ¡n. --- ## 7. Tháº£o luáº­n RSA cho phÃ©p ta: - So sÃ¡nh hai khÃ´ng gian embedding khÃ´ng cÃ¹ng há»‡ trá»¥c. - ÄÃ¡nh giÃ¡ tÃ­nh tÆ°Æ¡ng Ä‘á»“ng cáº¥u trÃºc. - TrÃ¡nh phá»¥ thuá»™c vÃ o tá»a Ä‘á»™ tuyá»‡t Ä‘á»‘i. PhÆ°Æ¡ng phÃ¡p nÃ y thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng trong: - Khoa há»c tháº§n kinh tÃ­nh toÃ¡n. - So sÃ¡nh mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n. - PhÃ¢n tÃ­ch Ä‘a miá»n dá»¯ liá»‡u. --- ## 8. Káº¿t luáº­n So sÃ¡nh embedding giá»¯a Wikipedia vÃ  Twitter khÃ´ng thá»ƒ thá»±c hiá»‡n báº±ng cÃ¡ch Ä‘á»‘i chiáº¿u trá»±c tiáº¿p vector. Tuy nhiÃªn, thÃ´ng qua cosine similarity vÃ  Ä‘áº·c biá»‡t lÃ  Representational Similarity Analysis (RSA), ta cÃ³ thá»ƒ Ä‘Ã¡nh giÃ¡ má»©c Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng cáº¥u trÃºc giá»¯a hai khÃ´ng gian biá»ƒu diá»…n. Vá» máº·t toÃ¡n há»c:
$$

\text{So sÃ¡nh trá»±c tiáº¿p vector} \neq \text{So sÃ¡nh cáº¥u trÃºc quan há»‡}