
<!-- Aero-Navigation-Start -->
[ğŸ  Home](../../index.md) > [12 Investigating neurons dimensions](../index.md)

---
### ğŸ§­ Äiá»u hÆ°á»›ng nhanh

- [ğŸ  Cá»•ng tÃ i liá»‡u](../../index.md)
- [ğŸ“š Module 01: LLM Course](../../01-LLM_Course/index.md)
- [ğŸ”¢ Module 02: Tokenization](../../02-Words-to-tokens-to-numbers/index.md)
- [ğŸ—ï¸ Module 04: Build GPT](../../04-buildGPT/index.md)
- [ğŸ¯ Module 07: Fine-tuning](../../07-Fine-tune-pretrained-models/index.md)
- [ğŸ” Module 19: AI Safety](../../19-AI-safety/index.md)
- [ğŸ Module 20: Python for AI](../../20-Python-Colab-notebooks/index.md)
---
<!-- Aero-Navigation-End -->
# Äiá»u chá»‰nh Danh tá»« riÃªng trong GPT-2 Medium

## TÃ³m táº¯t (Abstract)
BÃ¡o cÃ¡o nÃ y sá»­ dá»¥ng Há»“i quy Logistic Ä‘á»ƒ xÃ¡c Ä‘á»‹nh vÃ  phÃ¢n tÃ­ch cÃ¡c nÆ¡-ron MLP chuyÃªn biá»‡t hÃ³a cho viá»‡c nháº­n diá»‡n danh tá»« riÃªng (Proper Nouns) trong mÃ´ hÃ¬nh GPT-2 Medium. Báº±ng cÃ¡ch khai thÃ¡c Ä‘áº·c Ä‘iá»ƒm hÃ¬nh thÃ¡i cá»§a tiáº¿ng Anh (viáº¿t hoa cÃ¡c danh tá»« riÃªng), chÃºng ta triá»ƒn khai má»™t thuáº­t toÃ¡n lá»c tá»± Ä‘á»™ng trÃªn táº­p dá»¯ liá»‡u WikiText Ä‘á»ƒ phÃ¢n loáº¡i token. NghiÃªn cá»©u thá»±c nghiá»‡m trÃªn toÃ n bá»™ 4096 nÆ¡-ron cá»§a má»™t táº§ng MLP bá»™c lá»™ sá»± tá»“n táº¡i cá»§a cÃ¡c "Ä‘Æ¡n vá»‹ danh tá»« riÃªng" (proper noun units) vá»›i Ä‘á»™ tin cáº­y thá»‘ng kÃª cao. TÃ­nh bá»n vá»¯ng cá»§a phÃ¡t hiá»‡n Ä‘Æ°á»£c kiá»ƒm chá»©ng thÃ´ng qua cÃ¡c báº£n Ä‘á»“ nhiá»‡t vÄƒn báº£n trÃªn cÃ¡c máº«u dá»¯ liá»‡u chÆ°a tá»«ng xuáº¥t hiá»‡n trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n há»“i quy.

---

## 1. Má»Ÿ Äáº§u (Introduction)
Danh tá»« riÃªng Ä‘áº¡i diá»‡n cho cÃ¡c thá»±c thá»ƒ cá»¥ thá»ƒ (ngÆ°á»i, Ä‘á»‹a danh, tá»• chá»©c). Trong cÆ¡ cháº¿ ná»™i soi mÃ´ hÃ¬nh, viá»‡c hiá»ƒu cÃ¡ch LLM phÃ¢n tÃ¡ch danh tá»« riÃªng khá»i cÃ¡c danh tá»« chung vÃ  cÃ¡c thÃ nh pháº§n ngá»¯ phÃ¡p khÃ¡c lÃ  chÃ¬a khÃ³a Ä‘á»ƒ giáº£i mÃ£ cÃ¡ch mÃ´ hÃ¬nh xÃ¢y dá»±ng báº£n Ä‘á»“ tri thá»©c tháº¿ giá»›i. NghiÃªn cá»©u nÃ y táº­p trung vÃ o GPT-2 Medium â€“ má»™t mÃ´ hÃ¬nh cÃ³ kÃ­ch thÆ°á»›c trung bÃ¬nh vá»›i 24 khá»‘i Transformer vÃ  4096 nÆ¡-ron trong má»—i lá»›p má»Ÿ rá»™ng MLP.

---

## 2. XÃ¡c Ä‘á»‹nh Danh tá»« riÃªng báº±ng Thuáº­t toÃ¡n

### 2.1. Quy táº¯c PhÃ¢n loáº¡i HÃ¬nh thÃ¡i
Do cáº¥u trÃºc dá»¯ liá»‡u Wikipedia chá»©a máº­t Ä‘á»™ danh tá»« riÃªng cao, chÃºng ta Ã¡p dá»¥ng má»™t thuáº­t toÃ¡n lá»c Ä‘Æ¡n giáº£n nhÆ°ng hiá»‡u quáº£:
1. **Äiá»u kiá»‡n Chá»¯ hoa:** Token sau khi loáº¡i bá» khoáº£ng tráº¯ng (`strip()`) pháº£i báº¯t Ä‘áº§u báº±ng má»™t chá»¯ cÃ¡i viáº¿t hoa.
2. **Loáº¡i trá»« Äáº§u cÃ¢u:** Äá»ƒ trÃ¡nh nháº§m láº«n vá»›i cÃ¡c tá»« Ä‘Æ°á»£c viáº¿t hoa do Ä‘á»©ng Ä‘áº§u cÃ¢u, chÃºng ta kiá»ƒm tra token ngay phÃ­a trÆ°á»›c. Náº¿u token Ä‘Ã³ káº¿t thÃºc báº±ng dáº¥u cháº¥m (.), dáº¥u cháº¥m há»i (?) hoáº·c dáº¥u cháº¥m than (!), token hiá»‡n táº¡i sáº½ bá»‹ loáº¡i khá»i nhÃ³m danh tá»« riÃªng.

### 2.2. Chuáº©n bá»‹ Máº«u So sÃ¡nh
Äá»ƒ há»“i quy váº­n hÃ nh tá»‘i Æ°u, chÃºng ta thiáº¿t láº­p hai nhÃ³m cÃ³ kÃ­ch thÆ°á»›c báº±ng nhau ($n \approx 220$):
- **NhÃ³m ÄÃ­ch (Target):** CÃ¡c danh tá»« riÃªng há»£p lá»‡.
- **NhÃ³m Äá»‘i chá»©ng (Comparison):** CÃ¡c token khÃ¡c Ä‘Æ°á»£c chá»n ngáº«u nhiÃªn tá»« cÃ¹ng má»™t batch dá»¯ liá»‡u (bao gá»“m Ä‘á»™ng tá»«, giá»›i tá»«, sá»‘, v.v.).

---

## 3. PhÃ¢n tÃ­ch Äá»‹nh lÆ°á»£ng xuyÃªn Táº§ng

### 3.1. PhÃ¢n phá»‘i Há»‡ sá»‘ Beta
Thá»±c hiá»‡n há»“i quy trÃªn 4096 nÆ¡-ron vÃ  Ã¡p dá»¥ng hiá»‡u chá»‰nh Bonferroni ($p < 0.05 / 4096$):
- **Beta DÆ°Æ¡ng ($\beta > 0$):** Chá»‰ thá»‹ cÃ¡c nÆ¡-ron cÃ³ hoáº¡t hÃ³a máº¡nh khi gáº·p danh tá»« riÃªng. ÄÃ¢y lÃ  cÃ¡c Ä‘á»‘i tÆ°á»£ng nghiÃªn cá»©u chÃ­nh.
- **Beta Ã‚m ($\beta < 0$):** Chá»‰ thá»‹ cÃ¡c nÆ¡-ron bá»‹ á»©c cháº¿ hoáº¡t hÃ³a khi gáº·p danh tá»« riÃªng. Máº·c dÃ¹ khÃ³ diá»…n giáº£i hÆ¡n, hiá»‡n tÆ°á»£ng nÃ y tÆ°Æ¡ng Ä‘á»“ng vá»›i cÆ¡ cháº¿ á»©c cháº¿ chá»n lá»c (selective inhibition) thÆ°á»ng tháº¥y trong tháº§n kinh há»c sinh há»c.

### 3.2. Trá»±c quan hÃ³a Beta vs. P-value
Biá»ƒu Ä‘á»“ scatter plot giá»¯a há»‡ sá»‘ há»“i quy vÃ  $-\log(p)$ cho tháº¥y má»™t cáº¥u trÃºc hÃ¬nh phá»…u: cÃ¡c nÆ¡-ron cÃ³ hiá»‡u á»©ng máº¡nh nháº¥t ($\beta$ lá»›n) cÅ©ng Ä‘á»“ng thá»i lÃ  cÃ¡c nÆ¡-ron cÃ³ Ã½ nghÄ©a thá»‘ng kÃª cao nháº¥t.

---

## 4. PhÃ¢n tÃ­ch Äá»‹nh tÃ­nh vÃ  Kiá»ƒm chá»©ng Bá»n vá»¯ng

### 4.1. Báº£n Ä‘á»“ nhiá»‡t VÄƒn báº£n (Text Heatmap)
Báº±ng cÃ¡ch trá»±c quan hÃ³a hoáº¡t hÃ³a cá»§a nÆ¡-ron cÃ³ $\beta$ cá»±c Ä‘áº¡i lÃªn cÃ¡c Ä‘oáº¡n vÄƒn báº£n, chÃºng ta quan sÃ¡t tháº¥y sá»± "tháº¯p sÃ¡ng" rÃµ rá»‡t táº¡i cÃ¡c tÃªn ngÆ°á»i vÃ  Ä‘á»‹a danh. 
- **LÆ°u Ã½ vá» Polysemanticity:** Má»™t sá»‘ nÆ¡-ron cÃ³ thá»ƒ kÃ­ch hoáº¡t cáº£ vá»›i cÃ¡c thá»±c thá»ƒ liÃªn quan (vÃ­ dá»¥: kÃ­ch hoáº¡t vá»›i tÃªn ngÆ°á»i vÃ  cÃ¡c tá»« liÃªn quan Ä‘áº¿n truyá»n hÃ¬nh).

### 4.2. Kiá»ƒm chá»©ng NgoÃ i máº«u (Out-of-sample Validation)
Äá»ƒ loáº¡i trá»« hiá»‡n tÆ°á»£ng quÃ¡ khá»›p (overfitting), nÆ¡-ron Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh tá»« batch 1 Ä‘Æ°á»£c kiá»ƒm tra trÃªn batch 2. Káº¿t quáº£ duy trÃ¬ Ä‘Æ°á»£c tÃ­nh chá»n lá»c danh tá»« riÃªng, kháº³ng Ä‘á»‹nh ráº±ng nÆ¡-ron nÃ y Ä‘Ã£ thá»±c sá»± há»c Ä‘Æ°á»£c khÃ¡i niá»‡m trá»«u tÆ°á»£ng vá» danh tá»« riÃªng thay vÃ¬ chá»‰ ghi nhá»› cÃ¡c tá»« cá»¥ thá»ƒ.

---

## 5. Káº¿t Luáº­n
NghiÃªn cá»©u xÃ¡c nháº­n ráº±ng GPT-2 Medium sá»Ÿ há»¯u cÃ¡c kÃªnh xá»­ lÃ½ chuyÃªn biá»‡t cho danh tá»« riÃªng náº±m trong lá»›p MLP. Viá»‡c sá»­ dá»¥ng Há»“i quy Logistic káº¿t há»£p vá»›i cÃ¡c thuáº­t toÃ¡n lá»c ngÃ´n ngá»¯ cung cáº¥p má»™t cÃ´ng cá»¥ máº¡nh máº½ Ä‘á»ƒ "báº£n Ä‘á»“ hÃ³a" chá»©c nÄƒng cá»§a hÃ ng nghÃ¬n nÆ¡-ron trong cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n.

---

## TÃ i liá»‡u tham kháº£o (Citations)
1. NghiÃªn cá»©u Proper noun tuning trÃªn GPT-2 Medium dá»±a trÃªn `aero_LLM_19_Proper noun tuning in GPT2-medium.md`. PhÃ¢n tÃ­ch há»‡ sá»‘ Beta vÃ  kiá»ƒm chá»©ng ngoÃ i máº«u báº±ng Text Heatmap.
<!-- Aero-Footer-Start -->

## ğŸ“„ TÃ i liá»‡u cÃ¹ng chuyÃªn má»¥c
| BÃ i há»c | LiÃªn káº¿t |
| :--- | :--- |
| [ğŸ“‚ Module: 12-Investigating-neurons-dimensions](README.md) | [Xem bÃ i viáº¿t â†’](README.md) |
| [Cá»±c Ä‘áº¡i hÃ³a Hoáº¡t hÃ³a (Activation Maximization): CÆ¡ sá»Ÿ LÃ½ thuyáº¿t vÃ  Nhá»¯ng thÃ¡ch thá»©c trong LLM](aero_LLM_01_Activation maximization via gradient ascent (theory).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_01_Activation maximization via gradient ascent (theory).md) |
| [Triá»ƒn khai Cá»±c Ä‘áº¡i hÃ³a Hoáº¡t hÃ³a: Tá»« Gradient Ascent Ä‘áº¿n Giáº£i mÃ£ Token (Activation Maximization Implementation)](aero_LLM_02_Activation maximization (code).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_02_Activation maximization (code).md) |
| [Cá»±c Ä‘áº¡i hÃ³a Hoáº¡t hÃ³a qua Láº¥y máº«u Dá»¯ liá»‡u (Activation Maximization via Data Sampling)](aero_LLM_03_Activation maximization via data sampling.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_03_Activation maximization via data sampling.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Kiá»ƒm chá»©ng TÃ­nh láº·p láº¡i cá»§a Cá»±c Ä‘áº¡i hÃ³a Hoáº¡t hÃ³a (Reproducibility of Activation Maximization)](aero_LLM_04_CodeChallenge Reproducibility of activation maximization.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_04_CodeChallenge Reproducibility of activation maximization.md) |
| [Giáº£i pháº«u Ná»™i táº¡i MÃ´ hÃ¬nh báº±ng Hooks: Ká»¹ thuáº­t TrÃ­ch xuáº¥t Hoáº¡t hÃ³a (Extracting Activations via Hooks)](aero_LLM_05_Extracting activations using hooks.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_05_Extracting activations using hooks.md) |
| [Má»‘i tÆ°Æ¡ng quan giá»¯a Hooks vÃ  Hidden States: Giáº£i cáº¥u trÃºc Khá»‘i Transformer (Reconstructing Transformer Blocks)](aero_LLM_06_Relation between hooks and output.hidden_states.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_06_Relation between hooks and output.hidden_states.md) |
| [LÃ m rÃµ vá» Hidden States Táº§ng cuá»‘i: Vai trÃ² cá»§a LayerNorm (Clarification of Final Hidden States)](aero_LLM_07_Clarification of final hidden_states output.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_07_Clarification of final hidden_states output.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: TÃ­nh Chá»n lá»c Ngá»¯ phÃ¡p cá»§a NÆ¡-ron MLP (Pháº§n 1)](aero_LLM_08_CodeChallenge Grammar tuning in MLP neurons (part 1).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_08_CodeChallenge Grammar tuning in MLP neurons (part 1).md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: TÃ­nh Chá»n lá»c Ngá»¯ phÃ¡p cá»§a NÆ¡-ron MLP (Pháº§n 2)](aero_LLM_09_CodeChallenge Grammar tuning in MLP neurons (part 2).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_09_CodeChallenge Grammar tuning in MLP neurons (part 2).md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Sá»± Äiá»u cháº¿ Ngá»¯ cáº£nh trong Hoáº¡t hÃ³a MLP (Context-modulated Activation)](aero_LLM_10_CodeChallenge Context-modulated activation in MLP.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_10_CodeChallenge Context-modulated activation in MLP.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Äá»™ dÃ i Token vÃ  Äáº·c tÃ­nh Hoáº¡t hÃ³a (Pháº§n 1)](aero_LLM_11_CodeChallenge Activation histograms by token length (part 1).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_11_CodeChallenge Activation histograms by token length (part 1).md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Äá»™ dÃ i Token vÃ  Äáº·c tÃ­nh Hoáº¡t hÃ³a (Pháº§n 2)](aero_LLM_12_CodeChallenge Activation histograms by token length (part 2).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_12_CodeChallenge Activation histograms by token length (part 2).md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Äá»™ dÃ i Token vÃ  Äáº·c tÃ­nh Hoáº¡t hÃ³a (Pháº§n 3)](aero_LLM_13_CodeChallenge Activation histograms by token length (part 3).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_13_CodeChallenge Activation histograms by token length (part 3).md) |
| [Xá»­ lÃ½ Biá»ƒu diá»…n NÆ¡-ron cho cÃ¡c Tá»« Ä‘a Token (Multi-token Words)](aero_LLM_14_Dealing with multitoken word embeddings.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_14_Dealing with multitoken word embeddings.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: HÃ¬nh chiáº¿u MLP Äiá»u chá»‰nh theo Danh má»¥c (Pháº§n 1)](aero_LLM_15_CodeChallenge Category-tuned MLP projections (part 1).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_15_CodeChallenge Category-tuned MLP projections (part 1).md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: HÃ¬nh chiáº¿u MLP Äiá»u chá»‰nh theo Danh má»¥c (Pháº§n 2)](aero_LLM_16_CodeChallenge Category-tuned MLP projections (part 2).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_16_CodeChallenge Category-tuned MLP projections (part 2).md) |
| [Há»“i quy Logistic: LÃ½ thuyáº¿t vÃ  Triá»ƒn khai PhÃ¢n loáº¡i NÆ¡-ron](aero_LLM_17_Classification via logistic regression theory and code.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_17_Classification via logistic regression theory and code.md) |
| [Äá»‘i chiáº¿u Há»“i quy Logistic vÃ  Kiá»ƒm Ä‘á»‹nh T-test: Giáº£ Ä‘á»‹nh vÃ  á»¨ng dá»¥ng](aero_LLM_18_Logistic regression vs. t-test assumptions and applications.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_18_Logistic regression vs. t-test assumptions and applications.md) |
| ğŸ“Œ **[Äiá»u chá»‰nh Danh tá»« riÃªng trong GPT-2 Medium](aero_LLM_19_Proper noun tuning in GPT2-medium.md)** | [Xem bÃ i viáº¿t â†’](aero_LLM_19_Proper noun tuning in GPT2-medium.md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Äiá»u chá»‰nh Phá»§ Ä‘á»‹nh trong NÆ¡-ron MLP (Pháº§n 1)](aero_LLM_20_CodeChallenge Negation tuning in MLP neurons (part 1).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_20_CodeChallenge Negation tuning in MLP neurons (part 1).md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Äiá»u chá»‰nh Phá»§ Ä‘á»‹nh trong NÆ¡-ron MLP (Pháº§n 2)](aero_LLM_21_CodeChallenge Negation tuning in MLP neurons (part 2).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_21_CodeChallenge Negation tuning in MLP neurons (part 2).md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Äiá»u chá»‰nh Phá»§ Ä‘á»‹nh trong NÆ¡-ron MLP (Pháº§n 3)](aero_LLM_22_CodeChallenge Negation tuning in MLP neurons (part 3).md) | [Xem bÃ i viáº¿t â†’](aero_LLM_22_CodeChallenge Negation tuning in MLP neurons (part 3).md) |
| [Thá»­ thÃ¡ch Láº­p trÃ¬nh: Äiá»u chá»‰nh Phá»§ Ä‘á»‹nh trong NÆ¡-ron QVK (Attention)](aero_LLM_23_CodeChallenge Negation tuning in QVK neurons.md) | [Xem bÃ i viáº¿t â†’](aero_LLM_23_CodeChallenge Negation tuning in QVK neurons.md) |

---
## ğŸ¤ LiÃªn há»‡ & ÄÃ³ng gÃ³p
Dá»± Ã¡n Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **Pixibox**. Má»i Ä‘Ã³ng gÃ³p vá» ná»™i dung vÃ  mÃ£ nguá»“n Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n.

> *"Kiáº¿n thá»©c lÃ  Ä‘á»ƒ chia sáº». HÃ£y cÃ¹ng nhau xÃ¢y dá»±ng cá»™ng Ä‘á»“ng AI vá»¯ng máº¡nh!"* ğŸš€

*Cáº­p nháº­t tá»± Ä‘á»™ng bá»Ÿi Aero-Indexer - 2026*
<!-- Aero-Footer-End -->
