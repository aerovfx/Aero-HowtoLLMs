# üìÇ Index ‚Äî 12-Investigating-neurons-dimensions

[‚Üê Quay l·∫°i danh m·ª•c ch√≠nh](../README.md)

## üìÑ T√†i li·ªáu trong m·ª•c n√†y

- [C·ª±c ƒë·∫°i h√≥a Ho·∫°t h√≥a (Activation Maximization): C∆° s·ªü L√Ω thuy·∫øt v√† Nh·ªØng th√°ch th·ª©c trong LLM](aero_LLM_01_Activation maximization via gradient ascent (theory).md)
- [Tri·ªÉn khai C·ª±c ƒë·∫°i h√≥a Ho·∫°t h√≥a: T·ª´ Gradient Ascent ƒë·∫øn Gi·∫£i m√£ Token (Activation Maximization Implementation)](aero_LLM_02_Activation maximization (code).md)
- [C·ª±c ƒë·∫°i h√≥a Ho·∫°t h√≥a qua L·∫•y m·∫´u D·ªØ li·ªáu (Activation Maximization via Data Sampling)](aero_LLM_03_Activation maximization via data sampling.md)
- [Th·ª≠ th√°ch L·∫≠p tr√¨nh: Ki·ªÉm ch·ª©ng T√≠nh l·∫∑p l·∫°i c·ªßa C·ª±c ƒë·∫°i h√≥a Ho·∫°t h√≥a (Reproducibility of Activation Maximization)](aero_LLM_04_CodeChallenge Reproducibility of activation maximization.md)
- [Gi·∫£i ph·∫´u N·ªôi t·∫°i M√¥ h√¨nh b·∫±ng Hooks: K·ªπ thu·∫≠t Tr√≠ch xu·∫•t Ho·∫°t h√≥a (Extracting Activations via Hooks)](aero_LLM_05_Extracting activations using hooks.md)
- [M·ªëi t∆∞∆°ng quan gi·ªØa Hooks v√† Hidden States: Gi·∫£i c·∫•u tr√∫c Kh·ªëi Transformer (Reconstructing Transformer Blocks)](aero_LLM_06_Relation between hooks and output.hidden_states.md)
- [L√†m r√µ v·ªÅ Hidden States T·∫ßng cu·ªëi: Vai tr√≤ c·ªßa LayerNorm (Clarification of Final Hidden States)](aero_LLM_07_Clarification of final hidden_states output.md)
- [Th·ª≠ th√°ch L·∫≠p tr√¨nh: T√≠nh Ch·ªçn l·ªçc Ng·ªØ ph√°p c·ªßa N∆°-ron MLP (Ph·∫ßn 1)](aero_LLM_08_CodeChallenge Grammar tuning in MLP neurons (part 1).md)
- [Th·ª≠ th√°ch L·∫≠p tr√¨nh: T√≠nh Ch·ªçn l·ªçc Ng·ªØ ph√°p c·ªßa N∆°-ron MLP (Ph·∫ßn 2)](aero_LLM_09_CodeChallenge Grammar tuning in MLP neurons (part 2).md)
- [Th·ª≠ th√°ch L·∫≠p tr√¨nh: S·ª± ƒêi·ªÅu ch·∫ø Ng·ªØ c·∫£nh trong Ho·∫°t h√≥a MLP (Context-modulated Activation)](aero_LLM_10_CodeChallenge Context-modulated activation in MLP.md)
- [Th·ª≠ th√°ch L·∫≠p tr√¨nh: ƒê·ªô d√†i Token v√† ƒê·∫∑c t√≠nh Ho·∫°t h√≥a (Ph·∫ßn 1)](aero_LLM_11_CodeChallenge Activation histograms by token length (part 1).md)
- [Th·ª≠ th√°ch L·∫≠p tr√¨nh: ƒê·ªô d√†i Token v√† ƒê·∫∑c t√≠nh Ho·∫°t h√≥a (Ph·∫ßn 2)](aero_LLM_12_CodeChallenge Activation histograms by token length (part 2).md)
- [Th·ª≠ th√°ch L·∫≠p tr√¨nh: ƒê·ªô d√†i Token v√† ƒê·∫∑c t√≠nh Ho·∫°t h√≥a (Ph·∫ßn 3)](aero_LLM_13_CodeChallenge Activation histograms by token length (part 3).md)
- [X·ª≠ l√Ω Bi·ªÉu di·ªÖn N∆°-ron cho c√°c T·ª´ ƒëa Token (Multi-token Words)](aero_LLM_14_Dealing with multitoken word embeddings.md)
- [Th·ª≠ th√°ch L·∫≠p tr√¨nh: H√¨nh chi·∫øu MLP ƒêi·ªÅu ch·ªânh theo Danh m·ª•c (Ph·∫ßn 1)](aero_LLM_15_CodeChallenge Category-tuned MLP projections (part 1).md)
- [Th·ª≠ th√°ch L·∫≠p tr√¨nh: H√¨nh chi·∫øu MLP ƒêi·ªÅu ch·ªânh theo Danh m·ª•c (Ph·∫ßn 2)](aero_LLM_16_CodeChallenge Category-tuned MLP projections (part 2).md)
- [H·ªìi quy Logistic: L√Ω thuy·∫øt v√† Tri·ªÉn khai Ph√¢n lo·∫°i N∆°-ron](aero_LLM_17_Classification via logistic regression theory and code.md)
- [ƒê·ªëi chi·∫øu H·ªìi quy Logistic v√† Ki·ªÉm ƒë·ªãnh T-test: Gi·∫£ ƒë·ªãnh v√† ·ª®ng d·ª•ng](aero_LLM_18_Logistic regression vs. t-test assumptions and applications.md)
- [ƒêi·ªÅu ch·ªânh Danh t·ª´ ri√™ng trong GPT-2 Medium](aero_LLM_19_Proper noun tuning in GPT2-medium.md)
- [Th·ª≠ th√°ch L·∫≠p tr√¨nh: ƒêi·ªÅu ch·ªânh Ph·ªß ƒë·ªãnh trong N∆°-ron MLP (Ph·∫ßn 1)](aero_LLM_20_CodeChallenge Negation tuning in MLP neurons (part 1).md)
- [Th·ª≠ th√°ch L·∫≠p tr√¨nh: ƒêi·ªÅu ch·ªânh Ph·ªß ƒë·ªãnh trong N∆°-ron MLP (Ph·∫ßn 2)](aero_LLM_21_CodeChallenge Negation tuning in MLP neurons (part 2).md)
- [Th·ª≠ th√°ch L·∫≠p tr√¨nh: ƒêi·ªÅu ch·ªânh Ph·ªß ƒë·ªãnh trong N∆°-ron MLP (Ph·∫ßn 3)](aero_LLM_22_CodeChallenge Negation tuning in MLP neurons (part 3).md)
- [Th·ª≠ th√°ch L·∫≠p tr√¨nh: ƒêi·ªÅu ch·ªânh Ph·ªß ƒë·ªãnh trong N∆°-ron QVK (Attention)](aero_LLM_23_CodeChallenge Negation tuning in QVK neurons.md)

---
*T·ª± ƒë·ªông c·∫≠p nh·∫≠t b·ªüi Aero-Indexer*