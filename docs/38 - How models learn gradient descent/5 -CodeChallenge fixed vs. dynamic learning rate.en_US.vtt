WEBVTT

00:01.960 --> 00:07.880
So far, we've always been running gradient descent using a fixed learning rate.

00:07.880 --> 00:10.680
So that means that the learning rate was constant.

00:11.200 --> 00:18.400
Now of course, we did a couple of experiments where we systematically varied the learning rate, but

00:18.400 --> 00:24.520
that was changing the learning rate for different runs through the gradient descent for loop.

00:24.520 --> 00:27.240
So looping over all the training epochs.

00:27.480 --> 00:34.280
But within gradient descent, when going through that for loop, the learning rate was always the same.

00:34.840 --> 00:41.560
So the goal of this code challenge is to explore ways of changing the learning rate.

00:41.560 --> 00:44.920
So we are going to make the learning rate be dynamic.

00:44.960 --> 00:51.560
That means the learning rate is going to be different at each iteration through that for loop that goes

00:51.560 --> 00:53.280
over gradient descent.

00:53.640 --> 00:58.480
So in particular here is your mission for this code challenge.

00:58.600 --> 01:03.910
What you want to do is start from the code gradient descent in one dimension.

01:03.910 --> 01:09.390
So that was from the I think that was the first coding video in this section.

01:09.830 --> 01:12.430
And make a copy of this notebook.

01:12.430 --> 01:18.470
So you don't want to overwrite your the previous notebook, make a copy of this into a new file.

01:18.790 --> 01:25.390
And then you want to come up with a way to change the learning rate in the middle of gradient descent,

01:25.390 --> 01:30.230
so that during the learning algorithm, the learning rate is changing.

01:30.830 --> 01:35.550
Here I have provided four possibilities for ways to change the learning rate.

01:35.550 --> 01:38.870
You don't have to use all four of these, you can just pick one.

01:38.870 --> 01:40.670
Or maybe you can do two if you like.

01:40.830 --> 01:42.550
You don't have to do all of these.

01:43.030 --> 01:44.910
These are just for your inspiration.

01:44.950 --> 01:47.950
Now I am actually going to do two of these.

01:47.950 --> 01:49.270
I'm not going to tell you which two.

01:49.310 --> 01:51.070
Now I will explain that in the code.

01:51.590 --> 01:53.430
So pick one of these four.

01:53.470 --> 01:56.910
Or you know, if you think of your own way to change the learning rate, that's also okay.

01:57.270 --> 01:59.550
and implement this in the code.

01:59.910 --> 02:04.110
And then it's also useful to compare this against a fixed learning rate.

02:04.110 --> 02:08.670
So that can be basically just the same thing we did in this code file originally.

02:09.190 --> 02:14.710
Then you might want to spend some time thinking critically about how your choice of how the learning

02:14.710 --> 02:18.430
rate changes over the course of learning might fail.

02:18.430 --> 02:21.710
So what are the advantages and disadvantages of each of them?

02:22.070 --> 02:27.630
Now, I encourage you now to pause the video and switch to Python and start coding.

02:27.830 --> 02:33.670
When you're ready, come back to the video because not only am I going to show you my solution, I'm

02:33.670 --> 02:34.710
also going to.

02:35.150 --> 02:38.310
After I go through the code, I'm going to come back to the lecture.

02:38.350 --> 02:45.790
There's going to be more material about the advantages and disadvantages of different methods of changing

02:45.790 --> 02:47.390
the learning rate dynamically.

02:47.550 --> 02:48.030
All right.

02:48.070 --> 02:48.710
Good luck.

02:48.750 --> 02:52.150
I hope you enjoy this and I'll see you when you come back to the video.

02:53.350 --> 02:57.500
So we begin by importing numpy and matplotlib.

02:58.020 --> 03:00.820
Here I create the function and its derivative.

03:00.860 --> 03:06.100
This is exactly the same as several videos ago with the one dimensional function.

03:06.580 --> 03:08.380
Okay, so I did three.

03:08.380 --> 03:10.340
I took three different approaches here.

03:10.380 --> 03:14.540
The first one is gradient descent using a fixed learning rate.

03:14.580 --> 03:20.580
Now this is actually really no different from the code you have seen now several times before.

03:21.380 --> 03:22.900
A couple of minor changes.

03:22.900 --> 03:28.180
I decreased the the training epochs to 50 and all of this code here.

03:28.180 --> 03:31.220
This is all the this is the gradient descent algorithm in here.

03:31.340 --> 03:35.700
I just expanded it a little bit to add some comments here.

03:35.700 --> 03:37.820
So here we compute the gradient.

03:37.940 --> 03:44.820
Here we update the the parameter the estimate of the function minimum according to standard vanilla

03:44.820 --> 03:45.700
gradient descent.

03:45.700 --> 03:51.060
So the parameter equals itself minus the gradient times the learning rate.

03:51.500 --> 03:55.410
And now here I have this code line actually doesn't do anything.

03:55.450 --> 04:00.170
This is a this I specify the learning rate up here and then I just repeat it over here.

04:00.450 --> 04:06.770
The point of me including this here is just to set you up for what the code is going to look like in

04:06.770 --> 04:08.130
the next section.

04:08.330 --> 04:13.610
So in the future, when we get down here in the next section, I'm going to be modifying the learning

04:13.610 --> 04:19.450
rate on each step, each iteration through training in gradient descent.

04:19.450 --> 04:24.130
But for now, this is just here to prepare you for the future.

04:24.370 --> 04:24.570
Okay.

04:24.610 --> 04:26.850
And then here at the end we store all the parameters.

04:26.850 --> 04:33.410
You can see I'm calling this matrix of results model params fixed because the model the learning rate

04:33.410 --> 04:34.770
here is fixed.

04:35.050 --> 04:41.170
And yeah then we're storing at each iteration through training we're storing the estimate the local

04:41.170 --> 04:43.810
min the derivative and the learning rate.

04:44.370 --> 04:44.690
Okay.

04:44.730 --> 04:47.210
So let me run this cell here.

04:47.650 --> 04:52.800
And then we go to the next code cell where I use gradient descent using.

04:52.800 --> 04:55.560
I call this a gradient based learning rate.

04:55.720 --> 05:01.160
Now most of the code here is identical to the previous code that I just showed you.

05:01.400 --> 05:04.760
The only difference is well, I guess there's two differences.

05:04.760 --> 05:10.280
One is the variable name for storing the results of course is different, but the important difference

05:10.280 --> 05:12.800
is that I'm changing the learning rate.

05:12.800 --> 05:19.440
So now the learning rate equals itself times the gradient that I just computed.

05:19.440 --> 05:20.720
So times the derivative.

05:20.880 --> 05:24.360
So the learning rate is scaled by the derivative.

05:24.560 --> 05:26.720
And I take the absolute value here.

05:26.720 --> 05:32.280
That's because if this derivative happens to be negative we get a negative gradient here.

05:32.520 --> 05:37.160
Then the learning rate switches to be negative which means that it's going to start searching for.

05:37.640 --> 05:41.280
It's going to start implementing gradient ascent and not gradient descent.

05:41.280 --> 05:42.760
So that's that's wrong.

05:42.760 --> 05:47.680
So so we just multiply by the the magnitude of the gradient.

05:47.880 --> 05:50.280
Now why is this a sensible thing to do.

05:50.430 --> 05:52.070
And what is the effect of this?

05:52.310 --> 05:59.590
Well, the idea here is that when we are very far away from the minimum, the function minimum, the

05:59.590 --> 06:01.830
gradient is relatively large.

06:02.270 --> 06:07.310
So then the gradient is relatively large, which means that we are far away from where we need to be.

06:07.510 --> 06:10.990
So that means the learning rate is relatively larger.

06:11.510 --> 06:19.750
Conversely, the closer we get to the actual function minimum, the gradient gets closer and closer

06:19.750 --> 06:20.430
to zero.

06:20.550 --> 06:25.990
It might be negative or it might be positive, but the magnitude of the gradient is getting smaller

06:25.990 --> 06:26.550
and smaller.

06:26.550 --> 06:28.030
It's getting closer to zero.

06:28.310 --> 06:33.990
So that means that the effective learning rate that we use in gradient descent actually decreases.

06:33.990 --> 06:38.350
The learning rate is going to go towards zero as the gradient gets smaller.

06:38.630 --> 06:45.550
So that's a pretty useful concept in deep learning that the learning rate should be larger the further

06:45.550 --> 06:51.910
you are away from the final solution, and it should get smaller as you get closer to a good minimum.

06:51.950 --> 06:53.110
A good solution.

06:53.150 --> 06:56.830
We I'm going to talk a lot more about that in the future here.

06:56.830 --> 07:00.910
In this video I'm just introducing you to the basic concept of that.

07:01.150 --> 07:01.430
Okay.

07:01.470 --> 07:02.030
Very nice.

07:02.030 --> 07:04.870
So, uh, run this code, save those results.

07:04.870 --> 07:07.430
And then finally I'm using gradient descent.

07:07.470 --> 07:11.230
Dynamic gradient descent using a time based learning rate.

07:11.230 --> 07:12.310
So what does that mean.

07:12.790 --> 07:16.150
So here again is pretty much all the same code.

07:16.190 --> 07:18.910
I'm starting the learning rate at 0.1 in this case.

07:18.910 --> 07:22.790
Now I've removed all of the extra lines and comments.

07:22.790 --> 07:22.990
So.

07:22.990 --> 07:27.030
But otherwise this is the same lines of code that you've seen several times before.

07:27.230 --> 07:30.950
So we get the gradient and here we update the parameter.

07:31.110 --> 07:37.910
And now here I'm setting the learning rate to be the initially defined learning rate times this business

07:37.910 --> 07:38.150
here.

07:38.150 --> 07:39.470
So what is going on here.

07:39.470 --> 07:41.990
Well here I'm saying one minus.

07:41.990 --> 07:44.230
And then this is a a separate term here.

07:44.710 --> 07:50.980
So one minus the current training epoch divided by the total number of training epochs.

07:51.180 --> 07:59.820
So when when we first start the the training here I is zero or I is some, you know some small number.

08:00.300 --> 08:05.980
And this is going to be some, you know, some small number 01234 divided by 50.

08:06.020 --> 08:09.820
So this ends up being a very small number and we subtract that off of one.

08:09.940 --> 08:13.620
So this whole term here ends up being something very close to one.

08:13.740 --> 08:19.500
So at the beginning of learning the effective learning rate is very close to 0.1.

08:19.860 --> 08:26.340
And now what happens as we get later and later in learning as we move through learning, learning progresses.

08:26.500 --> 08:28.860
This looping index increases.

08:28.860 --> 08:32.220
We get higher and higher closer to the number 50.

08:32.260 --> 08:37.780
And that means that this ratio here gets closer and closer to one.

08:37.820 --> 08:37.980
Right.

08:38.020 --> 08:42.140
Because we're dividing the current index by the total number of training epochs.

08:42.340 --> 08:44.220
This gets close to one.

08:44.220 --> 08:45.530
And then we subtract that off.

08:45.530 --> 08:51.650
So that means that this quantity is getting closer to zero, which means that the effective learning

08:51.650 --> 08:55.810
rate is decreasing as the learning increases.

08:56.050 --> 09:03.850
So you can see that this method here adjusting the learning rate according to the time or training epoch.

09:04.130 --> 09:09.290
And this method up here of adjusting the learning rate according to the gradient.

09:09.690 --> 09:16.490
They both have a similar effect, which is to decrease the learning rate as learning progresses and

09:16.490 --> 09:18.410
the mechanism is slightly different.

09:18.810 --> 09:19.050
Okay.

09:19.090 --> 09:19.730
Very nice.

09:19.810 --> 09:20.170
Let's see.

09:20.210 --> 09:21.450
Run this code.

09:21.930 --> 09:24.730
And now we get to plot the results.

09:25.330 --> 09:27.730
And here you see the results appearing here.

09:28.050 --> 09:32.610
Okay so we have these three plots here showing the local minimum.

09:32.610 --> 09:39.050
So this is our estimate showing the derivative here and showing the learning rate over training epochs

09:39.050 --> 09:40.010
or iterations.

09:40.330 --> 09:45.530
And then blue is for the fixed learning rate you can see the learning rate doesn't change here.

09:45.530 --> 09:46.250
The blue line.

09:46.490 --> 09:51.250
And then orange is the gradient based learning rate and green is the time based learning rate.

09:51.770 --> 09:53.370
So what are we looking for here.

09:53.450 --> 10:00.170
Well we are looking for this to go to zero because we want the derivative to be very close to zero ideally

10:00.170 --> 10:01.130
exactly zero.

10:01.490 --> 10:05.970
So in this case it looks like the time based learning rate won the race.

10:05.970 --> 10:07.650
It got there the fastest.

10:07.770 --> 10:14.170
And in fact it looks like you know we for this particular case we could have stopped after ten training

10:14.210 --> 10:16.490
epochs with our time based learning rate.

10:17.130 --> 10:22.370
Similarly here with the looking at the actual function minimum it should be 0.5.

10:22.970 --> 10:25.130
You'll remember that from a couple videos ago.

10:25.130 --> 10:28.410
0.5 is the the theoretical value, the analytic value.

10:28.690 --> 10:35.410
And you see that not only does the time based learning rate get there first, it also gets it's also

10:35.450 --> 10:38.850
the most accurate even after 50 training iterations.

10:39.250 --> 10:44.520
Now the reason why this learning rate here is or sorry.

10:44.560 --> 10:50.800
The parameter here for the fixed learning rate starts negative is because we initialized all three of

10:50.800 --> 10:55.120
the experiments to have different random starting values.

10:55.120 --> 11:00.640
So in fact what I'm going to do now is rerun all the code in this entire notebook.

11:00.840 --> 11:05.520
And to do that you know, you don't need to go through every single thing and press Ctrl enter on the

11:05.520 --> 11:06.600
keyboard and so on.

11:06.640 --> 11:12.320
There's a keyboard shortcut to run the entire notebook, all of the code in the notebook, and you do

11:12.320 --> 11:16.360
that by on Windows and Linux, it's control and then F9.

11:16.360 --> 11:19.760
So you press the Ctrl key and then press F9.

11:19.880 --> 11:24.600
I don't know what it is offhand on a mac, but it's going to be something similar.

11:25.440 --> 11:31.480
You can find out actually by going clicking on runtime and you say run all this is the equivalent menu

11:31.480 --> 11:32.080
option.

11:32.600 --> 11:32.840
Okay.

11:32.880 --> 11:35.480
So anyway, I've run it again and again.

11:35.480 --> 11:40.750
We see that the starting locations are different for the three different experiments because they all

11:40.750 --> 11:42.830
start off being randomly selected.

11:43.070 --> 11:49.350
But in this case, it still seems like the time based learning rate algorithm is the best.

11:49.350 --> 11:52.630
It seems to get the most accurate result and the fastest.

11:53.270 --> 11:59.070
Now, there's a few potential issues with this experiment that we can explore, that you will explore

11:59.070 --> 12:01.950
when you go through these additional explorations.

12:02.070 --> 12:07.790
So I definitely encourage you to go through these four additional explorations here.

12:09.310 --> 12:16.110
What I want to do is spend a little bit of time summarizing what we've discovered, and building up

12:16.110 --> 12:21.150
some theory that we are going to get into more detail about later in the course.

12:21.790 --> 12:28.510
So possible ways to proportionate the learning rate or make the learning rate be dynamic over the course

12:28.510 --> 12:29.590
of the experiment.

12:29.950 --> 12:32.710
One which you saw is using the training epochs.

12:32.710 --> 12:38.380
So basically the more you go through learning, the smaller the learning rate becomes.

12:38.380 --> 12:39.340
This is a good method.

12:39.340 --> 12:40.180
It's often done.

12:40.180 --> 12:41.780
It's typically done in blocks.

12:41.780 --> 12:48.340
So not in every single learning rate, but let's say every you know or sorry, not on every single epoch

12:48.380 --> 12:54.500
the learning rate changes, but let's say every ten epochs or every 20 epochs, you would make the learning

12:54.500 --> 12:55.900
rate a little bit smaller.

12:56.580 --> 12:57.700
So this is a good method.

12:57.700 --> 12:59.060
It's pretty frequently done.

12:59.420 --> 13:03.900
A main disadvantage is that it's totally unrelated to the model performance.

13:04.060 --> 13:10.460
So the learning rate is changing, but not as a function of how the model is actually learning.

13:10.940 --> 13:16.780
So then there's another method which I showed you and that is setting or modulating the learning rate

13:16.780 --> 13:19.780
according to the derivative or the gradient.

13:20.100 --> 13:25.860
This is useful because it's adaptive to the problem, but it does require some additional parameters

13:25.860 --> 13:28.900
and sometimes it requires appropriate scaling.

13:29.660 --> 13:35.180
Simply multiplying the gradient by the learning rate by the gradient happen to work well.

13:35.180 --> 13:42.570
In this case you can imagine if the derivative were some large number like four or 10 or 100, then

13:42.770 --> 13:48.810
we could actually be possibly even increasing the learning rate above one instead of decreasing the

13:48.810 --> 13:49.530
learning rate.

13:49.530 --> 13:51.930
So it requires appropriate scaling.

13:52.530 --> 13:52.770
Okay.

13:52.810 --> 13:54.090
And then you can.

13:54.130 --> 13:57.690
So I haven't talked a whole lot about loss functions yet.

13:57.690 --> 14:04.370
But essentially the loss is the difference between what we know is the correct answer and what the model

14:04.370 --> 14:05.010
produces.

14:05.010 --> 14:08.370
This is something we learn about in supervised learning.

14:08.930 --> 14:15.250
So loss is also a useful way to modify the learning rate because it's adaptive to the problem.

14:15.410 --> 14:18.050
But this also requires some scaling.

14:18.290 --> 14:20.730
And then finally the current minimum value.

14:20.770 --> 14:26.370
This is actually it sounds initially like it might be a good idea because it's also adaptive to the

14:26.370 --> 14:27.610
model's performance.

14:27.610 --> 14:29.330
But there's just too many assumptions.

14:29.330 --> 14:32.370
And this tends not to be a viable solution.

14:32.530 --> 14:32.930
Okay.

14:32.970 --> 14:38.730
So I do want to say a few things about these first two points, because in fact, this is like industry

14:38.730 --> 14:45.450
standard ways to change the learning rate as a function of training and model performance.

14:45.650 --> 14:51.370
So this method here which I showed you how to implement this is called learning rate decay.

14:51.530 --> 14:55.930
And we're going to talk more about it in the section of the course called meta parameters.

14:56.290 --> 15:00.530
And this method here changing the learning rate according to the gradient.

15:00.690 --> 15:06.650
This is incorporated into optimization algorithms called Rmsprop and Adam.

15:06.770 --> 15:08.090
These are optimizers.

15:08.370 --> 15:13.330
And you'll also learn more about this method in the section meta parameters.

15:13.850 --> 15:18.890
So I hope you enjoyed this video and I hope you enjoyed working through the code challenge.

15:19.010 --> 15:25.930
The main point was to introduce you to the concept that the learning rate can change over time, and

15:25.930 --> 15:31.130
then it actually turns out to be a really powerful way to optimize deep learning.
